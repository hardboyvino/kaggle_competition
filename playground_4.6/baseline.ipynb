{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from lightgbm import LGBMClassifier\n",
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier, HistGradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "experiment_name = 'baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((76518, 38), (51012, 37))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "# original = pd.read_csv('original.csv', sep=';')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'Target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Change all values in the train but not in the original dataset to abitrary number (like -99999)\n",
    "# train.loc[train['Application mode'].isin([4, 9, 12, 26]), 'Application mode'] = -99999\n",
    "# train.loc[train['Course'].isin([39, 979]), 'Course'] = -99999\n",
    "# train.loc[train['Previous qualification'].isin([36, 37]), 'Previous qualification'] = -99999\n",
    "# train.loc[train[\"Mother's qualification\"].isin([7, 8, 15, 28]), \"Mother's qualification\"] = -99999\n",
    "# train.loc[train[\"Father's qualification\"].isin([15, 23, 24]), \"Father's qualification\"] = -99999\n",
    "# train.loc[train[\"Mother's occupation\"].isin([11, 38, 101, 103, 127, 163, 172]), \"Mother's occupation\"] = -99999\n",
    "# train.loc[train[\"Father's occupation\"].isin([12, 13, 19, 22, 39, 96, 148, 191]), \"Father's occupation\"] = -99999\n",
    "# train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['id', TARGET], axis=1)\n",
    "y = train[TARGET]\n",
    "\n",
    "n_splits = 3\n",
    "sk3 = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, ..., 1, 0, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(y)\n",
    "y_le = le.transform(y)\n",
    "y_le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipelines\n",
    "knn_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=50))\n",
    "])\n",
    "\n",
    "# ridge_pipeline = Pipeline([\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('nystroem', Nystroem(n_components=500, random_state=5)),\n",
    "#     ('ridge', Ridge())\n",
    "# ])\n",
    "\n",
    "linear_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ridge', LogisticRegression()),\n",
    "])\n",
    "\n",
    "# Manually set pipeline names\n",
    "knn_pipeline.name = 'KNN'\n",
    "# ridge_pipeline.name = 'Nystroem Ridge'\n",
    "linear_pipeline.name = 'LR Pipeline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    LogisticRegression(),\n",
    "    linear_pipeline,\n",
    "    LGBMClassifier(n_jobs=-1, random_state=5),\n",
    "    XGBClassifier(random_state=5),\n",
    "    RandomForestClassifier(random_state=5),\n",
    "    ExtraTreesClassifier(random_state=5),\n",
    "    HistGradientBoostingClassifier(random_state=5),\n",
    "    CatBoostClassifier(random_state=5, verbose=False, early_stopping_rounds=100),\n",
    "    knn_pipeline,\n",
    "    # ridge_pipeline,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(models, X, y, important_features, cv_split, experiment_name):\n",
    "    Model_compare = pd.DataFrame(columns=['Model Name', \n",
    "                                        'Model Parameters', \n",
    "                                        'Model Train Accuracy', \n",
    "                                        'Model Test Accuracy', \n",
    "                                        'Model Test Accuracy Std', \n",
    "                                        'Model Time'])\n",
    "    \n",
    "    def evaluate_model(alg, idx):\n",
    "        if hasattr(alg, 'name'):\n",
    "            model_name = alg.name\n",
    "        else:\n",
    "            model_name = alg.__class__.__name__\n",
    "        features = important_features.get(model_name, [])\n",
    "\n",
    "        # Check if the list of important features is empty\n",
    "        if len(features) == 0:\n",
    "            # If empty, return results with zero values\n",
    "            print(f'Skipping {model_name} due to no important features.')\n",
    "            return {\n",
    "                'Model Name': model_name,\n",
    "                'Model Parameters': str(alg.get_params()),\n",
    "                'Model Train Accuracy': 0,\n",
    "                'Model Test Accuracy': 0,\n",
    "                'Model Test Accuracy Std': 0,\n",
    "                'Model Time': \"0 min 0.00 sec\",\n",
    "            }\n",
    "        \n",
    "        cv_results = cross_validate(alg, \n",
    "                                    X[features], \n",
    "                                    y, cv=cv_split, \n",
    "                                    scoring='accuracy', \n",
    "                                    return_train_score=True, \n",
    "                                    n_jobs=-1)\n",
    "\n",
    "        # Time formatting\n",
    "        mean_fit_time = cv_results['fit_time'].mean()\n",
    "        minutes, seconds = divmod(mean_fit_time, 60)\n",
    "\n",
    "        # Results population\n",
    "        result = {\n",
    "            'Model Name': model_name,\n",
    "            'Model Parameters': str(alg.get_params()),\n",
    "            'Model Train Accuracy': cv_results['train_score'].mean(),\n",
    "            'Model Test Accuracy': cv_results['test_score'].mean(),\n",
    "            'Model Test Accuracy Std': cv_results['test_score'].std(),\n",
    "            'Model Time': f\"{int(minutes)} min {seconds:.2f} sec\",\n",
    "        }\n",
    "\n",
    "        print(f'Done with {model_name}.')\n",
    "        return result\n",
    "\n",
    "    results_list = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=50) as executor:\n",
    "        futures = [executor.submit(evaluate_model, alg, idx) for idx, alg in enumerate(tqdm(models, desc='Models'))]\n",
    "        for future in tqdm(futures, total=len(futures), desc='Progress'):\n",
    "            result = future.result()\n",
    "            results_list.append(result)\n",
    "\n",
    "    model_compare = pd.DataFrame(results_list)\n",
    "\n",
    "    model_compare.sort_values(by=['Model Test Accuracy'], ascending=False, inplace=True)\n",
    "    model_compare.to_csv(f'{experiment_name}_results.csv', index=False)\n",
    "\n",
    "    return model_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_features = {}\n",
    "\n",
    "for model in models:\n",
    "    if hasattr(model, 'name'):\n",
    "        model_name = model.name\n",
    "    else:\n",
    "        model_name = model.__class__.__name__\n",
    "\n",
    "    baseline_features[model_name] = list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2764d98352ac4ea39cdbbe576543f4ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Models:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "896afe9287a442638d0231666d9a29d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with LogisticRegression.\n",
      "Done with ExtraTreesClassifier.\n",
      "Done with LR Pipeline.\n",
      "Done with XGBClassifier.\n",
      "Done with HistGradientBoostingClassifier.\n",
      "Done with LGBMClassifier.\n",
      "Done with RandomForestClassifier.\n",
      "Done with KNN.\n",
      "Done with CatBoostClassifier.\n",
      "CPU times: total: 719 ms\n",
      "Wall time: 3min 23s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Model Parameters</th>\n",
       "      <th>Model Train Accuracy</th>\n",
       "      <th>Model Test Accuracy</th>\n",
       "      <th>Model Test Accuracy Std</th>\n",
       "      <th>Model Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>0.854564</td>\n",
       "      <td>0.830876</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>0 min 9.51 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>{'verbose': False, 'random_state': 5, 'early_s...</td>\n",
       "      <td>0.867861</td>\n",
       "      <td>0.830654</td>\n",
       "      <td>0.001682</td>\n",
       "      <td>1 min 24.56 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>{'categorical_features': None, 'early_stopping...</td>\n",
       "      <td>0.856040</td>\n",
       "      <td>0.830602</td>\n",
       "      <td>0.002196</td>\n",
       "      <td>0 min 15.66 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>{'objective': 'binary:logistic', 'use_label_en...</td>\n",
       "      <td>0.888974</td>\n",
       "      <td>0.829504</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>1 min 36.04 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.826132</td>\n",
       "      <td>0.001643</td>\n",
       "      <td>0 min 30.78 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.823100</td>\n",
       "      <td>0.001469</td>\n",
       "      <td>0 min 34.61 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR Pipeline</td>\n",
       "      <td>{'memory': None, 'steps': [('scaler', Standard...</td>\n",
       "      <td>0.817219</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0 min 2.14 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNN</td>\n",
       "      <td>{'memory': None, 'steps': [('scaler', Standard...</td>\n",
       "      <td>0.798655</td>\n",
       "      <td>0.792389</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0 min 0.21 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>0.742146</td>\n",
       "      <td>0.742178</td>\n",
       "      <td>0.008458</td>\n",
       "      <td>0 min 5.04 sec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model Name  \\\n",
       "2                  LGBMClassifier   \n",
       "7              CatBoostClassifier   \n",
       "6  HistGradientBoostingClassifier   \n",
       "3                   XGBClassifier   \n",
       "4          RandomForestClassifier   \n",
       "5            ExtraTreesClassifier   \n",
       "1                     LR Pipeline   \n",
       "8                             KNN   \n",
       "0              LogisticRegression   \n",
       "\n",
       "                                    Model Parameters  Model Train Accuracy  \\\n",
       "2  {'boosting_type': 'gbdt', 'class_weight': None...              0.854564   \n",
       "7  {'verbose': False, 'random_state': 5, 'early_s...              0.867861   \n",
       "6  {'categorical_features': None, 'early_stopping...              0.856040   \n",
       "3  {'objective': 'binary:logistic', 'use_label_en...              0.888974   \n",
       "4  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...              0.999987   \n",
       "5  {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...              1.000000   \n",
       "1  {'memory': None, 'steps': [('scaler', Standard...              0.817219   \n",
       "8  {'memory': None, 'steps': [('scaler', Standard...              0.798655   \n",
       "0  {'C': 1.0, 'class_weight': None, 'dual': False...              0.742146   \n",
       "\n",
       "   Model Test Accuracy  Model Test Accuracy Std       Model Time  \n",
       "2             0.830876                 0.002428   0 min 9.51 sec  \n",
       "7             0.830654                 0.001682  1 min 24.56 sec  \n",
       "6             0.830602                 0.002196  0 min 15.66 sec  \n",
       "3             0.829504                 0.001538  1 min 36.04 sec  \n",
       "4             0.826132                 0.001643  0 min 30.78 sec  \n",
       "5             0.823100                 0.001469  0 min 34.61 sec  \n",
       "1             0.816514                 0.001248   0 min 2.14 sec  \n",
       "8             0.792389                 0.001090   0 min 0.21 sec  \n",
       "0             0.742178                 0.008458   0 min 5.04 sec  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "baseline_models = evaluate_models(models, X, y_le, baseline_features, sk3, f'{experiment_name}')\n",
    "baseline_models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
