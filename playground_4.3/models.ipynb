{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.feature_selection import RFECV, SelectKBest, f_classif\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from pprint import pprint\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "experiment_name = 'multi-models_with_original_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "original = pd.read_csv('Fault.csv', delimiter='\\t')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19219, 35), (1940, 34), (12814, 28))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, original.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_Minimum</th>\n",
       "      <th>X_Maximum</th>\n",
       "      <th>Y_Minimum</th>\n",
       "      <th>Y_Maximum</th>\n",
       "      <th>Pixels_Areas</th>\n",
       "      <th>X_Perimeter</th>\n",
       "      <th>Y_Perimeter</th>\n",
       "      <th>Sum_of_Luminosity</th>\n",
       "      <th>Minimum_of_Luminosity</th>\n",
       "      <th>Maximum_of_Luminosity</th>\n",
       "      <th>Length_of_Conveyer</th>\n",
       "      <th>TypeOfSteel_A300</th>\n",
       "      <th>TypeOfSteel_A400</th>\n",
       "      <th>Steel_Plate_Thickness</th>\n",
       "      <th>Edges_Index</th>\n",
       "      <th>Empty_Index</th>\n",
       "      <th>Square_Index</th>\n",
       "      <th>Outside_X_Index</th>\n",
       "      <th>Edges_X_Index</th>\n",
       "      <th>Edges_Y_Index</th>\n",
       "      <th>Outside_Global_Index</th>\n",
       "      <th>LogOfAreas</th>\n",
       "      <th>Log_X_Index</th>\n",
       "      <th>Log_Y_Index</th>\n",
       "      <th>Orientation_Index</th>\n",
       "      <th>Luminosity_Index</th>\n",
       "      <th>SigmoidOfAreas</th>\n",
       "      <th>Pastry</th>\n",
       "      <th>Z_Scratch</th>\n",
       "      <th>K_Scatch</th>\n",
       "      <th>Stains</th>\n",
       "      <th>Dirtiness</th>\n",
       "      <th>Bumps</th>\n",
       "      <th>Other_Faults</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>584</td>\n",
       "      <td>590</td>\n",
       "      <td>909972</td>\n",
       "      <td>909977</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2274</td>\n",
       "      <td>113</td>\n",
       "      <td>140</td>\n",
       "      <td>1358</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.7393</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2041</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>0.6990</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>-0.0104</td>\n",
       "      <td>0.1417</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>808</td>\n",
       "      <td>816</td>\n",
       "      <td>728350</td>\n",
       "      <td>728372</td>\n",
       "      <td>433</td>\n",
       "      <td>20</td>\n",
       "      <td>54</td>\n",
       "      <td>44478</td>\n",
       "      <td>70</td>\n",
       "      <td>111</td>\n",
       "      <td>1687</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0.7772</td>\n",
       "      <td>0.2878</td>\n",
       "      <td>0.2581</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6365</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>1.7324</td>\n",
       "      <td>0.7419</td>\n",
       "      <td>-0.2997</td>\n",
       "      <td>0.9491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>192</td>\n",
       "      <td>2212076</td>\n",
       "      <td>2212144</td>\n",
       "      <td>11388</td>\n",
       "      <td>705</td>\n",
       "      <td>420</td>\n",
       "      <td>1311391</td>\n",
       "      <td>29</td>\n",
       "      <td>141</td>\n",
       "      <td>1400</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.5282</td>\n",
       "      <td>0.9895</td>\n",
       "      <td>0.1077</td>\n",
       "      <td>0.2363</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0564</td>\n",
       "      <td>2.1790</td>\n",
       "      <td>2.2095</td>\n",
       "      <td>-0.0105</td>\n",
       "      <td>-0.0944</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>781</td>\n",
       "      <td>789</td>\n",
       "      <td>3353146</td>\n",
       "      <td>3353173</td>\n",
       "      <td>210</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>3202</td>\n",
       "      <td>114</td>\n",
       "      <td>134</td>\n",
       "      <td>1387</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.7202</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.9310</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.3222</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>1.4314</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>-0.0402</td>\n",
       "      <td>0.4025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1540</td>\n",
       "      <td>1560</td>\n",
       "      <td>618457</td>\n",
       "      <td>618502</td>\n",
       "      <td>521</td>\n",
       "      <td>72</td>\n",
       "      <td>67</td>\n",
       "      <td>48231</td>\n",
       "      <td>82</td>\n",
       "      <td>111</td>\n",
       "      <td>1692</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>0.1211</td>\n",
       "      <td>0.5347</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.9861</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.7694</td>\n",
       "      <td>1.4150</td>\n",
       "      <td>1.8808</td>\n",
       "      <td>0.9158</td>\n",
       "      <td>-0.2455</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X_Minimum  X_Maximum  Y_Minimum  Y_Maximum  Pixels_Areas  X_Perimeter  \\\n",
       "0        584        590     909972     909977            16            8   \n",
       "1        808        816     728350     728372           433           20   \n",
       "2         39        192    2212076    2212144         11388          705   \n",
       "3        781        789    3353146    3353173           210           16   \n",
       "4       1540       1560     618457     618502           521           72   \n",
       "\n",
       "   Y_Perimeter  Sum_of_Luminosity  Minimum_of_Luminosity  \\\n",
       "0            5               2274                    113   \n",
       "1           54              44478                     70   \n",
       "2          420            1311391                     29   \n",
       "3           29               3202                    114   \n",
       "4           67              48231                     82   \n",
       "\n",
       "   Maximum_of_Luminosity  Length_of_Conveyer  TypeOfSteel_A300  \\\n",
       "0                    140                1358                 0   \n",
       "1                    111                1687                 1   \n",
       "2                    141                1400                 0   \n",
       "3                    134                1387                 0   \n",
       "4                    111                1692                 0   \n",
       "\n",
       "   TypeOfSteel_A400  Steel_Plate_Thickness  Edges_Index  Empty_Index  \\\n",
       "0                 1                     50       0.7393       0.4000   \n",
       "1                 0                     80       0.7772       0.2878   \n",
       "2                 1                     40       0.0557       0.5282   \n",
       "3                 1                     40       0.7202       0.3333   \n",
       "4                 1                    300       0.1211       0.5347   \n",
       "\n",
       "   Square_Index  Outside_X_Index  Edges_X_Index  Edges_Y_Index  \\\n",
       "0        0.5000           0.0059         1.0000         1.0000   \n",
       "1        0.2581           0.0044         0.2500         1.0000   \n",
       "2        0.9895           0.1077         0.2363         0.3857   \n",
       "3        0.3333           0.0044         0.3750         0.9310   \n",
       "4        0.0842           0.0192         0.2105         0.9861   \n",
       "\n",
       "   Outside_Global_Index  LogOfAreas  Log_X_Index  Log_Y_Index  \\\n",
       "0                   0.0      1.2041       0.9031       0.6990   \n",
       "1                   1.0      2.6365       0.7782       1.7324   \n",
       "2                   0.0      4.0564       2.1790       2.2095   \n",
       "3                   1.0      2.3222       0.7782       1.4314   \n",
       "4                   1.0      2.7694       1.4150       1.8808   \n",
       "\n",
       "   Orientation_Index  Luminosity_Index  SigmoidOfAreas  Pastry  Z_Scratch  \\\n",
       "0            -0.5000           -0.0104          0.1417       0          0   \n",
       "1             0.7419           -0.2997          0.9491       0          0   \n",
       "2            -0.0105           -0.0944          1.0000       0          0   \n",
       "3             0.6667           -0.0402          0.4025       0          0   \n",
       "4             0.9158           -0.2455          0.9998       0          0   \n",
       "\n",
       "   K_Scatch  Stains  Dirtiness  Bumps  Other_Faults  \n",
       "0         0       1          0      0             0  \n",
       "1         0       0          0      0             1  \n",
       "2         1       0          0      0             0  \n",
       "3         1       0          0      0             0  \n",
       "4         0       0          0      0             1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove id column and check the dataset\n",
    "train.drop('id', axis=1, inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>X_Minimum</th>\n",
       "      <th>X_Maximum</th>\n",
       "      <th>Y_Minimum</th>\n",
       "      <th>Y_Maximum</th>\n",
       "      <th>Pixels_Areas</th>\n",
       "      <th>X_Perimeter</th>\n",
       "      <th>Y_Perimeter</th>\n",
       "      <th>Sum_of_Luminosity</th>\n",
       "      <th>Minimum_of_Luminosity</th>\n",
       "      <th>Maximum_of_Luminosity</th>\n",
       "      <th>Length_of_Conveyer</th>\n",
       "      <th>TypeOfSteel_A300</th>\n",
       "      <th>TypeOfSteel_A400</th>\n",
       "      <th>Steel_Plate_Thickness</th>\n",
       "      <th>Edges_Index</th>\n",
       "      <th>Empty_Index</th>\n",
       "      <th>Square_Index</th>\n",
       "      <th>Outside_X_Index</th>\n",
       "      <th>Edges_X_Index</th>\n",
       "      <th>Edges_Y_Index</th>\n",
       "      <th>Outside_Global_Index</th>\n",
       "      <th>LogOfAreas</th>\n",
       "      <th>Log_X_Index</th>\n",
       "      <th>Log_Y_Index</th>\n",
       "      <th>Orientation_Index</th>\n",
       "      <th>Luminosity_Index</th>\n",
       "      <th>SigmoidOfAreas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19219</td>\n",
       "      <td>1015</td>\n",
       "      <td>1033</td>\n",
       "      <td>3826564</td>\n",
       "      <td>3826588</td>\n",
       "      <td>659</td>\n",
       "      <td>23</td>\n",
       "      <td>46</td>\n",
       "      <td>62357</td>\n",
       "      <td>67</td>\n",
       "      <td>127</td>\n",
       "      <td>1656</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0.3877</td>\n",
       "      <td>0.4896</td>\n",
       "      <td>0.3273</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.5652</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.8410</td>\n",
       "      <td>1.1139</td>\n",
       "      <td>1.6628</td>\n",
       "      <td>0.6727</td>\n",
       "      <td>-0.2261</td>\n",
       "      <td>0.9172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19220</td>\n",
       "      <td>1257</td>\n",
       "      <td>1271</td>\n",
       "      <td>419960</td>\n",
       "      <td>419973</td>\n",
       "      <td>370</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>39293</td>\n",
       "      <td>92</td>\n",
       "      <td>132</td>\n",
       "      <td>1354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.1629</td>\n",
       "      <td>0.4136</td>\n",
       "      <td>0.0938</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5682</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>1.4472</td>\n",
       "      <td>0.9063</td>\n",
       "      <td>-0.1453</td>\n",
       "      <td>0.9104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19221</td>\n",
       "      <td>1358</td>\n",
       "      <td>1372</td>\n",
       "      <td>117715</td>\n",
       "      <td>117724</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>32</td>\n",
       "      <td>29386</td>\n",
       "      <td>101</td>\n",
       "      <td>134</td>\n",
       "      <td>1360</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0609</td>\n",
       "      <td>0.6234</td>\n",
       "      <td>0.4762</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4609</td>\n",
       "      <td>1.3222</td>\n",
       "      <td>1.3222</td>\n",
       "      <td>-0.5238</td>\n",
       "      <td>-0.0435</td>\n",
       "      <td>0.6514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19222</td>\n",
       "      <td>158</td>\n",
       "      <td>168</td>\n",
       "      <td>232415</td>\n",
       "      <td>232440</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>8586</td>\n",
       "      <td>107</td>\n",
       "      <td>140</td>\n",
       "      <td>1690</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4439</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.8182</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.9031</td>\n",
       "      <td>0.6990</td>\n",
       "      <td>1.0414</td>\n",
       "      <td>0.1818</td>\n",
       "      <td>-0.0738</td>\n",
       "      <td>0.2051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19223</td>\n",
       "      <td>559</td>\n",
       "      <td>592</td>\n",
       "      <td>544375</td>\n",
       "      <td>544389</td>\n",
       "      <td>140</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>15524</td>\n",
       "      <td>103</td>\n",
       "      <td>134</td>\n",
       "      <td>1688</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0.8191</td>\n",
       "      <td>0.2619</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.8421</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1461</td>\n",
       "      <td>1.3222</td>\n",
       "      <td>1.1461</td>\n",
       "      <td>-0.5714</td>\n",
       "      <td>-0.0894</td>\n",
       "      <td>0.4170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  X_Minimum  X_Maximum  Y_Minimum  Y_Maximum  Pixels_Areas  \\\n",
       "0  19219       1015       1033    3826564    3826588           659   \n",
       "1  19220       1257       1271     419960     419973           370   \n",
       "2  19221       1358       1372     117715     117724           289   \n",
       "3  19222        158        168     232415     232440            80   \n",
       "4  19223        559        592     544375     544389           140   \n",
       "\n",
       "   X_Perimeter  Y_Perimeter  Sum_of_Luminosity  Minimum_of_Luminosity  \\\n",
       "0           23           46              62357                     67   \n",
       "1           26           28              39293                     92   \n",
       "2           36           32              29386                    101   \n",
       "3           10           11               8586                    107   \n",
       "4           19           15              15524                    103   \n",
       "\n",
       "   Maximum_of_Luminosity  Length_of_Conveyer  TypeOfSteel_A300  \\\n",
       "0                    127                1656                 0   \n",
       "1                    132                1354                 0   \n",
       "2                    134                1360                 0   \n",
       "3                    140                1690                 1   \n",
       "4                    134                1688                 1   \n",
       "\n",
       "   TypeOfSteel_A400  Steel_Plate_Thickness  Edges_Index  Empty_Index  \\\n",
       "0                 1                    150       0.3877       0.4896   \n",
       "1                 1                     40       0.1629       0.4136   \n",
       "2                 1                     40       0.0609       0.6234   \n",
       "3                 0                    100       0.4439       0.3333   \n",
       "4                 0                     60       0.8191       0.2619   \n",
       "\n",
       "   Square_Index  Outside_X_Index  Edges_X_Index  Edges_Y_Index  \\\n",
       "0        0.3273           0.0095         0.5652         1.0000   \n",
       "1        0.0938           0.0047         0.2414         1.0000   \n",
       "2        0.4762           0.0155         0.6000         0.7500   \n",
       "3        0.8182           0.0037         0.8000         1.0000   \n",
       "4        0.4286           0.0158         0.8421         0.5333   \n",
       "\n",
       "   Outside_Global_Index  LogOfAreas  Log_X_Index  Log_Y_Index  \\\n",
       "0                   1.0      2.8410       1.1139       1.6628   \n",
       "1                   1.0      2.5682       0.9031       1.4472   \n",
       "2                   0.0      2.4609       1.3222       1.3222   \n",
       "3                   1.0      1.9031       0.6990       1.0414   \n",
       "4                   0.0      2.1461       1.3222       1.1461   \n",
       "\n",
       "   Orientation_Index  Luminosity_Index  SigmoidOfAreas  \n",
       "0             0.6727           -0.2261          0.9172  \n",
       "1             0.9063           -0.1453          0.9104  \n",
       "2            -0.5238           -0.0435          0.6514  \n",
       "3             0.1818           -0.0738          0.2051  \n",
       "4            -0.5714           -0.0894          0.4170  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset_cols = list(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n",
    "                 'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n",
    "                 'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n",
    "                 'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n",
    "                 'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n",
    "                 'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n",
    "                 'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n",
    "                 'SigmoidOfAreas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_Minimum</th>\n",
       "      <th>X_Maximum</th>\n",
       "      <th>Y_Minimum</th>\n",
       "      <th>Y_Maximum</th>\n",
       "      <th>Pixels_Areas</th>\n",
       "      <th>X_Perimeter</th>\n",
       "      <th>Y_Perimeter</th>\n",
       "      <th>Sum_of_Luminosity</th>\n",
       "      <th>Minimum_of_Luminosity</th>\n",
       "      <th>Maximum_of_Luminosity</th>\n",
       "      <th>Length_of_Conveyer</th>\n",
       "      <th>TypeOfSteel_A300</th>\n",
       "      <th>TypeOfSteel_A400</th>\n",
       "      <th>Steel_Plate_Thickness</th>\n",
       "      <th>Edges_Index</th>\n",
       "      <th>Empty_Index</th>\n",
       "      <th>Square_Index</th>\n",
       "      <th>Outside_X_Index</th>\n",
       "      <th>Edges_X_Index</th>\n",
       "      <th>Edges_Y_Index</th>\n",
       "      <th>Outside_Global_Index</th>\n",
       "      <th>LogOfAreas</th>\n",
       "      <th>Log_X_Index</th>\n",
       "      <th>Log_Y_Index</th>\n",
       "      <th>Orientation_Index</th>\n",
       "      <th>Luminosity_Index</th>\n",
       "      <th>SigmoidOfAreas</th>\n",
       "      <th>Pastry</th>\n",
       "      <th>Z_Scratch</th>\n",
       "      <th>K_Scatch</th>\n",
       "      <th>Stains</th>\n",
       "      <th>Dirtiness</th>\n",
       "      <th>Bumps</th>\n",
       "      <th>Other_Faults</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>645</td>\n",
       "      <td>651</td>\n",
       "      <td>2538079</td>\n",
       "      <td>2538108</td>\n",
       "      <td>108</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>11397</td>\n",
       "      <td>84</td>\n",
       "      <td>123</td>\n",
       "      <td>1687</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0.7647</td>\n",
       "      <td>0.3793</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.9667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0334</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>1.4624</td>\n",
       "      <td>0.7931</td>\n",
       "      <td>-0.1756</td>\n",
       "      <td>0.2984</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>829</td>\n",
       "      <td>835</td>\n",
       "      <td>1553913</td>\n",
       "      <td>1553931</td>\n",
       "      <td>71</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>7972</td>\n",
       "      <td>99</td>\n",
       "      <td>125</td>\n",
       "      <td>1623</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.3426</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8513</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>1.2553</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>-0.1228</td>\n",
       "      <td>0.2150</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>853</td>\n",
       "      <td>860</td>\n",
       "      <td>369370</td>\n",
       "      <td>369415</td>\n",
       "      <td>176</td>\n",
       "      <td>13</td>\n",
       "      <td>45</td>\n",
       "      <td>18996</td>\n",
       "      <td>99</td>\n",
       "      <td>126</td>\n",
       "      <td>1353</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>290</td>\n",
       "      <td>0.7287</td>\n",
       "      <td>0.4413</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.5385</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2455</td>\n",
       "      <td>0.8451</td>\n",
       "      <td>1.6532</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>-0.1568</td>\n",
       "      <td>0.5212</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1289</td>\n",
       "      <td>1306</td>\n",
       "      <td>498078</td>\n",
       "      <td>498335</td>\n",
       "      <td>2409</td>\n",
       "      <td>60</td>\n",
       "      <td>260</td>\n",
       "      <td>246930</td>\n",
       "      <td>37</td>\n",
       "      <td>126</td>\n",
       "      <td>1353</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>185</td>\n",
       "      <td>0.0695</td>\n",
       "      <td>0.4486</td>\n",
       "      <td>0.0662</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.2833</td>\n",
       "      <td>0.9885</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.3818</td>\n",
       "      <td>1.2305</td>\n",
       "      <td>2.4099</td>\n",
       "      <td>0.9338</td>\n",
       "      <td>-0.1992</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>430</td>\n",
       "      <td>441</td>\n",
       "      <td>100250</td>\n",
       "      <td>100337</td>\n",
       "      <td>630</td>\n",
       "      <td>20</td>\n",
       "      <td>87</td>\n",
       "      <td>62357</td>\n",
       "      <td>64</td>\n",
       "      <td>127</td>\n",
       "      <td>1387</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.6200</td>\n",
       "      <td>0.3417</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.7993</td>\n",
       "      <td>1.0414</td>\n",
       "      <td>1.9395</td>\n",
       "      <td>0.8736</td>\n",
       "      <td>-0.2267</td>\n",
       "      <td>0.9874</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X_Minimum  X_Maximum  Y_Minimum  Y_Maximum  Pixels_Areas  X_Perimeter  \\\n",
       "0        645        651    2538079    2538108           108           10   \n",
       "1        829        835    1553913    1553931            71            8   \n",
       "2        853        860     369370     369415           176           13   \n",
       "3       1289       1306     498078     498335          2409           60   \n",
       "4        430        441     100250     100337           630           20   \n",
       "\n",
       "   Y_Perimeter  Sum_of_Luminosity  Minimum_of_Luminosity  \\\n",
       "0           30              11397                     84   \n",
       "1           19               7972                     99   \n",
       "2           45              18996                     99   \n",
       "3          260             246930                     37   \n",
       "4           87              62357                     64   \n",
       "\n",
       "   Maximum_of_Luminosity  Length_of_Conveyer  TypeOfSteel_A300  \\\n",
       "0                    123                1687                 1   \n",
       "1                    125                1623                 1   \n",
       "2                    126                1353                 0   \n",
       "3                    126                1353                 0   \n",
       "4                    127                1387                 0   \n",
       "\n",
       "   TypeOfSteel_A400  Steel_Plate_Thickness  Edges_Index  Empty_Index  \\\n",
       "0                 0                     80       0.7647       0.3793   \n",
       "1                 0                    100       0.9710       0.3426   \n",
       "2                 1                    290       0.7287       0.4413   \n",
       "3                 1                    185       0.0695       0.4486   \n",
       "4                 1                     40       0.6200       0.3417   \n",
       "\n",
       "   Square_Index  Outside_X_Index  Edges_X_Index  Edges_Y_Index  \\\n",
       "0        0.2069           0.0036         0.6000         0.9667   \n",
       "1        0.3333           0.0037         0.7500         0.9474   \n",
       "2        0.1556           0.0052         0.5385         1.0000   \n",
       "3        0.0662           0.0126         0.2833         0.9885   \n",
       "4        0.1264           0.0079         0.5500         1.0000   \n",
       "\n",
       "   Outside_Global_Index  LogOfAreas  Log_X_Index  Log_Y_Index  \\\n",
       "0                   1.0      2.0334       0.7782       1.4624   \n",
       "1                   1.0      1.8513       0.7782       1.2553   \n",
       "2                   1.0      2.2455       0.8451       1.6532   \n",
       "3                   1.0      3.3818       1.2305       2.4099   \n",
       "4                   1.0      2.7993       1.0414       1.9395   \n",
       "\n",
       "   Orientation_Index  Luminosity_Index  SigmoidOfAreas  Pastry  Z_Scratch  \\\n",
       "0             0.7931           -0.1756          0.2984       1          0   \n",
       "1             0.6667           -0.1228          0.2150       1          0   \n",
       "2             0.8444           -0.1568          0.5212       1          0   \n",
       "3             0.9338           -0.1992          1.0000       1          0   \n",
       "4             0.8736           -0.2267          0.9874       1          0   \n",
       "\n",
       "   K_Scatch  Stains  Dirtiness  Bumps  Other_Faults  \n",
       "0         0       0          0      0             0  \n",
       "1         0       0          0      0             0  \n",
       "2         0       0          0      0             0  \n",
       "3         0       0          0      0             0  \n",
       "4         0       0          0      0             0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original.columns = original_dataset_cols\n",
    "original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat the train and original dataset\n",
    "combined_df = pd.concat([train, original], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Got function from https://www.kaggle.com/code/thomasmeiner/ps4e3-eda-feature-engineering-model\n",
    "\n",
    "def reformat_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    target_cols = [\n",
    "        \"Pastry\", #4\n",
    "        \"Z_Scratch\", #6\n",
    "        \"K_Scatch\", #2\n",
    "        \"Stains\", #5\n",
    "        \"Dirtiness\", #1\n",
    "        \"Bumps\", #0\n",
    "        \"Other_Faults\", #3\n",
    "    ]\n",
    "    non_target_cols = df.drop(target_cols, axis=1).columns.to_list()\n",
    "    \n",
    "    binary_dfs = []\n",
    "    \n",
    "    for col in target_cols:\n",
    "        temp_df = df.loc[:, non_target_cols + [col]]\n",
    "        temp_df = temp_df.loc[temp_df[col] == 1].copy() # keep positives only\n",
    "        temp_df[col] = col # target value is class name now\n",
    "        temp_df = temp_df.rename(columns={col: \"target\"}) # make target col name uniform for final concat\n",
    "        binary_dfs.append(temp_df)\n",
    "        \n",
    "    reformatted_df = pd.concat(binary_dfs)\n",
    "    return reformatted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reformat_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "#     target_cols = [\n",
    "#         \"Pastry\",\n",
    "#         \"Z_Scratch\",\n",
    "#         \"K_Scatch\",\n",
    "#         \"Stains\",\n",
    "#         \"Dirtiness\",\n",
    "#         \"Bumps\",\n",
    "#         \"Other_Faults\",\n",
    "#     ]\n",
    "#     non_target_cols = df.drop(target_cols, axis=1).columns.to_list()\n",
    "\n",
    "#     binary_dfs = []\n",
    "\n",
    "#     for col in target_cols:\n",
    "#         temp_df = df.loc[:, non_target_cols + [col]]\n",
    "#         temp_df = temp_df.loc[temp_df[col] == 1].copy() # sub sample to lowest class\n",
    "#         temp_df[col] = col # target value is class name now\n",
    "#         temp_df = temp_df.rename(columns={col: \"target\"}) # make target col name uniform for final concat\n",
    "#         binary_dfs.append(temp_df)\n",
    "\n",
    "#     # collect non_defect rows\n",
    "#     temp_df = df.loc[\n",
    "#         (df[\"Pastry\"] == 0) &\n",
    "#         (df[\"Z_Scratch\"] == 0) &\n",
    "#         (df[\"K_Scatch\"] == 0) &\n",
    "#         (df[\"Stains\"] == 0) &\n",
    "#         (df[\"Dirtiness\"] == 0) &\n",
    "#         (df[\"Bumps\"] == 0) &\n",
    "#         (df[\"Other_Faults\"] == 0)\n",
    "#     ]\n",
    "#     temp_df = temp_df.loc[: , non_target_cols]\n",
    "#     temp_df[\"target\"] = \"No defect\"\n",
    "#     binary_dfs.append(temp_df)\n",
    "\n",
    "#     reformatted_df = pd.concat(binary_dfs)\n",
    "#     return reformatted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_Minimum</th>\n",
       "      <th>X_Maximum</th>\n",
       "      <th>Y_Minimum</th>\n",
       "      <th>Y_Maximum</th>\n",
       "      <th>Pixels_Areas</th>\n",
       "      <th>X_Perimeter</th>\n",
       "      <th>Y_Perimeter</th>\n",
       "      <th>Sum_of_Luminosity</th>\n",
       "      <th>Minimum_of_Luminosity</th>\n",
       "      <th>Maximum_of_Luminosity</th>\n",
       "      <th>Length_of_Conveyer</th>\n",
       "      <th>TypeOfSteel_A300</th>\n",
       "      <th>TypeOfSteel_A400</th>\n",
       "      <th>Steel_Plate_Thickness</th>\n",
       "      <th>Edges_Index</th>\n",
       "      <th>Empty_Index</th>\n",
       "      <th>Square_Index</th>\n",
       "      <th>Outside_X_Index</th>\n",
       "      <th>Edges_X_Index</th>\n",
       "      <th>Edges_Y_Index</th>\n",
       "      <th>Outside_Global_Index</th>\n",
       "      <th>LogOfAreas</th>\n",
       "      <th>Log_X_Index</th>\n",
       "      <th>Log_Y_Index</th>\n",
       "      <th>Orientation_Index</th>\n",
       "      <th>Luminosity_Index</th>\n",
       "      <th>SigmoidOfAreas</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1673</td>\n",
       "      <td>1687</td>\n",
       "      <td>294065</td>\n",
       "      <td>294091</td>\n",
       "      <td>571</td>\n",
       "      <td>38</td>\n",
       "      <td>57</td>\n",
       "      <td>53142</td>\n",
       "      <td>77</td>\n",
       "      <td>110</td>\n",
       "      <td>1692</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>0.1491</td>\n",
       "      <td>0.4326</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.5686</td>\n",
       "      <td>0.7179</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.7528</td>\n",
       "      <td>1.3802</td>\n",
       "      <td>1.7559</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>-0.2661</td>\n",
       "      <td>0.9408</td>\n",
       "      <td>Pastry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1538</td>\n",
       "      <td>1549</td>\n",
       "      <td>849219</td>\n",
       "      <td>849235</td>\n",
       "      <td>275</td>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "      <td>28986</td>\n",
       "      <td>71</td>\n",
       "      <td>117</td>\n",
       "      <td>1626</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0.1494</td>\n",
       "      <td>0.3990</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.6316</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.4393</td>\n",
       "      <td>1.0792</td>\n",
       "      <td>1.5051</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>-0.2988</td>\n",
       "      <td>0.6330</td>\n",
       "      <td>Pastry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1310</td>\n",
       "      <td>1316</td>\n",
       "      <td>435871</td>\n",
       "      <td>435916</td>\n",
       "      <td>153</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>17101</td>\n",
       "      <td>104</td>\n",
       "      <td>132</td>\n",
       "      <td>1352</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0532</td>\n",
       "      <td>0.3854</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.9688</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.1847</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>1.5051</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>-0.0916</td>\n",
       "      <td>0.4025</td>\n",
       "      <td>Pastry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>765</td>\n",
       "      <td>774</td>\n",
       "      <td>6571361</td>\n",
       "      <td>6571375</td>\n",
       "      <td>59</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>6682</td>\n",
       "      <td>77</td>\n",
       "      <td>133</td>\n",
       "      <td>1360</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.3571</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.7708</td>\n",
       "      <td>0.8451</td>\n",
       "      <td>1.0792</td>\n",
       "      <td>0.7200</td>\n",
       "      <td>-0.1522</td>\n",
       "      <td>0.1892</td>\n",
       "      <td>Pastry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1677</td>\n",
       "      <td>1686</td>\n",
       "      <td>1319063</td>\n",
       "      <td>1319076</td>\n",
       "      <td>91</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>5608</td>\n",
       "      <td>57</td>\n",
       "      <td>95</td>\n",
       "      <td>1692</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.3583</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.9590</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>1.1761</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>-0.3868</td>\n",
       "      <td>0.2660</td>\n",
       "      <td>Pastry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    X_Minimum  X_Maximum  Y_Minimum  Y_Maximum  Pixels_Areas  X_Perimeter  \\\n",
       "7        1673       1687     294065     294091           571           38   \n",
       "24       1538       1549     849219     849235           275           19   \n",
       "35       1310       1316     435871     435916           153           16   \n",
       "60        765        774    6571361    6571375            59            9   \n",
       "67       1677       1686    1319063    1319076            91           10   \n",
       "\n",
       "    Y_Perimeter  Sum_of_Luminosity  Minimum_of_Luminosity  \\\n",
       "7            57              53142                     77   \n",
       "24           32              28986                     71   \n",
       "35           32              17101                    104   \n",
       "60           12               6682                     77   \n",
       "67           15               5608                     57   \n",
       "\n",
       "    Maximum_of_Luminosity  Length_of_Conveyer  TypeOfSteel_A300  \\\n",
       "7                     110                1692                 0   \n",
       "24                    117                1626                 1   \n",
       "35                    132                1352                 0   \n",
       "60                    133                1360                 0   \n",
       "67                     95                1692                 1   \n",
       "\n",
       "    TypeOfSteel_A400  Steel_Plate_Thickness  Edges_Index  Empty_Index  \\\n",
       "7                  1                    300       0.1491       0.4326   \n",
       "24                 0                     70       0.1494       0.3990   \n",
       "35                 1                     40       0.0532       0.3854   \n",
       "60                 1                    100       0.3613       0.3571   \n",
       "67                 0                     70       0.0024       0.3583   \n",
       "\n",
       "    Square_Index  Outside_X_Index  Edges_X_Index  Edges_Y_Index  \\\n",
       "7         0.9643           0.0142         0.5686         0.7179   \n",
       "24        0.3750           0.0088         0.6316         1.0000   \n",
       "35        0.3333           0.0044         0.3750         0.9688   \n",
       "60        0.2800           0.0052         0.7778         1.0000   \n",
       "67        0.6667           0.0047         0.8000         1.0000   \n",
       "\n",
       "    Outside_Global_Index  LogOfAreas  Log_X_Index  Log_Y_Index  \\\n",
       "7                    1.0      2.7528       1.3802       1.7559   \n",
       "24                   1.0      2.4393       1.0792       1.5051   \n",
       "35                   1.0      2.1847       0.7782       1.5051   \n",
       "60                   1.0      1.7708       0.8451       1.0792   \n",
       "67                   1.0      1.9590       0.9031       1.1761   \n",
       "\n",
       "    Orientation_Index  Luminosity_Index  SigmoidOfAreas  target  \n",
       "7              0.0357           -0.2661          0.9408  Pastry  \n",
       "24             0.6250           -0.2988          0.6330  Pastry  \n",
       "35             0.6667           -0.0916          0.4025  Pastry  \n",
       "60             0.7200           -0.1522          0.1892  Pastry  \n",
       "67             0.3333           -0.3868          0.2660  Pastry  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = reformat_data(combined_df)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_Minimum</th>\n",
       "      <th>X_Maximum</th>\n",
       "      <th>Y_Minimum</th>\n",
       "      <th>Y_Maximum</th>\n",
       "      <th>Pixels_Areas</th>\n",
       "      <th>X_Perimeter</th>\n",
       "      <th>Y_Perimeter</th>\n",
       "      <th>Sum_of_Luminosity</th>\n",
       "      <th>Minimum_of_Luminosity</th>\n",
       "      <th>Maximum_of_Luminosity</th>\n",
       "      <th>Length_of_Conveyer</th>\n",
       "      <th>TypeOfSteel_A300</th>\n",
       "      <th>TypeOfSteel_A400</th>\n",
       "      <th>Steel_Plate_Thickness</th>\n",
       "      <th>Edges_Index</th>\n",
       "      <th>Empty_Index</th>\n",
       "      <th>Square_Index</th>\n",
       "      <th>Outside_X_Index</th>\n",
       "      <th>Edges_X_Index</th>\n",
       "      <th>Edges_Y_Index</th>\n",
       "      <th>Outside_Global_Index</th>\n",
       "      <th>LogOfAreas</th>\n",
       "      <th>Log_X_Index</th>\n",
       "      <th>Log_Y_Index</th>\n",
       "      <th>Orientation_Index</th>\n",
       "      <th>Luminosity_Index</th>\n",
       "      <th>SigmoidOfAreas</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1673</td>\n",
       "      <td>1687</td>\n",
       "      <td>294065</td>\n",
       "      <td>294091</td>\n",
       "      <td>571</td>\n",
       "      <td>38</td>\n",
       "      <td>57</td>\n",
       "      <td>53142</td>\n",
       "      <td>77</td>\n",
       "      <td>110</td>\n",
       "      <td>1692</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>0.1491</td>\n",
       "      <td>0.4326</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.5686</td>\n",
       "      <td>0.7179</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.7528</td>\n",
       "      <td>1.3802</td>\n",
       "      <td>1.7559</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>-0.2661</td>\n",
       "      <td>0.9408</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1538</td>\n",
       "      <td>1549</td>\n",
       "      <td>849219</td>\n",
       "      <td>849235</td>\n",
       "      <td>275</td>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "      <td>28986</td>\n",
       "      <td>71</td>\n",
       "      <td>117</td>\n",
       "      <td>1626</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0.1494</td>\n",
       "      <td>0.3990</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.6316</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.4393</td>\n",
       "      <td>1.0792</td>\n",
       "      <td>1.5051</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>-0.2988</td>\n",
       "      <td>0.6330</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1310</td>\n",
       "      <td>1316</td>\n",
       "      <td>435871</td>\n",
       "      <td>435916</td>\n",
       "      <td>153</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>17101</td>\n",
       "      <td>104</td>\n",
       "      <td>132</td>\n",
       "      <td>1352</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0532</td>\n",
       "      <td>0.3854</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.9688</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.1847</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>1.5051</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>-0.0916</td>\n",
       "      <td>0.4025</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>765</td>\n",
       "      <td>774</td>\n",
       "      <td>6571361</td>\n",
       "      <td>6571375</td>\n",
       "      <td>59</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>6682</td>\n",
       "      <td>77</td>\n",
       "      <td>133</td>\n",
       "      <td>1360</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.3571</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.7708</td>\n",
       "      <td>0.8451</td>\n",
       "      <td>1.0792</td>\n",
       "      <td>0.7200</td>\n",
       "      <td>-0.1522</td>\n",
       "      <td>0.1892</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1677</td>\n",
       "      <td>1686</td>\n",
       "      <td>1319063</td>\n",
       "      <td>1319076</td>\n",
       "      <td>91</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>5608</td>\n",
       "      <td>57</td>\n",
       "      <td>95</td>\n",
       "      <td>1692</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.3583</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.9590</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>1.1761</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>-0.3868</td>\n",
       "      <td>0.2660</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    X_Minimum  X_Maximum  Y_Minimum  Y_Maximum  Pixels_Areas  X_Perimeter  \\\n",
       "7        1673       1687     294065     294091           571           38   \n",
       "24       1538       1549     849219     849235           275           19   \n",
       "35       1310       1316     435871     435916           153           16   \n",
       "60        765        774    6571361    6571375            59            9   \n",
       "67       1677       1686    1319063    1319076            91           10   \n",
       "\n",
       "    Y_Perimeter  Sum_of_Luminosity  Minimum_of_Luminosity  \\\n",
       "7            57              53142                     77   \n",
       "24           32              28986                     71   \n",
       "35           32              17101                    104   \n",
       "60           12               6682                     77   \n",
       "67           15               5608                     57   \n",
       "\n",
       "    Maximum_of_Luminosity  Length_of_Conveyer  TypeOfSteel_A300  \\\n",
       "7                     110                1692                 0   \n",
       "24                    117                1626                 1   \n",
       "35                    132                1352                 0   \n",
       "60                    133                1360                 0   \n",
       "67                     95                1692                 1   \n",
       "\n",
       "    TypeOfSteel_A400  Steel_Plate_Thickness  Edges_Index  Empty_Index  \\\n",
       "7                  1                    300       0.1491       0.4326   \n",
       "24                 0                     70       0.1494       0.3990   \n",
       "35                 1                     40       0.0532       0.3854   \n",
       "60                 1                    100       0.3613       0.3571   \n",
       "67                 0                     70       0.0024       0.3583   \n",
       "\n",
       "    Square_Index  Outside_X_Index  Edges_X_Index  Edges_Y_Index  \\\n",
       "7         0.9643           0.0142         0.5686         0.7179   \n",
       "24        0.3750           0.0088         0.6316         1.0000   \n",
       "35        0.3333           0.0044         0.3750         0.9688   \n",
       "60        0.2800           0.0052         0.7778         1.0000   \n",
       "67        0.6667           0.0047         0.8000         1.0000   \n",
       "\n",
       "    Outside_Global_Index  LogOfAreas  Log_X_Index  Log_Y_Index  \\\n",
       "7                    1.0      2.7528       1.3802       1.7559   \n",
       "24                   1.0      2.4393       1.0792       1.5051   \n",
       "35                   1.0      2.1847       0.7782       1.5051   \n",
       "60                   1.0      1.7708       0.8451       1.0792   \n",
       "67                   1.0      1.9590       0.9031       1.1761   \n",
       "\n",
       "    Orientation_Index  Luminosity_Index  SigmoidOfAreas  target  \n",
       "7              0.0357           -0.2661          0.9408       4  \n",
       "24             0.6250           -0.2988          0.6330       4  \n",
       "35             0.6667           -0.0916          0.4025       4  \n",
       "60             0.7200           -0.1522          0.1892       4  \n",
       "67             0.3333           -0.3868          0.2660       4  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoder.fit(combined_df[TARGET])\n",
    "\n",
    "combined_df[TARGET] = label_encoder.transform(combined_df[TARGET])\n",
    "\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20362, 28), (12814, 28))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combined_df.drop([TARGET], axis=1)\n",
    "y = combined_df[TARGET]\n",
    "\n",
    "n_splits = 3\n",
    "sk10 = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    LGBMClassifier(n_jobs=-1, random_state=5),\n",
    "    XGBClassifier(random_state=5),\n",
    "    RandomForestClassifier(random_state=5),\n",
    "    ExtraTreesClassifier(random_state=5),\n",
    "    HistGradientBoostingClassifier(random_state=5),\n",
    "    CatBoostClassifier(random_state=5, verbose=False, early_stopping_rounds=100),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models_roc(models, X, y, important_features, cv_split, experiment_name):\n",
    "    MLA_compare = pd.DataFrame(columns=['MLA Name', \n",
    "                                        'MLA Parameters', \n",
    "                                        'MLA Train ROC AUC', \n",
    "                                        'MLA Test ROC AUC', \n",
    "                                        'MLA Test ROC AUC Std', \n",
    "                                        'MLA Time'])\n",
    "    \n",
    "    def evaluate_model(alg, idx):\n",
    "        MLA_name = alg.__class__.__name__\n",
    "        features = important_features.get(MLA_name, [])\n",
    "\n",
    "        # Check if the list of important features is empty\n",
    "        if len(features) == 0:\n",
    "            # If empty, return results with zero values\n",
    "            print(f'Skipping {MLA_name} due to no important features.')\n",
    "            return {\n",
    "                'MLA Name': MLA_name,\n",
    "                'MLA Parameters': str(alg.get_params()),\n",
    "                'MLA Train ROC': 0,\n",
    "                'MLA Test ROC': 0,\n",
    "                'MLA Test ROC Std': 0,\n",
    "                'MLA Time': \"0 min 0.00 sec\",\n",
    "            }\n",
    "        \n",
    "        cv_results = cross_validate(alg, \n",
    "                                    X[features], \n",
    "                                    y, cv=cv_split, \n",
    "                                    scoring='roc_auc_ovr', \n",
    "                                    return_train_score=True, \n",
    "                                    n_jobs=-1)\n",
    "\n",
    "        # Time formatting\n",
    "        mean_fit_time = cv_results['fit_time'].mean()\n",
    "        minutes, seconds = divmod(mean_fit_time, 60)\n",
    "\n",
    "        # Results population\n",
    "        result = {\n",
    "            'MLA Name': MLA_name,\n",
    "            'MLA Parameters': str(alg.get_params()),\n",
    "            'MLA Train ROC AUC': cv_results['train_score'].mean(),\n",
    "            'MLA Test ROC AUC': cv_results['test_score'].mean(),\n",
    "            'MLA Test ROC AUC Std': cv_results['test_score'].std(),\n",
    "            'MLA Time': f\"{int(minutes)} min {seconds:.2f} sec\",\n",
    "        }\n",
    "\n",
    "        print(f'Done with {MLA_name}.')\n",
    "        return result\n",
    "\n",
    "    results_list = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = [executor.submit(evaluate_model, alg, idx) for idx, alg in enumerate(models)]\n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            results_list.append(result)\n",
    "\n",
    "    MLA_compare = pd.DataFrame(results_list)\n",
    "\n",
    "    MLA_compare.sort_values(by=['MLA Test ROC AUC'], ascending=False, inplace=True)\n",
    "    MLA_compare.to_csv(f'{experiment_name}_results.csv', index=False)\n",
    "\n",
    "    return MLA_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_features = {}\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "\n",
    "    baseline_features[model_name] = list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "baseline_models = evaluate_models_roc(models, X, y, baseline_features, sk10, f'{experiment_name}_lgbm')\n",
    "baseline_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "baseline_models = evaluate_models_roc(models, X, y, baseline_features, sk10, f'{experiment_name}')\n",
    "baseline_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove Correlated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove correlated features (leaving just 1 of each pair)\n",
    "# Leave features highly correlated with the target\n",
    "df_no_corr = X.copy()\n",
    "correlation_matrix_spear = df_no_corr.corr(method='spearman').abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper_spear = correlation_matrix_spear.where(np.triu(np.ones(correlation_matrix_spear.shape), k=1).astype(bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than a threshold (e.g., 0.9 in this case)\n",
    "to_drop_spear = [column for column in upper_spear.columns if any(upper_spear[column] >= 0.9)]\n",
    "\n",
    "# Drop features\n",
    "df_reduced_spear = df_no_corr.drop(to_drop_spear, axis=1)\n",
    "\n",
    "# Get list of low correlation features excluding TARGET\n",
    "low_corr_feats_spear = list(df_reduced_spear.columns)\n",
    "\n",
    "with open('low_corr_spear.txt', 'w') as f:\n",
    "    f.write(str(low_corr_feats_spear))\n",
    "    f.write('\\n')\n",
    "\n",
    "# Print the high correlation features effect\n",
    "# Both pre and post drop dfs contain the TARGET\n",
    "print(f\"Dropped {len(to_drop_spear)} highly correlated features.\\nOld Shape of the dataset was {df_no_corr.shape}\\nNew shape of the dataset is {df_reduced_spear.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "no_corr_features = {}\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "\n",
    "    no_corr_features[model_name] = list(df_reduced_spear.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "no_corr_models = evaluate_models_roc(models, df_reduced_spear, y, no_corr_features, sk10, f'{experiment_name}_corr')\n",
    "no_corr_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_importance_features = {}\n",
    "\n",
    "# for model in models:\n",
    "#     model_name = model.__class__.__name__\n",
    "\n",
    "#     try:\n",
    "#         # Initialize array to store feature importances\n",
    "#         feature_importances = np.zeros(X.shape[1])\n",
    "\n",
    "#         # Loop through each fold and calculate the feature importances\n",
    "#         for train_index, test_index in sk10.split(X, y):\n",
    "#             X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "#             y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "#             model.fit(X_train, y_train)\n",
    "\n",
    "#             # Get the feature importances and them to the total\n",
    "#             feature_importances += model.feature_importances_\n",
    "\n",
    "#         feature_importances /= n_splits\n",
    "\n",
    "#         feature_importances_dict = dict(zip(X.columns, feature_importances))\n",
    "\n",
    "#         df = pd.DataFrame.from_dict(feature_importances_dict, orient='index')\n",
    "\n",
    "#         # Resetting index with a name for the column\n",
    "#         df = df.reset_index().rename(columns={'index': 'Feature', 0: 'Avg_Feat_Importance'})\n",
    "#         df.sort_values(by='Avg_Feat_Importance', ascending=False, inplace=True)\n",
    "\n",
    "#         # Save to CSV\n",
    "#         df.to_csv(f'{model_name}_feature_importances.csv')\n",
    "\n",
    "#         fi_threshold = 0\n",
    "\n",
    "#         fi_feats = df[df['Avg_Feat_Importance'] > fi_threshold]['Feature'].tolist()\n",
    "\n",
    "#         feat_importance_features[model_name] = fi_feats\n",
    "#         print(f'Done with {model_name}')\n",
    "\n",
    "#     except AttributeError:\n",
    "#         feat_importance_features[model_name] = list(X.columns)\n",
    "#         print(f'{model_name} does not have feature_importances_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('featimp_features.txt', mode='w') as f:\n",
    "#     pprint(feat_importance_features, stream=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random feature for X\n",
    "np.random.seed(5)\n",
    "df_reduced_spear['random_control_feature'] = np.round(np.random.uniform(-2, 2, df_reduced_spear.shape[0]), 6)\n",
    "df_reduced_spear.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "perm_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=5)\n",
    "\n",
    "perm_importances = {model.__class__.__name__: [] for model in models}\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(perm_cv.split(df_reduced_spear, y)):\n",
    "    X_train, X_test = df_reduced_spear.iloc[train_idx], df_reduced_spear.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        model.fit(X_train, y_train)\n",
    "        # Calculate permutation importance\n",
    "        result = permutation_importance(model, X_test, y_test, n_repeats=5, random_state=5, n_jobs=-1, scoring='roc_auc_ovr')\n",
    "        perm_importances[model_name].append(result.importances_mean)\n",
    "        print(f'Done with {model_name}.')\n",
    "    \n",
    "    print(f'Done with Fold {i+1}', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Average importances across folds and export to CSV\n",
    "for model_name, importances in perm_importances.items():\n",
    "    avg_importance = np.mean(importances, axis=0)\n",
    "    importance_df = pd.DataFrame({'Feature': df_reduced_spear.columns, 'Importance': avg_importance})\n",
    "    importance_df.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "    # Export to CSV\n",
    "    importance_df.to_csv(f'.\\permutation_importances\\{model_name}_permutation_importance.csv', index=False)\n",
    "\n",
    "print('Done with Permuation Importances', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'permutation_importances'\n",
    "\n",
    "# Initialize a dictionary for the features\n",
    "perm_important_features = {}\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    csv_path = os.path.join(directory, f'{model_name}_permutation_importance.csv')\n",
    "    if os.path.exists(csv_path):\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Check for 'random_control_feature' and its importance\n",
    "        if 'random_control_feature' in df['Feature'].values:\n",
    "            random_feature_importance = df.loc[df['Feature'] == 'random_control_feature', 'Importance'].iloc[0]\n",
    "        else:\n",
    "            random_feature_importance = 0\n",
    "\n",
    "        # Determine the threshold\n",
    "        threshold = max(0, random_feature_importance)\n",
    "\n",
    "        # Filter features where importance is greater than 0\n",
    "        important_feats_filtered = df[df['Importance'] > threshold]['Feature'].tolist()\n",
    "\n",
    "        # Reorder important_feats based on the predefined features_list\n",
    "        important_feats_ordered = [feat for feat in features_list if feat in important_feats_filtered]\n",
    "\n",
    "        # Add to importance dictionary\n",
    "        perm_important_features[model_name] = important_feats_ordered\n",
    "\n",
    "    else:\n",
    "        print(f'CSV file for {model_name} not found.')\n",
    "\n",
    "print('Done getting important features dictionary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('perm_important_features_lgbm.txt', mode='w') as f:\n",
    "    pprint(perm_important_features, stream=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "perm_importance_models = evaluate_models_roc(models, X, y, perm_important_features, sk10, f'{experiment_name}_permimp')\n",
    "perm_importance_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SelectKBest with f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features_list = []\n",
    "kbest_features = {}\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "\n",
    "    # Select whichever one had a better CV score generally\n",
    "    # Also, consider computational expense and accuracy balance\n",
    "    \n",
    "    features = perm_important_features[model_name]\n",
    "    # features = list(df_reduced_spear.columns)\n",
    "\n",
    "    # incase there is no feature that had importance, go to the next model\n",
    "    if len(features) == 0:\n",
    "        continue\n",
    "\t\n",
    "    X_kbest = X[features]\n",
    "    best_score = 0\n",
    "    best_k = 0\n",
    "    best_features = []\n",
    "\n",
    "    # Iterate over k from 1 to number of features\n",
    "    for k in range(1, len(features) + 1):\n",
    "        print(f'currently running {k} features on {model_name}')\n",
    "        # Apply SelectKBest\n",
    "        selector = SelectKBest(f_classif, k=k)\n",
    "        X_new = selector.fit_transform(X_kbest, y)\n",
    "\n",
    "        # Get the selected feature names\n",
    "        selected_features = X_kbest.columns[selector.get_support()]\n",
    "\n",
    "        # Evaluate the model\n",
    "        # model = LGBMClassifier(n_jobs=-1, random_state=5)\n",
    "        roc_auc_scores = cross_validate(model, X_new, y, cv=sk10, scoring='roc_auc_ovr', n_jobs=-1)\n",
    "        mean_roc_auc_scores = roc_auc_scores['test_score'].mean()\n",
    "\n",
    "        if mean_roc_auc_scores > best_score:\n",
    "            best_k = k\n",
    "            best_score = mean_roc_auc_scores\n",
    "            best_features = list(selected_features)\n",
    "\n",
    "    best_features_list.append({'k': best_k,\n",
    "                    'Selected Features': best_features,\n",
    "                    'ROC AUC Score': best_score,\n",
    "                    'Model Name': model_name})\n",
    "    \n",
    "    kbest_features[model_name] = best_features\n",
    "\n",
    "best_features_df = pd.DataFrame(best_features_list)\n",
    "\n",
    "best_features_df.sort_values(by='ROC AUC Score', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kbest_features.txt', mode='w') as f:\n",
    "    pprint(kbest_features, stream=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Initialize empty dictionary for RFECV features\n",
    "rfecv_features = {}\n",
    "\n",
    "for alg in models:\n",
    "    # set name\n",
    "    MLA_name = alg.__class__.__name__\n",
    "\t\t\n",
    "    features = perm_important_features[MLA_name]\n",
    "\n",
    "    # incase there is no feature that had importance, go to the next model\n",
    "    if len(features) == 0:\n",
    "        continue\n",
    "\t\n",
    "    X_rfecv = X[features]\n",
    "\n",
    "    try:\n",
    "        print(f'Starting with {MLA_name}')\n",
    "        # Create the RFECV object and rank each feature\n",
    "        selector = RFECV(alg, cv=sk10, step=1, scoring='roc_auc_ovr', verbose=2)\n",
    "        selector = selector.fit(X_rfecv, y)\n",
    "\n",
    "        selected_features = list(X_rfecv.columns[selector.support_])\n",
    "\n",
    "        # Reorder selected_features based on the predefined features_list\n",
    "        selected_features_ordered = [feat for feat in features_list if feat in selected_features]\n",
    "\n",
    "        rfecv_features[MLA_name] = selected_features_ordered\n",
    "\n",
    "        print(f'Done with {MLA_name}', end='\\n\\n')\n",
    "    \n",
    "    except ValueError:\n",
    "        # In case of an error, keep the original order but filtered by features_list\n",
    "        features_filtered = [feat for feat in features_list if feat in features]\n",
    "        rfecv_features[MLA_name] = features_filtered\n",
    "        print(f'{MLA_name} does not have coef_ or feature_importances_', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rfecv_features.txt', mode='w') as f:\n",
    "    pprint(rfecv_features, stream=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "rfecv_models = evaluate_models_roc(models, X, y, rfecv_features, sk10, f'{experiment_name}_rfecv')\n",
    "rfecv_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Initialize empty dictionary for SFS features\n",
    "sfs_features = {}\n",
    "\n",
    "for alg in models:\n",
    "    # set name\n",
    "    MLA_name = alg.__class__.__name__\n",
    "\n",
    "    try:\n",
    "            \n",
    "        # features = kbest_features[MLA_name]\n",
    "        # features = feat_importance_features[MLA_name]\n",
    "        features = rfecv_features[MLA_name]\n",
    "\n",
    "        # incase there is no feature that had importance, go to the next model\n",
    "        if len(features) == 0:\n",
    "            continue\n",
    "        \n",
    "        X_sfs = X[features]\n",
    "\n",
    "        print(f'Running backward feature selection with {MLA_name}')\n",
    "\n",
    "        sfs = SFS(alg,\n",
    "            k_features='best',\n",
    "            forward=False,\n",
    "            floating=False,\n",
    "            scoring='roc_auc_ovr',\n",
    "            verbose=2,\n",
    "            n_jobs=-1,\n",
    "            cv=sk10)\n",
    "        \n",
    "        sfs = sfs.fit(X_sfs, y)\n",
    "\n",
    "        # Get the selected features index\n",
    "        selected_sfs_idx = list(sfs.k_feature_idx_)\n",
    "\n",
    "        # Get the feature names\n",
    "        selected_sfs_feats = X_sfs.columns[selected_sfs_idx]\n",
    "\n",
    "        selected_features = list(selected_sfs_feats)\n",
    "\n",
    "        # Reorder selected_features based on the predefined features_list\n",
    "        selected_features_ordered = [feat for feat in features_list if feat in selected_features]\n",
    "\n",
    "        sfs_features[MLA_name] = selected_features_ordered\n",
    "\n",
    "        print(f'Done with {MLA_name}', end='\\n\\n')\n",
    "\n",
    "    except KeyError:\n",
    "        print(f'{MLA_name} not in the dictionary.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sfs_features.txt', mode='w') as f:\n",
    "    pprint(sfs_features, stream=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "sfs_models = evaluate_models_roc(models, X, y, sfs_features, sk10, f'{experiment_name}_sfs')\n",
    "sfs_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "feat_importance_models = evaluate_models_roc(models, X, y, feat_importance_features, sk10, f'{experiment_name}_featimp')\n",
    "feat_importance_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "kbest_models = evaluate_models_roc(models, X, y, kbest_features, sk10, f'{experiment_name}_kbest')\n",
    "kbest_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LGBMClassifier(n_jobs=-1, random_state=5)\n",
    "model2 = XGBClassifier(random_state=5)\n",
    "model3 = RandomForestClassifier(random_state=5)\n",
    "model4 = ExtraTreesClassifier(random_state=5)\n",
    "model5 = HistGradientBoostingClassifier(random_state=5)\n",
    "model6 = CatBoostClassifier(random_state=5, verbose=False, early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Features for Competition + Original dataset down to SFS for all models (Experiment Set 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_feats = ['X_Minimum', 'Y_Minimum', 'Pixels_Areas', 'X_Perimeter', 'Minimum_of_Luminosity', 'Length_of_Conveyer', 'TypeOfSteel_A300', 'Steel_Plate_Thickness', 'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index', 'Edges_X_Index', 'Edges_Y_Index', 'Orientation_Index', 'Luminosity_Index']\n",
    "model2_feats = ['X_Minimum', 'Pixels_Areas', 'X_Perimeter', 'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer', 'TypeOfSteel_A300', 'Steel_Plate_Thickness', 'Edges_Index', 'Empty_Index', 'Outside_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'Orientation_Index', 'Luminosity_Index']\n",
    "model3_feats = ['X_Minimum', 'Y_Minimum', 'Pixels_Areas', 'X_Perimeter', 'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer', 'TypeOfSteel_A300', 'Steel_Plate_Thickness', 'Edges_Index', 'Empty_Index', 'Outside_X_Index', 'Edges_Y_Index', 'Orientation_Index', 'Luminosity_Index']\n",
    "model4_feats = ['X_Minimum', 'Y_Minimum', 'Pixels_Areas', 'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer', 'TypeOfSteel_A300', 'Steel_Plate_Thickness', 'Edges_Index', 'Empty_Index', 'Outside_X_Index', 'Edges_Y_Index', 'Orientation_Index']\n",
    "model5_feats = ['X_Minimum', 'Y_Minimum', 'Pixels_Areas', 'Minimum_of_Luminosity', 'Length_of_Conveyer', 'TypeOfSteel_A300', 'Steel_Plate_Thickness', 'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index', 'Edges_Y_Index', 'Orientation_Index', 'Luminosity_Index']\n",
    "model6_feats = ['X_Minimum', 'Pixels_Areas', 'X_Perimeter', 'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer', 'TypeOfSteel_A300', 'Steel_Plate_Thickness', 'Edges_Index', 'Empty_Index', 'Outside_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'Orientation_Index', 'Luminosity_Index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with fold 1.\n",
      "Done with fold 2.\n",
      "Done with fold 3.\n",
      "CPU times: total: 22 s\n",
      "Wall time: 3.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model1_results, model2_results, model3_results, model4_results, model5_results, model6_results, y_test_list = [], [], [], [], [], [], []\n",
    "\n",
    "X_lgbm = X[model1_feats]\n",
    "X_xgb = X[model2_feats]\n",
    "X_rf = X[model3_feats]\n",
    "X_extrat = X[model4_feats]\n",
    "X_hist = X[model5_feats]\n",
    "X_cat = X[model6_feats]\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(sk10.split(X, y)):\n",
    "    X_train_lgbm, X_test_lgbm = X_lgbm.iloc[train_index], X_lgbm.iloc[test_index]\n",
    "    X_train_xgb, X_test_xgb = X_xgb.iloc[train_index], X_xgb.iloc[test_index]\n",
    "    X_train_rf, X_test_rf = X_rf.iloc[train_index], X_rf.iloc[test_index]\n",
    "    X_train_extrat, X_test_extrat = X_extrat.iloc[train_index], X_extrat.iloc[test_index]\n",
    "    X_train_hist, X_test_hist = X_hist.iloc[train_index], X_hist.iloc[test_index]\n",
    "    X_train_cat, X_test_cat = X_cat.iloc[train_index], X_cat.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model1.fit(X_train_lgbm, y_train)\n",
    "    model1_results.append(model1.predict_proba(X_test_lgbm))\n",
    "\n",
    "    # model2.fit(X_train_xgb, y_train)\n",
    "    # model2_results.append(model2.predict_proba(X_test_xgb))\n",
    "\n",
    "    # model3.fit(X_train_rf, y_train)\n",
    "    # model3_results.append(model3.predict_proba(X_test_rf))\n",
    "\n",
    "    # model4.fit(X_train_extrat, y_train)\n",
    "    # model4_results.append(model4.predict_proba(X_test_extrat))\n",
    "\n",
    "    # model5.fit(X_train_hist, y_train)\n",
    "    # model5_results.append(model5.predict_proba(X_test_hist))\n",
    "\n",
    "    # model6.fit(X_train_cat, y_train)\n",
    "    # model6_results.append(model6.predict_proba(X_test_cat))\n",
    "\n",
    "    # y_test_list.append(y_test)\n",
    "\n",
    "    print(f'Done with fold {i+1}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model1_weights, model2_weights, model3_weights, model4_weights, model5_weights, model6_weights, scores = [], [], [], [], [], [], []\n",
    "\n",
    "for i in tqdm(range(20000)):\n",
    "    weight_1 = np.random.random_sample(size=1)[0]\n",
    "    weight_2 = np.random.random_sample(size=1)[0]\n",
    "    weight_3 = np.random.random_sample(size=1)[0]\n",
    "    weight_4 = np.random.random_sample(size=1)[0]\n",
    "    weight_5 = np.random.random_sample(size=1)[0]\n",
    "    weight_6 = np.random.random_sample(size=1)[0]\n",
    "\n",
    "    model1_weights.append(weight_1)\n",
    "    model2_weights.append(weight_2)\n",
    "    model3_weights.append(weight_3)\n",
    "    model4_weights.append(weight_4)\n",
    "    model5_weights.append(weight_5)\n",
    "    model6_weights.append(weight_6)\n",
    "\n",
    "    scores_in = []\n",
    "\n",
    "    for j in range(n_splits):\n",
    "        weighted_pred = weight_1 * model1_results[j] + weight_2 * model2_results[j] + weight_3 * model3_results[j] + weight_4 * model4_results[j] + weight_5 * model5_results[j] + weight_6 * model6_results[j]\n",
    "        weighted_pred_normalized = weighted_pred / np.sum(weighted_pred, axis=1, keepdims=True)\n",
    "        scores_in.append(roc_auc_score(y_test_list[j], weighted_pred_normalized, multi_class='ovr'))\n",
    "        \n",
    "    scores.append(np.mean(scores_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame()\n",
    "results_df['model_1'] = model1_weights\n",
    "results_df['model_2'] = model2_weights\n",
    "results_df['model_3'] = model3_weights\n",
    "results_df['model_4'] = model4_weights\n",
    "results_df['model_5'] = model5_weights\n",
    "results_df['model_6'] = model6_weights\n",
    "results_df['score'] = scores\n",
    "results_df = results_df.sort_values(by='score', ascending=False).reset_index(drop=True)\n",
    "results_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Submission (Random Weight Ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model1_final = model1.fit(X_lgbm, y)\n",
    "model2_final = model2.fit(X_xgb, y)\n",
    "model3_final = model3.fit(X_rf, y)\n",
    "model4_final = model4.fit(X_extrat, y)\n",
    "model5_final = model5.fit(X_hist, y)\n",
    "model6_final = model6.fit(X_cat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_pred = (\n",
    "                results_df['model_1'][0] * model1_final.predict_proba(test[model1_feats]) +\n",
    "                results_df['model_2'][0] * model2_final.predict_proba(test[model2_feats]) +\n",
    "                results_df['model_3'][0] * model3_final.predict_proba(test[model3_feats]) +\n",
    "                results_df['model_4'][0] * model4_final.predict_proba(test[model4_feats]) +\n",
    "                results_df['model_5'][0] * model5_final.predict_proba(test[model5_feats]) +\n",
    "                results_df['model_6'][0] * model6_final.predict_proba(test[model6_feats])\n",
    "                 )\n",
    "\n",
    "ensemble_df = pd.DataFrame(ensemble_pred)\n",
    "\n",
    "# If all models predict 0, instead of getting NaN, fill in 0\n",
    "ensemble_df = ensemble_df.div(ensemble_df.sum(axis=1), axis=0).fillna(0)\n",
    "ensemble_df.columns = label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission_df = pd.concat([submission['id'], ensemble_df], axis=1)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission_ensemble_3fold_0.900483.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get submission (Stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "roc_auc_scores = []\n",
    "\n",
    "# Define the base models\n",
    "base_models = [\n",
    "    ('model1', model1_final),\n",
    "    ('model2', model2_final),\n",
    "    ('model3', model3_final),\n",
    "    ('model4', model4_final),\n",
    "    ('model5', model5_final),\n",
    "    ('model6', model6_final)\n",
    "]\n",
    "\n",
    "# Initialize the Stacking Classifier with LogisticRegression as the final estimator\n",
    "final_estimator = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs')\n",
    "# final_estimator = LGBMClassifier(n_jobs=-1, random_state=5)\n",
    "# final_estimator = XGBClassifier(random_state=5)\n",
    "# final_estimator = RandomForestClassifier(random_state=5)\n",
    "# final_estimator = ExtraTreesClassifier(random_state=5)\n",
    "# final_estimator = HistGradientBoostingClassifier(random_state=5)\n",
    "# final_estimator = CatBoostClassifier(random_state=5, verbose=False, early_stopping_rounds=100)\n",
    "\n",
    "stacking_clf = StackingClassifier(estimators=base_models, final_estimator=final_estimator, passthrough=False, cv=3)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(sk10.split(X, y)):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    stacking_clf.fit(X_train, y_train)\n",
    "    y_pred = stacking_clf.predict_proba(X_test)\n",
    "\n",
    "    # Assuming your classes are 0, 1, 2, etc., adjust as necessary\n",
    "    y_test_binarized = label_binarize(y_test, classes=np.unique(y))\n",
    "    roc_auc = roc_auc_score(y_test_binarized, y_pred, multi_class='ovr')\n",
    "\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "\n",
    "    print(f'Done with fold {i+1}.')\n",
    "    \n",
    "print(f'The average stacking score is {np.mean(roc_auc_scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Reg - 0.886778\n",
    "- LGBM - 0.885863\n",
    "- XGB - 0.881636\n",
    "- RF - 0.883835\n",
    "- ET - 0.884523\n",
    "- Hist - 0.886572\n",
    "- Cat - 0.886183"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on unseen test data\n",
    "y_test_pred = stacking_clf.predict_proba(test)\n",
    "\n",
    "stacking_df = pd.DataFrame(y_test_pred)\n",
    "\n",
    "ensemble_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 16.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model1_results, model2_results, model3_results, model4_results, model5_results, model6_results, y_test_list = [], [], [], [], [], [], []\n",
    "\n",
    "# # Placeholder for OOF predictions for each model\n",
    "# # Assuming you have a dataset with N samples\n",
    "# N = len(y)  # y_train is your target variable array\n",
    "# oof_preds1 = np.zeros((N, 1))\n",
    "# oof_preds2 = np.zeros((N, 1))\n",
    "# oof_preds3 = np.zeros((N, 1))\n",
    "# oof_preds4 = np.zeros((N, 1))\n",
    "# oof_preds5 = np.zeros((N, 1))\n",
    "# oof_preds6 = np.zeros((N, 1))\n",
    "\n",
    "# # Similarly, for test predictions, accumulate them over folds\n",
    "# # Assuming you have a test set with M samples\n",
    "# M = len(test)  # x_test needs to be defined by you\n",
    "# test_preds1 = np.zeros((M, 1))\n",
    "# test_preds2 = np.zeros((M, 1))\n",
    "# test_preds3 = np.zeros((M, 1))\n",
    "# test_preds4 = np.zeros((M, 1))\n",
    "# test_preds5 = np.zeros((M, 1))\n",
    "# test_preds6 = np.zeros((M, 1))\n",
    "\n",
    "target_length = len(y)\n",
    "no_classes = len(np.unique(y))\n",
    "test_length = len(test)\n",
    "\n",
    "# Initialize arrays for OOF and test predictions with dimensions for multiclass for each model\n",
    "lgbm_oof_preds = np.zeros((target_length, no_classes))\n",
    "lgbm_test_preds = np.zeros((test_length, no_classes))\n",
    "\n",
    "xgb_oof_preds = np.zeros((target_length, no_classes))\n",
    "xgb_test_preds = np.zeros((test_length, no_classes))\n",
    "\n",
    "rf_oof_preds = np.zeros((target_length, no_classes))\n",
    "rf_test_preds = np.zeros((test_length, no_classes))\n",
    "\n",
    "extrat_oof_preds = np.zeros((target_length, no_classes))\n",
    "extrat_test_preds = np.zeros((test_length, no_classes))\n",
    "\n",
    "hist_oof_preds = np.zeros((target_length, no_classes))\n",
    "hist_test_preds = np.zeros((test_length, no_classes))\n",
    "\n",
    "cat_oof_preds = np.zeros((target_length, no_classes))\n",
    "cat_test_preds = np.zeros((test_length, no_classes))\n",
    "\n",
    "X_lgbm = X[model1_feats]\n",
    "X_xgb = X[model2_feats]\n",
    "X_rf = X[model3_feats]\n",
    "X_extrat = X[model4_feats]\n",
    "X_hist = X[model5_feats]\n",
    "X_cat = X[model6_feats]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with fold 1.\n",
      "Done with fold 2.\n",
      "Done with fold 3.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, (train_index, test_index) in enumerate(sk10.split(X, y)):\n",
    "\n",
    "    # Placeholder arrays for the fold's predicition\n",
    "    fold_oof_preds_lgbm = np.zeros((len(test_index), no_classes))\n",
    "    fold_test_preds_lgbm = np.zeros((test_length, no_classes))\n",
    "\n",
    "    fold_oof_preds_xgb = np.zeros((len(test_index), no_classes))\n",
    "    fold_test_preds_xgb = np.zeros((test_length, no_classes))\n",
    "\n",
    "    fold_oof_preds_rf = np.zeros((len(test_index), no_classes))\n",
    "    fold_test_preds_rf = np.zeros((test_length, no_classes))\n",
    "\n",
    "    fold_oof_preds_extrat = np.zeros((len(test_index), no_classes))\n",
    "    fold_test_preds_extrat = np.zeros((test_length, no_classes))\n",
    "\n",
    "    fold_oof_preds_hist = np.zeros((len(test_index), no_classes))\n",
    "    fold_test_preds_hist = np.zeros((test_length, no_classes))\n",
    "\n",
    "    fold_oof_preds_cat = np.zeros((len(test_index), no_classes))\n",
    "    fold_test_preds_cat = np.zeros((test_length, no_classes))\n",
    "\n",
    "    # Get each models train and test for X and y\n",
    "    X_train_lgbm, X_test_lgbm = X_lgbm.iloc[train_index], X_lgbm.iloc[test_index]\n",
    "    X_train_xgb, X_test_xgb = X_xgb.iloc[train_index], X_xgb.iloc[test_index]\n",
    "    X_train_rf, X_test_rf = X_rf.iloc[train_index], X_rf.iloc[test_index]\n",
    "    X_train_extrat, X_test_extrat = X_extrat.iloc[train_index], X_extrat.iloc[test_index]\n",
    "    X_train_hist, X_test_hist = X_hist.iloc[train_index], X_hist.iloc[test_index]\n",
    "    X_train_cat, X_test_cat = X_cat.iloc[train_index], X_cat.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    ########\n",
    "    # LGBM #\n",
    "    ########\n",
    "    model1.fit(X_train_lgbm, y_train)\n",
    "    fold_oof_preds_lgbm = model1.predict_proba(X_test_lgbm)\n",
    "\n",
    "    # Update the OOF prediction for this fold\n",
    "    lgbm_oof_preds[test_index] = fold_oof_preds_lgbm\n",
    "\n",
    "    # Predict on the test set and accumulate predictions\n",
    "    fold_test_preds_lgbm += model1.predict_proba(test.loc[:, model1_feats]) / sk10.n_splits\n",
    "\n",
    "    lgbm_test_preds += fold_test_preds_lgbm\n",
    "\n",
    "\n",
    "    ###########\n",
    "    # XGBOOST #\n",
    "    ###########\n",
    "    model2.fit(X_train_xgb, y_train)\n",
    "    fold_oof_preds_xgb = model2.predict_proba(X_test_xgb)\n",
    "\n",
    "    # Update the OOF prediction for this fold\n",
    "    xgb_oof_preds[test_index] = fold_oof_preds_xgb\n",
    "\n",
    "    # Predict on the test set and accumulate predictions\n",
    "    fold_test_preds_xgb += model2.predict_proba(test.loc[:, model2_feats]) / sk10.n_splits\n",
    "\n",
    "    xgb_test_preds += fold_test_preds_xgb\n",
    "\n",
    "\n",
    "    #################\n",
    "    # RANDOM FOREST #\n",
    "    #################\n",
    "    model3.fit(X_train_rf, y_train)\n",
    "    fold_oof_preds_rf = model3.predict_proba(X_test_rf)\n",
    "\n",
    "    # Update the OOF prediction for this fold\n",
    "    rf_oof_preds[test_index] = fold_oof_preds_rf\n",
    "\n",
    "    # Predict on the test set and accumulate predictions\n",
    "    fold_test_preds_rf += model3.predict_proba(test.loc[:, model3_feats]) / sk10.n_splits\n",
    "\n",
    "    rf_test_preds += fold_test_preds_rf\n",
    "\n",
    "    \n",
    "    ###############\n",
    "    # EXTRA TREES #\n",
    "    ###############\n",
    "    model4.fit(X_train_extrat, y_train)\n",
    "    fold_oof_preds_extrat = model4.predict_proba(X_test_extrat)\n",
    "\n",
    "    # Update the OOF prediction for this fold\n",
    "    extrat_oof_preds[test_index] = fold_oof_preds_extrat\n",
    "\n",
    "    # Predict on the test set and accumulate predictions\n",
    "    fold_test_preds_extrat += model4.predict_proba(test.loc[:, model4_feats]) / sk10.n_splits\n",
    "\n",
    "    extrat_test_preds += fold_test_preds_extrat\n",
    "\n",
    "\n",
    "    #################\n",
    "    # HIST GRADIENT #\n",
    "    #################\n",
    "    model5.fit(X_train_hist, y_train)\n",
    "    fold_oof_preds_hist = model5.predict_proba(X_test_hist)\n",
    "\n",
    "    # Update the OOF prediction for this fold\n",
    "    hist_oof_preds[test_index] = fold_oof_preds_hist\n",
    "\n",
    "    # Predict on the test set and accumulate predictions\n",
    "    fold_test_preds_hist += model5.predict_proba(test.loc[:, model5_feats]) / sk10.n_splits\n",
    "\n",
    "    hist_test_preds += fold_test_preds_hist\n",
    "\n",
    "\n",
    "    ############\n",
    "    # CATBOOST #\n",
    "    ############\n",
    "    model6.fit(X_train_cat, y_train)\n",
    "    fold_oof_preds_cat = model6.predict_proba(X_test_cat)\n",
    "\n",
    "    # Update the OOF prediction for this fold\n",
    "    cat_oof_preds[test_index] = fold_oof_preds_cat\n",
    "\n",
    "    # Predict on the test set and accumulate predictions\n",
    "    fold_test_preds_cat += model6.predict_proba(test.loc[:, model6_feats]) / sk10.n_splits\n",
    "\n",
    "    cat_test_preds += fold_test_preds_cat\n",
    "    # y_test_list.append(y_test)\n",
    "\n",
    "    print(f'Done with fold {i+1}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average LGBM ROC AUC Score: 0.8935542157432373\n",
      "Average XGBoost ROC AUC Score: 0.8903635169380858\n",
      "Average Random Forest ROC AUC Score: 0.8896969099226436\n",
      "Average Extra Trees ROC AUC Score: 0.8857651421424897\n",
      "Average Hist Gradient ROC AUC Score: 0.8945433977015824\n",
      "Average CatBoost ROC AUC Score: 0.8953939964784441\n"
     ]
    }
   ],
   "source": [
    "# roc_auc_scores = [roc_auc_score((y == class_id).astype(int), oof_preds[:, class_id], multi_class='ovr') for class_id in range(no_classes)]\n",
    "lgbm_roc_auc = roc_auc_score(y, lgbm_oof_preds, multi_class='ovr', average='macro')\n",
    "print(\"Average LGBM ROC AUC Score:\", lgbm_roc_auc)\n",
    "\n",
    "xgb_roc_auc = roc_auc_score(y, xgb_oof_preds, multi_class='ovr', average='macro')\n",
    "print(\"Average XGBoost ROC AUC Score:\", xgb_roc_auc)\n",
    "\n",
    "rf_roc_auc = roc_auc_score(y, rf_oof_preds, multi_class='ovr', average='macro')\n",
    "print(\"Average Random Forest ROC AUC Score:\", rf_roc_auc)\n",
    "\n",
    "extrat_roc_auc = roc_auc_score(y, extrat_oof_preds, multi_class='ovr', average='macro')\n",
    "print(\"Average Extra Trees ROC AUC Score:\", extrat_roc_auc)\n",
    "\n",
    "hist_roc_auc = roc_auc_score(y, hist_oof_preds, multi_class='ovr', average='macro')\n",
    "print(\"Average Hist Gradient ROC AUC Score:\", hist_roc_auc)\n",
    "\n",
    "cat_roc_auc = roc_auc_score(y, cat_oof_preds, multi_class='ovr', average='macro')\n",
    "print(\"Average CatBoost ROC AUC Score:\", cat_roc_auc)\n",
    "\n",
    "# 0.89369590207664\n",
    "# 0.00201442835387733\n",
    "# 0.886778 - StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# After running the fitting and prediction with the first level of machine learning models\n",
    "x_train = np.concatenate(( lgbm_oof_preds, xgb_oof_preds, rf_oof_preds, extrat_oof_preds, hist_oof_preds, cat_oof_preds), axis=1)\n",
    "test_stack = np.concatenate(( lgbm_test_preds, xgb_test_preds, rf_test_preds, extrat_test_preds, hist_test_preds, cat_test_preds), axis=1)\n",
    "\n",
    "# Assuming the second-level stacking is to be done with XGboost (pre-tuned). Yes! You can tune second-level stack\n",
    "\n",
    "stacking_estimator = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs')\n",
    "\n",
    "xgb = stacking_estimator.fit(x_train, y)\n",
    "final_predictions = xgb.predict_proba(test_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with fold 1.\n",
      "Done with fold 2.\n",
      "Done with fold 3.\n",
      "The stacking score is 0.8846028966376445\n"
     ]
    }
   ],
   "source": [
    "oof_preds = np.zeros((x_train.shape[0], no_classes))\n",
    "test_preds = np.zeros(test_stack.shape[0])\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(sk10.split(x_train, y)):\n",
    "    X_train, X_test = x_train[train_index], x_train[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model2.fit(X_train, y_train)\n",
    "    y_pred = model2.predict_proba(X_test)\n",
    "\n",
    "    # Assign predictions for this fold to the appropriate indices in oof_preds\n",
    "    oof_preds[test_index, :] = y_pred\n",
    "    \n",
    "    print(f'Done with fold {i+1}.')\n",
    "\n",
    "# Calculate ROC AUC on the OOF predictions\n",
    "roc_auc = roc_auc_score(y, oof_preds, multi_class='ovr', average='macro')\n",
    "print(f'The stacking score is {roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Reg - 0.8883102077923056\n",
    "- LGBM - 0.8880225088607244\n",
    "- XGB - 0.8846028966376445\n",
    "- RF - \n",
    "- ET - \n",
    "- Hist - \n",
    "- Cat - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions_df = pd.DataFrame(final_predictions)\n",
    "final_predictions_df.columns = label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Bumps</th>\n",
       "      <th>Dirtiness</th>\n",
       "      <th>K_Scatch</th>\n",
       "      <th>Other_Faults</th>\n",
       "      <th>Pastry</th>\n",
       "      <th>Stains</th>\n",
       "      <th>Z_Scratch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19219</td>\n",
       "      <td>0.109995</td>\n",
       "      <td>0.041557</td>\n",
       "      <td>0.004287</td>\n",
       "      <td>0.247875</td>\n",
       "      <td>0.592884</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.003186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19220</td>\n",
       "      <td>0.121830</td>\n",
       "      <td>0.143814</td>\n",
       "      <td>0.009768</td>\n",
       "      <td>0.396005</td>\n",
       "      <td>0.317566</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>0.009479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19221</td>\n",
       "      <td>0.273418</td>\n",
       "      <td>0.013910</td>\n",
       "      <td>0.039735</td>\n",
       "      <td>0.600537</td>\n",
       "      <td>0.033596</td>\n",
       "      <td>0.008429</td>\n",
       "      <td>0.030374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19222</td>\n",
       "      <td>0.409350</td>\n",
       "      <td>0.021530</td>\n",
       "      <td>0.009839</td>\n",
       "      <td>0.439897</td>\n",
       "      <td>0.096654</td>\n",
       "      <td>0.003829</td>\n",
       "      <td>0.018901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19223</td>\n",
       "      <td>0.669567</td>\n",
       "      <td>0.008034</td>\n",
       "      <td>0.005439</td>\n",
       "      <td>0.261923</td>\n",
       "      <td>0.035301</td>\n",
       "      <td>0.003872</td>\n",
       "      <td>0.015864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id     Bumps  Dirtiness  K_Scatch  Other_Faults    Pastry    Stains  \\\n",
       "0  19219  0.109995   0.041557  0.004287      0.247875  0.592884  0.000217   \n",
       "1  19220  0.121830   0.143814  0.009768      0.396005  0.317566  0.001537   \n",
       "2  19221  0.273418   0.013910  0.039735      0.600537  0.033596  0.008429   \n",
       "3  19222  0.409350   0.021530  0.009839      0.439897  0.096654  0.003829   \n",
       "4  19223  0.669567   0.008034  0.005439      0.261923  0.035301  0.003872   \n",
       "\n",
       "   Z_Scratch  \n",
       "0   0.003186  \n",
       "1   0.009479  \n",
       "2   0.030374  \n",
       "3   0.018901  \n",
       "4   0.015864  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission_df = pd.concat([submission['id'], final_predictions_df], axis=1)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission_stacking_3fold_0.88831.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
