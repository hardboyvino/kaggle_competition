{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.inspection import permutation_importance, PartialDependenceDisplay\n",
    "from sklearn.feature_selection import RFECV, mutual_info_classif, SelectKBest, f_classif\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from pprint import pprint\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "experiment_name = 'multi-models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19219, 35), (12814, 28))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Got function from https://www.kaggle.com/code/thomasmeiner/ps4e3-eda-feature-engineering-model\n",
    "\n",
    "def reformat_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    target_cols = [\n",
    "        \"Pastry\", #4\n",
    "        \"Z_Scratch\", #6\n",
    "        \"K_Scatch\", #2\n",
    "        \"Stains\", #5\n",
    "        \"Dirtiness\", #1\n",
    "        \"Bumps\", #0\n",
    "        \"Other_Faults\", #3\n",
    "    ]\n",
    "    non_target_cols = df.drop(target_cols, axis=1).columns.to_list()\n",
    "    \n",
    "    binary_dfs = []\n",
    "    \n",
    "    for col in target_cols:\n",
    "        temp_df = df.loc[:, non_target_cols + [col]]\n",
    "        temp_df = temp_df.loc[temp_df[col] == 1].copy() # keep positives only\n",
    "        temp_df[col] = col # target value is class name now\n",
    "        temp_df = temp_df.rename(columns={col: \"target\"}) # make target col name uniform for final concat\n",
    "        binary_dfs.append(temp_df)\n",
    "        \n",
    "    reformatted_df = pd.concat(binary_dfs)\n",
    "    return reformatted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>X_Minimum</th>\n",
       "      <th>X_Maximum</th>\n",
       "      <th>Y_Minimum</th>\n",
       "      <th>Y_Maximum</th>\n",
       "      <th>Pixels_Areas</th>\n",
       "      <th>X_Perimeter</th>\n",
       "      <th>Y_Perimeter</th>\n",
       "      <th>Sum_of_Luminosity</th>\n",
       "      <th>Minimum_of_Luminosity</th>\n",
       "      <th>Maximum_of_Luminosity</th>\n",
       "      <th>Length_of_Conveyer</th>\n",
       "      <th>TypeOfSteel_A300</th>\n",
       "      <th>TypeOfSteel_A400</th>\n",
       "      <th>Steel_Plate_Thickness</th>\n",
       "      <th>Edges_Index</th>\n",
       "      <th>Empty_Index</th>\n",
       "      <th>Square_Index</th>\n",
       "      <th>Outside_X_Index</th>\n",
       "      <th>Edges_X_Index</th>\n",
       "      <th>Edges_Y_Index</th>\n",
       "      <th>Outside_Global_Index</th>\n",
       "      <th>LogOfAreas</th>\n",
       "      <th>Log_X_Index</th>\n",
       "      <th>Log_Y_Index</th>\n",
       "      <th>Orientation_Index</th>\n",
       "      <th>Luminosity_Index</th>\n",
       "      <th>SigmoidOfAreas</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>584</td>\n",
       "      <td>590</td>\n",
       "      <td>909972</td>\n",
       "      <td>909977</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2274</td>\n",
       "      <td>113</td>\n",
       "      <td>140</td>\n",
       "      <td>1358</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.7393</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2041</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>0.6990</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>-0.0104</td>\n",
       "      <td>0.1417</td>\n",
       "      <td>Stains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>808</td>\n",
       "      <td>816</td>\n",
       "      <td>728350</td>\n",
       "      <td>728372</td>\n",
       "      <td>433</td>\n",
       "      <td>20</td>\n",
       "      <td>54</td>\n",
       "      <td>44478</td>\n",
       "      <td>70</td>\n",
       "      <td>111</td>\n",
       "      <td>1687</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0.7772</td>\n",
       "      <td>0.2878</td>\n",
       "      <td>0.2581</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6365</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>1.7324</td>\n",
       "      <td>0.7419</td>\n",
       "      <td>-0.2997</td>\n",
       "      <td>0.9491</td>\n",
       "      <td>Other_Faults</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>192</td>\n",
       "      <td>2212076</td>\n",
       "      <td>2212144</td>\n",
       "      <td>11388</td>\n",
       "      <td>705</td>\n",
       "      <td>420</td>\n",
       "      <td>1311391</td>\n",
       "      <td>29</td>\n",
       "      <td>141</td>\n",
       "      <td>1400</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.5282</td>\n",
       "      <td>0.9895</td>\n",
       "      <td>0.1077</td>\n",
       "      <td>0.2363</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0564</td>\n",
       "      <td>2.1790</td>\n",
       "      <td>2.2095</td>\n",
       "      <td>-0.0105</td>\n",
       "      <td>-0.0944</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>K_Scatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>781</td>\n",
       "      <td>789</td>\n",
       "      <td>3353146</td>\n",
       "      <td>3353173</td>\n",
       "      <td>210</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>3202</td>\n",
       "      <td>114</td>\n",
       "      <td>134</td>\n",
       "      <td>1387</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.7202</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.9310</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.3222</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>1.4314</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>-0.0402</td>\n",
       "      <td>0.4025</td>\n",
       "      <td>K_Scatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1540</td>\n",
       "      <td>1560</td>\n",
       "      <td>618457</td>\n",
       "      <td>618502</td>\n",
       "      <td>521</td>\n",
       "      <td>72</td>\n",
       "      <td>67</td>\n",
       "      <td>48231</td>\n",
       "      <td>82</td>\n",
       "      <td>111</td>\n",
       "      <td>1692</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>0.1211</td>\n",
       "      <td>0.5347</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.9861</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.7694</td>\n",
       "      <td>1.4150</td>\n",
       "      <td>1.8808</td>\n",
       "      <td>0.9158</td>\n",
       "      <td>-0.2455</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>Other_Faults</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  X_Minimum  X_Maximum  Y_Minimum  Y_Maximum  Pixels_Areas  X_Perimeter  \\\n",
       "0   0        584        590     909972     909977            16            8   \n",
       "1   1        808        816     728350     728372           433           20   \n",
       "2   2         39        192    2212076    2212144         11388          705   \n",
       "3   3        781        789    3353146    3353173           210           16   \n",
       "4   4       1540       1560     618457     618502           521           72   \n",
       "\n",
       "   Y_Perimeter  Sum_of_Luminosity  Minimum_of_Luminosity  \\\n",
       "0            5               2274                    113   \n",
       "1           54              44478                     70   \n",
       "2          420            1311391                     29   \n",
       "3           29               3202                    114   \n",
       "4           67              48231                     82   \n",
       "\n",
       "   Maximum_of_Luminosity  Length_of_Conveyer  TypeOfSteel_A300  \\\n",
       "0                    140                1358                 0   \n",
       "1                    111                1687                 1   \n",
       "2                    141                1400                 0   \n",
       "3                    134                1387                 0   \n",
       "4                    111                1692                 0   \n",
       "\n",
       "   TypeOfSteel_A400  Steel_Plate_Thickness  Edges_Index  Empty_Index  \\\n",
       "0                 1                     50       0.7393       0.4000   \n",
       "1                 0                     80       0.7772       0.2878   \n",
       "2                 1                     40       0.0557       0.5282   \n",
       "3                 1                     40       0.7202       0.3333   \n",
       "4                 1                    300       0.1211       0.5347   \n",
       "\n",
       "   Square_Index  Outside_X_Index  Edges_X_Index  Edges_Y_Index  \\\n",
       "0        0.5000           0.0059         1.0000         1.0000   \n",
       "1        0.2581           0.0044         0.2500         1.0000   \n",
       "2        0.9895           0.1077         0.2363         0.3857   \n",
       "3        0.3333           0.0044         0.3750         0.9310   \n",
       "4        0.0842           0.0192         0.2105         0.9861   \n",
       "\n",
       "   Outside_Global_Index  LogOfAreas  Log_X_Index  Log_Y_Index  \\\n",
       "0                   0.0      1.2041       0.9031       0.6990   \n",
       "1                   1.0      2.6365       0.7782       1.7324   \n",
       "2                   0.0      4.0564       2.1790       2.2095   \n",
       "3                   1.0      2.3222       0.7782       1.4314   \n",
       "4                   1.0      2.7694       1.4150       1.8808   \n",
       "\n",
       "   Orientation_Index  Luminosity_Index  SigmoidOfAreas        target  \n",
       "0            -0.5000           -0.0104          0.1417        Stains  \n",
       "1             0.7419           -0.2997          0.9491  Other_Faults  \n",
       "2            -0.0105           -0.0944          1.0000      K_Scatch  \n",
       "3             0.6667           -0.0402          0.4025      K_Scatch  \n",
       "4             0.9158           -0.2455          0.9998  Other_Faults  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = reformat_data(train)\n",
    "train = train.sort_values(by='id', ascending=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>X_Minimum</th>\n",
       "      <th>X_Maximum</th>\n",
       "      <th>Y_Minimum</th>\n",
       "      <th>Y_Maximum</th>\n",
       "      <th>Pixels_Areas</th>\n",
       "      <th>X_Perimeter</th>\n",
       "      <th>Y_Perimeter</th>\n",
       "      <th>Sum_of_Luminosity</th>\n",
       "      <th>Minimum_of_Luminosity</th>\n",
       "      <th>Maximum_of_Luminosity</th>\n",
       "      <th>Length_of_Conveyer</th>\n",
       "      <th>TypeOfSteel_A300</th>\n",
       "      <th>TypeOfSteel_A400</th>\n",
       "      <th>Steel_Plate_Thickness</th>\n",
       "      <th>Edges_Index</th>\n",
       "      <th>Empty_Index</th>\n",
       "      <th>Square_Index</th>\n",
       "      <th>Outside_X_Index</th>\n",
       "      <th>Edges_X_Index</th>\n",
       "      <th>Edges_Y_Index</th>\n",
       "      <th>Outside_Global_Index</th>\n",
       "      <th>LogOfAreas</th>\n",
       "      <th>Log_X_Index</th>\n",
       "      <th>Log_Y_Index</th>\n",
       "      <th>Orientation_Index</th>\n",
       "      <th>Luminosity_Index</th>\n",
       "      <th>SigmoidOfAreas</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>584</td>\n",
       "      <td>590</td>\n",
       "      <td>909972</td>\n",
       "      <td>909977</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2274</td>\n",
       "      <td>113</td>\n",
       "      <td>140</td>\n",
       "      <td>1358</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.7393</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2041</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>0.6990</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>-0.0104</td>\n",
       "      <td>0.1417</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>808</td>\n",
       "      <td>816</td>\n",
       "      <td>728350</td>\n",
       "      <td>728372</td>\n",
       "      <td>433</td>\n",
       "      <td>20</td>\n",
       "      <td>54</td>\n",
       "      <td>44478</td>\n",
       "      <td>70</td>\n",
       "      <td>111</td>\n",
       "      <td>1687</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0.7772</td>\n",
       "      <td>0.2878</td>\n",
       "      <td>0.2581</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6365</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>1.7324</td>\n",
       "      <td>0.7419</td>\n",
       "      <td>-0.2997</td>\n",
       "      <td>0.9491</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>192</td>\n",
       "      <td>2212076</td>\n",
       "      <td>2212144</td>\n",
       "      <td>11388</td>\n",
       "      <td>705</td>\n",
       "      <td>420</td>\n",
       "      <td>1311391</td>\n",
       "      <td>29</td>\n",
       "      <td>141</td>\n",
       "      <td>1400</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.5282</td>\n",
       "      <td>0.9895</td>\n",
       "      <td>0.1077</td>\n",
       "      <td>0.2363</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0564</td>\n",
       "      <td>2.1790</td>\n",
       "      <td>2.2095</td>\n",
       "      <td>-0.0105</td>\n",
       "      <td>-0.0944</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>781</td>\n",
       "      <td>789</td>\n",
       "      <td>3353146</td>\n",
       "      <td>3353173</td>\n",
       "      <td>210</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>3202</td>\n",
       "      <td>114</td>\n",
       "      <td>134</td>\n",
       "      <td>1387</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.7202</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.9310</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.3222</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>1.4314</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>-0.0402</td>\n",
       "      <td>0.4025</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1540</td>\n",
       "      <td>1560</td>\n",
       "      <td>618457</td>\n",
       "      <td>618502</td>\n",
       "      <td>521</td>\n",
       "      <td>72</td>\n",
       "      <td>67</td>\n",
       "      <td>48231</td>\n",
       "      <td>82</td>\n",
       "      <td>111</td>\n",
       "      <td>1692</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>0.1211</td>\n",
       "      <td>0.5347</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.9861</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.7694</td>\n",
       "      <td>1.4150</td>\n",
       "      <td>1.8808</td>\n",
       "      <td>0.9158</td>\n",
       "      <td>-0.2455</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  X_Minimum  X_Maximum  Y_Minimum  Y_Maximum  Pixels_Areas  X_Perimeter  \\\n",
       "0   0        584        590     909972     909977            16            8   \n",
       "1   1        808        816     728350     728372           433           20   \n",
       "2   2         39        192    2212076    2212144         11388          705   \n",
       "3   3        781        789    3353146    3353173           210           16   \n",
       "4   4       1540       1560     618457     618502           521           72   \n",
       "\n",
       "   Y_Perimeter  Sum_of_Luminosity  Minimum_of_Luminosity  \\\n",
       "0            5               2274                    113   \n",
       "1           54              44478                     70   \n",
       "2          420            1311391                     29   \n",
       "3           29               3202                    114   \n",
       "4           67              48231                     82   \n",
       "\n",
       "   Maximum_of_Luminosity  Length_of_Conveyer  TypeOfSteel_A300  \\\n",
       "0                    140                1358                 0   \n",
       "1                    111                1687                 1   \n",
       "2                    141                1400                 0   \n",
       "3                    134                1387                 0   \n",
       "4                    111                1692                 0   \n",
       "\n",
       "   TypeOfSteel_A400  Steel_Plate_Thickness  Edges_Index  Empty_Index  \\\n",
       "0                 1                     50       0.7393       0.4000   \n",
       "1                 0                     80       0.7772       0.2878   \n",
       "2                 1                     40       0.0557       0.5282   \n",
       "3                 1                     40       0.7202       0.3333   \n",
       "4                 1                    300       0.1211       0.5347   \n",
       "\n",
       "   Square_Index  Outside_X_Index  Edges_X_Index  Edges_Y_Index  \\\n",
       "0        0.5000           0.0059         1.0000         1.0000   \n",
       "1        0.2581           0.0044         0.2500         1.0000   \n",
       "2        0.9895           0.1077         0.2363         0.3857   \n",
       "3        0.3333           0.0044         0.3750         0.9310   \n",
       "4        0.0842           0.0192         0.2105         0.9861   \n",
       "\n",
       "   Outside_Global_Index  LogOfAreas  Log_X_Index  Log_Y_Index  \\\n",
       "0                   0.0      1.2041       0.9031       0.6990   \n",
       "1                   1.0      2.6365       0.7782       1.7324   \n",
       "2                   0.0      4.0564       2.1790       2.2095   \n",
       "3                   1.0      2.3222       0.7782       1.4314   \n",
       "4                   1.0      2.7694       1.4150       1.8808   \n",
       "\n",
       "   Orientation_Index  Luminosity_Index  SigmoidOfAreas  target  \n",
       "0            -0.5000           -0.0104          0.1417       5  \n",
       "1             0.7419           -0.2997          0.9491       3  \n",
       "2            -0.0105           -0.0944          1.0000       2  \n",
       "3             0.6667           -0.0402          0.4025       2  \n",
       "4             0.9158           -0.2455          0.9998       3  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoder.fit(train[TARGET])\n",
    "\n",
    "train[TARGET] = label_encoder.transform(train[TARGET])\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop([TARGET, 'id'], axis=1)\n",
    "y = train[TARGET]\n",
    "\n",
    "n_splits = 10\n",
    "sk10 = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    LGBMClassifier(n_jobs=-1, random_state=5),\n",
    "    XGBClassifier(random_state=5),\n",
    "    RandomForestClassifier(random_state=5),\n",
    "    AdaBoostClassifier(random_state=5),\n",
    "    BaggingClassifier(random_state=5),\n",
    "    ExtraTreesClassifier(random_state=5),\n",
    "    HistGradientBoostingClassifier(random_state=5),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove Correlated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 9 highly correlated features.\n",
      "Old Shape of the dataset was (18422, 27)\n",
      "New shape of the dataset is (18422, 18)\n"
     ]
    }
   ],
   "source": [
    "# Remove correlated features (leaving just 1 of each pair)\n",
    "# Leave features highly correlated with the target\n",
    "df_no_corr = X.copy()\n",
    "correlation_matrix_spear = df_no_corr.corr(method='spearman').abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper_spear = correlation_matrix_spear.where(np.triu(np.ones(correlation_matrix_spear.shape), k=1).astype(bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than a threshold (e.g., 0.9 in this case)\n",
    "to_drop_spear = [column for column in upper_spear.columns if any(upper_spear[column] >= 0.9)]\n",
    "\n",
    "# Drop features\n",
    "df_reduced_spear = df_no_corr.drop(to_drop_spear, axis=1)\n",
    "\n",
    "# Get list of low correlation features excluding TARGET\n",
    "low_corr_feats_spear = list(df_reduced_spear.columns)\n",
    "\n",
    "with open('low_corr_spear.txt', 'w') as f:\n",
    "    f.write(str(low_corr_feats_spear))\n",
    "    f.write('\\n')\n",
    "\n",
    "# Print the high correlation features effect\n",
    "# Both pre and post drop dfs contain the TARGET\n",
    "print(f\"Dropped {len(to_drop_spear)} highly correlated features.\\nOld Shape of the dataset was {df_no_corr.shape}\\nNew shape of the dataset is {df_reduced_spear.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with LGBMClassifier\n",
      "Done with XGBClassifier\n",
      "Done with RandomForestClassifier\n",
      "Done with AdaBoostClassifier\n",
      "BaggingClassifier does not have feature_importances_\n",
      "Done with ExtraTreesClassifier\n",
      "HistGradientBoostingClassifier does not have feature_importances_\n"
     ]
    }
   ],
   "source": [
    "feat_importance_features = {}\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "\n",
    "    try:\n",
    "        # Initialize array to store feature importances\n",
    "        feature_importances = np.zeros(df_reduced_spear.shape[1])\n",
    "\n",
    "        # Loop through each fold and calculate the feature importances\n",
    "        for train_index, test_index in sk10.split(df_reduced_spear, y):\n",
    "            X_train, X_test = df_reduced_spear.iloc[train_index], df_reduced_spear.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Get the feature importances and them to the total\n",
    "            feature_importances += model.feature_importances_\n",
    "\n",
    "        feature_importances /= n_splits\n",
    "\n",
    "        feature_importances_dict = dict(zip(df_reduced_spear.columns, feature_importances))\n",
    "\n",
    "        df = pd.DataFrame.from_dict(feature_importances_dict, orient='index')\n",
    "\n",
    "        # Resetting index with a name for the column\n",
    "        df = df.reset_index().rename(columns={'index': 'Feature', 0: 'Avg_Feat_Importance'})\n",
    "        df.sort_values(by='Avg_Feat_Importance', ascending=False, inplace=True)\n",
    "\n",
    "        # Save to CSV\n",
    "        df.to_csv(f'{model_name}_feature_importances.csv')\n",
    "\n",
    "        fi_threshold = 0\n",
    "\n",
    "        fi_feats = df[df['Avg_Feat_Importance'] > fi_threshold]['Feature'].tolist()\n",
    "\n",
    "        feat_importance_features[model_name] = fi_feats\n",
    "        print(f'Done with {model_name}')\n",
    "\n",
    "    except AttributeError:\n",
    "        feat_importance_features[model_name] = list(df_reduced_spear.columns)\n",
    "        print(f'{model_name} does not have feature_importances_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('featimp_features.txt', mode='w') as f:\n",
    "    pprint(feat_importance_features, stream=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SelectKBest with Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currently running 1 features on LGBMClassifier\n",
      "currently running 2 features on LGBMClassifier\n",
      "currently running 3 features on LGBMClassifier\n",
      "currently running 4 features on LGBMClassifier\n",
      "currently running 5 features on LGBMClassifier\n",
      "currently running 6 features on LGBMClassifier\n",
      "currently running 7 features on LGBMClassifier\n",
      "currently running 8 features on LGBMClassifier\n",
      "currently running 9 features on LGBMClassifier\n",
      "currently running 10 features on LGBMClassifier\n",
      "currently running 11 features on LGBMClassifier\n",
      "currently running 12 features on LGBMClassifier\n",
      "currently running 13 features on LGBMClassifier\n",
      "currently running 14 features on LGBMClassifier\n",
      "currently running 15 features on LGBMClassifier\n",
      "currently running 16 features on LGBMClassifier\n",
      "currently running 17 features on LGBMClassifier\n",
      "currently running 18 features on LGBMClassifier\n",
      "currently running 1 features on XGBClassifier\n",
      "currently running 2 features on XGBClassifier\n",
      "currently running 3 features on XGBClassifier\n",
      "currently running 4 features on XGBClassifier\n",
      "currently running 5 features on XGBClassifier\n",
      "currently running 6 features on XGBClassifier\n",
      "currently running 7 features on XGBClassifier\n",
      "currently running 8 features on XGBClassifier\n",
      "currently running 9 features on XGBClassifier\n",
      "currently running 10 features on XGBClassifier\n",
      "currently running 11 features on XGBClassifier\n",
      "currently running 12 features on XGBClassifier\n",
      "currently running 13 features on XGBClassifier\n",
      "currently running 14 features on XGBClassifier\n",
      "currently running 15 features on XGBClassifier\n",
      "currently running 16 features on XGBClassifier\n",
      "currently running 17 features on XGBClassifier\n",
      "currently running 18 features on XGBClassifier\n",
      "currently running 1 features on RandomForestClassifier\n",
      "currently running 2 features on RandomForestClassifier\n",
      "currently running 3 features on RandomForestClassifier\n",
      "currently running 4 features on RandomForestClassifier\n",
      "currently running 5 features on RandomForestClassifier\n",
      "currently running 6 features on RandomForestClassifier\n",
      "currently running 7 features on RandomForestClassifier\n",
      "currently running 8 features on RandomForestClassifier\n",
      "currently running 9 features on RandomForestClassifier\n",
      "currently running 10 features on RandomForestClassifier\n",
      "currently running 11 features on RandomForestClassifier\n",
      "currently running 12 features on RandomForestClassifier\n",
      "currently running 13 features on RandomForestClassifier\n",
      "currently running 14 features on RandomForestClassifier\n",
      "currently running 15 features on RandomForestClassifier\n",
      "currently running 16 features on RandomForestClassifier\n",
      "currently running 17 features on RandomForestClassifier\n",
      "currently running 18 features on RandomForestClassifier\n",
      "currently running 1 features on AdaBoostClassifier\n",
      "currently running 2 features on AdaBoostClassifier\n",
      "currently running 3 features on AdaBoostClassifier\n",
      "currently running 4 features on AdaBoostClassifier\n",
      "currently running 5 features on AdaBoostClassifier\n",
      "currently running 6 features on AdaBoostClassifier\n",
      "currently running 7 features on AdaBoostClassifier\n",
      "currently running 8 features on AdaBoostClassifier\n",
      "currently running 9 features on AdaBoostClassifier\n",
      "currently running 10 features on AdaBoostClassifier\n",
      "currently running 11 features on AdaBoostClassifier\n",
      "currently running 12 features on AdaBoostClassifier\n",
      "currently running 13 features on AdaBoostClassifier\n",
      "currently running 14 features on AdaBoostClassifier\n",
      "currently running 15 features on AdaBoostClassifier\n",
      "currently running 16 features on AdaBoostClassifier\n",
      "currently running 17 features on AdaBoostClassifier\n",
      "currently running 18 features on AdaBoostClassifier\n",
      "currently running 1 features on BaggingClassifier\n",
      "currently running 2 features on BaggingClassifier\n",
      "currently running 3 features on BaggingClassifier\n",
      "currently running 4 features on BaggingClassifier\n",
      "currently running 5 features on BaggingClassifier\n",
      "currently running 6 features on BaggingClassifier\n",
      "currently running 7 features on BaggingClassifier\n",
      "currently running 8 features on BaggingClassifier\n",
      "currently running 9 features on BaggingClassifier\n",
      "currently running 10 features on BaggingClassifier\n",
      "currently running 11 features on BaggingClassifier\n",
      "currently running 12 features on BaggingClassifier\n",
      "currently running 13 features on BaggingClassifier\n",
      "currently running 14 features on BaggingClassifier\n",
      "currently running 15 features on BaggingClassifier\n",
      "currently running 16 features on BaggingClassifier\n",
      "currently running 17 features on BaggingClassifier\n",
      "currently running 18 features on BaggingClassifier\n",
      "currently running 1 features on ExtraTreesClassifier\n",
      "currently running 2 features on ExtraTreesClassifier\n",
      "currently running 3 features on ExtraTreesClassifier\n",
      "currently running 4 features on ExtraTreesClassifier\n",
      "currently running 5 features on ExtraTreesClassifier\n",
      "currently running 6 features on ExtraTreesClassifier\n",
      "currently running 7 features on ExtraTreesClassifier\n",
      "currently running 8 features on ExtraTreesClassifier\n",
      "currently running 9 features on ExtraTreesClassifier\n",
      "currently running 10 features on ExtraTreesClassifier\n",
      "currently running 11 features on ExtraTreesClassifier\n",
      "currently running 12 features on ExtraTreesClassifier\n",
      "currently running 13 features on ExtraTreesClassifier\n",
      "currently running 14 features on ExtraTreesClassifier\n",
      "currently running 15 features on ExtraTreesClassifier\n",
      "currently running 16 features on ExtraTreesClassifier\n",
      "currently running 17 features on ExtraTreesClassifier\n",
      "currently running 18 features on ExtraTreesClassifier\n",
      "currently running 1 features on HistGradientBoostingClassifier\n",
      "currently running 2 features on HistGradientBoostingClassifier\n",
      "currently running 3 features on HistGradientBoostingClassifier\n",
      "currently running 4 features on HistGradientBoostingClassifier\n",
      "currently running 5 features on HistGradientBoostingClassifier\n",
      "currently running 6 features on HistGradientBoostingClassifier\n",
      "currently running 7 features on HistGradientBoostingClassifier\n",
      "currently running 8 features on HistGradientBoostingClassifier\n",
      "currently running 9 features on HistGradientBoostingClassifier\n",
      "currently running 10 features on HistGradientBoostingClassifier\n",
      "currently running 11 features on HistGradientBoostingClassifier\n",
      "currently running 12 features on HistGradientBoostingClassifier\n",
      "currently running 13 features on HistGradientBoostingClassifier\n",
      "currently running 14 features on HistGradientBoostingClassifier\n",
      "currently running 15 features on HistGradientBoostingClassifier\n",
      "currently running 16 features on HistGradientBoostingClassifier\n",
      "currently running 17 features on HistGradientBoostingClassifier\n",
      "currently running 18 features on HistGradientBoostingClassifier\n"
     ]
    }
   ],
   "source": [
    "best_features_list = []\n",
    "kbest_features = {}\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "\n",
    "    # Select whichever one had a better CV score generally\n",
    "    # Also, consider computational expense and accuracy balance\n",
    "    \n",
    "    # features = feat_importance_features[model_name]\n",
    "    features = list(df_reduced_spear.columns)\n",
    "\n",
    "    # incase there is no feature that had importance, go to the next model\n",
    "    if len(features) == 0:\n",
    "        continue\n",
    "\t\n",
    "    X_kbest = X[features]\n",
    "    best_score = 0\n",
    "    best_k = 0\n",
    "    best_features = []\n",
    "\n",
    "    # Iterate over k from 1 to number of features\n",
    "    for k in range(1, len(features) + 1):\n",
    "        print(f'currently running {k} features on {model_name}')\n",
    "        # Apply SelectKBest\n",
    "        selector = SelectKBest(f_classif, k=k)\n",
    "        X_new = selector.fit_transform(X_kbest, y)\n",
    "\n",
    "        # Get the selected feature names\n",
    "        selected_features = X_kbest.columns[selector.get_support()]\n",
    "\n",
    "        # Evaluate the model\n",
    "        # model = LGBMClassifier(n_jobs=-1, random_state=5)\n",
    "        roc_auc_scores = cross_validate(model, X_new, y, cv=sk10, scoring='roc_auc_ovr', n_jobs=-1)\n",
    "        mean_roc_auc_scores = roc_auc_scores['test_score'].mean()\n",
    "\n",
    "        if mean_roc_auc_scores > best_score:\n",
    "            best_k = k\n",
    "            best_score = mean_roc_auc_scores\n",
    "            best_features = list(selected_features)\n",
    "\n",
    "    best_features_list.append({'k': best_k,\n",
    "                    'Selected Features': best_features,\n",
    "                    'ROC AUC Score': best_score,\n",
    "                    'Model Name': model_name})\n",
    "    \n",
    "    kbest_features[model_name] = best_features\n",
    "\n",
    "best_features_df = pd.DataFrame(best_features_list)\n",
    "\n",
    "best_features_df.sort_values(by='ROC AUC Score', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kbest_features.txt', mode='w') as f:\n",
    "    pprint(kbest_features, stream=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>Selected Features</th>\n",
       "      <th>ROC AUC Score</th>\n",
       "      <th>Model Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>[X_Minimum, Pixels_Areas, X_Perimeter, Minimum...</td>\n",
       "      <td>0.887207</td>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>[X_Minimum, Pixels_Areas, X_Perimeter, Minimum...</td>\n",
       "      <td>0.887172</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>[X_Minimum, Pixels_Areas, X_Perimeter, Minimum...</td>\n",
       "      <td>0.882923</td>\n",
       "      <td>XGBClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>[X_Minimum, Pixels_Areas, X_Perimeter, Minimum...</td>\n",
       "      <td>0.879708</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18</td>\n",
       "      <td>[X_Minimum, Y_Minimum, Pixels_Areas, X_Perimet...</td>\n",
       "      <td>0.873584</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>[X_Minimum, Pixels_Areas, X_Perimeter, Minimum...</td>\n",
       "      <td>0.825518</td>\n",
       "      <td>BaggingClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>[X_Minimum, Pixels_Areas, X_Perimeter, Minimum...</td>\n",
       "      <td>0.768518</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    k                                  Selected Features  ROC AUC Score  \\\n",
       "6  14  [X_Minimum, Pixels_Areas, X_Perimeter, Minimum...       0.887207   \n",
       "0  16  [X_Minimum, Pixels_Areas, X_Perimeter, Minimum...       0.887172   \n",
       "1  12  [X_Minimum, Pixels_Areas, X_Perimeter, Minimum...       0.882923   \n",
       "2  17  [X_Minimum, Pixels_Areas, X_Perimeter, Minimum...       0.879708   \n",
       "5  18  [X_Minimum, Y_Minimum, Pixels_Areas, X_Perimet...       0.873584   \n",
       "4  13  [X_Minimum, Pixels_Areas, X_Perimeter, Minimum...       0.825518   \n",
       "3  16  [X_Minimum, Pixels_Areas, X_Perimeter, Minimum...       0.768518   \n",
       "\n",
       "                       Model Name  \n",
       "6  HistGradientBoostingClassifier  \n",
       "0                  LGBMClassifier  \n",
       "1                   XGBClassifier  \n",
       "2          RandomForestClassifier  \n",
       "5            ExtraTreesClassifier  \n",
       "4               BaggingClassifier  \n",
       "3              AdaBoostClassifier  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with LGBMClassifier\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 16 features.\n",
      "Done with LGBMClassifier\n",
      "\n",
      "Starting with XGBClassifier\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Done with XGBClassifier\n",
      "\n",
      "Starting with RandomForestClassifier\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Done with RandomForestClassifier\n",
      "\n",
      "Starting with AdaBoostClassifier\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Done with AdaBoostClassifier\n",
      "\n",
      "Starting with BaggingClassifier\n",
      "Fitting estimator with 13 features.\n",
      "BaggingClassifier does not have coef_ or feature_importances_\n",
      "\n",
      "Starting with ExtraTreesClassifier\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 18 features.\n",
      "Done with ExtraTreesClassifier\n",
      "\n",
      "Starting with HistGradientBoostingClassifier\n",
      "Fitting estimator with 14 features.\n",
      "HistGradientBoostingClassifier does not have coef_ or feature_importances_\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty dictionary for RFECV features\n",
    "rfecv_features = {}\n",
    "\n",
    "for alg in models:\n",
    "    # set name\n",
    "    MLA_name = alg.__class__.__name__\n",
    "\t\t\n",
    "    features = kbest_features[MLA_name]\n",
    "\n",
    "    # incase there is no feature that had importance, go to the next model\n",
    "    if len(features) == 0:\n",
    "        continue\n",
    "\t\n",
    "    X_rfecv = X[features]\n",
    "\n",
    "    try:\n",
    "        print(f'Starting with {MLA_name}')\n",
    "        # Create the RFECV object and rank each feature\n",
    "        selector = RFECV(alg, cv=sk10, step=1, scoring='roc_auc_ovr', verbose=2)\n",
    "        selector = selector.fit(X_rfecv, y)\n",
    "\n",
    "        selected_features = list(X_rfecv.columns[selector.support_])\n",
    "\n",
    "        rfecv_features[MLA_name] = selected_features\n",
    "\n",
    "        print(f'Done with {MLA_name}', end='\\n\\n')\n",
    "    \n",
    "    except ValueError:\n",
    "        rfecv_features[MLA_name] = features\n",
    "        print(f'{MLA_name} does not have coef_ or feature_importances_', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rfecv_features.txt', mode='w') as f:\n",
    "    pprint(rfecv_features, stream=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running backward feature selection with LGBMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:   49.0s remaining:   42.8s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.5min finished\n",
      "\n",
      "[2024-03-02 00:25:20] Features: 14/1 -- score: 0.8870751097766492[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  14 | elapsed:   46.4s remaining:   46.4s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:  1.4min finished\n",
      "\n",
      "[2024-03-02 00:26:44] Features: 13/1 -- score: 0.887115235751871[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  13 | elapsed:   44.2s remaining:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:  1.2min finished\n",
      "\n",
      "[2024-03-02 00:27:58] Features: 12/1 -- score: 0.8873020849825289[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  12 | elapsed:   41.4s remaining:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:  1.1min finished\n",
      "\n",
      "[2024-03-02 00:29:07] Features: 11/1 -- score: 0.8870705754648913[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  11 | elapsed:   37.7s remaining:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  11 | elapsed:   39.7s remaining:   14.8s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:   59.8s finished\n",
      "\n",
      "[2024-03-02 00:30:07] Features: 10/1 -- score: 0.8867356764869857[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:   37.1s remaining:   15.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   51.6s finished\n",
      "\n",
      "[2024-03-02 00:30:59] Features: 9/1 -- score: 0.8855417233037611[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:   34.9s remaining:   43.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   46.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   46.4s finished\n",
      "\n",
      "[2024-03-02 00:31:45] Features: 8/1 -- score: 0.8844036346512713[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   8 | elapsed:   32.3s remaining:   54.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   33.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   33.3s finished\n",
      "\n",
      "[2024-03-02 00:32:19] Features: 7/1 -- score: 0.8834000091962217[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   7 | elapsed:   27.5s remaining:   20.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:   27.7s finished\n",
      "\n",
      "[2024-03-02 00:32:47] Features: 6/1 -- score: 0.88056880828976[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:   23.0s remaining:   23.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:   23.3s finished\n",
      "\n",
      "[2024-03-02 00:33:10] Features: 5/1 -- score: 0.8773106523521494[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   19.1s remaining:   28.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   19.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   19.6s finished\n",
      "\n",
      "[2024-03-02 00:33:30] Features: 4/1 -- score: 0.8733282553282311[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   16.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   16.3s finished\n",
      "\n",
      "[2024-03-02 00:33:47] Features: 3/1 -- score: 0.8658345243779181[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   12.9s finished\n",
      "\n",
      "[2024-03-02 00:34:00] Features: 2/1 -- score: 0.8395497950957719[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:   10.3s finished\n",
      "\n",
      "[2024-03-02 00:34:10] Features: 1/1 -- score: 0.766626652046276"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with LGBMClassifier\n",
      "\n",
      "Running backward feature selection with XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  12 | elapsed:  4.3min remaining:  8.6min\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:  7.0min finished\n",
      "\n",
      "[2024-03-02 00:41:58] Features: 11/1 -- score: 0.883421611982761[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  11 | elapsed:  3.9min remaining: 17.5min\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  11 | elapsed:  4.1min remaining:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:  6.2min finished\n",
      "\n",
      "[2024-03-02 00:48:07] Features: 10/1 -- score: 0.8833993781694703[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:  3.9min remaining:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  5.5min finished\n",
      "\n",
      "[2024-03-02 00:53:40] Features: 9/1 -- score: 0.8822716646499149[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:  3.4min remaining:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:  4.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:  4.5min finished\n",
      "\n",
      "[2024-03-02 00:58:10] Features: 8/1 -- score: 0.8813442890125094[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   8 | elapsed:  3.1min remaining:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  3.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  3.2min finished\n",
      "\n",
      "[2024-03-02 01:01:20] Features: 7/1 -- score: 0.8798116442236342[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   7 | elapsed:  2.6min remaining:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:  2.7min finished\n",
      "\n",
      "[2024-03-02 01:04:00] Features: 6/1 -- score: 0.877283055648068[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:  2.1min remaining:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:  2.2min finished\n",
      "\n",
      "[2024-03-02 01:06:09] Features: 5/1 -- score: 0.8747616387934579[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.6min remaining:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.7min finished\n",
      "\n",
      "[2024-03-02 01:07:49] Features: 4/1 -- score: 0.8712399100104322[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  1.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  1.2min finished\n",
      "\n",
      "[2024-03-02 01:09:01] Features: 3/1 -- score: 0.8644231177585251[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   47.6s finished\n",
      "\n",
      "[2024-03-02 01:09:49] Features: 2/1 -- score: 0.8405907592866677[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:   29.5s finished\n",
      "\n",
      "[2024-03-02 01:10:18] Features: 1/1 -- score: 0.7666350546772307"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with XGBClassifier\n",
      "\n",
      "Running backward feature selection with RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  17 | elapsed:  3.7min remaining:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:  4.4min finished\n",
      "\n",
      "[2024-03-02 01:15:26] Features: 16/1 -- score: 0.8797427048587174[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  16 | elapsed:  3.0min remaining:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:  3.0min finished\n",
      "\n",
      "[2024-03-02 01:18:25] Features: 15/1 -- score: 0.8804682219369477[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:  1.6min remaining:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  2.9min finished\n",
      "\n",
      "[2024-03-02 01:21:16] Features: 14/1 -- score: 0.8803470642794707[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  14 | elapsed:  1.5min remaining:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:  2.6min finished\n",
      "\n",
      "[2024-03-02 01:23:52] Features: 13/1 -- score: 0.879614866418034[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  13 | elapsed:  1.4min remaining:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:  2.5min finished\n",
      "\n",
      "[2024-03-02 01:26:20] Features: 12/1 -- score: 0.8782531720214999[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  12 | elapsed:  1.4min remaining:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:  2.2min finished\n",
      "\n",
      "[2024-03-02 01:28:32] Features: 11/1 -- score: 0.8775660285583925[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  11 | elapsed:  1.2min remaining:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  11 | elapsed:  1.4min remaining:   30.7s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:  2.0min finished\n",
      "\n",
      "[2024-03-02 01:30:32] Features: 10/1 -- score: 0.8764878037117724[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:  1.4min remaining:   36.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  1.9min finished\n",
      "\n",
      "[2024-03-02 01:32:29] Features: 9/1 -- score: 0.8749003293821112[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:  1.1min remaining:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:  1.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:  1.4min finished\n",
      "\n",
      "[2024-03-02 01:33:56] Features: 8/1 -- score: 0.8732548447892544[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   8 | elapsed:  1.1min remaining:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.2min finished\n",
      "\n",
      "[2024-03-02 01:35:06] Features: 7/1 -- score: 0.8702324977536027[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   7 | elapsed:  1.0min remaining:   46.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:  1.1min finished\n",
      "\n",
      "[2024-03-02 01:36:10] Features: 6/1 -- score: 0.8637591268438307[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:   52.5s remaining:   52.5s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:   56.0s finished\n",
      "\n",
      "[2024-03-02 01:37:06] Features: 5/1 -- score: 0.8544879894669718[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   45.5s remaining:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   50.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   50.6s finished\n",
      "\n",
      "[2024-03-02 01:37:57] Features: 4/1 -- score: 0.8352833714742524[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   31.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   31.9s finished\n",
      "\n",
      "[2024-03-02 01:38:29] Features: 3/1 -- score: 0.8082840348838193[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   15.2s finished\n",
      "\n",
      "[2024-03-02 01:38:45] Features: 2/1 -- score: 0.8227411984170436[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    5.9s finished\n",
      "\n",
      "[2024-03-02 01:38:51] Features: 1/1 -- score: 0.7710380808168047"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with RandomForestClassifier\n",
      "\n",
      "Running backward feature selection with AdaBoostClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  14 | elapsed:   24.5s remaining:   24.5s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:   43.5s finished\n",
      "\n",
      "[2024-03-02 01:39:43] Features: 13/1 -- score: 0.7746782691501986[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  13 | elapsed:   22.3s remaining:   35.8s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:   39.1s finished\n",
      "\n",
      "[2024-03-02 01:40:23] Features: 12/1 -- score: 0.777839897389148[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  12 | elapsed:   20.9s remaining:   41.9s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:   36.1s finished\n",
      "\n",
      "[2024-03-02 01:40:59] Features: 11/1 -- score: 0.7885161951538457[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  11 | elapsed:   19.1s remaining:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  11 | elapsed:   20.5s remaining:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:   32.0s finished\n",
      "\n",
      "[2024-03-02 01:41:31] Features: 10/1 -- score: 0.788855696204536[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:   20.2s remaining:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   28.6s finished\n",
      "\n",
      "[2024-03-02 01:42:00] Features: 9/1 -- score: 0.788833841715072[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:   17.7s remaining:   22.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   23.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   23.9s finished\n",
      "\n",
      "[2024-03-02 01:42:24] Features: 8/1 -- score: 0.781379211857476[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   8 | elapsed:   16.5s remaining:   27.5s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   17.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   17.3s finished\n",
      "\n",
      "[2024-03-02 01:42:42] Features: 7/1 -- score: 0.7820032753824114[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   7 | elapsed:   14.0s remaining:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:   14.3s finished\n",
      "\n",
      "[2024-03-02 01:42:56] Features: 6/1 -- score: 0.7791857750136388[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:   11.9s remaining:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:   12.2s finished\n",
      "\n",
      "[2024-03-02 01:43:08] Features: 5/1 -- score: 0.7696349167583363[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   10.0s remaining:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   10.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   10.4s finished\n",
      "\n",
      "[2024-03-02 01:43:19] Features: 4/1 -- score: 0.7420178287223763[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    8.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    8.3s finished\n",
      "\n",
      "[2024-03-02 01:43:28] Features: 3/1 -- score: 0.7029603730376864[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    6.3s finished\n",
      "\n",
      "[2024-03-02 01:43:34] Features: 2/1 -- score: 0.7248884753599448[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    4.8s finished\n",
      "\n",
      "[2024-03-02 01:43:39] Features: 1/1 -- score: 0.6971442411122053"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with AdaBoostClassifier\n",
      "\n",
      "Running backward feature selection with BaggingClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  13 | elapsed:   26.2s remaining:   42.0s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:   46.0s finished\n",
      "\n",
      "[2024-03-02 01:44:36] Features: 12/1 -- score: 0.8267622282380757[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  12 | elapsed:   24.0s remaining:   48.2s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:   39.5s finished\n",
      "\n",
      "[2024-03-02 01:45:16] Features: 11/1 -- score: 0.8282774221645305[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  11 | elapsed:   22.0s remaining:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  11 | elapsed:   24.2s remaining:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:   36.3s finished\n",
      "\n",
      "[2024-03-02 01:45:53] Features: 10/1 -- score: 0.8265954353197271[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:   21.0s remaining:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   29.6s finished\n",
      "\n",
      "[2024-03-02 01:46:22] Features: 9/1 -- score: 0.8263685826687895[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:   19.6s remaining:   24.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   27.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   27.1s finished\n",
      "\n",
      "[2024-03-02 01:46:50] Features: 8/1 -- score: 0.8236348880623705[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   8 | elapsed:   16.5s remaining:   27.5s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   18.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   18.4s finished\n",
      "\n",
      "[2024-03-02 01:47:08] Features: 7/1 -- score: 0.8222965256180279[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   7 | elapsed:   13.3s remaining:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:   14.1s finished\n",
      "\n",
      "[2024-03-02 01:47:23] Features: 6/1 -- score: 0.815115705043724[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    9.2s remaining:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    9.9s finished\n",
      "\n",
      "[2024-03-02 01:47:33] Features: 5/1 -- score: 0.8072210607271204[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    6.7s remaining:   10.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    8.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    8.0s finished\n",
      "\n",
      "[2024-03-02 01:47:41] Features: 4/1 -- score: 0.7981137696321979[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    5.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    5.4s finished\n",
      "\n",
      "[2024-03-02 01:47:47] Features: 3/1 -- score: 0.7841094472201694[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.7s finished\n",
      "\n",
      "[2024-03-02 01:47:49] Features: 2/1 -- score: 0.8207096586592412[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.5s finished\n",
      "\n",
      "[2024-03-02 01:47:50] Features: 1/1 -- score: 0.7705611686497408"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with BaggingClassifier\n",
      "\n",
      "Running backward feature selection with ExtraTreesClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  17 | elapsed:  2.4min remaining:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:  2.8min finished\n",
      "\n",
      "[2024-03-02 01:51:06] Features: 16/1 -- score: 0.8768819908862158[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  16 | elapsed:  2.1min remaining:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:  2.3min finished\n",
      "\n",
      "[2024-03-02 01:53:21] Features: 15/1 -- score: 0.8754591346614913[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:  1.2min remaining:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  2.1min finished\n",
      "\n",
      "[2024-03-02 01:55:28] Features: 14/1 -- score: 0.8753157290320731[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  14 | elapsed:  1.2min remaining:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:  2.0min finished\n",
      "\n",
      "[2024-03-02 01:57:29] Features: 13/1 -- score: 0.8759099809794483[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  13 | elapsed:  1.1min remaining:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:  1.9min finished\n",
      "\n",
      "[2024-03-02 01:59:23] Features: 12/1 -- score: 0.874046402820564[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  12 | elapsed:  1.1min remaining:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:  1.8min finished\n",
      "\n",
      "[2024-03-02 02:01:11] Features: 11/1 -- score: 0.87451771518872[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  11 | elapsed:  1.0min remaining:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  11 | elapsed:  1.2min remaining:   26.2s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:  1.7min finished\n",
      "\n",
      "[2024-03-02 02:02:51] Features: 10/1 -- score: 0.873611316021147[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:  1.1min remaining:   29.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  1.6min finished\n",
      "\n",
      "[2024-03-02 02:04:24] Features: 9/1 -- score: 0.8721842014288411[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:  1.0min remaining:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:  1.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:  1.4min finished\n",
      "\n",
      "[2024-03-02 02:05:46] Features: 8/1 -- score: 0.8703734641331827[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   8 | elapsed:   56.6s remaining:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  1.0min finished\n",
      "\n",
      "[2024-03-02 02:06:48] Features: 7/1 -- score: 0.8664770561846931[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   7 | elapsed:   52.4s remaining:   39.3s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:   54.6s finished\n",
      "\n",
      "[2024-03-02 02:07:42] Features: 6/1 -- score: 0.8606169188270586[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:   46.8s remaining:   46.8s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:   48.1s finished\n",
      "\n",
      "[2024-03-02 02:08:31] Features: 5/1 -- score: 0.850199536464147[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   40.2s remaining:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   42.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   42.7s finished\n",
      "\n",
      "[2024-03-02 02:09:14] Features: 4/1 -- score: 0.8273169503173875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   32.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   32.7s finished\n",
      "\n",
      "[2024-03-02 02:09:47] Features: 3/1 -- score: 0.7855304662671708[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   24.0s finished\n",
      "\n",
      "[2024-03-02 02:10:11] Features: 2/1 -- score: 0.7280405309394976[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    9.2s finished\n",
      "\n",
      "[2024-03-02 02:10:20] Features: 1/1 -- score: 0.7709319294981533"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with ExtraTreesClassifier\n",
      "\n",
      "Running backward feature selection with HistGradientBoostingClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  14 | elapsed:   53.0s remaining:   53.0s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:  1.6min finished\n",
      "\n",
      "[2024-03-02 02:12:32] Features: 13/1 -- score: 0.8870079776406999[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  13 | elapsed:   50.0s remaining:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:  1.4min finished\n",
      "\n",
      "[2024-03-02 02:13:58] Features: 12/1 -- score: 0.887019597723242[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  12 | elapsed:   47.9s remaining:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:  1.3min finished\n",
      "\n",
      "[2024-03-02 02:15:16] Features: 11/1 -- score: 0.8877296602336584[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  11 | elapsed:   44.7s remaining:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  11 | elapsed:   48.0s remaining:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:  1.2min finished\n",
      "\n",
      "[2024-03-02 02:16:25] Features: 10/1 -- score: 0.8869711080124267[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:   44.6s remaining:   19.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  1.1min finished\n",
      "\n",
      "[2024-03-02 02:17:29] Features: 9/1 -- score: 0.8859484528182324[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:   42.0s remaining:   52.5s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   55.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   55.8s finished\n",
      "\n",
      "[2024-03-02 02:18:25] Features: 8/1 -- score: 0.8854547204232721[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   8 | elapsed:   39.2s remaining:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   41.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   41.0s finished\n",
      "\n",
      "[2024-03-02 02:19:06] Features: 7/1 -- score: 0.8839266327766457[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   7 | elapsed:   34.8s remaining:   26.1s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:   35.7s finished\n",
      "\n",
      "[2024-03-02 02:19:42] Features: 6/1 -- score: 0.8819636350965411[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:   28.7s remaining:   28.7s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:   29.8s finished\n",
      "\n",
      "[2024-03-02 02:20:12] Features: 5/1 -- score: 0.8786869414866869[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   23.5s remaining:   35.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   24.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   24.7s finished\n",
      "\n",
      "[2024-03-02 02:20:37] Features: 4/1 -- score: 0.8745333371331003[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   19.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   19.8s finished\n",
      "\n",
      "[2024-03-02 02:20:57] Features: 3/1 -- score: 0.8678682952614427[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   16.5s finished\n",
      "\n",
      "[2024-03-02 02:21:14] Features: 2/1 -- score: 0.842790090802653[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with HistGradientBoostingClassifier\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:   12.2s finished\n",
      "\n",
      "[2024-03-02 02:21:26] Features: 1/1 -- score: 0.7665165683344928"
     ]
    }
   ],
   "source": [
    "# Initialize empty dictionary for SFS features\n",
    "sfs_features = {}\n",
    "\n",
    "for alg in models:\n",
    "    # set name\n",
    "    MLA_name = alg.__class__.__name__\n",
    "\n",
    "    try:\n",
    "            \n",
    "        features = rfecv_features[MLA_name]\n",
    "        # features = feat_importance_features[MLA_name]\n",
    "\n",
    "        # incase there is no feature that had importance, go to the next model\n",
    "        if len(features) == 0:\n",
    "            continue\n",
    "        \n",
    "        X_sfs = X[features]\n",
    "\n",
    "        print(f'Running backward feature selection with {MLA_name}')\n",
    "\n",
    "        sfs = SFS(alg,\n",
    "            k_features='best',\n",
    "            forward=False,\n",
    "            floating=False,\n",
    "            scoring='roc_auc_ovr',\n",
    "            verbose=2,\n",
    "            n_jobs=-1,\n",
    "            cv=sk10)\n",
    "        \n",
    "        sfs = sfs.fit(X_sfs, y)\n",
    "\n",
    "        # Get the selected features index\n",
    "        selected_sfs_idx = list(sfs.k_feature_idx_)\n",
    "\n",
    "        # Get the feature names\n",
    "        selected_sfs_feats = X_sfs.columns[selected_sfs_idx]\n",
    "\n",
    "        sfs_features[MLA_name] = list(selected_sfs_feats)\n",
    "\n",
    "        print(f'Done with {MLA_name}', end='\\n\\n')\n",
    "\n",
    "    except KeyError:\n",
    "        print(f'{MLA_name} not in the dictionary.')\n",
    "\n",
    "# LGBM 12 features - 0.8874701640374246"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sfs_features.txt', mode='w') as f:\n",
    "    pprint(sfs_features, stream=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models_roc(models, X, y, important_features, cv_split, experiment_name):\n",
    "    MLA_compare = pd.DataFrame(columns=['MLA Name', \n",
    "                                        'MLA Parameters', \n",
    "                                        'MLA Train ROC AUC', \n",
    "                                        'MLA Test ROC AUC', \n",
    "                                        'MLA Test ROC AUC Std', \n",
    "                                        'MLA Time'])\n",
    "    \n",
    "    def evaluate_model(alg, idx):\n",
    "        MLA_name = alg.__class__.__name__\n",
    "        features = important_features.get(MLA_name, [])\n",
    "\n",
    "        # Check if the list of important features is empty\n",
    "        if len(features) == 0:\n",
    "            # If empty, return results with zero values\n",
    "            print(f'Skipping {MLA_name} due to no important features.')\n",
    "            return {\n",
    "                'MLA Name': MLA_name,\n",
    "                'MLA Parameters': str(alg.get_params()),\n",
    "                'MLA Train ROC': 0,\n",
    "                'MLA Test ROC': 0,\n",
    "                'MLA Test ROC Std': 0,\n",
    "                'MLA Time': \"0 min 0.00 sec\",\n",
    "            }\n",
    "        \n",
    "        cv_results = cross_validate(alg, \n",
    "                                    X[features], \n",
    "                                    y, cv=cv_split, \n",
    "                                    scoring='roc_auc_ovr', \n",
    "                                    return_train_score=True, \n",
    "                                    n_jobs=-1)\n",
    "\n",
    "        # Time formatting\n",
    "        mean_fit_time = cv_results['fit_time'].mean()\n",
    "        minutes, seconds = divmod(mean_fit_time, 60)\n",
    "\n",
    "        # Results population\n",
    "        result = {\n",
    "            'MLA Name': MLA_name,\n",
    "            'MLA Parameters': str(alg.get_params()),\n",
    "            'MLA Train ROC AUC': cv_results['train_score'].mean(),\n",
    "            'MLA Test ROC AUC': cv_results['test_score'].mean(),\n",
    "            'MLA Test ROC AUC Std': cv_results['test_score'].std(),\n",
    "            'MLA Time': f\"{int(minutes)} min {seconds:.2f} sec\",\n",
    "        }\n",
    "\n",
    "        print(f'Done with {MLA_name}.')\n",
    "        return result\n",
    "\n",
    "    results_list = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = [executor.submit(evaluate_model, alg, idx) for idx, alg in enumerate(models)]\n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            results_list.append(result)\n",
    "\n",
    "    MLA_compare = pd.DataFrame(results_list)\n",
    "\n",
    "    MLA_compare.sort_values(by=['MLA Test ROC AUC'], ascending=False, inplace=True)\n",
    "    MLA_compare.to_csv(f'{experiment_name}_results.csv', index=False)\n",
    "\n",
    "    return MLA_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_features = {}\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "\n",
    "    baseline_features[model_name] = list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with LGBMClassifier.\n",
      "Done with BaggingClassifier.\n",
      "Done with AdaBoostClassifier.\n",
      "Done with RandomForestClassifier.\n",
      "Done with ExtraTreesClassifier.\n",
      "Done with HistGradientBoostingClassifier.\n",
      "Done with XGBClassifier.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Parameters</th>\n",
       "      <th>MLA Train ROC AUC</th>\n",
       "      <th>MLA Test ROC AUC</th>\n",
       "      <th>MLA Test ROC AUC Std</th>\n",
       "      <th>MLA Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>{'categorical_features': None, 'early_stopping...</td>\n",
       "      <td>0.960699</td>\n",
       "      <td>0.886802</td>\n",
       "      <td>0.002795</td>\n",
       "      <td>0 min 7.20 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>0.984409</td>\n",
       "      <td>0.886012</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>0 min 7.73 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>{'objective': 'multi:softprob', 'use_label_enc...</td>\n",
       "      <td>0.994039</td>\n",
       "      <td>0.881990</td>\n",
       "      <td>0.003418</td>\n",
       "      <td>1 min 2.28 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.877453</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>0 min 16.49 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.872837</td>\n",
       "      <td>0.002675</td>\n",
       "      <td>0 min 8.35 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
       "      <td>0.999629</td>\n",
       "      <td>0.823856</td>\n",
       "      <td>0.005831</td>\n",
       "      <td>0 min 7.69 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>0.759459</td>\n",
       "      <td>0.756858</td>\n",
       "      <td>0.012197</td>\n",
       "      <td>0 min 3.93 sec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         MLA Name  \\\n",
       "6  HistGradientBoostingClassifier   \n",
       "0                  LGBMClassifier   \n",
       "1                   XGBClassifier   \n",
       "2          RandomForestClassifier   \n",
       "5            ExtraTreesClassifier   \n",
       "4               BaggingClassifier   \n",
       "3              AdaBoostClassifier   \n",
       "\n",
       "                                      MLA Parameters  MLA Train ROC AUC  \\\n",
       "6  {'categorical_features': None, 'early_stopping...           0.960699   \n",
       "0  {'boosting_type': 'gbdt', 'class_weight': None...           0.984409   \n",
       "1  {'objective': 'multi:softprob', 'use_label_enc...           0.994039   \n",
       "2  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...           0.999999   \n",
       "5  {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...           0.999999   \n",
       "4  {'base_estimator': None, 'bootstrap': True, 'b...           0.999629   \n",
       "3  {'algorithm': 'SAMME.R', 'base_estimator': Non...           0.759459   \n",
       "\n",
       "   MLA Test ROC AUC  MLA Test ROC AUC Std         MLA Time  \n",
       "6          0.886802              0.002795   0 min 7.20 sec  \n",
       "0          0.886012              0.002457   0 min 7.73 sec  \n",
       "1          0.881990              0.003418   1 min 2.28 sec  \n",
       "2          0.877453              0.002847  0 min 16.49 sec  \n",
       "5          0.872837              0.002675   0 min 8.35 sec  \n",
       "4          0.823856              0.005831   0 min 7.69 sec  \n",
       "3          0.756858              0.012197   0 min 3.93 sec  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_models = evaluate_models_roc(models, X, y, baseline_features, sk10, experiment_name)\n",
    "baseline_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_corr_features = {}\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "\n",
    "    no_corr_features[model_name] = list(df_reduced_spear.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with RandomForestClassifier.\n",
      "Done with AdaBoostClassifier.\n",
      "Done with HistGradientBoostingClassifier.\n",
      "Done with ExtraTreesClassifier.\n",
      "Done with XGBClassifier.\n",
      "Done with LGBMClassifier.\n",
      "Done with BaggingClassifier.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Parameters</th>\n",
       "      <th>MLA Train ROC AUC</th>\n",
       "      <th>MLA Test ROC AUC</th>\n",
       "      <th>MLA Test ROC AUC Std</th>\n",
       "      <th>MLA Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>{'categorical_features': None, 'early_stopping...</td>\n",
       "      <td>0.958243</td>\n",
       "      <td>0.887165</td>\n",
       "      <td>0.002962</td>\n",
       "      <td>0 min 5.79 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>0.982443</td>\n",
       "      <td>0.885717</td>\n",
       "      <td>0.002586</td>\n",
       "      <td>0 min 5.66 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>{'objective': 'multi:softprob', 'use_label_enc...</td>\n",
       "      <td>0.992867</td>\n",
       "      <td>0.882526</td>\n",
       "      <td>0.002277</td>\n",
       "      <td>0 min 43.38 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.879269</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>0 min 12.82 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.873584</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0 min 7.14 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
       "      <td>0.999626</td>\n",
       "      <td>0.824220</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>0 min 4.76 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>0.765191</td>\n",
       "      <td>0.761636</td>\n",
       "      <td>0.013790</td>\n",
       "      <td>0 min 2.89 sec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         MLA Name  \\\n",
       "6  HistGradientBoostingClassifier   \n",
       "0                  LGBMClassifier   \n",
       "1                   XGBClassifier   \n",
       "2          RandomForestClassifier   \n",
       "5            ExtraTreesClassifier   \n",
       "4               BaggingClassifier   \n",
       "3              AdaBoostClassifier   \n",
       "\n",
       "                                      MLA Parameters  MLA Train ROC AUC  \\\n",
       "6  {'categorical_features': None, 'early_stopping...           0.958243   \n",
       "0  {'boosting_type': 'gbdt', 'class_weight': None...           0.982443   \n",
       "1  {'objective': 'multi:softprob', 'use_label_enc...           0.992867   \n",
       "2  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...           0.999999   \n",
       "5  {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...           0.999999   \n",
       "4  {'base_estimator': None, 'bootstrap': True, 'b...           0.999626   \n",
       "3  {'algorithm': 'SAMME.R', 'base_estimator': Non...           0.765191   \n",
       "\n",
       "   MLA Test ROC AUC  MLA Test ROC AUC Std         MLA Time  \n",
       "6          0.887165              0.002962   0 min 5.79 sec  \n",
       "0          0.885717              0.002586   0 min 5.66 sec  \n",
       "1          0.882526              0.002277  0 min 43.38 sec  \n",
       "2          0.879269              0.001812  0 min 12.82 sec  \n",
       "5          0.873584              0.003030   0 min 7.14 sec  \n",
       "4          0.824220              0.003279   0 min 4.76 sec  \n",
       "3          0.761636              0.013790   0 min 2.89 sec  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_corr_models = evaluate_models_roc(models, df_reduced_spear, y, no_corr_features, sk10, f'{experiment_name}_corr')\n",
    "no_corr_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with AdaBoostClassifier.\n",
      "Done with HistGradientBoostingClassifier.\n",
      "Done with BaggingClassifier.\n",
      "Done with LGBMClassifier.\n",
      "Done with ExtraTreesClassifier.\n",
      "Done with RandomForestClassifier.\n",
      "Done with XGBClassifier.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Parameters</th>\n",
       "      <th>MLA Train ROC AUC</th>\n",
       "      <th>MLA Test ROC AUC</th>\n",
       "      <th>MLA Test ROC AUC Std</th>\n",
       "      <th>MLA Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>{'categorical_features': None, 'early_stopping...</td>\n",
       "      <td>0.958243</td>\n",
       "      <td>0.887165</td>\n",
       "      <td>0.002962</td>\n",
       "      <td>0 min 5.92 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>0.982300</td>\n",
       "      <td>0.885443</td>\n",
       "      <td>0.002803</td>\n",
       "      <td>0 min 5.58 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>{'objective': 'multi:softprob', 'use_label_enc...</td>\n",
       "      <td>0.992826</td>\n",
       "      <td>0.881240</td>\n",
       "      <td>0.002708</td>\n",
       "      <td>0 min 38.88 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.878704</td>\n",
       "      <td>0.003609</td>\n",
       "      <td>0 min 12.36 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.872309</td>\n",
       "      <td>0.002279</td>\n",
       "      <td>0 min 7.13 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
       "      <td>0.999626</td>\n",
       "      <td>0.824220</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>0 min 4.81 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>0.765191</td>\n",
       "      <td>0.761636</td>\n",
       "      <td>0.013790</td>\n",
       "      <td>0 min 2.87 sec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         MLA Name  \\\n",
       "6  HistGradientBoostingClassifier   \n",
       "0                  LGBMClassifier   \n",
       "1                   XGBClassifier   \n",
       "2          RandomForestClassifier   \n",
       "5            ExtraTreesClassifier   \n",
       "4               BaggingClassifier   \n",
       "3              AdaBoostClassifier   \n",
       "\n",
       "                                      MLA Parameters  MLA Train ROC AUC  \\\n",
       "6  {'categorical_features': None, 'early_stopping...           0.958243   \n",
       "0  {'boosting_type': 'gbdt', 'class_weight': None...           0.982300   \n",
       "1  {'objective': 'multi:softprob', 'use_label_enc...           0.992826   \n",
       "2  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...           0.999999   \n",
       "5  {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...           0.999999   \n",
       "4  {'base_estimator': None, 'bootstrap': True, 'b...           0.999626   \n",
       "3  {'algorithm': 'SAMME.R', 'base_estimator': Non...           0.765191   \n",
       "\n",
       "   MLA Test ROC AUC  MLA Test ROC AUC Std         MLA Time  \n",
       "6          0.887165              0.002962   0 min 5.92 sec  \n",
       "0          0.885443              0.002803   0 min 5.58 sec  \n",
       "1          0.881240              0.002708  0 min 38.88 sec  \n",
       "2          0.878704              0.003609  0 min 12.36 sec  \n",
       "5          0.872309              0.002279   0 min 7.13 sec  \n",
       "4          0.824220              0.003279   0 min 4.81 sec  \n",
       "3          0.761636              0.013790   0 min 2.87 sec  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "feat_importance_models = evaluate_models_roc(models, X, y, feat_importance_features, sk10, f'{experiment_name}_featimp')\n",
    "feat_importance_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with ExtraTreesClassifier.\n",
      "Done with AdaBoostClassifier.\n",
      "Done with XGBClassifier.\n",
      "Done with BaggingClassifier.\n",
      "Done with LGBMClassifier.\n",
      "Done with HistGradientBoostingClassifier.\n",
      "Done with RandomForestClassifier.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Parameters</th>\n",
       "      <th>MLA Train ROC AUC</th>\n",
       "      <th>MLA Test ROC AUC</th>\n",
       "      <th>MLA Test ROC AUC Std</th>\n",
       "      <th>MLA Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>{'categorical_features': None, 'early_stopping...</td>\n",
       "      <td>0.955614</td>\n",
       "      <td>0.887207</td>\n",
       "      <td>0.003033</td>\n",
       "      <td>0 min 5.31 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>0.980523</td>\n",
       "      <td>0.887172</td>\n",
       "      <td>0.003243</td>\n",
       "      <td>0 min 5.06 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>{'objective': 'multi:softprob', 'use_label_enc...</td>\n",
       "      <td>0.986529</td>\n",
       "      <td>0.882923</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>0 min 28.26 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.879708</td>\n",
       "      <td>0.003137</td>\n",
       "      <td>0 min 11.56 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.873584</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0 min 6.88 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
       "      <td>0.999590</td>\n",
       "      <td>0.825518</td>\n",
       "      <td>0.007205</td>\n",
       "      <td>0 min 3.11 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>0.771378</td>\n",
       "      <td>0.768518</td>\n",
       "      <td>0.015698</td>\n",
       "      <td>0 min 2.68 sec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         MLA Name  \\\n",
       "6  HistGradientBoostingClassifier   \n",
       "0                  LGBMClassifier   \n",
       "1                   XGBClassifier   \n",
       "2          RandomForestClassifier   \n",
       "5            ExtraTreesClassifier   \n",
       "4               BaggingClassifier   \n",
       "3              AdaBoostClassifier   \n",
       "\n",
       "                                      MLA Parameters  MLA Train ROC AUC  \\\n",
       "6  {'categorical_features': None, 'early_stopping...           0.955614   \n",
       "0  {'boosting_type': 'gbdt', 'class_weight': None...           0.980523   \n",
       "1  {'objective': 'multi:softprob', 'use_label_enc...           0.986529   \n",
       "2  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...           0.999999   \n",
       "5  {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...           0.999999   \n",
       "4  {'base_estimator': None, 'bootstrap': True, 'b...           0.999590   \n",
       "3  {'algorithm': 'SAMME.R', 'base_estimator': Non...           0.771378   \n",
       "\n",
       "   MLA Test ROC AUC  MLA Test ROC AUC Std         MLA Time  \n",
       "6          0.887207              0.003033   0 min 5.31 sec  \n",
       "0          0.887172              0.003243   0 min 5.06 sec  \n",
       "1          0.882923              0.003383  0 min 28.26 sec  \n",
       "2          0.879708              0.003137  0 min 11.56 sec  \n",
       "5          0.873584              0.003030   0 min 6.88 sec  \n",
       "4          0.825518              0.007205   0 min 3.11 sec  \n",
       "3          0.768518              0.015698   0 min 2.68 sec  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "kbest_models = evaluate_models_roc(models, X, y, kbest_features, sk10, f'{experiment_name}_kbest')\n",
    "kbest_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with LGBMClassifier.\n",
      "Done with XGBClassifier.\n",
      "Done with ExtraTreesClassifier.\n",
      "Done with HistGradientBoostingClassifier.\n",
      "Done with BaggingClassifier.\n",
      "Done with RandomForestClassifier.\n",
      "Done with AdaBoostClassifier.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Parameters</th>\n",
       "      <th>MLA Train ROC AUC</th>\n",
       "      <th>MLA Test ROC AUC</th>\n",
       "      <th>MLA Test ROC AUC Std</th>\n",
       "      <th>MLA Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>0.980453</td>\n",
       "      <td>0.887673</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>0 min 5.00 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>{'categorical_features': None, 'early_stopping...</td>\n",
       "      <td>0.955614</td>\n",
       "      <td>0.887207</td>\n",
       "      <td>0.003033</td>\n",
       "      <td>0 min 4.94 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>{'objective': 'multi:softprob', 'use_label_enc...</td>\n",
       "      <td>0.986529</td>\n",
       "      <td>0.882923</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>0 min 28.09 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.879708</td>\n",
       "      <td>0.003137</td>\n",
       "      <td>0 min 11.66 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.874068</td>\n",
       "      <td>0.004031</td>\n",
       "      <td>0 min 6.92 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
       "      <td>0.999590</td>\n",
       "      <td>0.825518</td>\n",
       "      <td>0.007205</td>\n",
       "      <td>0 min 2.94 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>0.772502</td>\n",
       "      <td>0.770144</td>\n",
       "      <td>0.016261</td>\n",
       "      <td>0 min 2.26 sec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         MLA Name  \\\n",
       "0                  LGBMClassifier   \n",
       "6  HistGradientBoostingClassifier   \n",
       "1                   XGBClassifier   \n",
       "2          RandomForestClassifier   \n",
       "5            ExtraTreesClassifier   \n",
       "4               BaggingClassifier   \n",
       "3              AdaBoostClassifier   \n",
       "\n",
       "                                      MLA Parameters  MLA Train ROC AUC  \\\n",
       "0  {'boosting_type': 'gbdt', 'class_weight': None...           0.980453   \n",
       "6  {'categorical_features': None, 'early_stopping...           0.955614   \n",
       "1  {'objective': 'multi:softprob', 'use_label_enc...           0.986529   \n",
       "2  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...           0.999999   \n",
       "5  {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...           0.999999   \n",
       "4  {'base_estimator': None, 'bootstrap': True, 'b...           0.999590   \n",
       "3  {'algorithm': 'SAMME.R', 'base_estimator': Non...           0.772502   \n",
       "\n",
       "   MLA Test ROC AUC  MLA Test ROC AUC Std         MLA Time  \n",
       "0          0.887673              0.003201   0 min 5.00 sec  \n",
       "6          0.887207              0.003033   0 min 4.94 sec  \n",
       "1          0.882923              0.003383  0 min 28.09 sec  \n",
       "2          0.879708              0.003137  0 min 11.66 sec  \n",
       "5          0.874068              0.004031   0 min 6.92 sec  \n",
       "4          0.825518              0.007205   0 min 2.94 sec  \n",
       "3          0.770144              0.016261   0 min 2.26 sec  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "rfecv_models = evaluate_models_roc(models, X, y, rfecv_features, sk10, f'{experiment_name}_rfecv')\n",
    "rfecv_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with AdaBoostClassifier.\n",
      "Done with HistGradientBoostingClassifier.\n",
      "Done with XGBClassifier.\n",
      "Done with RandomForestClassifier.\n",
      "Done with BaggingClassifier.\n",
      "Done with ExtraTreesClassifier.\n",
      "Done with LGBMClassifier.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Parameters</th>\n",
       "      <th>MLA Train ROC AUC</th>\n",
       "      <th>MLA Test ROC AUC</th>\n",
       "      <th>MLA Test ROC AUC Std</th>\n",
       "      <th>MLA Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>{'categorical_features': None, 'early_stopping...</td>\n",
       "      <td>0.953919</td>\n",
       "      <td>0.887730</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0 min 4.63 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>0.980453</td>\n",
       "      <td>0.887673</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>0 min 4.70 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>{'objective': 'multi:softprob', 'use_label_enc...</td>\n",
       "      <td>0.985274</td>\n",
       "      <td>0.883422</td>\n",
       "      <td>0.003786</td>\n",
       "      <td>0 min 26.03 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.880468</td>\n",
       "      <td>0.002408</td>\n",
       "      <td>0 min 9.03 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.876882</td>\n",
       "      <td>0.003447</td>\n",
       "      <td>0 min 6.89 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
       "      <td>0.999592</td>\n",
       "      <td>0.828277</td>\n",
       "      <td>0.004752</td>\n",
       "      <td>0 min 2.78 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>0.791082</td>\n",
       "      <td>0.788856</td>\n",
       "      <td>0.006228</td>\n",
       "      <td>0 min 1.87 sec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         MLA Name  \\\n",
       "6  HistGradientBoostingClassifier   \n",
       "0                  LGBMClassifier   \n",
       "1                   XGBClassifier   \n",
       "2          RandomForestClassifier   \n",
       "5            ExtraTreesClassifier   \n",
       "4               BaggingClassifier   \n",
       "3              AdaBoostClassifier   \n",
       "\n",
       "                                      MLA Parameters  MLA Train ROC AUC  \\\n",
       "6  {'categorical_features': None, 'early_stopping...           0.953919   \n",
       "0  {'boosting_type': 'gbdt', 'class_weight': None...           0.980453   \n",
       "1  {'objective': 'multi:softprob', 'use_label_enc...           0.985274   \n",
       "2  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...           0.999999   \n",
       "5  {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...           0.999999   \n",
       "4  {'base_estimator': None, 'bootstrap': True, 'b...           0.999592   \n",
       "3  {'algorithm': 'SAMME.R', 'base_estimator': Non...           0.791082   \n",
       "\n",
       "   MLA Test ROC AUC  MLA Test ROC AUC Std         MLA Time  \n",
       "6          0.887730              0.002992   0 min 4.63 sec  \n",
       "0          0.887673              0.003201   0 min 4.70 sec  \n",
       "1          0.883422              0.003786  0 min 26.03 sec  \n",
       "2          0.880468              0.002408   0 min 9.03 sec  \n",
       "5          0.876882              0.003447   0 min 6.89 sec  \n",
       "4          0.828277              0.004752   0 min 2.78 sec  \n",
       "3          0.788856              0.006228   0 min 1.87 sec  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "sfs_models = evaluate_models_roc(models, X, y, sfs_features, sk10, f'{experiment_name}_sfs')\n",
    "sfs_models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
