{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.feature_selection import RFECV, SelectKBest, f_classif\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from pprint import pprint\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "experiment_name = 'multi-models_with_original_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "original = pd.read_csv('Fault.csv', delimiter='\\t')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19219, 35), (1940, 34), (12814, 28))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, original.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_Minimum</th>\n",
       "      <th>X_Maximum</th>\n",
       "      <th>Y_Minimum</th>\n",
       "      <th>Y_Maximum</th>\n",
       "      <th>Pixels_Areas</th>\n",
       "      <th>X_Perimeter</th>\n",
       "      <th>Y_Perimeter</th>\n",
       "      <th>Sum_of_Luminosity</th>\n",
       "      <th>Minimum_of_Luminosity</th>\n",
       "      <th>Maximum_of_Luminosity</th>\n",
       "      <th>Length_of_Conveyer</th>\n",
       "      <th>TypeOfSteel_A300</th>\n",
       "      <th>TypeOfSteel_A400</th>\n",
       "      <th>Steel_Plate_Thickness</th>\n",
       "      <th>Edges_Index</th>\n",
       "      <th>Empty_Index</th>\n",
       "      <th>Square_Index</th>\n",
       "      <th>Outside_X_Index</th>\n",
       "      <th>Edges_X_Index</th>\n",
       "      <th>Edges_Y_Index</th>\n",
       "      <th>Outside_Global_Index</th>\n",
       "      <th>LogOfAreas</th>\n",
       "      <th>Log_X_Index</th>\n",
       "      <th>Log_Y_Index</th>\n",
       "      <th>Orientation_Index</th>\n",
       "      <th>Luminosity_Index</th>\n",
       "      <th>SigmoidOfAreas</th>\n",
       "      <th>Pastry</th>\n",
       "      <th>Z_Scratch</th>\n",
       "      <th>K_Scatch</th>\n",
       "      <th>Stains</th>\n",
       "      <th>Dirtiness</th>\n",
       "      <th>Bumps</th>\n",
       "      <th>Other_Faults</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>584</td>\n",
       "      <td>590</td>\n",
       "      <td>909972</td>\n",
       "      <td>909977</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2274</td>\n",
       "      <td>113</td>\n",
       "      <td>140</td>\n",
       "      <td>1358</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.7393</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2041</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>0.6990</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>-0.0104</td>\n",
       "      <td>0.1417</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>808</td>\n",
       "      <td>816</td>\n",
       "      <td>728350</td>\n",
       "      <td>728372</td>\n",
       "      <td>433</td>\n",
       "      <td>20</td>\n",
       "      <td>54</td>\n",
       "      <td>44478</td>\n",
       "      <td>70</td>\n",
       "      <td>111</td>\n",
       "      <td>1687</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0.7772</td>\n",
       "      <td>0.2878</td>\n",
       "      <td>0.2581</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6365</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>1.7324</td>\n",
       "      <td>0.7419</td>\n",
       "      <td>-0.2997</td>\n",
       "      <td>0.9491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>192</td>\n",
       "      <td>2212076</td>\n",
       "      <td>2212144</td>\n",
       "      <td>11388</td>\n",
       "      <td>705</td>\n",
       "      <td>420</td>\n",
       "      <td>1311391</td>\n",
       "      <td>29</td>\n",
       "      <td>141</td>\n",
       "      <td>1400</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.5282</td>\n",
       "      <td>0.9895</td>\n",
       "      <td>0.1077</td>\n",
       "      <td>0.2363</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0564</td>\n",
       "      <td>2.1790</td>\n",
       "      <td>2.2095</td>\n",
       "      <td>-0.0105</td>\n",
       "      <td>-0.0944</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>781</td>\n",
       "      <td>789</td>\n",
       "      <td>3353146</td>\n",
       "      <td>3353173</td>\n",
       "      <td>210</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>3202</td>\n",
       "      <td>114</td>\n",
       "      <td>134</td>\n",
       "      <td>1387</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.7202</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.9310</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.3222</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>1.4314</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>-0.0402</td>\n",
       "      <td>0.4025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1540</td>\n",
       "      <td>1560</td>\n",
       "      <td>618457</td>\n",
       "      <td>618502</td>\n",
       "      <td>521</td>\n",
       "      <td>72</td>\n",
       "      <td>67</td>\n",
       "      <td>48231</td>\n",
       "      <td>82</td>\n",
       "      <td>111</td>\n",
       "      <td>1692</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>0.1211</td>\n",
       "      <td>0.5347</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.9861</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.7694</td>\n",
       "      <td>1.4150</td>\n",
       "      <td>1.8808</td>\n",
       "      <td>0.9158</td>\n",
       "      <td>-0.2455</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X_Minimum  X_Maximum  Y_Minimum  Y_Maximum  Pixels_Areas  X_Perimeter  \\\n",
       "0        584        590     909972     909977            16            8   \n",
       "1        808        816     728350     728372           433           20   \n",
       "2         39        192    2212076    2212144         11388          705   \n",
       "3        781        789    3353146    3353173           210           16   \n",
       "4       1540       1560     618457     618502           521           72   \n",
       "\n",
       "   Y_Perimeter  Sum_of_Luminosity  Minimum_of_Luminosity  \\\n",
       "0            5               2274                    113   \n",
       "1           54              44478                     70   \n",
       "2          420            1311391                     29   \n",
       "3           29               3202                    114   \n",
       "4           67              48231                     82   \n",
       "\n",
       "   Maximum_of_Luminosity  Length_of_Conveyer  TypeOfSteel_A300  \\\n",
       "0                    140                1358                 0   \n",
       "1                    111                1687                 1   \n",
       "2                    141                1400                 0   \n",
       "3                    134                1387                 0   \n",
       "4                    111                1692                 0   \n",
       "\n",
       "   TypeOfSteel_A400  Steel_Plate_Thickness  Edges_Index  Empty_Index  \\\n",
       "0                 1                     50       0.7393       0.4000   \n",
       "1                 0                     80       0.7772       0.2878   \n",
       "2                 1                     40       0.0557       0.5282   \n",
       "3                 1                     40       0.7202       0.3333   \n",
       "4                 1                    300       0.1211       0.5347   \n",
       "\n",
       "   Square_Index  Outside_X_Index  Edges_X_Index  Edges_Y_Index  \\\n",
       "0        0.5000           0.0059         1.0000         1.0000   \n",
       "1        0.2581           0.0044         0.2500         1.0000   \n",
       "2        0.9895           0.1077         0.2363         0.3857   \n",
       "3        0.3333           0.0044         0.3750         0.9310   \n",
       "4        0.0842           0.0192         0.2105         0.9861   \n",
       "\n",
       "   Outside_Global_Index  LogOfAreas  Log_X_Index  Log_Y_Index  \\\n",
       "0                   0.0      1.2041       0.9031       0.6990   \n",
       "1                   1.0      2.6365       0.7782       1.7324   \n",
       "2                   0.0      4.0564       2.1790       2.2095   \n",
       "3                   1.0      2.3222       0.7782       1.4314   \n",
       "4                   1.0      2.7694       1.4150       1.8808   \n",
       "\n",
       "   Orientation_Index  Luminosity_Index  SigmoidOfAreas  Pastry  Z_Scratch  \\\n",
       "0            -0.5000           -0.0104          0.1417       0          0   \n",
       "1             0.7419           -0.2997          0.9491       0          0   \n",
       "2            -0.0105           -0.0944          1.0000       0          0   \n",
       "3             0.6667           -0.0402          0.4025       0          0   \n",
       "4             0.9158           -0.2455          0.9998       0          0   \n",
       "\n",
       "   K_Scatch  Stains  Dirtiness  Bumps  Other_Faults  \n",
       "0         0       1          0      0             0  \n",
       "1         0       0          0      0             1  \n",
       "2         1       0          0      0             0  \n",
       "3         1       0          0      0             0  \n",
       "4         0       0          0      0             1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove id column and check the dataset\n",
    "train.drop('id', axis=1, inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>X_Minimum</th>\n",
       "      <th>X_Maximum</th>\n",
       "      <th>Y_Minimum</th>\n",
       "      <th>Y_Maximum</th>\n",
       "      <th>Pixels_Areas</th>\n",
       "      <th>X_Perimeter</th>\n",
       "      <th>Y_Perimeter</th>\n",
       "      <th>Sum_of_Luminosity</th>\n",
       "      <th>Minimum_of_Luminosity</th>\n",
       "      <th>Maximum_of_Luminosity</th>\n",
       "      <th>Length_of_Conveyer</th>\n",
       "      <th>TypeOfSteel_A300</th>\n",
       "      <th>TypeOfSteel_A400</th>\n",
       "      <th>Steel_Plate_Thickness</th>\n",
       "      <th>Edges_Index</th>\n",
       "      <th>Empty_Index</th>\n",
       "      <th>Square_Index</th>\n",
       "      <th>Outside_X_Index</th>\n",
       "      <th>Edges_X_Index</th>\n",
       "      <th>Edges_Y_Index</th>\n",
       "      <th>Outside_Global_Index</th>\n",
       "      <th>LogOfAreas</th>\n",
       "      <th>Log_X_Index</th>\n",
       "      <th>Log_Y_Index</th>\n",
       "      <th>Orientation_Index</th>\n",
       "      <th>Luminosity_Index</th>\n",
       "      <th>SigmoidOfAreas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19219</td>\n",
       "      <td>1015</td>\n",
       "      <td>1033</td>\n",
       "      <td>3826564</td>\n",
       "      <td>3826588</td>\n",
       "      <td>659</td>\n",
       "      <td>23</td>\n",
       "      <td>46</td>\n",
       "      <td>62357</td>\n",
       "      <td>67</td>\n",
       "      <td>127</td>\n",
       "      <td>1656</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0.3877</td>\n",
       "      <td>0.4896</td>\n",
       "      <td>0.3273</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.5652</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.8410</td>\n",
       "      <td>1.1139</td>\n",
       "      <td>1.6628</td>\n",
       "      <td>0.6727</td>\n",
       "      <td>-0.2261</td>\n",
       "      <td>0.9172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19220</td>\n",
       "      <td>1257</td>\n",
       "      <td>1271</td>\n",
       "      <td>419960</td>\n",
       "      <td>419973</td>\n",
       "      <td>370</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>39293</td>\n",
       "      <td>92</td>\n",
       "      <td>132</td>\n",
       "      <td>1354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.1629</td>\n",
       "      <td>0.4136</td>\n",
       "      <td>0.0938</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5682</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>1.4472</td>\n",
       "      <td>0.9063</td>\n",
       "      <td>-0.1453</td>\n",
       "      <td>0.9104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19221</td>\n",
       "      <td>1358</td>\n",
       "      <td>1372</td>\n",
       "      <td>117715</td>\n",
       "      <td>117724</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>32</td>\n",
       "      <td>29386</td>\n",
       "      <td>101</td>\n",
       "      <td>134</td>\n",
       "      <td>1360</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0609</td>\n",
       "      <td>0.6234</td>\n",
       "      <td>0.4762</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4609</td>\n",
       "      <td>1.3222</td>\n",
       "      <td>1.3222</td>\n",
       "      <td>-0.5238</td>\n",
       "      <td>-0.0435</td>\n",
       "      <td>0.6514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19222</td>\n",
       "      <td>158</td>\n",
       "      <td>168</td>\n",
       "      <td>232415</td>\n",
       "      <td>232440</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>8586</td>\n",
       "      <td>107</td>\n",
       "      <td>140</td>\n",
       "      <td>1690</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4439</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.8182</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.9031</td>\n",
       "      <td>0.6990</td>\n",
       "      <td>1.0414</td>\n",
       "      <td>0.1818</td>\n",
       "      <td>-0.0738</td>\n",
       "      <td>0.2051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19223</td>\n",
       "      <td>559</td>\n",
       "      <td>592</td>\n",
       "      <td>544375</td>\n",
       "      <td>544389</td>\n",
       "      <td>140</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>15524</td>\n",
       "      <td>103</td>\n",
       "      <td>134</td>\n",
       "      <td>1688</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0.8191</td>\n",
       "      <td>0.2619</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.8421</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1461</td>\n",
       "      <td>1.3222</td>\n",
       "      <td>1.1461</td>\n",
       "      <td>-0.5714</td>\n",
       "      <td>-0.0894</td>\n",
       "      <td>0.4170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  X_Minimum  X_Maximum  Y_Minimum  Y_Maximum  Pixels_Areas  \\\n",
       "0  19219       1015       1033    3826564    3826588           659   \n",
       "1  19220       1257       1271     419960     419973           370   \n",
       "2  19221       1358       1372     117715     117724           289   \n",
       "3  19222        158        168     232415     232440            80   \n",
       "4  19223        559        592     544375     544389           140   \n",
       "\n",
       "   X_Perimeter  Y_Perimeter  Sum_of_Luminosity  Minimum_of_Luminosity  \\\n",
       "0           23           46              62357                     67   \n",
       "1           26           28              39293                     92   \n",
       "2           36           32              29386                    101   \n",
       "3           10           11               8586                    107   \n",
       "4           19           15              15524                    103   \n",
       "\n",
       "   Maximum_of_Luminosity  Length_of_Conveyer  TypeOfSteel_A300  \\\n",
       "0                    127                1656                 0   \n",
       "1                    132                1354                 0   \n",
       "2                    134                1360                 0   \n",
       "3                    140                1690                 1   \n",
       "4                    134                1688                 1   \n",
       "\n",
       "   TypeOfSteel_A400  Steel_Plate_Thickness  Edges_Index  Empty_Index  \\\n",
       "0                 1                    150       0.3877       0.4896   \n",
       "1                 1                     40       0.1629       0.4136   \n",
       "2                 1                     40       0.0609       0.6234   \n",
       "3                 0                    100       0.4439       0.3333   \n",
       "4                 0                     60       0.8191       0.2619   \n",
       "\n",
       "   Square_Index  Outside_X_Index  Edges_X_Index  Edges_Y_Index  \\\n",
       "0        0.3273           0.0095         0.5652         1.0000   \n",
       "1        0.0938           0.0047         0.2414         1.0000   \n",
       "2        0.4762           0.0155         0.6000         0.7500   \n",
       "3        0.8182           0.0037         0.8000         1.0000   \n",
       "4        0.4286           0.0158         0.8421         0.5333   \n",
       "\n",
       "   Outside_Global_Index  LogOfAreas  Log_X_Index  Log_Y_Index  \\\n",
       "0                   1.0      2.8410       1.1139       1.6628   \n",
       "1                   1.0      2.5682       0.9031       1.4472   \n",
       "2                   0.0      2.4609       1.3222       1.3222   \n",
       "3                   1.0      1.9031       0.6990       1.0414   \n",
       "4                   0.0      2.1461       1.3222       1.1461   \n",
       "\n",
       "   Orientation_Index  Luminosity_Index  SigmoidOfAreas  \n",
       "0             0.6727           -0.2261          0.9172  \n",
       "1             0.9063           -0.1453          0.9104  \n",
       "2            -0.5238           -0.0435          0.6514  \n",
       "3             0.1818           -0.0738          0.2051  \n",
       "4            -0.5714           -0.0894          0.4170  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset_cols = list(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n",
    "                 'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n",
    "                 'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n",
    "                 'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n",
    "                 'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n",
    "                 'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n",
    "                 'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n",
    "                 'SigmoidOfAreas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_Minimum</th>\n",
       "      <th>X_Maximum</th>\n",
       "      <th>Y_Minimum</th>\n",
       "      <th>Y_Maximum</th>\n",
       "      <th>Pixels_Areas</th>\n",
       "      <th>X_Perimeter</th>\n",
       "      <th>Y_Perimeter</th>\n",
       "      <th>Sum_of_Luminosity</th>\n",
       "      <th>Minimum_of_Luminosity</th>\n",
       "      <th>Maximum_of_Luminosity</th>\n",
       "      <th>Length_of_Conveyer</th>\n",
       "      <th>TypeOfSteel_A300</th>\n",
       "      <th>TypeOfSteel_A400</th>\n",
       "      <th>Steel_Plate_Thickness</th>\n",
       "      <th>Edges_Index</th>\n",
       "      <th>Empty_Index</th>\n",
       "      <th>Square_Index</th>\n",
       "      <th>Outside_X_Index</th>\n",
       "      <th>Edges_X_Index</th>\n",
       "      <th>Edges_Y_Index</th>\n",
       "      <th>Outside_Global_Index</th>\n",
       "      <th>LogOfAreas</th>\n",
       "      <th>Log_X_Index</th>\n",
       "      <th>Log_Y_Index</th>\n",
       "      <th>Orientation_Index</th>\n",
       "      <th>Luminosity_Index</th>\n",
       "      <th>SigmoidOfAreas</th>\n",
       "      <th>Pastry</th>\n",
       "      <th>Z_Scratch</th>\n",
       "      <th>K_Scatch</th>\n",
       "      <th>Stains</th>\n",
       "      <th>Dirtiness</th>\n",
       "      <th>Bumps</th>\n",
       "      <th>Other_Faults</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>645</td>\n",
       "      <td>651</td>\n",
       "      <td>2538079</td>\n",
       "      <td>2538108</td>\n",
       "      <td>108</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>11397</td>\n",
       "      <td>84</td>\n",
       "      <td>123</td>\n",
       "      <td>1687</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0.7647</td>\n",
       "      <td>0.3793</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.9667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0334</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>1.4624</td>\n",
       "      <td>0.7931</td>\n",
       "      <td>-0.1756</td>\n",
       "      <td>0.2984</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>829</td>\n",
       "      <td>835</td>\n",
       "      <td>1553913</td>\n",
       "      <td>1553931</td>\n",
       "      <td>71</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>7972</td>\n",
       "      <td>99</td>\n",
       "      <td>125</td>\n",
       "      <td>1623</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.3426</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8513</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>1.2553</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>-0.1228</td>\n",
       "      <td>0.2150</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>853</td>\n",
       "      <td>860</td>\n",
       "      <td>369370</td>\n",
       "      <td>369415</td>\n",
       "      <td>176</td>\n",
       "      <td>13</td>\n",
       "      <td>45</td>\n",
       "      <td>18996</td>\n",
       "      <td>99</td>\n",
       "      <td>126</td>\n",
       "      <td>1353</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>290</td>\n",
       "      <td>0.7287</td>\n",
       "      <td>0.4413</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.5385</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2455</td>\n",
       "      <td>0.8451</td>\n",
       "      <td>1.6532</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>-0.1568</td>\n",
       "      <td>0.5212</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1289</td>\n",
       "      <td>1306</td>\n",
       "      <td>498078</td>\n",
       "      <td>498335</td>\n",
       "      <td>2409</td>\n",
       "      <td>60</td>\n",
       "      <td>260</td>\n",
       "      <td>246930</td>\n",
       "      <td>37</td>\n",
       "      <td>126</td>\n",
       "      <td>1353</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>185</td>\n",
       "      <td>0.0695</td>\n",
       "      <td>0.4486</td>\n",
       "      <td>0.0662</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.2833</td>\n",
       "      <td>0.9885</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.3818</td>\n",
       "      <td>1.2305</td>\n",
       "      <td>2.4099</td>\n",
       "      <td>0.9338</td>\n",
       "      <td>-0.1992</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>430</td>\n",
       "      <td>441</td>\n",
       "      <td>100250</td>\n",
       "      <td>100337</td>\n",
       "      <td>630</td>\n",
       "      <td>20</td>\n",
       "      <td>87</td>\n",
       "      <td>62357</td>\n",
       "      <td>64</td>\n",
       "      <td>127</td>\n",
       "      <td>1387</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.6200</td>\n",
       "      <td>0.3417</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.7993</td>\n",
       "      <td>1.0414</td>\n",
       "      <td>1.9395</td>\n",
       "      <td>0.8736</td>\n",
       "      <td>-0.2267</td>\n",
       "      <td>0.9874</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X_Minimum  X_Maximum  Y_Minimum  Y_Maximum  Pixels_Areas  X_Perimeter  \\\n",
       "0        645        651    2538079    2538108           108           10   \n",
       "1        829        835    1553913    1553931            71            8   \n",
       "2        853        860     369370     369415           176           13   \n",
       "3       1289       1306     498078     498335          2409           60   \n",
       "4        430        441     100250     100337           630           20   \n",
       "\n",
       "   Y_Perimeter  Sum_of_Luminosity  Minimum_of_Luminosity  \\\n",
       "0           30              11397                     84   \n",
       "1           19               7972                     99   \n",
       "2           45              18996                     99   \n",
       "3          260             246930                     37   \n",
       "4           87              62357                     64   \n",
       "\n",
       "   Maximum_of_Luminosity  Length_of_Conveyer  TypeOfSteel_A300  \\\n",
       "0                    123                1687                 1   \n",
       "1                    125                1623                 1   \n",
       "2                    126                1353                 0   \n",
       "3                    126                1353                 0   \n",
       "4                    127                1387                 0   \n",
       "\n",
       "   TypeOfSteel_A400  Steel_Plate_Thickness  Edges_Index  Empty_Index  \\\n",
       "0                 0                     80       0.7647       0.3793   \n",
       "1                 0                    100       0.9710       0.3426   \n",
       "2                 1                    290       0.7287       0.4413   \n",
       "3                 1                    185       0.0695       0.4486   \n",
       "4                 1                     40       0.6200       0.3417   \n",
       "\n",
       "   Square_Index  Outside_X_Index  Edges_X_Index  Edges_Y_Index  \\\n",
       "0        0.2069           0.0036         0.6000         0.9667   \n",
       "1        0.3333           0.0037         0.7500         0.9474   \n",
       "2        0.1556           0.0052         0.5385         1.0000   \n",
       "3        0.0662           0.0126         0.2833         0.9885   \n",
       "4        0.1264           0.0079         0.5500         1.0000   \n",
       "\n",
       "   Outside_Global_Index  LogOfAreas  Log_X_Index  Log_Y_Index  \\\n",
       "0                   1.0      2.0334       0.7782       1.4624   \n",
       "1                   1.0      1.8513       0.7782       1.2553   \n",
       "2                   1.0      2.2455       0.8451       1.6532   \n",
       "3                   1.0      3.3818       1.2305       2.4099   \n",
       "4                   1.0      2.7993       1.0414       1.9395   \n",
       "\n",
       "   Orientation_Index  Luminosity_Index  SigmoidOfAreas  Pastry  Z_Scratch  \\\n",
       "0             0.7931           -0.1756          0.2984       1          0   \n",
       "1             0.6667           -0.1228          0.2150       1          0   \n",
       "2             0.8444           -0.1568          0.5212       1          0   \n",
       "3             0.9338           -0.1992          1.0000       1          0   \n",
       "4             0.8736           -0.2267          0.9874       1          0   \n",
       "\n",
       "   K_Scatch  Stains  Dirtiness  Bumps  Other_Faults  \n",
       "0         0       0          0      0             0  \n",
       "1         0       0          0      0             0  \n",
       "2         0       0          0      0             0  \n",
       "3         0       0          0      0             0  \n",
       "4         0       0          0      0             0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original.columns = original_dataset_cols\n",
    "original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat the train and original dataset\n",
    "combined_df = pd.concat([train, original], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Got function from https://www.kaggle.com/code/thomasmeiner/ps4e3-eda-feature-engineering-model\n",
    "\n",
    "def reformat_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    target_cols = [\n",
    "        \"Pastry\", #4\n",
    "        \"Z_Scratch\", #6\n",
    "        \"K_Scatch\", #2\n",
    "        \"Stains\", #5\n",
    "        \"Dirtiness\", #1\n",
    "        \"Bumps\", #0\n",
    "        \"Other_Faults\", #3\n",
    "    ]\n",
    "    non_target_cols = df.drop(target_cols, axis=1).columns.to_list()\n",
    "    \n",
    "    binary_dfs = []\n",
    "    \n",
    "    for col in target_cols:\n",
    "        temp_df = df.loc[:, non_target_cols + [col]]\n",
    "        temp_df = temp_df.loc[temp_df[col] == 1].copy() # keep positives only\n",
    "        temp_df[col] = col # target value is class name now\n",
    "        temp_df = temp_df.rename(columns={col: \"target\"}) # make target col name uniform for final concat\n",
    "        binary_dfs.append(temp_df)\n",
    "        \n",
    "    reformatted_df = pd.concat(binary_dfs)\n",
    "    return reformatted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reformat_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "#     target_cols = [\n",
    "#         \"Pastry\",\n",
    "#         \"Z_Scratch\",\n",
    "#         \"K_Scatch\",\n",
    "#         \"Stains\",\n",
    "#         \"Dirtiness\",\n",
    "#         \"Bumps\",\n",
    "#         \"Other_Faults\",\n",
    "#     ]\n",
    "#     non_target_cols = df.drop(target_cols, axis=1).columns.to_list()\n",
    "\n",
    "#     binary_dfs = []\n",
    "\n",
    "#     for col in target_cols:\n",
    "#         temp_df = df.loc[:, non_target_cols + [col]]\n",
    "#         temp_df = temp_df.loc[temp_df[col] == 1].copy() # sub sample to lowest class\n",
    "#         temp_df[col] = col # target value is class name now\n",
    "#         temp_df = temp_df.rename(columns={col: \"target\"}) # make target col name uniform for final concat\n",
    "#         binary_dfs.append(temp_df)\n",
    "\n",
    "#     # collect non_defect rows\n",
    "#     temp_df = df.loc[\n",
    "#         (df[\"Pastry\"] == 0) &\n",
    "#         (df[\"Z_Scratch\"] == 0) &\n",
    "#         (df[\"K_Scatch\"] == 0) &\n",
    "#         (df[\"Stains\"] == 0) &\n",
    "#         (df[\"Dirtiness\"] == 0) &\n",
    "#         (df[\"Bumps\"] == 0) &\n",
    "#         (df[\"Other_Faults\"] == 0)\n",
    "#     ]\n",
    "#     temp_df = temp_df.loc[: , non_target_cols]\n",
    "#     temp_df[\"target\"] = \"No defect\"\n",
    "#     binary_dfs.append(temp_df)\n",
    "\n",
    "#     reformatted_df = pd.concat(binary_dfs)\n",
    "#     return reformatted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_Minimum</th>\n",
       "      <th>X_Maximum</th>\n",
       "      <th>Y_Minimum</th>\n",
       "      <th>Y_Maximum</th>\n",
       "      <th>Pixels_Areas</th>\n",
       "      <th>X_Perimeter</th>\n",
       "      <th>Y_Perimeter</th>\n",
       "      <th>Sum_of_Luminosity</th>\n",
       "      <th>Minimum_of_Luminosity</th>\n",
       "      <th>Maximum_of_Luminosity</th>\n",
       "      <th>Length_of_Conveyer</th>\n",
       "      <th>TypeOfSteel_A300</th>\n",
       "      <th>TypeOfSteel_A400</th>\n",
       "      <th>Steel_Plate_Thickness</th>\n",
       "      <th>Edges_Index</th>\n",
       "      <th>Empty_Index</th>\n",
       "      <th>Square_Index</th>\n",
       "      <th>Outside_X_Index</th>\n",
       "      <th>Edges_X_Index</th>\n",
       "      <th>Edges_Y_Index</th>\n",
       "      <th>Outside_Global_Index</th>\n",
       "      <th>LogOfAreas</th>\n",
       "      <th>Log_X_Index</th>\n",
       "      <th>Log_Y_Index</th>\n",
       "      <th>Orientation_Index</th>\n",
       "      <th>Luminosity_Index</th>\n",
       "      <th>SigmoidOfAreas</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1673</td>\n",
       "      <td>1687</td>\n",
       "      <td>294065</td>\n",
       "      <td>294091</td>\n",
       "      <td>571</td>\n",
       "      <td>38</td>\n",
       "      <td>57</td>\n",
       "      <td>53142</td>\n",
       "      <td>77</td>\n",
       "      <td>110</td>\n",
       "      <td>1692</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>0.1491</td>\n",
       "      <td>0.4326</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.5686</td>\n",
       "      <td>0.7179</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.7528</td>\n",
       "      <td>1.3802</td>\n",
       "      <td>1.7559</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>-0.2661</td>\n",
       "      <td>0.9408</td>\n",
       "      <td>Pastry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1538</td>\n",
       "      <td>1549</td>\n",
       "      <td>849219</td>\n",
       "      <td>849235</td>\n",
       "      <td>275</td>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "      <td>28986</td>\n",
       "      <td>71</td>\n",
       "      <td>117</td>\n",
       "      <td>1626</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0.1494</td>\n",
       "      <td>0.3990</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.6316</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.4393</td>\n",
       "      <td>1.0792</td>\n",
       "      <td>1.5051</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>-0.2988</td>\n",
       "      <td>0.6330</td>\n",
       "      <td>Pastry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1310</td>\n",
       "      <td>1316</td>\n",
       "      <td>435871</td>\n",
       "      <td>435916</td>\n",
       "      <td>153</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>17101</td>\n",
       "      <td>104</td>\n",
       "      <td>132</td>\n",
       "      <td>1352</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0532</td>\n",
       "      <td>0.3854</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.9688</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.1847</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>1.5051</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>-0.0916</td>\n",
       "      <td>0.4025</td>\n",
       "      <td>Pastry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>765</td>\n",
       "      <td>774</td>\n",
       "      <td>6571361</td>\n",
       "      <td>6571375</td>\n",
       "      <td>59</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>6682</td>\n",
       "      <td>77</td>\n",
       "      <td>133</td>\n",
       "      <td>1360</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.3571</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.7708</td>\n",
       "      <td>0.8451</td>\n",
       "      <td>1.0792</td>\n",
       "      <td>0.7200</td>\n",
       "      <td>-0.1522</td>\n",
       "      <td>0.1892</td>\n",
       "      <td>Pastry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1677</td>\n",
       "      <td>1686</td>\n",
       "      <td>1319063</td>\n",
       "      <td>1319076</td>\n",
       "      <td>91</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>5608</td>\n",
       "      <td>57</td>\n",
       "      <td>95</td>\n",
       "      <td>1692</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.3583</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.9590</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>1.1761</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>-0.3868</td>\n",
       "      <td>0.2660</td>\n",
       "      <td>Pastry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    X_Minimum  X_Maximum  Y_Minimum  Y_Maximum  Pixels_Areas  X_Perimeter  \\\n",
       "7        1673       1687     294065     294091           571           38   \n",
       "24       1538       1549     849219     849235           275           19   \n",
       "35       1310       1316     435871     435916           153           16   \n",
       "60        765        774    6571361    6571375            59            9   \n",
       "67       1677       1686    1319063    1319076            91           10   \n",
       "\n",
       "    Y_Perimeter  Sum_of_Luminosity  Minimum_of_Luminosity  \\\n",
       "7            57              53142                     77   \n",
       "24           32              28986                     71   \n",
       "35           32              17101                    104   \n",
       "60           12               6682                     77   \n",
       "67           15               5608                     57   \n",
       "\n",
       "    Maximum_of_Luminosity  Length_of_Conveyer  TypeOfSteel_A300  \\\n",
       "7                     110                1692                 0   \n",
       "24                    117                1626                 1   \n",
       "35                    132                1352                 0   \n",
       "60                    133                1360                 0   \n",
       "67                     95                1692                 1   \n",
       "\n",
       "    TypeOfSteel_A400  Steel_Plate_Thickness  Edges_Index  Empty_Index  \\\n",
       "7                  1                    300       0.1491       0.4326   \n",
       "24                 0                     70       0.1494       0.3990   \n",
       "35                 1                     40       0.0532       0.3854   \n",
       "60                 1                    100       0.3613       0.3571   \n",
       "67                 0                     70       0.0024       0.3583   \n",
       "\n",
       "    Square_Index  Outside_X_Index  Edges_X_Index  Edges_Y_Index  \\\n",
       "7         0.9643           0.0142         0.5686         0.7179   \n",
       "24        0.3750           0.0088         0.6316         1.0000   \n",
       "35        0.3333           0.0044         0.3750         0.9688   \n",
       "60        0.2800           0.0052         0.7778         1.0000   \n",
       "67        0.6667           0.0047         0.8000         1.0000   \n",
       "\n",
       "    Outside_Global_Index  LogOfAreas  Log_X_Index  Log_Y_Index  \\\n",
       "7                    1.0      2.7528       1.3802       1.7559   \n",
       "24                   1.0      2.4393       1.0792       1.5051   \n",
       "35                   1.0      2.1847       0.7782       1.5051   \n",
       "60                   1.0      1.7708       0.8451       1.0792   \n",
       "67                   1.0      1.9590       0.9031       1.1761   \n",
       "\n",
       "    Orientation_Index  Luminosity_Index  SigmoidOfAreas  target  \n",
       "7              0.0357           -0.2661          0.9408  Pastry  \n",
       "24             0.6250           -0.2988          0.6330  Pastry  \n",
       "35             0.6667           -0.0916          0.4025  Pastry  \n",
       "60             0.7200           -0.1522          0.1892  Pastry  \n",
       "67             0.3333           -0.3868          0.2660  Pastry  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = reformat_data(combined_df)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_Minimum</th>\n",
       "      <th>X_Maximum</th>\n",
       "      <th>Y_Minimum</th>\n",
       "      <th>Y_Maximum</th>\n",
       "      <th>Pixels_Areas</th>\n",
       "      <th>X_Perimeter</th>\n",
       "      <th>Y_Perimeter</th>\n",
       "      <th>Sum_of_Luminosity</th>\n",
       "      <th>Minimum_of_Luminosity</th>\n",
       "      <th>Maximum_of_Luminosity</th>\n",
       "      <th>Length_of_Conveyer</th>\n",
       "      <th>TypeOfSteel_A300</th>\n",
       "      <th>TypeOfSteel_A400</th>\n",
       "      <th>Steel_Plate_Thickness</th>\n",
       "      <th>Edges_Index</th>\n",
       "      <th>Empty_Index</th>\n",
       "      <th>Square_Index</th>\n",
       "      <th>Outside_X_Index</th>\n",
       "      <th>Edges_X_Index</th>\n",
       "      <th>Edges_Y_Index</th>\n",
       "      <th>Outside_Global_Index</th>\n",
       "      <th>LogOfAreas</th>\n",
       "      <th>Log_X_Index</th>\n",
       "      <th>Log_Y_Index</th>\n",
       "      <th>Orientation_Index</th>\n",
       "      <th>Luminosity_Index</th>\n",
       "      <th>SigmoidOfAreas</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1673</td>\n",
       "      <td>1687</td>\n",
       "      <td>294065</td>\n",
       "      <td>294091</td>\n",
       "      <td>571</td>\n",
       "      <td>38</td>\n",
       "      <td>57</td>\n",
       "      <td>53142</td>\n",
       "      <td>77</td>\n",
       "      <td>110</td>\n",
       "      <td>1692</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>0.1491</td>\n",
       "      <td>0.4326</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.5686</td>\n",
       "      <td>0.7179</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.7528</td>\n",
       "      <td>1.3802</td>\n",
       "      <td>1.7559</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>-0.2661</td>\n",
       "      <td>0.9408</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1538</td>\n",
       "      <td>1549</td>\n",
       "      <td>849219</td>\n",
       "      <td>849235</td>\n",
       "      <td>275</td>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "      <td>28986</td>\n",
       "      <td>71</td>\n",
       "      <td>117</td>\n",
       "      <td>1626</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0.1494</td>\n",
       "      <td>0.3990</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.6316</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.4393</td>\n",
       "      <td>1.0792</td>\n",
       "      <td>1.5051</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>-0.2988</td>\n",
       "      <td>0.6330</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1310</td>\n",
       "      <td>1316</td>\n",
       "      <td>435871</td>\n",
       "      <td>435916</td>\n",
       "      <td>153</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>17101</td>\n",
       "      <td>104</td>\n",
       "      <td>132</td>\n",
       "      <td>1352</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0532</td>\n",
       "      <td>0.3854</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.9688</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.1847</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>1.5051</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>-0.0916</td>\n",
       "      <td>0.4025</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>765</td>\n",
       "      <td>774</td>\n",
       "      <td>6571361</td>\n",
       "      <td>6571375</td>\n",
       "      <td>59</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>6682</td>\n",
       "      <td>77</td>\n",
       "      <td>133</td>\n",
       "      <td>1360</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.3571</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.7708</td>\n",
       "      <td>0.8451</td>\n",
       "      <td>1.0792</td>\n",
       "      <td>0.7200</td>\n",
       "      <td>-0.1522</td>\n",
       "      <td>0.1892</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1677</td>\n",
       "      <td>1686</td>\n",
       "      <td>1319063</td>\n",
       "      <td>1319076</td>\n",
       "      <td>91</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>5608</td>\n",
       "      <td>57</td>\n",
       "      <td>95</td>\n",
       "      <td>1692</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.3583</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.9590</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>1.1761</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>-0.3868</td>\n",
       "      <td>0.2660</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    X_Minimum  X_Maximum  Y_Minimum  Y_Maximum  Pixels_Areas  X_Perimeter  \\\n",
       "7        1673       1687     294065     294091           571           38   \n",
       "24       1538       1549     849219     849235           275           19   \n",
       "35       1310       1316     435871     435916           153           16   \n",
       "60        765        774    6571361    6571375            59            9   \n",
       "67       1677       1686    1319063    1319076            91           10   \n",
       "\n",
       "    Y_Perimeter  Sum_of_Luminosity  Minimum_of_Luminosity  \\\n",
       "7            57              53142                     77   \n",
       "24           32              28986                     71   \n",
       "35           32              17101                    104   \n",
       "60           12               6682                     77   \n",
       "67           15               5608                     57   \n",
       "\n",
       "    Maximum_of_Luminosity  Length_of_Conveyer  TypeOfSteel_A300  \\\n",
       "7                     110                1692                 0   \n",
       "24                    117                1626                 1   \n",
       "35                    132                1352                 0   \n",
       "60                    133                1360                 0   \n",
       "67                     95                1692                 1   \n",
       "\n",
       "    TypeOfSteel_A400  Steel_Plate_Thickness  Edges_Index  Empty_Index  \\\n",
       "7                  1                    300       0.1491       0.4326   \n",
       "24                 0                     70       0.1494       0.3990   \n",
       "35                 1                     40       0.0532       0.3854   \n",
       "60                 1                    100       0.3613       0.3571   \n",
       "67                 0                     70       0.0024       0.3583   \n",
       "\n",
       "    Square_Index  Outside_X_Index  Edges_X_Index  Edges_Y_Index  \\\n",
       "7         0.9643           0.0142         0.5686         0.7179   \n",
       "24        0.3750           0.0088         0.6316         1.0000   \n",
       "35        0.3333           0.0044         0.3750         0.9688   \n",
       "60        0.2800           0.0052         0.7778         1.0000   \n",
       "67        0.6667           0.0047         0.8000         1.0000   \n",
       "\n",
       "    Outside_Global_Index  LogOfAreas  Log_X_Index  Log_Y_Index  \\\n",
       "7                    1.0      2.7528       1.3802       1.7559   \n",
       "24                   1.0      2.4393       1.0792       1.5051   \n",
       "35                   1.0      2.1847       0.7782       1.5051   \n",
       "60                   1.0      1.7708       0.8451       1.0792   \n",
       "67                   1.0      1.9590       0.9031       1.1761   \n",
       "\n",
       "    Orientation_Index  Luminosity_Index  SigmoidOfAreas  target  \n",
       "7              0.0357           -0.2661          0.9408       4  \n",
       "24             0.6250           -0.2988          0.6330       4  \n",
       "35             0.6667           -0.0916          0.4025       4  \n",
       "60             0.7200           -0.1522          0.1892       4  \n",
       "67             0.3333           -0.3868          0.2660       4  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoder.fit(combined_df[TARGET])\n",
    "\n",
    "combined_df[TARGET] = label_encoder.transform(combined_df[TARGET])\n",
    "\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20362, 28), (12814, 28))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combined_df.drop([TARGET], axis=1)\n",
    "y = combined_df[TARGET]\n",
    "\n",
    "n_splits = 3\n",
    "sk10 = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params_1 = {'objective': 'multiclass', 'num_class': 7, 'n_jobs': -1, 'random_state': 5, 'class_weight': None, 'boosting': 'gbdt', 'colsample_bytree': 0.3732513300418112, 'learning_rate': 0.11407449915410499, 'max_depth': 41, 'min_child_samples': 46, 'min_child_weight': 5.402556610174332, 'min_split_gain': 0.7031617243606461, 'n_estimators': 168, 'num_leaves': 4, 'reg_alpha': 0.6688125857557925, 'reg_lambda': 0.3006431833867248, 'subsample': 0.7700917000679017}\n",
    "lgbm_params_2 = {'objective': 'multiclass', 'num_class': 7, 'n_jobs': -1, 'random_state': 5, 'class_weight': None, 'boosting': 'dart', 'colsample_bytree': 0.5772149549047157, 'learning_rate': 0.33002721528421214, 'max_depth': 28, 'min_child_samples': 23, 'min_child_weight': 7.99839845350044, 'min_split_gain': 0.9239893181066746, 'n_estimators': 699, 'num_leaves': 21, 'reg_alpha': 0.4760265812563772, 'reg_lambda': 0.15634739914542023, 'subsample': 0.4590800039755062}\n",
    "lgbm_params_3 = {'objective': 'multiclass', 'num_class': 7, 'n_jobs': -1, 'random_state': 5, 'class_weight': None, 'boosting': 'dart', 'colsample_bytree': 0.31193732162008925, 'learning_rate': 0.03107980185406725, 'max_depth': 58, 'min_child_samples': 26, 'min_child_weight': 0.9044244579504741, 'min_split_gain': 0.6988647291560484, 'n_estimators': 814, 'num_leaves': 10, 'reg_alpha': 0.8952949360981323, 'reg_lambda': 0.12911118443546726, 'subsample': 0.9423432553265046}\n",
    "lgbm_params_4 = {'objective': 'multiclass', 'num_class': 7, 'n_jobs': -1, 'random_state': 5, 'class_weight': None, 'boosting': 'dart', 'colsample_bytree': 0.35885033102300595, 'learning_rate': 0.21902422874173558, 'max_depth': 3, 'min_child_samples': 34, 'min_child_weight': 4.768878441321062, 'min_split_gain': 0.8804385788228134, 'n_estimators': 334, 'num_leaves': 19, 'reg_alpha': 0.9922927799932719, 'reg_lambda': 0.010366800790489683, 'subsample': 0.5713199333429264}\n",
    "hist_params_1 = {'random_state': 5, 'learning_rate': 0.052466626497163174, 'max_iter': 72, 'max_leaf_nodes': 23, 'min_samples_leaf': 66, 'l2_regularization': 0.8935374409410728, 'max_bins': 151, 'max_depth': 45}\n",
    "hist_params_2 = {'random_state': 5, 'learning_rate': 0.08690147432171641, 'max_iter': 363, 'max_leaf_nodes': 49, 'min_samples_leaf': 77, 'l2_regularization': 0.5540219768909869, 'max_bins': 175, 'max_depth': 4}\n",
    "hist_params_3 = {'random_state': 5, 'learning_rate': 0.09432387429473288, 'max_iter': 269, 'max_leaf_nodes': 22, 'min_samples_leaf': 87, 'l2_regularization': 0.9939707101523615, 'max_bins': 246, 'max_depth': 39}\n",
    "hist_params_4 = {'random_state': 5, 'learning_rate': 0.010334329050417028, 'max_iter': 450, 'max_leaf_nodes': 20, 'min_samples_leaf': 87, 'l2_regularization': 0.6496937198849339, 'max_bins': 118, 'max_depth': 63}\n",
    "hist_params_5 = {'random_state': 5, 'learning_rate': 0.05116790153455628, 'max_leaf_nodes': 15, 'min_samples_leaf': 358, 'l2_regularization': 0.870263366116972, 'max_bins': 78}\n",
    "extrat_params_1 = {'n_jobs': -1, 'random_state': 5, 'max_leaf_nodes': 1245, 'min_samples_leaf': 2, 'min_samples_split': 18, 'min_weight_fraction_leaf': 0.0001389853877993949, 'n_estimators': 2712}\n",
    "extrat_params_2 = {'n_jobs': -1, 'random_state': 5, 'max_leaf_nodes': 1643, 'min_samples_leaf': 2, 'min_samples_split': 75, 'min_weight_fraction_leaf': 4.1528306236372726e-05, 'n_estimators': 2580}\n",
    "extrat_params_3 = {'n_jobs': -1, 'random_state': 5, 'max_leaf_nodes': 2768, 'min_samples_leaf': 1, 'min_samples_split': 55, 'min_weight_fraction_leaf': 5.532962720126739e-05, 'n_estimators': 2989}\n",
    "extrat_params_4 = {'n_jobs': -1, 'random_state': 5, 'max_leaf_nodes': 1835, 'min_samples_leaf': 1, 'min_samples_split': 50, 'min_weight_fraction_leaf': 4.0520720198360216e-05, 'n_estimators': 2504}\n",
    "rf_params_1 = {'max_features': 'log2', 'criterion': 'entropy', 'n_estimators': 1000, 'random_state': 5, 'n_jobs': -1, 'max_depth': 28, 'max_leaf_nodes': 532, 'max_samples': 0.997319110588176, 'min_samples_leaf': 1, 'min_samples_split': 15}\n",
    "rf_params_2 = {'max_features': 'log2', 'criterion': 'entropy', 'n_estimators': 1000, 'random_state': 5, 'n_jobs': -1, 'max_depth': 23, 'max_leaf_nodes': 692, 'max_samples': 0.7633473827420749, 'min_samples_leaf': 4, 'min_samples_split': 7}\n",
    "# rf_params_3 = \n",
    "# rf_params_4 = \n",
    "cat_params_1 = {\n",
    "'bagging_temperature' : 0.5,\n",
    "'colsample_bylevel'   : 0.50,\n",
    "'iterations'          : 2500,\n",
    "'learning_rate'       : 0.04,\n",
    "'max_depth'           : 8,\n",
    "'l2_leaf_reg'         : 1.235,\n",
    "'min_data_in_leaf'    : 25,\n",
    "'random_strength'     : 0.35, \n",
    "'max_bin'             : 160,\n",
    "'verbose'             : False,\n",
    "'early_stopping_rounds': 100,\n",
    "'random_state'        : 5}\n",
    "cat_params_2 = {\n",
    "'bagging_temperature' : 0.1,\n",
    "'colsample_bylevel'   : 0.88,\n",
    "'iterations'          : 3000,\n",
    "'learning_rate'       : 0.065,\n",
    "'max_depth'           : 7,\n",
    "'l2_leaf_reg'         : 1.75,\n",
    "'min_data_in_leaf'    : 25,\n",
    "'random_strength'     : 0.1, \n",
    "'max_bin'             : 100,\n",
    "'verbose'             : False,\n",
    "'early_stopping_rounds': 100,\n",
    "'random_state'        : 5}\n",
    "cat_params_3 = {\n",
    "'bagging_temperature' : 0.2,\n",
    "'colsample_bylevel'   : 0.85,\n",
    "'iterations'          : 2500,\n",
    "'learning_rate'       : 0.025,\n",
    "'max_depth'           : 7,\n",
    "'l2_leaf_reg'         : 1.235,\n",
    "'min_data_in_leaf'    : 8,\n",
    "'random_strength'     : 0.60, \n",
    "'max_bin'             : 160,\n",
    "'verbose'             : False,\n",
    "'early_stopping_rounds': 100,\n",
    "'random_state'        : 5}\n",
    "cat_params_4 = {\n",
    "'grow_policy'         : 'Lossguide',\n",
    "'colsample_bylevel'   : 0.25,\n",
    "'iterations'          : 2500,\n",
    "'learning_rate'       : 0.035,\n",
    "'max_depth'           : 7,\n",
    "'l2_leaf_reg'         : 1.80,\n",
    "'random_strength'     : 0.60, \n",
    "'max_bin'             : 160,\n",
    "'verbose'             : False,\n",
    "'early_stopping_rounds': 100,\n",
    "'random_state'        : 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    LGBMClassifier(n_jobs=-1, random_state=5),\n",
    "    LGBMClassifier(**lgbm_params_1),\n",
    "    LGBMClassifier(**lgbm_params_2),\n",
    "    LGBMClassifier(**lgbm_params_3),\n",
    "    LGBMClassifier(**lgbm_params_4),\n",
    "    XGBClassifier(random_state=5),\n",
    "    RandomForestClassifier(random_state=5),\n",
    "    RandomForestClassifier(**rf_params_1),\n",
    "    RandomForestClassifier(**rf_params_2),\n",
    "    ExtraTreesClassifier(random_state=5),\n",
    "    ExtraTreesClassifier(**extrat_params_1),\n",
    "    ExtraTreesClassifier(**extrat_params_2),\n",
    "    ExtraTreesClassifier(**extrat_params_3),\n",
    "    ExtraTreesClassifier(**extrat_params_4),\n",
    "    HistGradientBoostingClassifier(random_state=5),\n",
    "    HistGradientBoostingClassifier(**hist_params_1),\n",
    "    HistGradientBoostingClassifier(**hist_params_2),\n",
    "    HistGradientBoostingClassifier(**hist_params_3),\n",
    "    HistGradientBoostingClassifier(**hist_params_4),\n",
    "    HistGradientBoostingClassifier(**hist_params_5),\n",
    "    CatBoostClassifier(random_state=5, verbose=False, early_stopping_rounds=100),\n",
    "    CatBoostClassifier(**cat_params_1),\n",
    "    CatBoostClassifier(**cat_params_2),\n",
    "    CatBoostClassifier(**cat_params_3),\n",
    "    CatBoostClassifier(**cat_params_4),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models_roc(models, X, y, important_features, cv_split, experiment_name):\n",
    "    MLA_compare = pd.DataFrame(columns=['MLA Name', \n",
    "                                        'MLA Parameters', \n",
    "                                        'MLA Train ROC AUC', \n",
    "                                        'MLA Test ROC AUC', \n",
    "                                        'MLA Test ROC AUC Std', \n",
    "                                        'MLA Time'])\n",
    "    \n",
    "    def evaluate_model(alg, idx):\n",
    "        MLA_name = alg.__class__.__name__\n",
    "        features = important_features.get(MLA_name, [])\n",
    "\n",
    "        # Check if the list of important features is empty\n",
    "        if len(features) == 0:\n",
    "            # If empty, return results with zero values\n",
    "            print(f'Skipping {MLA_name} due to no important features.')\n",
    "            return {\n",
    "                'MLA Name': MLA_name,\n",
    "                'MLA Parameters': str(alg.get_params()),\n",
    "                'MLA Train ROC': 0,\n",
    "                'MLA Test ROC': 0,\n",
    "                'MLA Test ROC Std': 0,\n",
    "                'MLA Time': \"0 min 0.00 sec\",\n",
    "            }\n",
    "        \n",
    "        cv_results = cross_validate(alg, \n",
    "                                    X[features], \n",
    "                                    y, cv=cv_split, \n",
    "                                    scoring='roc_auc_ovr', \n",
    "                                    return_train_score=True, \n",
    "                                    n_jobs=-1)\n",
    "\n",
    "        # Time formatting\n",
    "        mean_fit_time = cv_results['fit_time'].mean()\n",
    "        minutes, seconds = divmod(mean_fit_time, 60)\n",
    "\n",
    "        # Results population\n",
    "        result = {\n",
    "            'MLA Name': MLA_name,\n",
    "            'MLA Parameters': str(alg.get_params()),\n",
    "            'MLA Train ROC AUC': cv_results['train_score'].mean(),\n",
    "            'MLA Test ROC AUC': cv_results['test_score'].mean(),\n",
    "            'MLA Test ROC AUC Std': cv_results['test_score'].std(),\n",
    "            'MLA Time': f\"{int(minutes)} min {seconds:.2f} sec\",\n",
    "        }\n",
    "\n",
    "        print(f'Done with {MLA_name}.')\n",
    "        return result\n",
    "\n",
    "    results_list = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = [executor.submit(evaluate_model, alg, idx) for idx, alg in enumerate(models)]\n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            results_list.append(result)\n",
    "\n",
    "    MLA_compare = pd.DataFrame(results_list)\n",
    "\n",
    "    MLA_compare.sort_values(by=['MLA Test ROC AUC'], ascending=False, inplace=True)\n",
    "    MLA_compare.to_csv(f'{experiment_name}_results.csv', index=False)\n",
    "\n",
    "    return MLA_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_features = {}\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "\n",
    "    baseline_features[model_name] = list(X_hist.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "baseline_models = evaluate_models_roc(models, X, y, baseline_features, sk10, f'{experiment_name}_lgbm')\n",
    "baseline_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "baseline_models = evaluate_models_roc(models, X, y, baseline_features, sk10, f'{experiment_name}')\n",
    "baseline_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove Correlated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove correlated features (leaving just 1 of each pair)\n",
    "# Leave features highly correlated with the target\n",
    "df_no_corr = X.copy()\n",
    "correlation_matrix_spear = df_no_corr.corr(method='spearman').abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper_spear = correlation_matrix_spear.where(np.triu(np.ones(correlation_matrix_spear.shape), k=1).astype(bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than a threshold (e.g., 0.9 in this case)\n",
    "to_drop_spear = [column for column in upper_spear.columns if any(upper_spear[column] >= 0.9)]\n",
    "\n",
    "# Drop features\n",
    "df_reduced_spear = df_no_corr.drop(to_drop_spear, axis=1)\n",
    "\n",
    "# Get list of low correlation features excluding TARGET\n",
    "low_corr_feats_spear = list(df_reduced_spear.columns)\n",
    "\n",
    "with open('low_corr_spear.txt', 'w') as f:\n",
    "    f.write(str(low_corr_feats_spear))\n",
    "    f.write('\\n')\n",
    "\n",
    "# Print the high correlation features effect\n",
    "# Both pre and post drop dfs contain the TARGET\n",
    "print(f\"Dropped {len(to_drop_spear)} highly correlated features.\\nOld Shape of the dataset was {df_no_corr.shape}\\nNew shape of the dataset is {df_reduced_spear.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "no_corr_features = {}\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "\n",
    "    no_corr_features[model_name] = list(df_reduced_spear.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "no_corr_models = evaluate_models_roc(models, df_reduced_spear, y, no_corr_features, sk10, f'{experiment_name}_corr')\n",
    "no_corr_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_importance_features = {}\n",
    "\n",
    "# for model in models:\n",
    "#     model_name = model.__class__.__name__\n",
    "\n",
    "#     try:\n",
    "#         # Initialize array to store feature importances\n",
    "#         feature_importances = np.zeros(X.shape[1])\n",
    "\n",
    "#         # Loop through each fold and calculate the feature importances\n",
    "#         for train_index, test_index in sk10.split(X, y):\n",
    "#             X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "#             y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "#             model.fit(X_train, y_train)\n",
    "\n",
    "#             # Get the feature importances and them to the total\n",
    "#             feature_importances += model.feature_importances_\n",
    "\n",
    "#         feature_importances /= n_splits\n",
    "\n",
    "#         feature_importances_dict = dict(zip(X.columns, feature_importances))\n",
    "\n",
    "#         df = pd.DataFrame.from_dict(feature_importances_dict, orient='index')\n",
    "\n",
    "#         # Resetting index with a name for the column\n",
    "#         df = df.reset_index().rename(columns={'index': 'Feature', 0: 'Avg_Feat_Importance'})\n",
    "#         df.sort_values(by='Avg_Feat_Importance', ascending=False, inplace=True)\n",
    "\n",
    "#         # Save to CSV\n",
    "#         df.to_csv(f'{model_name}_feature_importances.csv')\n",
    "\n",
    "#         fi_threshold = 0\n",
    "\n",
    "#         fi_feats = df[df['Avg_Feat_Importance'] > fi_threshold]['Feature'].tolist()\n",
    "\n",
    "#         feat_importance_features[model_name] = fi_feats\n",
    "#         print(f'Done with {model_name}')\n",
    "\n",
    "#     except AttributeError:\n",
    "#         feat_importance_features[model_name] = list(X.columns)\n",
    "#         print(f'{model_name} does not have feature_importances_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('featimp_features.txt', mode='w') as f:\n",
    "#     pprint(feat_importance_features, stream=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random feature for X\n",
    "np.random.seed(5)\n",
    "df_reduced_spear['random_control_feature'] = np.round(np.random.uniform(-2, 2, df_reduced_spear.shape[0]), 6)\n",
    "df_reduced_spear.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "perm_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=5)\n",
    "\n",
    "perm_importances = {model.__class__.__name__: [] for model in models}\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(perm_cv.split(df_reduced_spear, y)):\n",
    "    X_train, X_test = df_reduced_spear.iloc[train_idx], df_reduced_spear.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        model.fit(X_train, y_train)\n",
    "        # Calculate permutation importance\n",
    "        result = permutation_importance(model, X_test, y_test, n_repeats=5, random_state=5, n_jobs=-1, scoring='roc_auc_ovr')\n",
    "        perm_importances[model_name].append(result.importances_mean)\n",
    "        print(f'Done with {model_name}.')\n",
    "    \n",
    "    print(f'Done with Fold {i+1}', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Average importances across folds and export to CSV\n",
    "for model_name, importances in perm_importances.items():\n",
    "    avg_importance = np.mean(importances, axis=0)\n",
    "    importance_df = pd.DataFrame({'Feature': df_reduced_spear.columns, 'Importance': avg_importance})\n",
    "    importance_df.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "    # Export to CSV\n",
    "    importance_df.to_csv(f'.\\permutation_importances\\{model_name}_permutation_importance.csv', index=False)\n",
    "\n",
    "print('Done with Permuation Importances', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'permutation_importances'\n",
    "\n",
    "# Initialize a dictionary for the features\n",
    "perm_important_features = {}\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    csv_path = os.path.join(directory, f'{model_name}_permutation_importance.csv')\n",
    "    if os.path.exists(csv_path):\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Check for 'random_control_feature' and its importance\n",
    "        if 'random_control_feature' in df['Feature'].values:\n",
    "            random_feature_importance = df.loc[df['Feature'] == 'random_control_feature', 'Importance'].iloc[0]\n",
    "        else:\n",
    "            random_feature_importance = 0\n",
    "\n",
    "        # Determine the threshold\n",
    "        threshold = max(0, random_feature_importance)\n",
    "\n",
    "        # Filter features where importance is greater than 0\n",
    "        important_feats_filtered = df[df['Importance'] > threshold]['Feature'].tolist()\n",
    "\n",
    "        # Reorder important_feats based on the predefined features_list\n",
    "        important_feats_ordered = [feat for feat in features_list if feat in important_feats_filtered]\n",
    "\n",
    "        # Add to importance dictionary\n",
    "        perm_important_features[model_name] = important_feats_ordered\n",
    "\n",
    "    else:\n",
    "        print(f'CSV file for {model_name} not found.')\n",
    "\n",
    "print('Done getting important features dictionary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('perm_important_features_lgbm.txt', mode='w') as f:\n",
    "    pprint(perm_important_features, stream=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "perm_importance_models = evaluate_models_roc(models, X, y, perm_important_features, sk10, f'{experiment_name}_permimp')\n",
    "perm_importance_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SelectKBest with f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features_list = []\n",
    "kbest_features = {}\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "\n",
    "    # Select whichever one had a better CV score generally\n",
    "    # Also, consider computational expense and accuracy balance\n",
    "    \n",
    "    features = perm_important_features[model_name]\n",
    "    # features = list(df_reduced_spear.columns)\n",
    "\n",
    "    # incase there is no feature that had importance, go to the next model\n",
    "    if len(features) == 0:\n",
    "        continue\n",
    "\t\n",
    "    X_kbest = X[features]\n",
    "    best_score = 0\n",
    "    best_k = 0\n",
    "    best_features = []\n",
    "\n",
    "    # Iterate over k from 1 to number of features\n",
    "    for k in range(1, len(features) + 1):\n",
    "        print(f'currently running {k} features on {model_name}')\n",
    "        # Apply SelectKBest\n",
    "        selector = SelectKBest(f_classif, k=k)\n",
    "        X_new = selector.fit_transform(X_kbest, y)\n",
    "\n",
    "        # Get the selected feature names\n",
    "        selected_features = X_kbest.columns[selector.get_support()]\n",
    "\n",
    "        # Evaluate the model\n",
    "        # model = LGBMClassifier(n_jobs=-1, random_state=5)\n",
    "        roc_auc_scores = cross_validate(model, X_new, y, cv=sk10, scoring='roc_auc_ovr', n_jobs=-1)\n",
    "        mean_roc_auc_scores = roc_auc_scores['test_score'].mean()\n",
    "\n",
    "        if mean_roc_auc_scores > best_score:\n",
    "            best_k = k\n",
    "            best_score = mean_roc_auc_scores\n",
    "            best_features = list(selected_features)\n",
    "\n",
    "    best_features_list.append({'k': best_k,\n",
    "                    'Selected Features': best_features,\n",
    "                    'ROC AUC Score': best_score,\n",
    "                    'Model Name': model_name})\n",
    "    \n",
    "    kbest_features[model_name] = best_features\n",
    "\n",
    "best_features_df = pd.DataFrame(best_features_list)\n",
    "\n",
    "best_features_df.sort_values(by='ROC AUC Score', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kbest_features.txt', mode='w') as f:\n",
    "    pprint(kbest_features, stream=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Initialize empty dictionary for RFECV features\n",
    "rfecv_features = {}\n",
    "\n",
    "for alg in models:\n",
    "    # set name\n",
    "    MLA_name = alg.__class__.__name__\n",
    "\t\t\n",
    "    features = perm_important_features[MLA_name]\n",
    "\n",
    "    # incase there is no feature that had importance, go to the next model\n",
    "    if len(features) == 0:\n",
    "        continue\n",
    "\t\n",
    "    X_rfecv = X[features]\n",
    "\n",
    "    try:\n",
    "        print(f'Starting with {MLA_name}')\n",
    "        # Create the RFECV object and rank each feature\n",
    "        selector = RFECV(alg, cv=sk10, step=1, scoring='roc_auc_ovr', verbose=2)\n",
    "        selector = selector.fit(X_rfecv, y)\n",
    "\n",
    "        selected_features = list(X_rfecv.columns[selector.support_])\n",
    "\n",
    "        # Reorder selected_features based on the predefined features_list\n",
    "        selected_features_ordered = [feat for feat in features_list if feat in selected_features]\n",
    "\n",
    "        rfecv_features[MLA_name] = selected_features_ordered\n",
    "\n",
    "        print(f'Done with {MLA_name}', end='\\n\\n')\n",
    "    \n",
    "    except ValueError:\n",
    "        # In case of an error, keep the original order but filtered by features_list\n",
    "        features_filtered = [feat for feat in features_list if feat in features]\n",
    "        rfecv_features[MLA_name] = features_filtered\n",
    "        print(f'{MLA_name} does not have coef_ or feature_importances_', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rfecv_features.txt', mode='w') as f:\n",
    "    pprint(rfecv_features, stream=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "rfecv_models = evaluate_models_roc(models, X, y, rfecv_features, sk10, f'{experiment_name}_rfecv')\n",
    "rfecv_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Initialize empty dictionary for SFS features\n",
    "sfs_features = {}\n",
    "\n",
    "for alg in models:\n",
    "    # set name\n",
    "    MLA_name = alg.__class__.__name__\n",
    "\n",
    "    try:\n",
    "            \n",
    "        # features = kbest_features[MLA_name]\n",
    "        # features = feat_importance_features[MLA_name]\n",
    "        features = rfecv_features[MLA_name]\n",
    "\n",
    "        # incase there is no feature that had importance, go to the next model\n",
    "        if len(features) == 0:\n",
    "            continue\n",
    "        \n",
    "        X_sfs = X[features]\n",
    "\n",
    "        print(f'Running backward feature selection with {MLA_name}')\n",
    "\n",
    "        sfs = SFS(alg,\n",
    "            k_features='best',\n",
    "            forward=False,\n",
    "            floating=False,\n",
    "            scoring='roc_auc_ovr',\n",
    "            verbose=2,\n",
    "            n_jobs=-1,\n",
    "            cv=sk10)\n",
    "        \n",
    "        sfs = sfs.fit(X_sfs, y)\n",
    "\n",
    "        # Get the selected features index\n",
    "        selected_sfs_idx = list(sfs.k_feature_idx_)\n",
    "\n",
    "        # Get the feature names\n",
    "        selected_sfs_feats = X_sfs.columns[selected_sfs_idx]\n",
    "\n",
    "        selected_features = list(selected_sfs_feats)\n",
    "\n",
    "        # Reorder selected_features based on the predefined features_list\n",
    "        selected_features_ordered = [feat for feat in features_list if feat in selected_features]\n",
    "\n",
    "        sfs_features[MLA_name] = selected_features_ordered\n",
    "\n",
    "        print(f'Done with {MLA_name}', end='\\n\\n')\n",
    "\n",
    "    except KeyError:\n",
    "        print(f'{MLA_name} not in the dictionary.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sfs_features.txt', mode='w') as f:\n",
    "    pprint(sfs_features, stream=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_features = {'CatBoostClassifier': ['X_Minimum', 'Pixels_Areas', 'X_Perimeter', 'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer', 'TypeOfSteel_A300', 'Steel_Plate_Thickness', 'Edges_Index', 'Empty_Index', 'Outside_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'Orientation_Index', 'Luminosity_Index'],\n",
    " 'ExtraTreesClassifier': ['X_Minimum', 'Y_Minimum', 'Pixels_Areas', 'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer', 'TypeOfSteel_A300', 'Steel_Plate_Thickness', 'Edges_Index', 'Empty_Index', 'Outside_X_Index', 'Edges_Y_Index', 'Orientation_Index'],\n",
    " 'HistGradientBoostingClassifier': ['X_Minimum', 'Y_Minimum', 'Pixels_Areas', 'Minimum_of_Luminosity', 'Length_of_Conveyer', 'TypeOfSteel_A300', 'Steel_Plate_Thickness', 'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index', 'Edges_Y_Index', 'Orientation_Index', 'Luminosity_Index'],\n",
    " 'LGBMClassifier': ['X_Minimum', 'Y_Minimum', 'Pixels_Areas', 'X_Perimeter', 'Minimum_of_Luminosity', 'Length_of_Conveyer', 'TypeOfSteel_A300', 'Steel_Plate_Thickness', 'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index', 'Edges_X_Index', 'Edges_Y_Index', 'Orientation_Index', 'Luminosity_Index'],\n",
    " 'RandomForestClassifier': ['X_Minimum', 'Y_Minimum', 'Pixels_Areas', 'X_Perimeter', 'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer', 'TypeOfSteel_A300', 'Steel_Plate_Thickness', 'Edges_Index', 'Empty_Index', 'Outside_X_Index', 'Edges_Y_Index', 'Orientation_Index', 'Luminosity_Index'],\n",
    " 'XGBClassifier': ['X_Minimum', 'Pixels_Areas', 'X_Perimeter', 'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer', 'TypeOfSteel_A300', 'Steel_Plate_Thickness', 'Edges_Index', 'Empty_Index', 'Outside_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'Orientation_Index', 'Luminosity_Index']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with LGBMClassifier.\n",
      "Done with RandomForestClassifier.\n",
      "Done with RandomForestClassifier.\n",
      "Done with LGBMClassifier.\n",
      "Done with ExtraTreesClassifier.\n",
      "Done with LGBMClassifier.\n",
      "Done with RandomForestClassifier.\n",
      "Done with XGBClassifier.\n",
      "Done with ExtraTreesClassifier.\n",
      "Done with ExtraTreesClassifier.\n",
      "Done with LGBMClassifier.\n",
      "Done with ExtraTreesClassifier.\n",
      "Done with ExtraTreesClassifier.\n",
      "Done with HistGradientBoostingClassifier.\n",
      "Done with HistGradientBoostingClassifier.\n",
      "Done with HistGradientBoostingClassifier.\n",
      "Done with HistGradientBoostingClassifier.\n",
      "Done with HistGradientBoostingClassifier.\n",
      "Done with HistGradientBoostingClassifier.\n",
      "Done with LGBMClassifier.\n",
      "Done with CatBoostClassifier.\n",
      "CPU times: total: 1.08 s\n",
      "Wall time: 11min 40s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Parameters</th>\n",
       "      <th>MLA Train ROC AUC</th>\n",
       "      <th>MLA Test ROC AUC</th>\n",
       "      <th>MLA Test ROC AUC Std</th>\n",
       "      <th>MLA Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>0.933004</td>\n",
       "      <td>0.900265</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>8 min 8.26 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>0.934512</td>\n",
       "      <td>0.899455</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>2 min 11.36 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>0.958327</td>\n",
       "      <td>0.898667</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>2 min 31.77 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>0.974999</td>\n",
       "      <td>0.898633</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>0 min 50.96 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>0.981378</td>\n",
       "      <td>0.898618</td>\n",
       "      <td>0.003206</td>\n",
       "      <td>1 min 7.91 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>{'categorical_features': None, 'early_stopping...</td>\n",
       "      <td>0.939049</td>\n",
       "      <td>0.897724</td>\n",
       "      <td>0.002971</td>\n",
       "      <td>0 min 47.29 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>{'categorical_features': None, 'early_stopping...</td>\n",
       "      <td>0.930866</td>\n",
       "      <td>0.897680</td>\n",
       "      <td>0.003052</td>\n",
       "      <td>0 min 6.49 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>0.921078</td>\n",
       "      <td>0.897596</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>0 min 3.32 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>{'categorical_features': None, 'early_stopping...</td>\n",
       "      <td>0.942095</td>\n",
       "      <td>0.897519</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0 min 11.90 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>{'categorical_features': None, 'early_stopping...</td>\n",
       "      <td>0.928550</td>\n",
       "      <td>0.897471</td>\n",
       "      <td>0.002210</td>\n",
       "      <td>0 min 9.77 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>{'categorical_features': None, 'early_stopping...</td>\n",
       "      <td>0.951425</td>\n",
       "      <td>0.896366</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>0 min 7.50 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>{'verbose': False, 'random_state': 5, 'early_s...</td>\n",
       "      <td>0.981920</td>\n",
       "      <td>0.895510</td>\n",
       "      <td>0.002137</td>\n",
       "      <td>1 min 25.79 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>{'categorical_features': None, 'early_stopping...</td>\n",
       "      <td>0.964685</td>\n",
       "      <td>0.894672</td>\n",
       "      <td>0.002302</td>\n",
       "      <td>0 min 13.97 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>0.988834</td>\n",
       "      <td>0.893696</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0 min 23.97 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "      <td>0.977425</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.002981</td>\n",
       "      <td>0 min 36.94 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "      <td>0.952865</td>\n",
       "      <td>0.892176</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>0 min 58.97 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "      <td>0.949421</td>\n",
       "      <td>0.891852</td>\n",
       "      <td>0.002963</td>\n",
       "      <td>0 min 53.27 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>{'objective': 'binary:logistic', 'use_label_en...</td>\n",
       "      <td>0.994761</td>\n",
       "      <td>0.890506</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>0 min 42.63 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "      <td>0.933591</td>\n",
       "      <td>0.890329</td>\n",
       "      <td>0.003173</td>\n",
       "      <td>0 min 46.16 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.889755</td>\n",
       "      <td>0.002782</td>\n",
       "      <td>0 min 14.35 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.885806</td>\n",
       "      <td>0.002558</td>\n",
       "      <td>0 min 8.89 sec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          MLA Name  \\\n",
       "3                   LGBMClassifier   \n",
       "4                   LGBMClassifier   \n",
       "2                   LGBMClassifier   \n",
       "7           RandomForestClassifier   \n",
       "8           RandomForestClassifier   \n",
       "18  HistGradientBoostingClassifier   \n",
       "16  HistGradientBoostingClassifier   \n",
       "1                   LGBMClassifier   \n",
       "15  HistGradientBoostingClassifier   \n",
       "19  HistGradientBoostingClassifier   \n",
       "17  HistGradientBoostingClassifier   \n",
       "20              CatBoostClassifier   \n",
       "14  HistGradientBoostingClassifier   \n",
       "0                   LGBMClassifier   \n",
       "10            ExtraTreesClassifier   \n",
       "13            ExtraTreesClassifier   \n",
       "12            ExtraTreesClassifier   \n",
       "5                    XGBClassifier   \n",
       "11            ExtraTreesClassifier   \n",
       "6           RandomForestClassifier   \n",
       "9             ExtraTreesClassifier   \n",
       "\n",
       "                                       MLA Parameters  MLA Train ROC AUC  \\\n",
       "3   {'boosting_type': 'gbdt', 'class_weight': None...           0.933004   \n",
       "4   {'boosting_type': 'gbdt', 'class_weight': None...           0.934512   \n",
       "2   {'boosting_type': 'gbdt', 'class_weight': None...           0.958327   \n",
       "7   {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...           0.974999   \n",
       "8   {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...           0.981378   \n",
       "18  {'categorical_features': None, 'early_stopping...           0.939049   \n",
       "16  {'categorical_features': None, 'early_stopping...           0.930866   \n",
       "1   {'boosting_type': 'gbdt', 'class_weight': None...           0.921078   \n",
       "15  {'categorical_features': None, 'early_stopping...           0.942095   \n",
       "19  {'categorical_features': None, 'early_stopping...           0.928550   \n",
       "17  {'categorical_features': None, 'early_stopping...           0.951425   \n",
       "20  {'verbose': False, 'random_state': 5, 'early_s...           0.981920   \n",
       "14  {'categorical_features': None, 'early_stopping...           0.964685   \n",
       "0   {'boosting_type': 'gbdt', 'class_weight': None...           0.988834   \n",
       "10  {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...           0.977425   \n",
       "13  {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...           0.952865   \n",
       "12  {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...           0.949421   \n",
       "5   {'objective': 'binary:logistic', 'use_label_en...           0.994761   \n",
       "11  {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...           0.933591   \n",
       "6   {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...           0.999999   \n",
       "9   {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...           1.000000   \n",
       "\n",
       "    MLA Test ROC AUC  MLA Test ROC AUC Std         MLA Time  \n",
       "3           0.900265              0.002224   8 min 8.26 sec  \n",
       "4           0.899455              0.002012  2 min 11.36 sec  \n",
       "2           0.898667              0.001489  2 min 31.77 sec  \n",
       "7           0.898633              0.003085  0 min 50.96 sec  \n",
       "8           0.898618              0.003206   1 min 7.91 sec  \n",
       "18          0.897724              0.002971  0 min 47.29 sec  \n",
       "16          0.897680              0.003052   0 min 6.49 sec  \n",
       "1           0.897596              0.001941   0 min 3.32 sec  \n",
       "15          0.897519              0.002527  0 min 11.90 sec  \n",
       "19          0.897471              0.002210   0 min 9.77 sec  \n",
       "17          0.896366              0.002597   0 min 7.50 sec  \n",
       "20          0.895510              0.002137  1 min 25.79 sec  \n",
       "14          0.894672              0.002302  0 min 13.97 sec  \n",
       "0           0.893696              0.002014  0 min 23.97 sec  \n",
       "10          0.893519              0.002981  0 min 36.94 sec  \n",
       "13          0.892176              0.002970  0 min 58.97 sec  \n",
       "12          0.891852              0.002963  0 min 53.27 sec  \n",
       "5           0.890506              0.001488  0 min 42.63 sec  \n",
       "11          0.890329              0.003173  0 min 46.16 sec  \n",
       "6           0.889755              0.002782  0 min 14.35 sec  \n",
       "9           0.885806              0.002558   0 min 8.89 sec  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "sfs_models = evaluate_models_roc(models, X, y, sfs_features, sk10, f'{experiment_name}_sfs')\n",
    "sfs_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with CatBoostClassifier.\n",
      "Done with CatBoostClassifier.\n",
      "Done with CatBoostClassifier.\n",
      "Done with CatBoostClassifier.\n",
      "Done with CatBoostClassifier.\n",
      "CPU times: total: 78.1 ms\n",
      "Wall time: 15min 24s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Parameters</th>\n",
       "      <th>MLA Train ROC AUC</th>\n",
       "      <th>MLA Test ROC AUC</th>\n",
       "      <th>MLA Test ROC AUC Std</th>\n",
       "      <th>MLA Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>{'iterations': 2500, 'learning_rate': 0.035, '...</td>\n",
       "      <td>0.980475</td>\n",
       "      <td>0.897967</td>\n",
       "      <td>0.001899</td>\n",
       "      <td>3 min 31.66 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>{'verbose': False, 'random_state': 5, 'early_s...</td>\n",
       "      <td>0.981920</td>\n",
       "      <td>0.895510</td>\n",
       "      <td>0.002137</td>\n",
       "      <td>2 min 46.36 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>{'iterations': 2500, 'learning_rate': 0.025, '...</td>\n",
       "      <td>0.991445</td>\n",
       "      <td>0.895481</td>\n",
       "      <td>0.002223</td>\n",
       "      <td>7 min 52.93 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>{'iterations': 2500, 'learning_rate': 0.04, 'l...</td>\n",
       "      <td>0.999508</td>\n",
       "      <td>0.891668</td>\n",
       "      <td>0.001760</td>\n",
       "      <td>10 min 42.27 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>{'iterations': 3000, 'learning_rate': 0.065, '...</td>\n",
       "      <td>0.999795</td>\n",
       "      <td>0.888489</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>11 min 49.56 sec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MLA Name                                     MLA Parameters  \\\n",
       "4  CatBoostClassifier  {'iterations': 2500, 'learning_rate': 0.035, '...   \n",
       "0  CatBoostClassifier  {'verbose': False, 'random_state': 5, 'early_s...   \n",
       "3  CatBoostClassifier  {'iterations': 2500, 'learning_rate': 0.025, '...   \n",
       "1  CatBoostClassifier  {'iterations': 2500, 'learning_rate': 0.04, 'l...   \n",
       "2  CatBoostClassifier  {'iterations': 3000, 'learning_rate': 0.065, '...   \n",
       "\n",
       "   MLA Train ROC AUC  MLA Test ROC AUC  MLA Test ROC AUC Std          MLA Time  \n",
       "4           0.980475          0.897967              0.001899   3 min 31.66 sec  \n",
       "0           0.981920          0.895510              0.002137   2 min 46.36 sec  \n",
       "3           0.991445          0.895481              0.002223   7 min 52.93 sec  \n",
       "1           0.999508          0.891668              0.001760  10 min 42.27 sec  \n",
       "2           0.999795          0.888489              0.001065  11 min 49.56 sec  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "sfs_models = evaluate_models_roc(models, X, y, sfs_features, sk10, f'{experiment_name}_sfs_cat')\n",
    "sfs_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Model Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1 = LGBMClassifier(n_jobs=-1, random_state=5)\n",
    "# model2 = XGBClassifier(random_state=5)\n",
    "# model3 = RandomForestClassifier(random_state=5)\n",
    "# model4 = ExtraTreesClassifier(random_state=5)\n",
    "# model5 = HistGradientBoostingClassifier(random_state=5)\n",
    "# model6 = CatBoostClassifier(random_state=5, verbose=False, early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LGBMClassifier(n_jobs=-1, random_state=5)\n",
    "model1b = LGBMClassifier(**lgbm_params_1)\n",
    "model1c = LGBMClassifier(**lgbm_params_2)\n",
    "model1d = LGBMClassifier(**lgbm_params_3)\n",
    "model1e = LGBMClassifier(**lgbm_params_4)\n",
    "model2 = XGBClassifier(random_state=5)\n",
    "model3 = RandomForestClassifier(random_state=5)\n",
    "model3b = RandomForestClassifier(**rf_params_1)\n",
    "model3c = RandomForestClassifier(**rf_params_2)\n",
    "model4 = ExtraTreesClassifier(random_state=5)\n",
    "model4b = ExtraTreesClassifier(**extrat_params_1)\n",
    "model4c = ExtraTreesClassifier(**extrat_params_2)\n",
    "model4d = ExtraTreesClassifier(**extrat_params_3)\n",
    "model4e = ExtraTreesClassifier(**extrat_params_4)\n",
    "model5 = HistGradientBoostingClassifier(random_state=5)\n",
    "model5b = HistGradientBoostingClassifier(**hist_params_1)\n",
    "model5c = HistGradientBoostingClassifier(**hist_params_2)\n",
    "model5d = HistGradientBoostingClassifier(**hist_params_3)\n",
    "model5e = HistGradientBoostingClassifier(**hist_params_4)\n",
    "model5f = HistGradientBoostingClassifier(**hist_params_5)\n",
    "model6 = CatBoostClassifier(random_state=5, verbose=False, early_stopping_rounds=100)\n",
    "# model6b = CatBoostClassifier(**cat_params_1)\n",
    "# model6c = CatBoostClassifier(**cat_params_2)\n",
    "# model6d = CatBoostClassifier(**cat_params_3)\n",
    "model6e = CatBoostClassifier(**cat_params_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Features for Competition + Original dataset down to SFS for all models (Experiment Set 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_feats = ['X_Minimum', 'Y_Minimum', 'Pixels_Areas', 'X_Perimeter', 'Minimum_of_Luminosity', 'Length_of_Conveyer', 'TypeOfSteel_A300', 'Steel_Plate_Thickness', 'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index', 'Edges_X_Index', 'Edges_Y_Index', 'Orientation_Index', 'Luminosity_Index']\n",
    "model2_feats = ['X_Minimum', 'Pixels_Areas', 'X_Perimeter', 'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer', 'TypeOfSteel_A300', 'Steel_Plate_Thickness', 'Edges_Index', 'Empty_Index', 'Outside_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'Orientation_Index', 'Luminosity_Index']\n",
    "model3_feats = ['X_Minimum', 'Y_Minimum', 'Pixels_Areas', 'X_Perimeter', 'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer', 'TypeOfSteel_A300', 'Steel_Plate_Thickness', 'Edges_Index', 'Empty_Index', 'Outside_X_Index', 'Edges_Y_Index', 'Orientation_Index', 'Luminosity_Index']\n",
    "model4_feats = ['X_Minimum', 'Y_Minimum', 'Pixels_Areas', 'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer', 'TypeOfSteel_A300', 'Steel_Plate_Thickness', 'Edges_Index', 'Empty_Index', 'Outside_X_Index', 'Edges_Y_Index', 'Orientation_Index']\n",
    "model5_feats = ['X_Minimum', 'Y_Minimum', 'Pixels_Areas', 'Minimum_of_Luminosity', 'Length_of_Conveyer', 'TypeOfSteel_A300', 'Steel_Plate_Thickness', 'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index', 'Edges_Y_Index', 'Orientation_Index', 'Luminosity_Index']\n",
    "model6_feats = ['X_Minimum', 'Pixels_Areas', 'X_Perimeter', 'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer', 'TypeOfSteel_A300', 'Steel_Plate_Thickness', 'Edges_Index', 'Empty_Index', 'Outside_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'Orientation_Index', 'Luminosity_Index']\n",
    "\n",
    "X_lgbm = X[model1_feats]\n",
    "X_xgb = X[model2_feats]\n",
    "X_rf = X[model3_feats]\n",
    "X_extrat = X[model4_feats]\n",
    "X_hist = X[model5_feats]\n",
    "X_cat = X[model6_feats]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Raw Parameters for individual tunings\n",
    "    class_weight_option = trial.suggest_categorical('class_weight', ['none', 'balanced', 'custom'])\n",
    "    if class_weight_option == 'none':\n",
    "        class_weight = None\n",
    "    elif class_weight_option == 'balanced':\n",
    "        class_weight = 'balanced'\n",
    "    else:\n",
    "        # For multi-class, you could define a range or specific values to test\n",
    "        weight_for_class_0 = trial.suggest_float('weight_for_class_0', 0.1, 10.0)\n",
    "        weight_for_class_1 = trial.suggest_float('weight_for_class_1', 0.1, 10.0)\n",
    "        weight_for_class_2 = trial.suggest_float('weight_for_class_2', 0.1, 10.0)\n",
    "        weight_for_class_3 = trial.suggest_float('weight_for_class_3', 0.1, 10.0)\n",
    "        weight_for_class_4 = trial.suggest_float('weight_for_class_4', 0.1, 10.0)\n",
    "        weight_for_class_5 = trial.suggest_float('weight_for_class_5', 0.1, 10.0)\n",
    "        weight_for_class_6 = trial.suggest_float('weight_for_class_6', 0.1, 10.0)\n",
    "        class_weight = {0: weight_for_class_0, 1: weight_for_class_1, 2: weight_for_class_2, 3: weight_for_class_3, 4: weight_for_class_4, 5: weight_for_class_5, 6: weight_for_class_6}\n",
    "\n",
    "    param = {\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': 7,\n",
    "        'boosting_type': trial.suggest_categorical('boosting', ['gbdt', 'dart', 'goss']),\n",
    "        # 'class_weight': class_weight,\n",
    "        # 'colsample_bytree': trial.suggest_float('colsample_bytree', 0.2, 1.0),\n",
    "        # 'learning_rate': trial.suggest_float('learning_rate', 0.000001, 0.5),\n",
    "        # 'max_depth': trial.suggest_int('max_depth', -1, 64),\n",
    "        # 'min_child_samples': trial.suggest_int('min_child_samples', 5, 500),\n",
    "        # 'min_child_weight': trial.suggest_float('min_child_weight', 0.001, 10.0),\n",
    "        # 'min_split_gain': trial.suggest_float('min_split_gain', 0.5, 1.0),\n",
    "        # 'n_estimators': trial.suggest_int('n_estimators', 100, 3000),\n",
    "        # 'n_jobs': -1,\n",
    "        # 'num_leaves': trial.suggest_int('num_leaves', 2, 1000),\n",
    "        # 'random_state': 5,\n",
    "        # 'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "        # 'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0),\n",
    "        # 'subsample': trial.suggest_float('subsample', 0.1, 1.0),\n",
    "        }\n",
    "\n",
    "    # # Group Parameters after individual tunings (change after testing the individual params)\n",
    "    # param = {\n",
    "    #     'objective': 'multiclass',\n",
    "    #     'num_class': 7,\n",
    "    #     'boosting_type': trial.suggest_categorical('boosting', ['gbdt', 'dart', 'goss']),\n",
    "    #     'class_weight': class_weight,\n",
    "    #     'colsample_bytree': trial.suggest_float('colsample_bytree', 0.2, 1.0),\n",
    "    #     'learning_rate': trial.suggest_float('learning_rate', 0.000001, 0.5),\n",
    "    #     'max_depth': trial.suggest_int('max_depth', -1, 64),\n",
    "    #     'min_child_samples': trial.suggest_int('min_child_samples', 5, 500),\n",
    "    #     'min_child_weight': trial.suggest_float('min_child_weight', 0.001, 10.0),\n",
    "    #     'min_split_gain': trial.suggest_float('min_split_gain', 0.5, 1.0),\n",
    "    #     'n_estimators': trial.suggest_int('n_estimators', 100, 3000),\n",
    "    #     'n_jobs': -1,\n",
    "    #     'num_leaves': trial.suggest_int('num_leaves', 2, 1000),\n",
    "    #     'random_state': 5,\n",
    "    #     'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "    #     'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0),\n",
    "    #     'subsample': trial.suggest_float('subsample', 0.1, 1.0),\n",
    "    #     }\n",
    "    \n",
    "    roc_auc_scores = []\n",
    "    \n",
    "    for train_index, test_index in sk10.split(X_lgbm, y):\n",
    "        X_train, X_test = X_lgbm.iloc[train_index], X_lgbm.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        model = LGBMClassifier(**param)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=100, verbose=False)\n",
    "        preds = model.predict_proba(X_test)\n",
    "        roc_auc = roc_auc_score(y_test, preds, multi_class='ovr', average='macro')\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "    \n",
    "    return np.mean(roc_auc_scores)\n",
    "\n",
    "# Using median pruner\n",
    "pruner = optuna.pruners.MedianPruner(n_startup_trials=2, n_warmup_steps=1, interval_steps=1)\n",
    "\n",
    "study = optuna.create_study(direction='maximize', pruner=pruner)\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)\n",
    "\n",
    "# 0.893695902"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HistGradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # # Raw Parameters for individual tunings\n",
    "    # param = {\n",
    "    #     # 'learning_rate': trial.suggest_float('learning_rate', 0.000001, 0.15),\n",
    "    #     # 'max_iter': trial.suggest_int('max_iter', 50, 5000),\n",
    "    #     # 'max_leaf_nodes': trial.suggest_int('max_leaf_nodes', 20, 1000),\n",
    "    #     # 'min_samples_leaf': trial.suggest_int('min_samples_leaf', 10, 1000),\n",
    "    #     # 'l2_regularization': trial.suggest_float('l2_regularization', 0.1, 1.0),\n",
    "    #     # 'max_bins': trial.suggest_int('max_bins', 10, 255),\n",
    "    #     'max_depth': trial.suggest_int('max_depth', 2, 64),\n",
    "    #     'random_state': 5,\n",
    "    # }\n",
    "\n",
    "    # Group Parameters after individual tunings (change after testing the individual params)\n",
    "    param = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.02, 0.06),\n",
    "        'max_iter': 100,\n",
    "        'max_leaf_nodes': trial.suggest_int('max_leaf_nodes', 10, 50),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 300, 800),\n",
    "        'l2_regularization': trial.suggest_float('l2_regularization', 0.8, 1.0),\n",
    "        'max_bins': trial.suggest_int('max_bins', 50, 150),\n",
    "        'max_depth': 25,\n",
    "        'random_state': 5,\n",
    "    }\n",
    "\n",
    "    roc_auc_scores = []\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(sk10.split(X_hist, y)):\n",
    "        X_train, X_test = X_hist.iloc[train_index], X_hist.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        model = HistGradientBoostingClassifier(**param)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict_proba(X_test)\n",
    "        roc_auc = roc_auc_score(y_test, preds, multi_class='ovr', average='macro')\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "\n",
    "        # Report intermediate objective value\n",
    "        trial.report(roc_auc, i)\n",
    "\n",
    "        # Handle pruning based on the intermediate value\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned('ROC score lower than threshold.')\n",
    "\n",
    "        # # Check if performance is below threshold\n",
    "        # if roc_auc < performance_threshold:\n",
    "        #     raise optuna.exceptions.TrialPruned('ROC score lower than threshold.')\n",
    "\n",
    "    return np.mean(roc_auc_scores)\n",
    "\n",
    "pruner = optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=1, interval_steps=1)\n",
    "\n",
    "study = optuna.create_study(direction='maximize', pruner=pruner)\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ExtraTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # # Raw Parameters for individual tunings\n",
    "    # param = {\n",
    "    #     # 'ccp_alpha': trial.suggest_float('ccp_alpha', 0.0, 0.1),\n",
    "    #     # 'class_weight': trial.suggest_categorical('class_weight', [None, 'balanced', 'balanced_subsample']),\n",
    "    #     # 'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy', 'log_loss']),\n",
    "    #     # 'max_depth': trial.suggest_int('max_depth', 10, 3000),\n",
    "    #     # 'max_features': trial.suggest_categorical('max_features', [None, 'sqrt', 'log2']),\n",
    "    #     # 'max_leaf_nodes': trial.suggest_int('max_leaf_nodes', 100, 3000, log=True) or None,\n",
    "    #     # 'min_impurity_decrease': trial.suggest_float('min_impurity_decrease', 0.0, 0.1),\n",
    "    #     # 'min_samples_leaf': trial.suggest_int('min_samples_leaf',1, 500),\n",
    "    #     # 'min_samples_split': trial.suggest_int('min_samples_split', 2, 500),\n",
    "    #     # 'min_weight_fraction_leaf': trial.suggest_float('min_weight_fraction_leaf', 0.0, 0.5),\n",
    "    #     'n_estimators': trial.suggest_int('n_estimators', 50, 3000),\n",
    "    #     'random_state': 5,\n",
    "    #     'n_jobs': -1,\n",
    "    # }\n",
    "\n",
    "    # Group Parameters after individual tunings (change after testing the individual params)\n",
    "    param = {\n",
    "        'ccp_alpha': 0.0,\n",
    "        'class_weight': None,\n",
    "        'criterion': 'gini',\n",
    "        'max_depth': None,\n",
    "        'max_features': 'sqrt',\n",
    "        'max_leaf_nodes': trial.suggest_int('max_leaf_nodes', 1000, 3000, log=True) or None,\n",
    "        'min_impurity_decrease': 0.0,\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf',1, 20),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 100),\n",
    "        'min_weight_fraction_leaf': trial.suggest_float('min_weight_fraction_leaf', 0.0, 0.002),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 2500, 3000),\n",
    "        'random_state': 5,\n",
    "        'n_jobs': -1,\n",
    "    }\n",
    "\n",
    "    roc_auc_scores = []\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(sk10.split(X_extrat, y)):\n",
    "        X_train, X_test = X_extrat.iloc[train_index], X_extrat.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        model = ExtraTreesClassifier(**param)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict_proba(X_test)\n",
    "        roc_auc = roc_auc_score(y_test, preds, multi_class='ovr', average='macro')\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "\n",
    "        # Report intermediate objective value\n",
    "        trial.report(roc_auc, i)\n",
    "\n",
    "        # Handle pruning based on the intermediate value\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned('ROC score lower than threshold.')\n",
    "\n",
    "        # # Check if performance is below threshold\n",
    "        # if roc_auc < performance_threshold:\n",
    "        #     raise optuna.exceptions.TrialPruned('ROC score lower than threshold.')\n",
    "\n",
    "    return np.mean(roc_auc_scores)\n",
    "\n",
    "pruner = optuna.pruners.MedianPruner(n_startup_trials=2, n_warmup_steps=0, interval_steps=1)\n",
    "\n",
    "study = optuna.create_study(direction='maximize', pruner=pruner)\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=25)\n",
    "\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # # # Raw Parameters for individual tunings\n",
    "    # param = {\n",
    "    #     # 'ccp_alpha': trial.suggest_float('ccp_alpha', 0.0, 0.1),\n",
    "    #     # 'class_weight': trial.suggest_categorical('class_weight', [None, 'balanced', 'balanced_subsample']),\n",
    "    #     # 'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
    "    #     # 'max_depth': trial.suggest_int('max_depth', 10, 1000, log=True) or None,\n",
    "    #     # 'max_features': trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2']),\n",
    "    #     # 'max_leaf_nodes': trial.suggest_int('max_leaf_nodes', 10, 1000, log=True) or None,\n",
    "    #     # 'max_samples': trial.suggest_float('max_samples', 0.1, 1.0),\n",
    "    #     # 'min_impurity_decrease': trial.suggest_float('min_impurity_decrease', 0.0, 0.05),\n",
    "    #     # 'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 100),\n",
    "    #     # 'min_samples_split': trial.suggest_int('min_samples_split', 2, 200),\n",
    "    #     # 'min_weight_fraction_leaf': trial.suggest_float('min_weight_fraction_leaf', 0.0, 0.1),\n",
    "    #     'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n",
    "    #     'random_state': 5,\n",
    "    #     'n_jobs': -1,\n",
    "    # }\n",
    "\n",
    "    # Group Parameters after individual tunings (change after testing the individual params)\n",
    "    param = {\n",
    "        'ccp_alpha': 0.0,\n",
    "        'class_weight': None,\n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 30, log=True),\n",
    "        'max_leaf_nodes': trial.suggest_int('max_leaf_nodes', 300, 700, log=True) or None,\n",
    "        'max_samples': trial.suggest_float('max_samples', 0.1, 1.0),\n",
    "        'min_impurity_decrease': 0.0,\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_weight_fraction_leaf': 0.0,\n",
    "        'max_features': 'log2',\n",
    "        'criterion': 'entropy',\n",
    "        'n_estimators': 1000,\n",
    "        'random_state': 5,\n",
    "        'n_jobs': -1,\n",
    "    }\n",
    "\n",
    "    roc_auc_scores = []\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(sk10.split(X_rf, y)):\n",
    "        X_train, X_test = X_rf.iloc[train_index], X_rf.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        model = RandomForestClassifier(**param)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict_proba(X_test)\n",
    "        roc_auc = roc_auc_score(y_test, preds, multi_class='ovr', average='macro')\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "\n",
    "        # Report intermediate objective value\n",
    "        trial.report(roc_auc, i)\n",
    "\n",
    "        # Handle pruning based on the intermediate value\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned('ROC score lower than threshold.')\n",
    "\n",
    "        # # Check if performance is below threshold\n",
    "        # if roc_auc < performance_threshold:\n",
    "        #     raise optuna.exceptions.TrialPruned('ROC score lower than threshold.')\n",
    "\n",
    "    return np.mean(roc_auc_scores)\n",
    "\n",
    "pruner = optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=1, interval_steps=1)\n",
    "\n",
    "study = optuna.create_study(direction='maximize', pruner=pruner)\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Raw Parameters for individual tunings\n",
    "    param = {\n",
    "        'iterations': trial.suggest_int('iterations', 50, 2000),\n",
    "        # 'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        # 'learning_rate': trial.suggest_float('learning_rate', 0.0001, 0.3, log=True),\n",
    "        # 'depth': trial.suggest_int('max_depth', 1, 10),\n",
    "        # 'subsample': trial.suggest_float('subsample', 0.05, 1),\n",
    "        # 'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.05, 1.0),\n",
    "        # 'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 100),\n",
    "        # 'l2_leaf_reg': trial.suggest_float('l2_reg', 1e-2, 10),\n",
    "        # 'random_strength': trial.suggest_float('random_strength', 1e-2, 10),\n",
    "        # 'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 1),\n",
    "        'random_state': 5,\n",
    "        'verbose': False,\n",
    "    }\n",
    "\n",
    "    # Group Parameters after individual tunings (change after testing the individual params)\n",
    "    # param = {\n",
    "    #     'iterations': trial.suggest_int('iterations', 50, 2000),\n",
    "    #     'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "    #     'learning_rate': trial.suggest_float('learning_rate', 0.0001, 0.3, log=True),\n",
    "    #     'depth': trial.suggest_int('max_depth', 1, 10),\n",
    "    #     'subsample': trial.suggest_float('subsample', 0.05, 1),\n",
    "    #     'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.05, 1.0),\n",
    "    #     'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 100),\n",
    "    #     'l2_leaf_reg': trial.suggest_float('l2_reg', 1e-2, 10),\n",
    "    #     'random_strength': trial.suggest_float('random_strength', 1e-2, 10),\n",
    "    #     'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 1),\n",
    "    #     'random_state': 5,\n",
    "    #     'verbose': False,\n",
    "    # }\n",
    "\n",
    "    roc_auc_scores = []\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(sk10.split(X_rf, y)):\n",
    "        X_train, X_test = X_rf.iloc[train_index], X_rf.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        model = CatBoostClassifier(**param)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict_proba(X_test)\n",
    "        roc_auc = roc_auc_score(y_test, preds, multi_class='ovr', average='macro')\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "\n",
    "        # Report intermediate objective value\n",
    "        trial.report(roc_auc, i)\n",
    "\n",
    "        # Handle pruning based on the intermediate value\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned('ROC score lower than threshold.')\n",
    "\n",
    "        # # Check if performance is below threshold\n",
    "        # if roc_auc < performance_threshold:\n",
    "        #     raise optuna.exceptions.TrialPruned('ROC score lower than threshold.')\n",
    "\n",
    "    return np.mean(roc_auc_scores)\n",
    "\n",
    "pruner = optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=1, interval_steps=1)\n",
    "\n",
    "study = optuna.create_study(direction='maximize', pruner=pruner)\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Running XGBoost\n",
      "Running Random Forest\n",
      "Running ExtraTrees\n",
      "Running Hist Gradient\n",
      "Running CatBoost\n",
      "Done with fold 1.\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Running XGBoost\n",
      "Running Random Forest\n",
      "Running ExtraTrees\n",
      "Running Hist Gradient\n",
      "Running CatBoost\n",
      "Done with fold 2.\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "Running XGBoost\n",
      "Running Random Forest\n",
      "Running ExtraTrees\n",
      "Running Hist Gradient\n",
      "Running CatBoost\n",
      "Done with fold 3.\n",
      "CPU times: total: 38min 43s\n",
      "Wall time: 20min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model1_results, model1b_results, model1c_results, model1d_results, model1e_results, model2_results, model3_results, model3b_results, model3c_results, model4_results, model4b_results, model4c_results, model4d_results, model4e_results, model5_results, model5b_results, model5c_results, model5d_results, model5e_results, model5f_results, model6_results, model6b_results, model6c_results, model6d_results, model6e_results, y_test_list = [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []\n",
    "\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(sk10.split(X, y)):\n",
    "    X_train_lgbm, X_test_lgbm = X_lgbm.iloc[train_index], X_lgbm.iloc[test_index]\n",
    "    X_train_xgb, X_test_xgb = X_xgb.iloc[train_index], X_xgb.iloc[test_index]\n",
    "    X_train_rf, X_test_rf = X_rf.iloc[train_index], X_rf.iloc[test_index]\n",
    "    X_train_extrat, X_test_extrat = X_extrat.iloc[train_index], X_extrat.iloc[test_index]\n",
    "    X_train_hist, X_test_hist = X_hist.iloc[train_index], X_hist.iloc[test_index]\n",
    "    X_train_cat, X_test_cat = X_cat.iloc[train_index], X_cat.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model1.fit(X_train_lgbm, y_train)\n",
    "    model1_results.append(model1.predict_proba(X_test_lgbm))\n",
    "\n",
    "    model1b.fit(X_train_lgbm, y_train)\n",
    "    model1b_results.append(model1b.predict_proba(X_test_lgbm))\n",
    "\n",
    "    model1c.fit(X_train_lgbm, y_train)\n",
    "    model1c_results.append(model1c.predict_proba(X_test_lgbm))\n",
    "\n",
    "    model1d.fit(X_train_lgbm, y_train)\n",
    "    model1d_results.append(model1d.predict_proba(X_test_lgbm))\n",
    "\n",
    "    model1e.fit(X_train_lgbm, y_train)\n",
    "    model1e_results.append(model1e.predict_proba(X_test_lgbm))\n",
    "\n",
    "    print('Running XGBoost')\n",
    "\n",
    "    model2.fit(X_train_xgb, y_train)\n",
    "    model2_results.append(model2.predict_proba(X_test_xgb))\n",
    "\n",
    "    print('Running Random Forest')\n",
    "\n",
    "    model3.fit(X_train_rf, y_train)\n",
    "    model3_results.append(model3.predict_proba(X_test_rf))\n",
    "\n",
    "    model3b.fit(X_train_rf, y_train)\n",
    "    model3b_results.append(model3b.predict_proba(X_test_rf))\n",
    "\n",
    "    model3c.fit(X_train_rf, y_train)\n",
    "    model3c_results.append(model3c.predict_proba(X_test_rf))\n",
    "\n",
    "    print('Running ExtraTrees')\n",
    "\n",
    "    model4.fit(X_train_extrat, y_train)\n",
    "    model4_results.append(model4.predict_proba(X_test_extrat))\n",
    "\n",
    "    model4b.fit(X_train_extrat, y_train)\n",
    "    model4b_results.append(model4b.predict_proba(X_test_extrat))\n",
    "\n",
    "    model4c.fit(X_train_extrat, y_train)\n",
    "    model4c_results.append(model4c.predict_proba(X_test_extrat))\n",
    "\n",
    "    model4d.fit(X_train_extrat, y_train)\n",
    "    model4d_results.append(model4d.predict_proba(X_test_extrat))\n",
    "\n",
    "    model4e.fit(X_train_extrat, y_train)\n",
    "    model4e_results.append(model4e.predict_proba(X_test_extrat))\n",
    "\n",
    "    print('Running Hist Gradient')\n",
    "\n",
    "    model5.fit(X_train_hist, y_train)\n",
    "    model5_results.append(model5.predict_proba(X_test_hist))\n",
    "\n",
    "    model5b.fit(X_train_hist, y_train)\n",
    "    model5b_results.append(model5b.predict_proba(X_test_hist))\n",
    "\n",
    "    model5c.fit(X_train_hist, y_train)\n",
    "    model5c_results.append(model5c.predict_proba(X_test_hist))\n",
    "\n",
    "    model5d.fit(X_train_hist, y_train)\n",
    "    model5d_results.append(model5d.predict_proba(X_test_hist))\n",
    "\n",
    "    model5e.fit(X_train_hist, y_train)\n",
    "    model5e_results.append(model5e.predict_proba(X_test_hist))\n",
    "\n",
    "    model5f.fit(X_train_hist, y_train)\n",
    "    model5f_results.append(model5f.predict_proba(X_test_hist))\n",
    "\n",
    "    print('Running CatBoost')\n",
    "\n",
    "    model6.fit(X_train_cat, y_train)\n",
    "    model6_results.append(model6.predict_proba(X_test_cat))\n",
    "\n",
    "    # model6b.fit(X_train_cat, y_train)\n",
    "    # model6b_results.append(model6b.predict_proba(X_test_cat))\n",
    "\n",
    "    # model6c.fit(X_train_cat, y_train)\n",
    "    # model6c_results.append(model6c.predict_proba(X_test_cat))\n",
    "\n",
    "    # model6d.fit(X_train_cat, y_train)\n",
    "    # model6d_results.append(model6d.predict_proba(X_test_cat))\n",
    "\n",
    "    model6e.fit(X_train_cat, y_train)\n",
    "    model6e_results.append(model6e.predict_proba(X_test_cat))\n",
    "\n",
    "    y_test_list.append(y_test)\n",
    "\n",
    "    print(f'Done with fold {i+1}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0118df56066c46b9980387610b465a25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (6788,7) (6788,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:89\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (6788,7) (6788,) "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# model1_weights, model1b_weights, model1c_weights, model1d_weights, model1e_weights, model2_weights, model3_weights, model3b_weights, model3c_weights, model4_weights, model4b_weights, model4c_weights, model4d_weights, model4e_weights, model5_weights, model5b_weights, model5c_weights, model5d_weights, model5e_weights, model5f_weights, model6_weights, model6b_weights, model6c_weights, model6d_weights, model6e_weights, scores = [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []\n",
    "\n",
    "model1_weights, model1b_weights, model1c_weights, model1d_weights, model1e_weights, model2_weights, model3_weights, model3b_weights, model3c_weights, model4_weights, model4b_weights, model4c_weights, model4d_weights, model4e_weights, model5_weights, model5b_weights, model5c_weights, model5d_weights, model5e_weights, model5f_weights, model6_weights, model6e_weights, scores = [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []\n",
    "\n",
    "scores_in = []\n",
    "\n",
    "for i in tqdm(range(20)):\n",
    "    weight_1 = np.random.random_sample(size=1)[0]\n",
    "    weight_1b = np.random.random_sample(size=1)[0]\n",
    "    weight_1c = np.random.random_sample(size=1)[0]\n",
    "    weight_1d = np.random.random_sample(size=1)[0]\n",
    "    weight_1e = np.random.random_sample(size=1)[0]\n",
    "    weight_2 = np.random.random_sample(size=1)[0]\n",
    "    weight_3 = np.random.random_sample(size=1)[0]\n",
    "    weight_3b = np.random.random_sample(size=1)[0]\n",
    "    weight_3c = np.random.random_sample(size=1)[0]\n",
    "    weight_4 = np.random.random_sample(size=1)[0]\n",
    "    weight_4b = np.random.random_sample(size=1)[0]\n",
    "    weight_4c = np.random.random_sample(size=1)[0]\n",
    "    weight_4d = np.random.random_sample(size=1)[0]\n",
    "    weight_4e = np.random.random_sample(size=1)[0]\n",
    "    weight_5 = np.random.random_sample(size=1)[0]\n",
    "    weight_5b = np.random.random_sample(size=1)[0]\n",
    "    weight_5c = np.random.random_sample(size=1)[0]\n",
    "    weight_5d = np.random.random_sample(size=1)[0]\n",
    "    weight_5e = np.random.random_sample(size=1)[0]\n",
    "    weight_5f = np.random.random_sample(size=1)[0]\n",
    "    weight_6 = np.random.random_sample(size=1)[0]\n",
    "    # weight_6b = np.random.random_sample(size=1)[0]\n",
    "    # weight_6c = np.random.random_sample(size=1)[0]\n",
    "    # weight_6d = np.random.random_sample(size=1)[0]\n",
    "    weight_6e = np.random.random_sample(size=1)[0]\n",
    "\n",
    "    model1_weights.append(weight_1)\n",
    "    model1b_weights.append(weight_1b)\n",
    "    model1c_weights.append(weight_1c)\n",
    "    model1d_weights.append(weight_1d)\n",
    "    model1e_weights.append(weight_1e)\n",
    "    model2_weights.append(weight_2)\n",
    "    model3_weights.append(weight_3)\n",
    "    model3b_weights.append(weight_3b)\n",
    "    model3c_weights.append(weight_3c)\n",
    "    model4_weights.append(weight_4)\n",
    "    model4b_weights.append(weight_4b)\n",
    "    model4c_weights.append(weight_4c)\n",
    "    model4d_weights.append(weight_4d)\n",
    "    model4e_weights.append(weight_4e)\n",
    "    model5_weights.append(weight_5)\n",
    "    model5b_weights.append(weight_5b)\n",
    "    model5c_weights.append(weight_5c)\n",
    "    model5d_weights.append(weight_5d)\n",
    "    model5e_weights.append(weight_5e)\n",
    "    model5f_weights.append(weight_5f)\n",
    "    model6_weights.append(weight_6)\n",
    "    # model6b_weights.append(weight_6b)\n",
    "    # model6c_weights.append(weight_6c)\n",
    "    # model6d_weights.append(weight_6d)\n",
    "    model6e_weights.append(weight_6e)\n",
    "\n",
    "    # scores_in = []\n",
    "\n",
    "    for j in range(n_splits):\n",
    "        weighted_pred = (weight_1 * model1_results[j])\n",
    "        + (weight_1b * model1b_results[j])\n",
    "        + (weight_1c * model1c_results[j])\n",
    "        + (weight_1d * model1d_results[j])\n",
    "        + (weight_1e * model1e_results[j])\n",
    "        + (weight_2 * model2_results[j])\n",
    "        + (weight_3 * model3_results[j])\n",
    "        + (weight_3b * model3b_results[j])\n",
    "        + (weight_3c * model3c_results[j])\n",
    "        + (weight_4 * model4_results[j])\n",
    "        + (weight_4b * model4b_results[j])\n",
    "        + (weight_4c * model4c_results[j])\n",
    "        + (weight_4d * model4d_results[j])\n",
    "        + (weight_4e * model4e_results[j])\n",
    "        + (weight_5 * model5_results[j])\n",
    "        + (weight_5b * model5b_results[j])\n",
    "        + (weight_5c * model5c_results[j])\n",
    "        + (weight_5d * model5d_results[j])\n",
    "        + (weight_5e * model5e_results[j])\n",
    "        + (weight_5f * model5f_results[j])\n",
    "        + (weight_6 * model6_results[j])\n",
    "        # + (weight_6b * model6b_results[j])\n",
    "        # + (weight_6c * model6c_results[j])\n",
    "        # + (weight_6d * model6d_results[j])\n",
    "        + (weight_6e * model6e_results[j])\n",
    "\n",
    "        weighted_pred_normalized = weighted_pred / np.sum(weighted_pred, axis=1, keepdims=True)\n",
    "\n",
    "        scores_in.append(roc_auc_score(y_test_list[j], weighted_pred_normalized, multi_class='ovr'))\n",
    "        \n",
    "    scores.append(np.mean(scores_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_1</th>\n",
       "      <th>model_1b</th>\n",
       "      <th>model_1c</th>\n",
       "      <th>model_1d</th>\n",
       "      <th>model_1e</th>\n",
       "      <th>model_2</th>\n",
       "      <th>model_3</th>\n",
       "      <th>model_3b</th>\n",
       "      <th>model_3c</th>\n",
       "      <th>model_4</th>\n",
       "      <th>model_4b</th>\n",
       "      <th>model_4c</th>\n",
       "      <th>model_4d</th>\n",
       "      <th>model_4e</th>\n",
       "      <th>model_5</th>\n",
       "      <th>model_5b</th>\n",
       "      <th>model_5c</th>\n",
       "      <th>model_5d</th>\n",
       "      <th>model_5e</th>\n",
       "      <th>model_5f</th>\n",
       "      <th>model_6</th>\n",
       "      <th>model_6e</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.626877</td>\n",
       "      <td>0.364680</td>\n",
       "      <td>0.100944</td>\n",
       "      <td>0.461033</td>\n",
       "      <td>0.924784</td>\n",
       "      <td>0.583100</td>\n",
       "      <td>0.184504</td>\n",
       "      <td>0.649023</td>\n",
       "      <td>0.465462</td>\n",
       "      <td>0.931380</td>\n",
       "      <td>0.160940</td>\n",
       "      <td>0.712012</td>\n",
       "      <td>0.681602</td>\n",
       "      <td>0.983542</td>\n",
       "      <td>0.564912</td>\n",
       "      <td>0.871574</td>\n",
       "      <td>0.024714</td>\n",
       "      <td>0.122892</td>\n",
       "      <td>0.345939</td>\n",
       "      <td>0.619327</td>\n",
       "      <td>0.449079</td>\n",
       "      <td>0.202696</td>\n",
       "      <td>0.893696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.165247</td>\n",
       "      <td>0.600356</td>\n",
       "      <td>0.232739</td>\n",
       "      <td>0.770631</td>\n",
       "      <td>0.644003</td>\n",
       "      <td>0.571605</td>\n",
       "      <td>0.825227</td>\n",
       "      <td>0.500273</td>\n",
       "      <td>0.269852</td>\n",
       "      <td>0.620705</td>\n",
       "      <td>0.957063</td>\n",
       "      <td>0.601159</td>\n",
       "      <td>0.629619</td>\n",
       "      <td>0.934751</td>\n",
       "      <td>0.515275</td>\n",
       "      <td>0.996357</td>\n",
       "      <td>0.159662</td>\n",
       "      <td>0.537040</td>\n",
       "      <td>0.212901</td>\n",
       "      <td>0.453326</td>\n",
       "      <td>0.170574</td>\n",
       "      <td>0.222529</td>\n",
       "      <td>0.893696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.271119</td>\n",
       "      <td>0.498622</td>\n",
       "      <td>0.438723</td>\n",
       "      <td>0.473713</td>\n",
       "      <td>0.616040</td>\n",
       "      <td>0.230961</td>\n",
       "      <td>0.134704</td>\n",
       "      <td>0.878878</td>\n",
       "      <td>0.633941</td>\n",
       "      <td>0.060663</td>\n",
       "      <td>0.961052</td>\n",
       "      <td>0.693069</td>\n",
       "      <td>0.151705</td>\n",
       "      <td>0.969134</td>\n",
       "      <td>0.365407</td>\n",
       "      <td>0.984510</td>\n",
       "      <td>0.103276</td>\n",
       "      <td>0.159969</td>\n",
       "      <td>0.657420</td>\n",
       "      <td>0.022143</td>\n",
       "      <td>0.018690</td>\n",
       "      <td>0.791983</td>\n",
       "      <td>0.893696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.589204</td>\n",
       "      <td>0.566699</td>\n",
       "      <td>0.524447</td>\n",
       "      <td>0.090556</td>\n",
       "      <td>0.927025</td>\n",
       "      <td>0.592255</td>\n",
       "      <td>0.263992</td>\n",
       "      <td>0.687418</td>\n",
       "      <td>0.317908</td>\n",
       "      <td>0.505856</td>\n",
       "      <td>0.341132</td>\n",
       "      <td>0.880394</td>\n",
       "      <td>0.993981</td>\n",
       "      <td>0.161182</td>\n",
       "      <td>0.023579</td>\n",
       "      <td>0.219323</td>\n",
       "      <td>0.589952</td>\n",
       "      <td>0.173951</td>\n",
       "      <td>0.811484</td>\n",
       "      <td>0.408671</td>\n",
       "      <td>0.610533</td>\n",
       "      <td>0.455618</td>\n",
       "      <td>0.893696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.210800</td>\n",
       "      <td>0.320031</td>\n",
       "      <td>0.134605</td>\n",
       "      <td>0.809342</td>\n",
       "      <td>0.220676</td>\n",
       "      <td>0.416569</td>\n",
       "      <td>0.016057</td>\n",
       "      <td>0.104882</td>\n",
       "      <td>0.896272</td>\n",
       "      <td>0.837160</td>\n",
       "      <td>0.840922</td>\n",
       "      <td>0.411353</td>\n",
       "      <td>0.141531</td>\n",
       "      <td>0.107895</td>\n",
       "      <td>0.605603</td>\n",
       "      <td>0.828193</td>\n",
       "      <td>0.900114</td>\n",
       "      <td>0.288732</td>\n",
       "      <td>0.321027</td>\n",
       "      <td>0.100877</td>\n",
       "      <td>0.774410</td>\n",
       "      <td>0.275690</td>\n",
       "      <td>0.893696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.385890</td>\n",
       "      <td>0.358834</td>\n",
       "      <td>0.148947</td>\n",
       "      <td>0.904053</td>\n",
       "      <td>0.118529</td>\n",
       "      <td>0.472077</td>\n",
       "      <td>0.236518</td>\n",
       "      <td>0.996328</td>\n",
       "      <td>0.585844</td>\n",
       "      <td>0.149585</td>\n",
       "      <td>0.667564</td>\n",
       "      <td>0.991609</td>\n",
       "      <td>0.605043</td>\n",
       "      <td>0.457379</td>\n",
       "      <td>0.293270</td>\n",
       "      <td>0.092123</td>\n",
       "      <td>0.228246</td>\n",
       "      <td>0.553621</td>\n",
       "      <td>0.753786</td>\n",
       "      <td>0.877931</td>\n",
       "      <td>0.793712</td>\n",
       "      <td>0.125465</td>\n",
       "      <td>0.893696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.903328</td>\n",
       "      <td>0.035135</td>\n",
       "      <td>0.729302</td>\n",
       "      <td>0.652172</td>\n",
       "      <td>0.649515</td>\n",
       "      <td>0.413989</td>\n",
       "      <td>0.015675</td>\n",
       "      <td>0.689241</td>\n",
       "      <td>0.829471</td>\n",
       "      <td>0.085230</td>\n",
       "      <td>0.441618</td>\n",
       "      <td>0.162595</td>\n",
       "      <td>0.610938</td>\n",
       "      <td>0.785605</td>\n",
       "      <td>0.666707</td>\n",
       "      <td>0.318060</td>\n",
       "      <td>0.139733</td>\n",
       "      <td>0.794268</td>\n",
       "      <td>0.323917</td>\n",
       "      <td>0.022140</td>\n",
       "      <td>0.571421</td>\n",
       "      <td>0.246677</td>\n",
       "      <td>0.893696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.540048</td>\n",
       "      <td>0.186820</td>\n",
       "      <td>0.526889</td>\n",
       "      <td>0.706941</td>\n",
       "      <td>0.769788</td>\n",
       "      <td>0.523702</td>\n",
       "      <td>0.217368</td>\n",
       "      <td>0.926689</td>\n",
       "      <td>0.773617</td>\n",
       "      <td>0.270688</td>\n",
       "      <td>0.811813</td>\n",
       "      <td>0.347863</td>\n",
       "      <td>0.312431</td>\n",
       "      <td>0.863077</td>\n",
       "      <td>0.873235</td>\n",
       "      <td>0.398481</td>\n",
       "      <td>0.008923</td>\n",
       "      <td>0.186566</td>\n",
       "      <td>0.909296</td>\n",
       "      <td>0.898749</td>\n",
       "      <td>0.453345</td>\n",
       "      <td>0.304117</td>\n",
       "      <td>0.893696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.773460</td>\n",
       "      <td>0.581605</td>\n",
       "      <td>0.469108</td>\n",
       "      <td>0.572764</td>\n",
       "      <td>0.008075</td>\n",
       "      <td>0.067730</td>\n",
       "      <td>0.525849</td>\n",
       "      <td>0.173619</td>\n",
       "      <td>0.545541</td>\n",
       "      <td>0.354214</td>\n",
       "      <td>0.907412</td>\n",
       "      <td>0.949683</td>\n",
       "      <td>0.979784</td>\n",
       "      <td>0.898938</td>\n",
       "      <td>0.985891</td>\n",
       "      <td>0.706147</td>\n",
       "      <td>0.960542</td>\n",
       "      <td>0.641792</td>\n",
       "      <td>0.809214</td>\n",
       "      <td>0.131910</td>\n",
       "      <td>0.682600</td>\n",
       "      <td>0.931103</td>\n",
       "      <td>0.893696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.094016</td>\n",
       "      <td>0.523708</td>\n",
       "      <td>0.506745</td>\n",
       "      <td>0.606548</td>\n",
       "      <td>0.330793</td>\n",
       "      <td>0.925918</td>\n",
       "      <td>0.270061</td>\n",
       "      <td>0.649696</td>\n",
       "      <td>0.495927</td>\n",
       "      <td>0.266673</td>\n",
       "      <td>0.188854</td>\n",
       "      <td>0.956562</td>\n",
       "      <td>0.561291</td>\n",
       "      <td>0.604191</td>\n",
       "      <td>0.782895</td>\n",
       "      <td>0.081227</td>\n",
       "      <td>0.713764</td>\n",
       "      <td>0.165140</td>\n",
       "      <td>0.740481</td>\n",
       "      <td>0.141329</td>\n",
       "      <td>0.832494</td>\n",
       "      <td>0.681016</td>\n",
       "      <td>0.893696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_1  model_1b  model_1c  model_1d  model_1e   model_2   model_3  \\\n",
       "0  0.626877  0.364680  0.100944  0.461033  0.924784  0.583100  0.184504   \n",
       "1  0.165247  0.600356  0.232739  0.770631  0.644003  0.571605  0.825227   \n",
       "2  0.271119  0.498622  0.438723  0.473713  0.616040  0.230961  0.134704   \n",
       "3  0.589204  0.566699  0.524447  0.090556  0.927025  0.592255  0.263992   \n",
       "4  0.210800  0.320031  0.134605  0.809342  0.220676  0.416569  0.016057   \n",
       "5  0.385890  0.358834  0.148947  0.904053  0.118529  0.472077  0.236518   \n",
       "6  0.903328  0.035135  0.729302  0.652172  0.649515  0.413989  0.015675   \n",
       "7  0.540048  0.186820  0.526889  0.706941  0.769788  0.523702  0.217368   \n",
       "8  0.773460  0.581605  0.469108  0.572764  0.008075  0.067730  0.525849   \n",
       "9  0.094016  0.523708  0.506745  0.606548  0.330793  0.925918  0.270061   \n",
       "\n",
       "   model_3b  model_3c   model_4  model_4b  model_4c  model_4d  model_4e  \\\n",
       "0  0.649023  0.465462  0.931380  0.160940  0.712012  0.681602  0.983542   \n",
       "1  0.500273  0.269852  0.620705  0.957063  0.601159  0.629619  0.934751   \n",
       "2  0.878878  0.633941  0.060663  0.961052  0.693069  0.151705  0.969134   \n",
       "3  0.687418  0.317908  0.505856  0.341132  0.880394  0.993981  0.161182   \n",
       "4  0.104882  0.896272  0.837160  0.840922  0.411353  0.141531  0.107895   \n",
       "5  0.996328  0.585844  0.149585  0.667564  0.991609  0.605043  0.457379   \n",
       "6  0.689241  0.829471  0.085230  0.441618  0.162595  0.610938  0.785605   \n",
       "7  0.926689  0.773617  0.270688  0.811813  0.347863  0.312431  0.863077   \n",
       "8  0.173619  0.545541  0.354214  0.907412  0.949683  0.979784  0.898938   \n",
       "9  0.649696  0.495927  0.266673  0.188854  0.956562  0.561291  0.604191   \n",
       "\n",
       "    model_5  model_5b  model_5c  model_5d  model_5e  model_5f   model_6  \\\n",
       "0  0.564912  0.871574  0.024714  0.122892  0.345939  0.619327  0.449079   \n",
       "1  0.515275  0.996357  0.159662  0.537040  0.212901  0.453326  0.170574   \n",
       "2  0.365407  0.984510  0.103276  0.159969  0.657420  0.022143  0.018690   \n",
       "3  0.023579  0.219323  0.589952  0.173951  0.811484  0.408671  0.610533   \n",
       "4  0.605603  0.828193  0.900114  0.288732  0.321027  0.100877  0.774410   \n",
       "5  0.293270  0.092123  0.228246  0.553621  0.753786  0.877931  0.793712   \n",
       "6  0.666707  0.318060  0.139733  0.794268  0.323917  0.022140  0.571421   \n",
       "7  0.873235  0.398481  0.008923  0.186566  0.909296  0.898749  0.453345   \n",
       "8  0.985891  0.706147  0.960542  0.641792  0.809214  0.131910  0.682600   \n",
       "9  0.782895  0.081227  0.713764  0.165140  0.740481  0.141329  0.832494   \n",
       "\n",
       "   model_6e     score  \n",
       "0  0.202696  0.893696  \n",
       "1  0.222529  0.893696  \n",
       "2  0.791983  0.893696  \n",
       "3  0.455618  0.893696  \n",
       "4  0.275690  0.893696  \n",
       "5  0.125465  0.893696  \n",
       "6  0.246677  0.893696  \n",
       "7  0.304117  0.893696  \n",
       "8  0.931103  0.893696  \n",
       "9  0.681016  0.893696  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame()\n",
    "results_df['model_1'] = model1_weights\n",
    "results_df['model_1b'] = model1b_weights\n",
    "results_df['model_1c'] = model1c_weights\n",
    "results_df['model_1d'] = model1d_weights\n",
    "results_df['model_1e'] = model1e_weights\n",
    "results_df['model_2'] = model2_weights\n",
    "results_df['model_3'] = model3_weights\n",
    "results_df['model_3b'] = model3b_weights\n",
    "results_df['model_3c'] = model3c_weights\n",
    "results_df['model_4'] = model4_weights\n",
    "results_df['model_4b'] = model4b_weights\n",
    "results_df['model_4c'] = model4c_weights\n",
    "results_df['model_4d'] = model4d_weights\n",
    "results_df['model_4e'] = model4e_weights\n",
    "results_df['model_5'] = model5_weights\n",
    "results_df['model_5b'] = model5b_weights\n",
    "results_df['model_5c'] = model5c_weights\n",
    "results_df['model_5d'] = model5d_weights\n",
    "results_df['model_5e'] = model5e_weights\n",
    "results_df['model_5f'] = model5f_weights\n",
    "results_df['model_6'] = model6_weights\n",
    "# results_df['model_6b'] = model6b_weights\n",
    "# results_df['model_6c'] = model6c_weights\n",
    "# results_df['model_6d'] = model6d_weights\n",
    "results_df['model_6e'] = model6e_weights\n",
    "results_df['score'] = scores\n",
    "\n",
    "results_df = results_df.sort_values(by='score', ascending=False).reset_index(drop=True)\n",
    "results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('random_weights_normalized.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Submission (Random Weight Ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 22min 41s\n",
      "Wall time: 16min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('Running LGBM')\n",
    "model1_final = model1.fit(X_lgbm, y)\n",
    "model1b_final = model1b.fit(X_lgbm, y)\n",
    "model1c_final = model1c.fit(X_lgbm, y)\n",
    "model1d_final = model1d.fit(X_lgbm, y)\n",
    "model1e_final = model1e.fit(X_lgbm, y)\n",
    "\n",
    "print('Running XGBoost')\n",
    "model2_final = model2.fit(X_xgb, y)\n",
    "\n",
    "print('Running Random Forest')\n",
    "model3_final = model3.fit(X_rf, y)\n",
    "model3b_final = model3b.fit(X_rf, y)\n",
    "model3c_final = model3c.fit(X_rf, y)\n",
    "\n",
    "print('Running ExtraTrees')\n",
    "model4_final = model4.fit(X_extrat, y)\n",
    "model4b_final = model4b.fit(X_extrat, y)\n",
    "model4c_final = model4c.fit(X_extrat, y)\n",
    "model4d_final = model4d.fit(X_extrat, y)\n",
    "model4e_final = model4e.fit(X_extrat, y)\n",
    "\n",
    "print('Running HistGradient')\n",
    "model5_final = model5.fit(X_hist, y)\n",
    "model5b_final = model5b.fit(X_hist, y)\n",
    "model5c_final = model5c.fit(X_hist, y)\n",
    "model5d_final = model5d.fit(X_hist, y)\n",
    "model5e_final = model5e.fit(X_hist, y)\n",
    "model5f_final = model5f.fit(X_hist, y)\n",
    "\n",
    "print('Running CatBoost')\n",
    "model6_final = model6.fit(X_cat, y)\n",
    "# model6b_final = model6b.fit(X_cat, y)\n",
    "# model6c_final = model6c.fit(X_cat, y)\n",
    "# model6d_final = model6d.fit(X_cat, y)\n",
    "model6e_final = model6e.fit(X_cat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ensemble_pred = (\n",
    "                results_df['model_1'][0] * model1_final.predict_proba(test[model1_feats]) +\n",
    "                results_df['model_1b'][0] * model1b_final.predict_proba(test[model1_feats]) +\n",
    "                results_df['model_1c'][0] * model1c_final.predict_proba(test[model1_feats]) +\n",
    "                results_df['model_1d'][0] * model1d_final.predict_proba(test[model1_feats]) +\n",
    "                results_df['model_1e'][0] * model1e_final.predict_proba(test[model1_feats]) +\n",
    "                results_df['model_2'][0] * model2_final.predict_proba(test[model2_feats]) +\n",
    "                results_df['model_3'][0] * model3_final.predict_proba(test[model3_feats]) +\n",
    "                results_df['model_3b'][0] * model3b_final.predict_proba(test[model3_feats]) +\n",
    "                results_df['model_3c'][0] * model3c_final.predict_proba(test[model3_feats]) +\n",
    "                results_df['model_4'][0] * model4_final.predict_proba(test[model4_feats]) +\n",
    "                results_df['model_4b'][0] * model4b_final.predict_proba(test[model4_feats]) +\n",
    "                results_df['model_4c'][0] * model4c_final.predict_proba(test[model4_feats]) +\n",
    "                results_df['model_4d'][0] * model4d_final.predict_proba(test[model4_feats]) +\n",
    "                results_df['model_4e'][0] * model4e_final.predict_proba(test[model4_feats]) +\n",
    "                results_df['model_5'][0] * model5_final.predict_proba(test[model5_feats]) +\n",
    "                results_df['model_5b'][0] * model5b_final.predict_proba(test[model5_feats]) +\n",
    "                results_df['model_5c'][0] * model5c_final.predict_proba(test[model5_feats]) +\n",
    "                results_df['model_5d'][0] * model5d_final.predict_proba(test[model5_feats]) +\n",
    "                results_df['model_5e'][0] * model5e_final.predict_proba(test[model5_feats]) +\n",
    "                results_df['model_5f'][0] * model5f_final.predict_proba(test[model5_feats]) +\n",
    "                results_df['model_6'][0] * model6_final.predict_proba(test[model6_feats]) +\n",
    "                # results_df['model_6b'][0] * model6b_final.predict_proba(test[model6_feats]) +\n",
    "                # results_df['model_6c'][0] * model6c_final.predict_proba(test[model6_feats]) +\n",
    "                # results_df['model_6d'][0] * model6d_final.predict_proba(test[model6_feats]) +\n",
    "                results_df['model_6e'][0] * model6e_final.predict_proba(test[model6_feats])\n",
    "                 )\n",
    "\n",
    "ensemble_df = pd.DataFrame(ensemble_pred)\n",
    "\n",
    "# If all models predict 0, instead of getting NaN, fill in 0\n",
    "ensemble_df = ensemble_df.div(ensemble_df.sum(axis=1), axis=0).fillna(0)\n",
    "ensemble_df.columns = label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bumps</th>\n",
       "      <th>Dirtiness</th>\n",
       "      <th>K_Scatch</th>\n",
       "      <th>Other_Faults</th>\n",
       "      <th>Pastry</th>\n",
       "      <th>Stains</th>\n",
       "      <th>Z_Scratch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.131240</td>\n",
       "      <td>0.026219</td>\n",
       "      <td>0.005702</td>\n",
       "      <td>0.343930</td>\n",
       "      <td>0.488380</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.004143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.154362</td>\n",
       "      <td>0.211441</td>\n",
       "      <td>0.009527</td>\n",
       "      <td>0.345254</td>\n",
       "      <td>0.258984</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>0.018583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.276297</td>\n",
       "      <td>0.009285</td>\n",
       "      <td>0.067533</td>\n",
       "      <td>0.592444</td>\n",
       "      <td>0.004124</td>\n",
       "      <td>0.007742</td>\n",
       "      <td>0.042575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.390152</td>\n",
       "      <td>0.012591</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>0.446294</td>\n",
       "      <td>0.140416</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>0.006854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.608551</td>\n",
       "      <td>0.009964</td>\n",
       "      <td>0.002360</td>\n",
       "      <td>0.358683</td>\n",
       "      <td>0.008212</td>\n",
       "      <td>0.005592</td>\n",
       "      <td>0.006637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Bumps  Dirtiness  K_Scatch  Other_Faults    Pastry    Stains  Z_Scratch\n",
       "0  0.131240   0.026219  0.005702      0.343930  0.488380  0.000387   0.004143\n",
       "1  0.154362   0.211441  0.009527      0.345254  0.258984  0.001850   0.018583\n",
       "2  0.276297   0.009285  0.067533      0.592444  0.004124  0.007742   0.042575\n",
       "3  0.390152   0.012591  0.000884      0.446294  0.140416  0.002809   0.006854\n",
       "4  0.608551   0.009964  0.002360      0.358683  0.008212  0.005592   0.006637"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Bumps</th>\n",
       "      <th>Dirtiness</th>\n",
       "      <th>K_Scatch</th>\n",
       "      <th>Other_Faults</th>\n",
       "      <th>Pastry</th>\n",
       "      <th>Stains</th>\n",
       "      <th>Z_Scratch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19219</td>\n",
       "      <td>0.131240</td>\n",
       "      <td>0.026219</td>\n",
       "      <td>0.005702</td>\n",
       "      <td>0.343930</td>\n",
       "      <td>0.488380</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.004143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19220</td>\n",
       "      <td>0.154362</td>\n",
       "      <td>0.211441</td>\n",
       "      <td>0.009527</td>\n",
       "      <td>0.345254</td>\n",
       "      <td>0.258984</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>0.018583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19221</td>\n",
       "      <td>0.276297</td>\n",
       "      <td>0.009285</td>\n",
       "      <td>0.067533</td>\n",
       "      <td>0.592444</td>\n",
       "      <td>0.004124</td>\n",
       "      <td>0.007742</td>\n",
       "      <td>0.042575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19222</td>\n",
       "      <td>0.390152</td>\n",
       "      <td>0.012591</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>0.446294</td>\n",
       "      <td>0.140416</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>0.006854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19223</td>\n",
       "      <td>0.608551</td>\n",
       "      <td>0.009964</td>\n",
       "      <td>0.002360</td>\n",
       "      <td>0.358683</td>\n",
       "      <td>0.008212</td>\n",
       "      <td>0.005592</td>\n",
       "      <td>0.006637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id     Bumps  Dirtiness  K_Scatch  Other_Faults    Pastry    Stains  \\\n",
       "0  19219  0.131240   0.026219  0.005702      0.343930  0.488380  0.000387   \n",
       "1  19220  0.154362   0.211441  0.009527      0.345254  0.258984  0.001850   \n",
       "2  19221  0.276297   0.009285  0.067533      0.592444  0.004124  0.007742   \n",
       "3  19222  0.390152   0.012591  0.000884      0.446294  0.140416  0.002809   \n",
       "4  19223  0.608551   0.009964  0.002360      0.358683  0.008212  0.005592   \n",
       "\n",
       "   Z_Scratch  \n",
       "0   0.004143  \n",
       "1   0.018583  \n",
       "2   0.042575  \n",
       "3   0.006854  \n",
       "4   0.006637  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission_df = pd.concat([submission['id'], ensemble_df], axis=1)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission_ensemble_3fold_0.893696.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get submission (Stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "roc_auc_scores = []\n",
    "\n",
    "# Define the base models\n",
    "base_models = [\n",
    "    ('model1', model1_final),\n",
    "    ('model2', model2_final),\n",
    "    ('model3', model3_final),\n",
    "    ('model4', model4_final),\n",
    "    ('model5', model5_final),\n",
    "    ('model6', model6_final)\n",
    "]\n",
    "\n",
    "# Initialize the Stacking Classifier with LogisticRegression as the final estimator\n",
    "final_estimator = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs')\n",
    "# final_estimator = LGBMClassifier(n_jobs=-1, random_state=5)\n",
    "# final_estimator = XGBClassifier(random_state=5)\n",
    "# final_estimator = RandomForestClassifier(random_state=5)\n",
    "# final_estimator = ExtraTreesClassifier(random_state=5)\n",
    "# final_estimator = HistGradientBoostingClassifier(random_state=5)\n",
    "# final_estimator = CatBoostClassifier(random_state=5, verbose=False, early_stopping_rounds=100)\n",
    "\n",
    "stacking_clf = StackingClassifier(estimators=base_models, final_estimator=final_estimator, passthrough=False, cv=3)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(sk10.split(X, y)):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    stacking_clf.fit(X_train, y_train)\n",
    "    y_pred = stacking_clf.predict_proba(X_test)\n",
    "\n",
    "    # Assuming your classes are 0, 1, 2, etc., adjust as necessary\n",
    "    y_test_binarized = label_binarize(y_test, classes=np.unique(y))\n",
    "    roc_auc = roc_auc_score(y_test_binarized, y_pred, multi_class='ovr')\n",
    "\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "\n",
    "    print(f'Done with fold {i+1}.')\n",
    "    \n",
    "print(f'The average stacking score is {np.mean(roc_auc_scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Reg - 0.886778\n",
    "- LGBM - 0.885863\n",
    "- XGB - 0.881636\n",
    "- RF - 0.883835\n",
    "- ET - 0.884523\n",
    "- Hist - 0.886572\n",
    "- Cat - 0.886183"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on unseen test data\n",
    "y_test_pred = stacking_clf.predict_proba(test)\n",
    "\n",
    "stacking_df = pd.DataFrame(y_test_pred)\n",
    "\n",
    "ensemble_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model1_results, model2_results, model3_results, model4_results, model5_results, model6_results, y_test_list = [], [], [], [], [], [], []\n",
    "\n",
    "# # Placeholder for OOF predictions for each model\n",
    "# # Assuming you have a dataset with N samples\n",
    "# N = len(y)  # y_train is your target variable array\n",
    "# oof_preds1 = np.zeros((N, 1))\n",
    "# oof_preds2 = np.zeros((N, 1))\n",
    "# oof_preds3 = np.zeros((N, 1))\n",
    "# oof_preds4 = np.zeros((N, 1))\n",
    "# oof_preds5 = np.zeros((N, 1))\n",
    "# oof_preds6 = np.zeros((N, 1))\n",
    "\n",
    "# # Similarly, for test predictions, accumulate them over folds\n",
    "# # Assuming you have a test set with M samples\n",
    "# M = len(test)  # x_test needs to be defined by you\n",
    "# test_preds1 = np.zeros((M, 1))\n",
    "# test_preds2 = np.zeros((M, 1))\n",
    "# test_preds3 = np.zeros((M, 1))\n",
    "# test_preds4 = np.zeros((M, 1))\n",
    "# test_preds5 = np.zeros((M, 1))\n",
    "# test_preds6 = np.zeros((M, 1))\n",
    "\n",
    "target_length = len(y)\n",
    "no_classes = len(np.unique(y))\n",
    "test_length = len(test)\n",
    "\n",
    "# Initialize arrays for OOF and test predictions with dimensions for multiclass for each model\n",
    "lgbm_oof_preds = np.zeros((target_length, no_classes))\n",
    "lgbm_test_preds = np.zeros((test_length, no_classes))\n",
    "\n",
    "xgb_oof_preds = np.zeros((target_length, no_classes))\n",
    "xgb_test_preds = np.zeros((test_length, no_classes))\n",
    "\n",
    "rf_oof_preds = np.zeros((target_length, no_classes))\n",
    "rf_test_preds = np.zeros((test_length, no_classes))\n",
    "\n",
    "extrat_oof_preds = np.zeros((target_length, no_classes))\n",
    "extrat_test_preds = np.zeros((test_length, no_classes))\n",
    "\n",
    "hist_oof_preds = np.zeros((target_length, no_classes))\n",
    "hist_test_preds = np.zeros((test_length, no_classes))\n",
    "\n",
    "cat_oof_preds = np.zeros((target_length, no_classes))\n",
    "cat_test_preds = np.zeros((test_length, no_classes))\n",
    "\n",
    "X_lgbm = X[model1_feats]\n",
    "X_xgb = X[model2_feats]\n",
    "X_rf = X[model3_feats]\n",
    "X_extrat = X[model4_feats]\n",
    "X_hist = X[model5_feats]\n",
    "X_cat = X[model6_feats]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, (train_index, test_index) in enumerate(sk10.split(X, y)):\n",
    "\n",
    "    # Placeholder arrays for the fold's predicition\n",
    "    fold_oof_preds_lgbm = np.zeros((len(test_index), no_classes))\n",
    "    fold_test_preds_lgbm = np.zeros((test_length, no_classes))\n",
    "\n",
    "    fold_oof_preds_xgb = np.zeros((len(test_index), no_classes))\n",
    "    fold_test_preds_xgb = np.zeros((test_length, no_classes))\n",
    "\n",
    "    fold_oof_preds_rf = np.zeros((len(test_index), no_classes))\n",
    "    fold_test_preds_rf = np.zeros((test_length, no_classes))\n",
    "\n",
    "    fold_oof_preds_extrat = np.zeros((len(test_index), no_classes))\n",
    "    fold_test_preds_extrat = np.zeros((test_length, no_classes))\n",
    "\n",
    "    fold_oof_preds_hist = np.zeros((len(test_index), no_classes))\n",
    "    fold_test_preds_hist = np.zeros((test_length, no_classes))\n",
    "\n",
    "    fold_oof_preds_cat = np.zeros((len(test_index), no_classes))\n",
    "    fold_test_preds_cat = np.zeros((test_length, no_classes))\n",
    "\n",
    "    # Get each models train and test for X and y\n",
    "    X_train_lgbm, X_test_lgbm = X_lgbm.iloc[train_index], X_lgbm.iloc[test_index]\n",
    "    X_train_xgb, X_test_xgb = X_xgb.iloc[train_index], X_xgb.iloc[test_index]\n",
    "    X_train_rf, X_test_rf = X_rf.iloc[train_index], X_rf.iloc[test_index]\n",
    "    X_train_extrat, X_test_extrat = X_extrat.iloc[train_index], X_extrat.iloc[test_index]\n",
    "    X_train_hist, X_test_hist = X_hist.iloc[train_index], X_hist.iloc[test_index]\n",
    "    X_train_cat, X_test_cat = X_cat.iloc[train_index], X_cat.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    ########\n",
    "    # LGBM #\n",
    "    ########\n",
    "    model1.fit(X_train_lgbm, y_train)\n",
    "    fold_oof_preds_lgbm = model1.predict_proba(X_test_lgbm)\n",
    "\n",
    "    # Update the OOF prediction for this fold\n",
    "    lgbm_oof_preds[test_index] = fold_oof_preds_lgbm\n",
    "\n",
    "    # Predict on the test set and accumulate predictions\n",
    "    fold_test_preds_lgbm += model1.predict_proba(test.loc[:, model1_feats]) / sk10.n_splits\n",
    "\n",
    "    lgbm_test_preds += fold_test_preds_lgbm\n",
    "\n",
    "\n",
    "    ###########\n",
    "    # XGBOOST #\n",
    "    ###########\n",
    "    model2.fit(X_train_xgb, y_train)\n",
    "    fold_oof_preds_xgb = model2.predict_proba(X_test_xgb)\n",
    "\n",
    "    # Update the OOF prediction for this fold\n",
    "    xgb_oof_preds[test_index] = fold_oof_preds_xgb\n",
    "\n",
    "    # Predict on the test set and accumulate predictions\n",
    "    fold_test_preds_xgb += model2.predict_proba(test.loc[:, model2_feats]) / sk10.n_splits\n",
    "\n",
    "    xgb_test_preds += fold_test_preds_xgb\n",
    "\n",
    "\n",
    "    #################\n",
    "    # RANDOM FOREST #\n",
    "    #################\n",
    "    model3.fit(X_train_rf, y_train)\n",
    "    fold_oof_preds_rf = model3.predict_proba(X_test_rf)\n",
    "\n",
    "    # Update the OOF prediction for this fold\n",
    "    rf_oof_preds[test_index] = fold_oof_preds_rf\n",
    "\n",
    "    # Predict on the test set and accumulate predictions\n",
    "    fold_test_preds_rf += model3.predict_proba(test.loc[:, model3_feats]) / sk10.n_splits\n",
    "\n",
    "    rf_test_preds += fold_test_preds_rf\n",
    "\n",
    "    \n",
    "    ###############\n",
    "    # EXTRA TREES #\n",
    "    ###############\n",
    "    model4.fit(X_train_extrat, y_train)\n",
    "    fold_oof_preds_extrat = model4.predict_proba(X_test_extrat)\n",
    "\n",
    "    # Update the OOF prediction for this fold\n",
    "    extrat_oof_preds[test_index] = fold_oof_preds_extrat\n",
    "\n",
    "    # Predict on the test set and accumulate predictions\n",
    "    fold_test_preds_extrat += model4.predict_proba(test.loc[:, model4_feats]) / sk10.n_splits\n",
    "\n",
    "    extrat_test_preds += fold_test_preds_extrat\n",
    "\n",
    "\n",
    "    #################\n",
    "    # HIST GRADIENT #\n",
    "    #################\n",
    "    model5.fit(X_train_hist, y_train)\n",
    "    fold_oof_preds_hist = model5.predict_proba(X_test_hist)\n",
    "\n",
    "    # Update the OOF prediction for this fold\n",
    "    hist_oof_preds[test_index] = fold_oof_preds_hist\n",
    "\n",
    "    # Predict on the test set and accumulate predictions\n",
    "    fold_test_preds_hist += model5.predict_proba(test.loc[:, model5_feats]) / sk10.n_splits\n",
    "\n",
    "    hist_test_preds += fold_test_preds_hist\n",
    "\n",
    "\n",
    "    ############\n",
    "    # CATBOOST #\n",
    "    ############\n",
    "    model6.fit(X_train_cat, y_train)\n",
    "    fold_oof_preds_cat = model6.predict_proba(X_test_cat)\n",
    "\n",
    "    # Update the OOF prediction for this fold\n",
    "    cat_oof_preds[test_index] = fold_oof_preds_cat\n",
    "\n",
    "    # Predict on the test set and accumulate predictions\n",
    "    fold_test_preds_cat += model6.predict_proba(test.loc[:, model6_feats]) / sk10.n_splits\n",
    "\n",
    "    cat_test_preds += fold_test_preds_cat\n",
    "    # y_test_list.append(y_test)\n",
    "\n",
    "    print(f'Done with fold {i+1}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc_auc_scores = [roc_auc_score((y == class_id).astype(int), oof_preds[:, class_id], multi_class='ovr') for class_id in range(no_classes)]\n",
    "lgbm_roc_auc = roc_auc_score(y, lgbm_oof_preds, multi_class='ovr', average='macro')\n",
    "print(\"Average LGBM ROC AUC Score:\", lgbm_roc_auc)\n",
    "\n",
    "xgb_roc_auc = roc_auc_score(y, xgb_oof_preds, multi_class='ovr', average='macro')\n",
    "print(\"Average XGBoost ROC AUC Score:\", xgb_roc_auc)\n",
    "\n",
    "rf_roc_auc = roc_auc_score(y, rf_oof_preds, multi_class='ovr', average='macro')\n",
    "print(\"Average Random Forest ROC AUC Score:\", rf_roc_auc)\n",
    "\n",
    "extrat_roc_auc = roc_auc_score(y, extrat_oof_preds, multi_class='ovr', average='macro')\n",
    "print(\"Average Extra Trees ROC AUC Score:\", extrat_roc_auc)\n",
    "\n",
    "hist_roc_auc = roc_auc_score(y, hist_oof_preds, multi_class='ovr', average='macro')\n",
    "print(\"Average Hist Gradient ROC AUC Score:\", hist_roc_auc)\n",
    "\n",
    "cat_roc_auc = roc_auc_score(y, cat_oof_preds, multi_class='ovr', average='macro')\n",
    "print(\"Average CatBoost ROC AUC Score:\", cat_roc_auc)\n",
    "\n",
    "# 0.89369590207664\n",
    "# 0.00201442835387733\n",
    "# 0.886778 - StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# After running the fitting and prediction with the first level of machine learning models\n",
    "x_train = np.concatenate(( lgbm_oof_preds, xgb_oof_preds, rf_oof_preds, extrat_oof_preds, hist_oof_preds, cat_oof_preds), axis=1)\n",
    "test_stack = np.concatenate(( lgbm_test_preds, xgb_test_preds, rf_test_preds, extrat_test_preds, hist_test_preds, cat_test_preds), axis=1)\n",
    "\n",
    "# Assuming the second-level stacking is to be done with XGboost (pre-tuned). Yes! You can tune second-level stack\n",
    "\n",
    "stacking_estimator = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs')\n",
    "\n",
    "xgb = stacking_estimator.fit(x_train, y)\n",
    "final_predictions = xgb.predict_proba(test_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds = np.zeros((x_train.shape[0], no_classes))\n",
    "test_preds = np.zeros(test_stack.shape[0])\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(sk10.split(x_train, y)):\n",
    "    X_train, X_test = x_train[train_index], x_train[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model2.fit(X_train, y_train)\n",
    "    y_pred = model2.predict_proba(X_test)\n",
    "\n",
    "    # Assign predictions for this fold to the appropriate indices in oof_preds\n",
    "    oof_preds[test_index, :] = y_pred\n",
    "    \n",
    "    print(f'Done with fold {i+1}.')\n",
    "\n",
    "# Calculate ROC AUC on the OOF predictions\n",
    "roc_auc = roc_auc_score(y, oof_preds, multi_class='ovr', average='macro')\n",
    "print(f'The stacking score is {roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Reg - 0.8883102077923056\n",
    "- LGBM - 0.8880225088607244\n",
    "- XGB - 0.8846028966376445\n",
    "- RF - \n",
    "- ET - \n",
    "- Hist - \n",
    "- Cat - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions_df = pd.DataFrame(final_predictions)\n",
    "final_predictions_df.columns = label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission_df = pd.concat([submission['id'], final_predictions_df], axis=1)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission_stacking_3fold_0.88831.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
