{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-22T17:27:14.072205Z","iopub.execute_input":"2023-09-22T17:27:14.072622Z","iopub.status.idle":"2023-09-22T17:27:14.588064Z","shell.execute_reply.started":"2023-09-22T17:27:14.072588Z","shell.execute_reply":"2023-09-22T17:27:14.586541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold, StratifiedKFold\nfrom catboost import CatBoostClassifier\nfrom sklearn.metrics import f1_score\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.preprocessing import OneHotEncoder, PolynomialFeatures\nfrom itertools import combinations\nimport warnings\n\nfrom sklearn.compose import make_column_transformer\n\nmodel_number = 'final_model'\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:27:15.489393Z","iopub.execute_input":"2023-09-22T17:27:15.489944Z","iopub.status.idle":"2023-09-22T17:27:17.538619Z","shell.execute_reply.started":"2023-09-22T17:27:15.489909Z","shell.execute_reply":"2023-09-22T17:27:17.536623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/playground-series-s3e22/train.csv')\ndf_test = pd.read_csv('../input/playground-series-s3e22/test.csv')\n\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:27:17.540939Z","iopub.execute_input":"2023-09-22T17:27:17.541584Z","iopub.status.idle":"2023-09-22T17:27:17.643569Z","shell.execute_reply.started":"2023-09-22T17:27:17.541537Z","shell.execute_reply":"2023-09-22T17:27:17.641770Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dropped_columns = ['id']\nTARGET = \"outcome\"\n\ndf_train_model = df_train.drop(dropped_columns, axis=1)\ndf_test_model = df_test.drop(dropped_columns, axis=1)\n\n# Assign train and test for X and y\nX_train = df_train_model.drop('outcome', axis=1)\ny_train = df_train_model['outcome']\n\nX_test = df_test_model.copy()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:27:18.936171Z","iopub.execute_input":"2023-09-22T17:27:18.936623Z","iopub.status.idle":"2023-09-22T17:27:18.958335Z","shell.execute_reply.started":"2023-09-22T17:27:18.936588Z","shell.execute_reply":"2023-09-22T17:27:18.956943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train[:5]","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:27:19.796527Z","iopub.execute_input":"2023-09-22T17:27:19.797833Z","iopub.status.idle":"2023-09-22T17:27:19.807995Z","shell.execute_reply.started":"2023-09-22T17:27:19.797773Z","shell.execute_reply":"2023-09-22T17:27:19.806551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"object_cat_features = list(X_train.select_dtypes('object').columns)\nnumerical_features = list(X_train.select_dtypes(include=['int', 'float']).columns)\n\nnum_cat_features = ['lesion_3', 'lesion_2', 'hospital_number']\n\ncat_features = object_cat_features + num_cat_features\nnum_features = [feat for feat in numerical_features if feat not in num_cat_features]\nmain_features = cat_features + num_features\nmain_features","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:27:20.744849Z","iopub.execute_input":"2023-09-22T17:27:20.745339Z","iopub.status.idle":"2023-09-22T17:27:20.765057Z","shell.execute_reply.started":"2023-09-22T17:27:20.745302Z","shell.execute_reply":"2023-09-22T17:27:20.763615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in cat_features:\n    X_train[f'{col}_missing'] = X_train[col].isna().astype(int)\n    X_train[col].fillna('Unknown', inplace=True)\n    \nX_train.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:27:21.917216Z","iopub.execute_input":"2023-09-22T17:27:21.917624Z","iopub.status.idle":"2023-09-22T17:27:21.999670Z","shell.execute_reply.started":"2023-09-22T17:27:21.917594Z","shell.execute_reply":"2023-09-22T17:27:21.998397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train['abdomen'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:27:24.589204Z","iopub.execute_input":"2023-09-22T17:27:24.589641Z","iopub.status.idle":"2023-09-22T17:27:24.604515Z","shell.execute_reply.started":"2023-09-22T17:27:24.589608Z","shell.execute_reply":"2023-09-22T17:27:24.603166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train['abdomen_missing'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:27:27.796380Z","iopub.execute_input":"2023-09-22T17:27:27.797304Z","iopub.status.idle":"2023-09-22T17:27:27.808108Z","shell.execute_reply.started":"2023-09-22T17:27:27.797255Z","shell.execute_reply":"2023-09-22T17:27:27.806741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a ColumnTransformer\ntransformer = make_column_transformer(\n    (OneHotEncoder(sparse=False, handle_unknown='ignore'), object_cat_features),\n    remainder='passthrough')\n\n# Fit and transform the data\ntransformed = transformer.fit_transform(X_train)\n\n# Get the transformed feature names\ntransformed_feature_names = [name.split('__')[-1] for name in transformer.get_feature_names_out()]\n\n# Create a DataFrame for the transformed features\ntransformed_df = pd.DataFrame(transformed, columns=transformed_feature_names)\n\n# Concatenate the transformed features DataFrame with the original DataFrame\ncombined_df_train = pd.concat([X_train[object_cat_features].reset_index(drop=True), transformed_df], axis=1)\ncombined_df_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:27:28.996141Z","iopub.execute_input":"2023-09-22T17:27:28.996590Z","iopub.status.idle":"2023-09-22T17:27:29.185352Z","shell.execute_reply.started":"2023-09-22T17:27:28.996554Z","shell.execute_reply":"2023-09-22T17:27:29.184132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_df_train['abdomen_missing'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:27:31.985394Z","iopub.execute_input":"2023-09-22T17:27:31.985812Z","iopub.status.idle":"2023-09-22T17:27:31.998023Z","shell.execute_reply.started":"2023-09-22T17:27:31.985777Z","shell.execute_reply":"2023-09-22T17:27:31.996076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_test_transformed = transformer.transform(X_test)\n# transformed_test_df = pd.DataFrame(X_test_transformed, columns=transformed_feature_names)\n\n# # Concatenate the transformed features DataFrame with the original DataFrame\n# combined_df_test = pd.concat([X_test[object_cat_features].reset_index(drop=True), transformed_test_df], axis=1)\n# combined_df_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_comprehensive_interactive_features(df, df_features, numerical_features):\n    \"\"\"\n    Generate interaction features between the given columns in a DataFrame.\n\n    Parameters:\n    -----------\n    df : pandas.DataFrame\n        The DataFrame containing the original features.\n    df_features : list\n        A list of feature names to be used for generating interaction features.\n\n    Returns:\n    --------\n    pandas.DataFrame\n        The DataFrame with the interaction features added.\n    \"\"\"\n    df_interactive = pd.DataFrame()\n\n    # Get the list of features to create interaction terms\n    features = [col for col in df.columns if col in df_features]\n\n    # Iterate through the features and create interaction terms\n    for i in range(len(features)):\n        for j in range(i+1, len(features)):\n            # Generate a new feature name for the interaction term\n            new_feature_name = f\"{features[i]}_{features[j]}\"\n\n            if features[i] in numerical_features and features[j] in numerical_features:\n                # Create the interaction feature by multiplying the values of the two original features\n                df_interactive[new_feature_name] = df[features[i]] * df[features[j]]\n\n            else:\n                df_interactive[new_feature_name] = df[features[i]].astype(str) + '_' + df[features[j]].astype(str)\n\n    combined_df = pd.concat([df, df_interactive], axis=1)\n    \n    return df_interactive, combined_df","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:27:34.534444Z","iopub.execute_input":"2023-09-22T17:27:34.534855Z","iopub.status.idle":"2023-09-22T17:27:34.547822Z","shell.execute_reply.started":"2023-09-22T17:27:34.534823Z","shell.execute_reply":"2023-09-22T17:27:34.545631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_interactive, X_train_complete_interactive = generate_comprehensive_interactive_features(X_train[main_features], main_features, num_features)\ndf_interactive.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:27:36.870688Z","iopub.execute_input":"2023-09-22T17:27:36.871145Z","iopub.status.idle":"2023-09-22T17:27:37.906563Z","shell.execute_reply.started":"2023-09-22T17:27:36.871110Z","shell.execute_reply":"2023-09-22T17:27:37.905233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_domain_features(df, df_features):\n    \"\"\"\n    Generate domain-specific features as ratios between the given columns in a DataFrame.\n\n    Parameters:\n    -----------\n    df : pandas.DataFrame\n        The DataFrame containing the original features.\n    df_features : list\n        A list of feature names to be used for generating domain-specific features.\n\n    Returns:\n    --------\n    pandas.DataFrame\n        The DataFrame with the domain-specific features added.\n    \"\"\"\n    # Get the list of features to create domain-specific features\n    features = [col for col in df.columns if col in df_features]\n    \n    df_new_features = pd.DataFrame()\n\n    # Iterate through the features and create domain-specific features as ratios\n    for i in range(len(features)):\n        for j in range(len(features)):\n            # Check if the features are different\n            if i != j:\n                # Generate a new feature name for the domain-specific feature\n                new_feature_name = f\"{features[i]}_{features[j]}_ratio\"\n                \n                # Create the domain-specific feature by dividing the values of the two original features\n                # If the denominator is 0, use a small value (1e-6) to avoid division by zero\n                df_new_features[new_feature_name] = df[features[i]] / np.where(df[features[j]] == 0, 1e-6, df[features[j]])\n                \n    df_combined = pd.concat([df, df_new_features], axis=1)\n\n    return df_new_features, df_combined","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:27:39.210030Z","iopub.execute_input":"2023-09-22T17:27:39.210543Z","iopub.status.idle":"2023-09-22T17:27:39.221656Z","shell.execute_reply.started":"2023-09-22T17:27:39.210500Z","shell.execute_reply":"2023-09-22T17:27:39.220303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_domain, X_train_complete_domain = generate_domain_features(X_train[main_features], numerical_features)\ndf_domain.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:27:40.818518Z","iopub.execute_input":"2023-09-22T17:27:40.819174Z","iopub.status.idle":"2023-09-22T17:27:41.069537Z","shell.execute_reply.started":"2023-09-22T17:27:40.819112Z","shell.execute_reply":"2023-09-22T17:27:41.068205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_polynomial_features(df, degree, df_features):\n    \"\"\"\n    Generate polynomial features for the specified columns in a DataFrame.\n\n    Parameters:\n    -----------\n    df : pandas.DataFrame\n        The DataFrame containing the original features.\n    degree : int\n        The degree of the polynomial features to generate.\n    df_features : list\n        A list of feature names to be used for generating polynomial features.\n\n    Returns:\n    --------\n    pandas.DataFrame\n        The DataFrame with the polynomial features added.\n    \"\"\"\n    # Get the list of features to create polynomial features\n    features = [col for col in df.columns if col in df_features]\n\n    # Create a PolynomialFeatures object with the specified degree, no interaction features, and no bias term\n    poly = PolynomialFeatures(degree, interaction_only=False, include_bias=False)\n\n    # Fit and transform the selected features in the DataFrame\n    poly_features = poly.fit_transform(df[features])\n\n    # Get the feature names for the generated polynomial features\n    poly_features_names = poly.get_feature_names_out(features)\n\n    # Create a new DataFrame with the generated polynomial features\n    poly_df = pd.DataFrame(poly_features, columns=poly_features_names)\n\n    # Keep only the columns with polynomial features of the specified degree\n    poly_df = poly_df[[f\"{col}^{degree}\" for col in features]]\n\n    # Concatenate the original DataFrame and the polynomial features DataFrame\n    result_combined = pd.concat([df, poly_df], axis=1)\n\n    return poly_df, result_combined","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:27:42.383029Z","iopub.execute_input":"2023-09-22T17:27:42.383493Z","iopub.status.idle":"2023-09-22T17:27:42.394080Z","shell.execute_reply.started":"2023-09-22T17:27:42.383457Z","shell.execute_reply":"2023-09-22T17:27:42.392143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_poly_2, X_train_complete_poly_2 = generate_polynomial_features(X_train[main_features], 2, num_features)\ndf_poly_2.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:27:44.909153Z","iopub.execute_input":"2023-09-22T17:27:44.909617Z","iopub.status.idle":"2023-09-22T17:27:44.951209Z","shell.execute_reply.started":"2023-09-22T17:27:44.909584Z","shell.execute_reply":"2023-09-22T17:27:44.949923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_poly_3, X_train_complete_poly_3 = generate_polynomial_features(X_train[main_features], 3, num_features)\ndf_poly_3.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:27:45.922414Z","iopub.execute_input":"2023-09-22T17:27:45.923466Z","iopub.status.idle":"2023-09-22T17:27:45.960640Z","shell.execute_reply.started":"2023-09-22T17:27:45.923415Z","shell.execute_reply":"2023-09-22T17:27:45.959319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_final = pd.concat([combined_df_train, df_interactive, df_domain, df_poly_2, df_poly_2], axis=1)\ndf_final = pd.concat([combined_df_train, df_interactive, df_domain, df_poly_2, df_poly_3], axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:27:47.221048Z","iopub.execute_input":"2023-09-22T17:27:47.221948Z","iopub.status.idle":"2023-09-22T17:27:47.239039Z","shell.execute_reply.started":"2023-09-22T17:27:47.221906Z","shell.execute_reply":"2023-09-22T17:27:47.237485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_final.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:27:49.494852Z","iopub.execute_input":"2023-09-22T17:27:49.495497Z","iopub.status.idle":"2023-09-22T17:27:50.105707Z","shell.execute_reply.started":"2023-09-22T17:27:49.495456Z","shell.execute_reply":"2023-09-22T17:27:50.103957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_final.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:27:51.534956Z","iopub.execute_input":"2023-09-22T17:27:51.536323Z","iopub.status.idle":"2023-09-22T17:27:51.545619Z","shell.execute_reply.started":"2023-09-22T17:27:51.536261Z","shell.execute_reply":"2023-09-22T17:27:51.543090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_object_cat_features = list(df_final.select_dtypes('object').columns)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:27:53.877825Z","iopub.execute_input":"2023-09-22T17:27:53.878243Z","iopub.status.idle":"2023-09-22T17:27:53.938728Z","shell.execute_reply.started":"2023-09-22T17:27:53.878212Z","shell.execute_reply":"2023-09-22T17:27:53.937200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def catboost_kfold_feature_importance(X_train, y_train, cat_features=None, n_splits=5, random_state=5):\n    \"\"\"\n    Perform K-Fold cross-validation with CatBoost and calculate feature importances.\n\n    Args:\n    - X_train: DataFrame, training features.\n    - y_train: Series, training target.\n    - cat_features: List of categorical feature names (default is None).\n    - n_splits: Number of K-Fold splits (default is 5).\n    - random_state: Random seed for reproducibility (default is 5).\n\n    Returns:\n    - fi_df: DataFrame, feature importances with fold-wise and average values.\n    \"\"\"    \n    # Initialize DataFrame to store feature importances\n    fi_df = pd.DataFrame({'Feature': X_train.columns})\n\n    # Initialize K-Fold cross-validator\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n\n    # Create empty array to store fold AUC scores\n    fold_scores = np.zeros(n_splits)\n\n    # Initialize CatBoost model\n    model = CatBoostClassifier(random_state=random_state, cat_features=cat_features, verbose=False)\n\n    # Perform K-Fold cross-validation\n    for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n        X_train_fold, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n        y_train_fold, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n\n        # Fit the CatBoost model\n        model.fit(X_train_fold, y_train_fold, eval_set=(X_val, y_val), verbose=100, early_stopping_rounds=100)\n\n        # Calculate fold AUC score\n        y_pred_val = model.predict(X_val)\n        fold_score = f1_score(y_val, y_pred_val, average='micro')\n        fold_scores[fold] = fold_score\n\n        # Record feature importances for this fold\n        feature_importance = model.get_feature_importance()\n        fi_df[f'Fold_{fold + 1}'] = feature_importance\n\n    # Calculate and append average feature importance\n    fi_df['Average'] = fi_df.iloc[:, 1:].mean(axis=1)\n\n    fi_df.to_csv('catboost_feature_importance.csv', index=False)\n\n    return fi_df","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:27:55.238019Z","iopub.execute_input":"2023-09-22T17:27:55.238431Z","iopub.status.idle":"2023-09-22T17:27:55.250098Z","shell.execute_reply.started":"2023-09-22T17:27:55.238401Z","shell.execute_reply":"2023-09-22T17:27:55.249091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_catboost_cat_feature_importance(X_train, y_train, cat_features, figsize=(16, 12)):\n    fi_df = catboost_kfold_feature_importance(X_train, y_train, cat_features=cat_features)\n    fi_df.sort_values(by='Average', ascending=False, inplace=True)\n\n    plt.figure(figsize=figsize)\n    sns.barplot(\n        x=fi_df['Average'],\n        y=fi_df['Feature'],\n    )\n\n    plt.title('Features Importance (avg over folds)')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:28:00.360121Z","iopub.execute_input":"2023-09-22T17:28:00.360559Z","iopub.status.idle":"2023-09-22T17:28:00.369791Z","shell.execute_reply.started":"2023-09-22T17:28:00.360521Z","shell.execute_reply":"2023-09-22T17:28:00.368030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_catboost_cat_feature_importance(df_final, y_train, cat_features=final_object_cat_features, figsize=(32, 32))","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:28:02.913486Z","iopub.execute_input":"2023-09-22T17:28:02.914421Z","iopub.status.idle":"2023-09-22T17:53:38.588164Z","shell.execute_reply.started":"2023-09-22T17:28:02.914365Z","shell.execute_reply":"2023-09-22T17:53:38.586125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feats = pd.read_csv('catboost_feature_importance.csv')\nfeats.sort_values(by='Average', ascending=False, inplace=True)\nfeats.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T17:54:08.199465Z","iopub.execute_input":"2023-09-22T17:54:08.200104Z","iopub.status.idle":"2023-09-22T17:54:08.228318Z","shell.execute_reply.started":"2023-09-22T17:54:08.200059Z","shell.execute_reply":"2023-09-22T17:54:08.226864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feats_in_use = feats[(feats['Fold_1'] > 0.0001) & (feats['Fold_2'] > 0.0001) & (feats['Fold_3'] > 0.0001) & (feats['Fold_4'] > 0.0001) & (feats['Fold_5'] > 0.0001) & (feats['Average'] > 0)]['Feature'].to_list()\nlen(feats_in_use)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T18:17:40.050320Z","iopub.execute_input":"2023-09-22T18:17:40.050807Z","iopub.status.idle":"2023-09-22T18:17:40.069940Z","shell.execute_reply.started":"2023-09-22T18:17:40.050758Z","shell.execute_reply":"2023-09-22T18:17:40.068478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # feats_in_use = feats[feats['Average'] > 0]['Feature'].to_list()\n# feats_in_use = ['lesion_3_lesion_1', \n#                 'age_pain', \n#                 'age_lesion_1', \n#                 'surgery_pain',\n#                 'packed_cell_volume_total_protein',\n#                 'packed_cell_volume_total_protein_ratio',\n#                 'surgery_surgical_lesion',\n#                 'pain_lesion_3',\n#                 'nasogastric_reflux_ph_total_protein_ratio',\n#                 'abdomo_protein_total_protein_ratio',\n#                 'lesion_3_packed_cell_volume',\n#                 'abdominal_distention_abdomo_appearance',\n#                 'rectal_temp_nasogastric_reflux_ph',\n#                 'rectal_exam_feces_surgical_lesion',\n#                 'age_packed_cell_volume',\n#                 'nasogastric_reflux_ph_total_protein',\n#                 'nasogastric_tube_nasogastric_reflux',\n#                 'surgery_peristalsis',\n#                 'peripheral_pulse_pain',\n#                ]\n\n# len(feats_in_use)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feats_in_use_object = list(df_final[feats_in_use].select_dtypes('object').columns)\nlen(feats_in_use_object)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T18:17:50.214672Z","iopub.execute_input":"2023-09-22T18:17:50.215136Z","iopub.status.idle":"2023-09-22T18:17:50.246359Z","shell.execute_reply.started":"2023-09-22T18:17:50.215100Z","shell.execute_reply":"2023-09-22T18:17:50.244945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_folds = 5\ncv = RepeatedStratifiedKFold(n_splits=num_folds, n_repeats=3, random_state=5)\n\ndef calculate_cv_score(features):\n    if not features:\n        return -np.inf # Return negative inifinity if no features are selected\n    input_df = df_final[features]\n    \n    feats_in_use_object = list(df_final[features].select_dtypes('object').columns)\n    print(\"The number of categorical features: \", len(feats_in_use_object))\n    print()\n    \n    if feats_in_use_object:\n        # Initialize CatBoost model\n        model = CatBoostClassifier(random_state=5, cat_features=feats_in_use_object, verbose=500)\n    else:\n        model = CatBoostClassifier(random_state=5, cat_features=None, verbose=500)\n        \n    scores = cross_val_score(model, input_df, y_train, cv=cv, n_jobs=-1, scoring='f1_micro')\n    print(\"Scores Mean:\", np.mean(scores))\n    print()\n    return np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T18:18:36.509660Z","iopub.execute_input":"2023-09-22T18:18:36.510087Z","iopub.status.idle":"2023-09-22T18:18:36.520408Z","shell.execute_reply.started":"2023-09-22T18:18:36.510055Z","shell.execute_reply":"2023-09-22T18:18:36.518779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize the list of different features\nmain_features = [] # The final features list\nunused_features = [] # The features not to be used in the final model","metadata":{"execution":{"iopub.status.busy":"2023-09-22T18:18:38.214858Z","iopub.execute_input":"2023-09-22T18:18:38.215336Z","iopub.status.idle":"2023-09-22T18:18:38.221759Z","shell.execute_reply.started":"2023-09-22T18:18:38.215298Z","shell.execute_reply":"2023-09-22T18:18:38.220073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Start the feature selection process\nbest_score = -np.inf # Initialize with a low score\n\nfor feature in feats_in_use:\n    main_features.append(feature)\n    print(main_features)\n    print()\n    cv_score = calculate_cv_score(main_features)\n    if cv_score > best_score:\n        best_score = cv_score\n        print('Current Best CV Score is: ', best_score)\n        print()\n    else:\n        main_features.remove(feature)\n        unused_features.append(feature)\n        print('Current Best CV Score is: ', best_score)\n        print()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T18:18:54.329549Z","iopub.execute_input":"2023-09-22T18:18:54.330184Z","iopub.status.idle":"2023-09-23T04:22:04.037863Z","shell.execute_reply.started":"2023-09-22T18:18:54.330134Z","shell.execute_reply":"2023-09-23T04:22:04.036270Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Selected Features:\", main_features)\nprint(\"Unused Features:\", unused_features)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T18:16:50.048510Z","iopub.status.idle":"2023-09-22T18:16:50.049082Z","shell.execute_reply.started":"2023-09-22T18:16:50.048814Z","shell.execute_reply":"2023-09-22T18:16:50.048836Z"},"trusted":true},"execution_count":null,"outputs":[]}]}