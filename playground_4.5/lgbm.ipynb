{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEPS\n",
    "\n",
    "~~ 1. Because the dataset is more than 1 million rows, run a train_test_split to get the R2 test score and get the LB result for the best model~~\n",
    "\n",
    "~~ 2. Get a smaller form of the dataset (about 150,000 rows) and get both a train_test_split and 5CV scores then get the LB results for the best model~~\n",
    "\n",
    "~~ 3. If there is no difference between 1 and 2 then perform SFS on the dataset from 2~~\n",
    "\n",
    "4. Stack the models using either LinearRegression or Ridge\n",
    "5. Hyperparameter tuning on each model 5 times\n",
    "6. Stack all the 54 models\n",
    "7. Perform feature engineering using OpenFE on the dataset from 2\n",
    "8. Perform feature selection using FFS in OpenFE on 7 for each model\n",
    "9. Hyperparameter tune each model from 8 5 times\n",
    "10. Stack all the 54 models from 9\n",
    "11. Stack all 108 models from 5 and 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "import numpy as np\n",
    "from openfe import OpenFE, tree_to_formula, transform, TwoStageFeatureSelector, ForwardFeatureSelector\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor, HistGradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "from sklearn.model_selection import cross_validate, KFold, train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import time\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "experiment_name = 'openfe_smaller_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv('train.csv')\n",
    "train = pd.read_csv('smaller_train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "train.drop('id', axis=1, inplace=True)\n",
    "test.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((149960, 21), (745305, 20))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement',\n",
    "       'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality',\n",
    "       'Siltation', 'AgriculturalPractices', 'Encroachments',\n",
    "       'IneffectiveDisasterPreparedness', 'DrainageSystems',\n",
    "       'CoastalVulnerability', 'Landslides', 'Watersheds',\n",
    "       'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss',\n",
    "       'InadequatePlanning', 'PoliticalFactors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'FloodProbability'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Sum_All_w_Intercept'] = (train[features_list].sum(axis=1) * 0.0056) - 0.0533\n",
    "test['Sum_All_w_Intercept'] = (test[features_list].sum(axis=1) * 0.0056) - 0.0533\n",
    "\n",
    "train['Sum_All'] = train[features_list].sum(axis=1)\n",
    "test['Sum_All'] = test[features_list].sum(axis=1)\n",
    "\n",
    "train['Sum_Special'] = (train[features_list].sum(axis=1).isin(np.arange(72, 76))).astype(int)\n",
    "test['Sum_Special'] = (test[features_list].sum(axis=1).isin(np.arange(72, 76))).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MonsoonIntensity</th>\n",
       "      <th>TopographyDrainage</th>\n",
       "      <th>RiverManagement</th>\n",
       "      <th>Deforestation</th>\n",
       "      <th>Urbanization</th>\n",
       "      <th>ClimateChange</th>\n",
       "      <th>DamsQuality</th>\n",
       "      <th>Siltation</th>\n",
       "      <th>AgriculturalPractices</th>\n",
       "      <th>Encroachments</th>\n",
       "      <th>IneffectiveDisasterPreparedness</th>\n",
       "      <th>DrainageSystems</th>\n",
       "      <th>CoastalVulnerability</th>\n",
       "      <th>Landslides</th>\n",
       "      <th>Watersheds</th>\n",
       "      <th>DeterioratingInfrastructure</th>\n",
       "      <th>PopulationScore</th>\n",
       "      <th>WetlandLoss</th>\n",
       "      <th>InadequatePlanning</th>\n",
       "      <th>PoliticalFactors</th>\n",
       "      <th>FloodProbability</th>\n",
       "      <th>Sum_All_w_Intercept</th>\n",
       "      <th>Sum_All</th>\n",
       "      <th>Sum_Special</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93203</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.4843</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81681</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.5459</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74100</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.5235</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MonsoonIntensity  TopographyDrainage  RiverManagement  Deforestation  \\\n",
       "93203                 1                   7                3              3   \n",
       "81681                 6                   5                5              6   \n",
       "74100                 6                   4                2              4   \n",
       "\n",
       "       Urbanization  ClimateChange  DamsQuality  Siltation  \\\n",
       "93203             7              4            3          5   \n",
       "81681             3              7            7          4   \n",
       "74100             8              8            5          5   \n",
       "\n",
       "       AgriculturalPractices  Encroachments  IneffectiveDisasterPreparedness  \\\n",
       "93203                      8              8                                2   \n",
       "81681                      5              4                                8   \n",
       "74100                      7              6                                5   \n",
       "\n",
       "       DrainageSystems  CoastalVulnerability  Landslides  Watersheds  \\\n",
       "93203                5                     5           2           6   \n",
       "81681                7                     7           5           5   \n",
       "74100                4                     5           4           3   \n",
       "\n",
       "       DeterioratingInfrastructure  PopulationScore  WetlandLoss  \\\n",
       "93203                            6                6            4   \n",
       "81681                            7                5            4   \n",
       "74100                            7                6            3   \n",
       "\n",
       "       InadequatePlanning  PoliticalFactors  FloodProbability  \\\n",
       "93203                   4                 7             0.465   \n",
       "81681                   3                 4             0.545   \n",
       "74100                   5                 6             0.525   \n",
       "\n",
       "       Sum_All_w_Intercept  Sum_All  Sum_Special  \n",
       "93203               0.4843       96            0  \n",
       "81681               0.5459      107            0  \n",
       "74100               0.5235      103            0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop([TARGET], axis=1)\n",
    "y = train[TARGET]\n",
    "\n",
    "n_splits = 5\n",
    "k5 = KFold(n_splits=n_splits, shuffle=True, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define Models list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipelines\n",
    "knn_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsRegressor(n_neighbors=50))\n",
    "])\n",
    "\n",
    "ridge_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    # ('nystroem', Nystroem(n_components=500, random_state=5)),\n",
    "    ('ridge', Ridge())\n",
    "])\n",
    "\n",
    "linear_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ridge', LinearRegression()),\n",
    "])\n",
    "\n",
    "# Manually set pipeline names\n",
    "knn_pipeline.name = 'KNN'\n",
    "ridge_pipeline.name = 'Nystroem Ridge'\n",
    "linear_pipeline.name = 'LR Pipeline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    # CatBoostRegressor(random_state=5, verbose=False, early_stopping_rounds=100),\n",
    "    CatBoostRegressor(random_state=5, verbose=False),\n",
    "    ExtraTreesRegressor(random_state=5),\n",
    "    HistGradientBoostingRegressor(random_state=5),\n",
    "    LinearRegression(),\n",
    "    # linear_pipeline,\n",
    "    LGBMRegressor(random_state=5, n_jobs=-1),\n",
    "    RandomForestRegressor(random_state=5),\n",
    "    knn_pipeline,\n",
    "    ridge_pipeline,\n",
    "    XGBRegressor(random_state=5),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create custom evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models_cv(models, X, y, important_features, cv_split, experiment_name):\n",
    "    MLA_compare = pd.DataFrame(columns=['MLA Name', \n",
    "                                        'MLA Parameters', \n",
    "                                        'MLA Train R2', \n",
    "                                        'MLA Test R2', \n",
    "                                        'MLA Test R2 Std', \n",
    "                                        'MLA Time'])\n",
    "    \n",
    "    def evaluate_model(alg, idx):\n",
    "        if hasattr(alg, 'name'):\n",
    "            MLA_name = alg.name\n",
    "        else:\n",
    "            MLA_name = alg.__class__.__name__\n",
    "        features = important_features.get(MLA_name, [])\n",
    "\n",
    "        # Check if the list of important features is empty\n",
    "        if len(features) == 0:\n",
    "            # If empty, return results with zero values\n",
    "            print(f'Skipping {MLA_name} due to no important features.')\n",
    "            return {\n",
    "                'MLA Name': MLA_name,\n",
    "                'MLA Parameters': str(alg.get_params()),\n",
    "                'MLA Train R2': 0,\n",
    "                'MLA Test R2': 0,\n",
    "                'MLA Test R2 Std': 0,\n",
    "                'MLA Time': \"0 min 0.00 sec\",\n",
    "            }\n",
    "        \n",
    "        cv_results = cross_validate(alg, \n",
    "                                    X[features], \n",
    "                                    y, cv=cv_split, \n",
    "                                    scoring='r2',\n",
    "                                    return_train_score=True, \n",
    "                                    n_jobs=-1)\n",
    "\n",
    "        # Time formatting\n",
    "        mean_fit_time = cv_results['fit_time'].mean()\n",
    "        minutes, seconds = divmod(mean_fit_time, 60)\n",
    "\n",
    "        # Results population\n",
    "        result = {\n",
    "            'MLA Name': MLA_name,\n",
    "            'MLA Parameters': str(alg.get_params()),\n",
    "            'MLA Train R2': cv_results['train_score'].mean(),\n",
    "            'MLA Test R2': cv_results['test_score'].mean(),\n",
    "            'MLA Test R2 Std': cv_results['test_score'].std(),\n",
    "            'MLA Time': f\"{int(minutes)} min {seconds:.2f} sec\",\n",
    "        }\n",
    "\n",
    "        print(f'Done with {MLA_name}.')\n",
    "        return result\n",
    "\n",
    "    results_list = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = [executor.submit(evaluate_model, alg, idx) for idx, alg in enumerate(models)]\n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            results_list.append(result)\n",
    "\n",
    "    MLA_compare = pd.DataFrame(results_list)\n",
    "\n",
    "    MLA_compare.sort_values(by=['MLA Test R2'], ascending=False, inplace=True)\n",
    "    MLA_compare.to_csv(f'{experiment_name}_results.csv', index=False)\n",
    "\n",
    "    return MLA_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models_test_train(models, X, y, important_features, cv_split, experiment_name):\n",
    "    MLA_compare = pd.DataFrame(columns=['MLA Name', \n",
    "                                        'MLA Parameters', \n",
    "                                        'MLA Train R2', \n",
    "                                        'MLA Test R2', \n",
    "                                        'MLA Time'])\n",
    "    \n",
    "    def evaluate_model(alg, idx):\n",
    "        if hasattr(alg, 'name'):\n",
    "            MLA_name = alg.name\n",
    "        else:\n",
    "            MLA_name = alg.__class__.__name__\n",
    "\n",
    "        features = important_features.get(MLA_name, [])\n",
    "\n",
    "        # Check if the list of important features is empty\n",
    "        if len(features) == 0:\n",
    "            # If empty, return results with zero values\n",
    "            print(f'Skipping {MLA_name} due to no important features.')\n",
    "            return {\n",
    "                'MLA Name': MLA_name,\n",
    "                'MLA Parameters': str(alg.get_params()),\n",
    "                'MLA Train R2': 0,\n",
    "                'MLA Test R2': 0,\n",
    "                'MLA Time': \"0 min 0.00 sec\",\n",
    "            }\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X[features],\n",
    "                                                            y,\n",
    "                                                            test_size=0.1,\n",
    "                                                            stratify=y,\n",
    "                                                            shuffle=True,\n",
    "                                                            random_state=5)\n",
    "\n",
    "        start_time = time.time()\n",
    "        alg.fit(X_train, y_train)\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Evaluate the model\n",
    "        train_score = r2_score(y_train, alg.predict(X_train))\n",
    "        test_score = r2_score(y_test, alg.predict(X_test))\n",
    "\n",
    "        # Results population\n",
    "        result = {\n",
    "            'MLA Name': MLA_name,\n",
    "            'MLA Parameters': str(alg.get_params()),\n",
    "            'MLA Train R2': train_score,\n",
    "            'MLA Test R2': test_score,\n",
    "            'MLA Time': f'{(end_time - start_time) / 60:.2f} min',\n",
    "        }\n",
    "\n",
    "        print(f'Done with {MLA_name}.')\n",
    "        return result\n",
    "\n",
    "    results_list = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = [executor.submit(evaluate_model, alg, idx) for idx, alg in enumerate(models)]\n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            results_list.append(result)\n",
    "\n",
    "    MLA_compare = pd.DataFrame(results_list)\n",
    "\n",
    "    MLA_compare.sort_values(by=['MLA Test R2'], ascending=False, inplace=True)\n",
    "    MLA_compare.to_csv(f'{experiment_name}_results.csv', index=False)\n",
    "\n",
    "    return MLA_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_features = {}\n",
    "\n",
    "for model in models:\n",
    "    if hasattr(model, 'name'):\n",
    "        model_name = model.name\n",
    "    else:\n",
    "        model_name = model.__class__.__name__\n",
    "\n",
    "    baseline_features[model_name] = list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with LinearRegression.\n",
      "Done with Nystroem Ridge.\n",
      "Done with CatBoostRegressor.\n",
      "Done with KNN.\n",
      "Done with XGBRegressor.\n",
      "Done with LGBMRegressor.\n",
      "Done with HistGradientBoostingRegressor.\n",
      "Done with ExtraTreesRegressor.\n",
      "Done with RandomForestRegressor.\n",
      "CPU times: total: 11min 15s\n",
      "Wall time: 4min 46s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Parameters</th>\n",
       "      <th>MLA Train R2</th>\n",
       "      <th>MLA Test R2</th>\n",
       "      <th>MLA Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'criter...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.876312</td>\n",
       "      <td>3.66 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...</td>\n",
       "      <td>0.982560</td>\n",
       "      <td>0.873900</td>\n",
       "      <td>4.66 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoostRegressor</td>\n",
       "      <td>{'loss_function': 'RMSE', 'verbose': False, 'r...</td>\n",
       "      <td>0.874549</td>\n",
       "      <td>0.865113</td>\n",
       "      <td>1.18 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>0.869311</td>\n",
       "      <td>0.864707</td>\n",
       "      <td>1.52 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>{'categorical_features': None, 'early_stopping...</td>\n",
       "      <td>0.867356</td>\n",
       "      <td>0.864518</td>\n",
       "      <td>1.55 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>{'objective': 'reg:squarederror', 'base_score'...</td>\n",
       "      <td>0.878386</td>\n",
       "      <td>0.864389</td>\n",
       "      <td>1.47 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nystroem Ridge</td>\n",
       "      <td>{'memory': None, 'steps': [('scaler', Standard...</td>\n",
       "      <td>0.849782</td>\n",
       "      <td>0.849928</td>\n",
       "      <td>0.00 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>{'copy_X': True, 'fit_intercept': True, 'n_job...</td>\n",
       "      <td>0.849781</td>\n",
       "      <td>0.849927</td>\n",
       "      <td>0.01 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>{'memory': None, 'steps': [('scaler', Standard...</td>\n",
       "      <td>0.813004</td>\n",
       "      <td>0.803755</td>\n",
       "      <td>0.01 min</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        MLA Name  \\\n",
       "1            ExtraTreesRegressor   \n",
       "5          RandomForestRegressor   \n",
       "0              CatBoostRegressor   \n",
       "4                  LGBMRegressor   \n",
       "2  HistGradientBoostingRegressor   \n",
       "8                   XGBRegressor   \n",
       "7                 Nystroem Ridge   \n",
       "3               LinearRegression   \n",
       "6                            KNN   \n",
       "\n",
       "                                      MLA Parameters  MLA Train R2  \\\n",
       "1  {'bootstrap': False, 'ccp_alpha': 0.0, 'criter...      1.000000   \n",
       "5  {'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...      0.982560   \n",
       "0  {'loss_function': 'RMSE', 'verbose': False, 'r...      0.874549   \n",
       "4  {'boosting_type': 'gbdt', 'class_weight': None...      0.869311   \n",
       "2  {'categorical_features': None, 'early_stopping...      0.867356   \n",
       "8  {'objective': 'reg:squarederror', 'base_score'...      0.878386   \n",
       "7  {'memory': None, 'steps': [('scaler', Standard...      0.849782   \n",
       "3  {'copy_X': True, 'fit_intercept': True, 'n_job...      0.849781   \n",
       "6  {'memory': None, 'steps': [('scaler', Standard...      0.813004   \n",
       "\n",
       "   MLA Test R2  MLA Time  \n",
       "1     0.876312  3.66 min  \n",
       "5     0.873900  4.66 min  \n",
       "0     0.865113  1.18 min  \n",
       "4     0.864707  1.52 min  \n",
       "2     0.864518  1.55 min  \n",
       "8     0.864389  1.47 min  \n",
       "7     0.849928  0.00 min  \n",
       "3     0.849927  0.01 min  \n",
       "6     0.803755  0.01 min  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "baseline_models = evaluate_models_test_train(models, X, y, baseline_features, k5, f'{experiment_name}')\n",
    "baseline_models\n",
    "\n",
    "# Raw train Linear Regression score - 0.845309\n",
    "# Raw train Linear Regression 5CV score - 0.844941 (0.000751)\n",
    "# Smaller train Linear Regression train_test score - 0.843288\n",
    "# Smaller train Linear Regression 5CV score - 0.843459 (0.001384)\n",
    "# Smaller train Linear Regression w/ kaggle discussion features (Sum_All_w_Intercept and Sum_Special) score - 0.849927\n",
    "# Smaller train Linear Regression w/ default OpenFE 5CV score - \n",
    "\n",
    "# 0.864707 LGBM - Sum_All_w_Intercept and Sum_Special\n",
    "# 0.864829 LGBM - Sum_All ONLY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Initialize empty dictionary for SFS features\n",
    "sfs_features = {}\n",
    "\n",
    "for model in models:\n",
    "    # set name\n",
    "    if hasattr(model, 'name'):\n",
    "        model_name = model.name\n",
    "    else:\n",
    "        model_name = model.__class__.__name__\n",
    "\n",
    "    try:\n",
    "        features = baseline_features[model_name]\n",
    "\n",
    "        # incase there is no feature that had importance, go to the next model\n",
    "        if len(features) == 0:\n",
    "            continue\n",
    "        \n",
    "        X_sfs = X[features]\n",
    "\n",
    "        print(f'Running backward feature selection with {model_name}')\n",
    "\n",
    "        sfs = SFS(model,\n",
    "            k_features='best',\n",
    "            forward=False,\n",
    "            floating=True,\n",
    "            scoring='r2',\n",
    "            verbose=2,\n",
    "            n_jobs=7,\n",
    "            cv=None)\n",
    "        \n",
    "        sfs = sfs.fit(X_sfs, y)\n",
    "\n",
    "        # Get the selected features index\n",
    "        selected_sfs_idx = list(sfs.k_feature_idx_)\n",
    "\n",
    "        # Get the feature names\n",
    "        selected_sfs_feats = X_sfs.columns[selected_sfs_idx]\n",
    "\n",
    "        selected_features = list(selected_sfs_feats)\n",
    "\n",
    "        # # Reorder selected_features based on the predefined features_list\n",
    "        # selected_features_ordered = [feat for feat in features_list if feat in selected_features]\n",
    "\n",
    "        sfs_features[model_name] = selected_features\n",
    "\n",
    "        print(f'Done with {model_name}', end='\\n\\n')\n",
    "\n",
    "    except KeyError:\n",
    "        print(f'{model_name} not in the dictionary.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sfs_features_lgbm.txt', mode='w') as f:\n",
    "    pprint(sfs_features, stream=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_features = {'CatBoostRegressor': ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors', 'Sum_All_w_Intercept', 'Sum_All', 'Sum_Special'],\n",
    "'ExtraTreesRegressor': ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors', 'Sum_All'],\n",
    "'HistGradientBoostingRegressor': ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors', 'Sum_All'],\n",
    "'LinearRegression': ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'InadequatePlanning', 'PoliticalFactors', 'Sum_All_w_Intercept', 'Sum_Special'],\n",
    "'LGBMRegressor': ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors', 'Sum_All'],\n",
    "'RandomForestRegressor': ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors', 'Sum_All_w_Intercept', 'Sum_All', 'Sum_Special'],\n",
    "'KNN': ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors', 'Sum_All_w_Intercept', 'Sum_All', 'Sum_Special'],\n",
    "'Nystroem Ridge': ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'InadequatePlanning', 'PoliticalFactors', 'Sum_All_w_Intercept', 'Sum_Special'],\n",
    "'XGBRegressor': ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors', 'Sum_All'],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with Nystroem Ridge.\n",
      "Done with LinearRegression.\n",
      "Done with KNN.\n",
      "Done with XGBRegressor.\n",
      "Done with LGBMRegressor.\n",
      "Done with CatBoostRegressor.\n",
      "Done with HistGradientBoostingRegressor.\n",
      "Done with ExtraTreesRegressor.\n",
      "Done with RandomForestRegressor.\n",
      "CPU times: total: 13min 19s\n",
      "Wall time: 5min 35s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Parameters</th>\n",
       "      <th>MLA Train R2</th>\n",
       "      <th>MLA Test R2</th>\n",
       "      <th>MLA Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'criter...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.876849</td>\n",
       "      <td>4.20 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...</td>\n",
       "      <td>0.982560</td>\n",
       "      <td>0.873900</td>\n",
       "      <td>5.46 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoostRegressor</td>\n",
       "      <td>{'loss_function': 'RMSE', 'verbose': False, 'r...</td>\n",
       "      <td>0.874549</td>\n",
       "      <td>0.865113</td>\n",
       "      <td>2.15 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>0.869327</td>\n",
       "      <td>0.864829</td>\n",
       "      <td>2.03 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>{'objective': 'reg:squarederror', 'base_score'...</td>\n",
       "      <td>0.878170</td>\n",
       "      <td>0.864683</td>\n",
       "      <td>1.80 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>{'categorical_features': None, 'early_stopping...</td>\n",
       "      <td>0.868183</td>\n",
       "      <td>0.864578</td>\n",
       "      <td>2.17 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>{'copy_X': True, 'fit_intercept': True, 'n_job...</td>\n",
       "      <td>0.849782</td>\n",
       "      <td>0.849928</td>\n",
       "      <td>0.01 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nystroem Ridge</td>\n",
       "      <td>{'memory': None, 'steps': [('scaler', Standard...</td>\n",
       "      <td>0.849782</td>\n",
       "      <td>0.849927</td>\n",
       "      <td>0.01 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>{'memory': None, 'steps': [('scaler', Standard...</td>\n",
       "      <td>0.813004</td>\n",
       "      <td>0.803755</td>\n",
       "      <td>0.01 min</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        MLA Name  \\\n",
       "1            ExtraTreesRegressor   \n",
       "5          RandomForestRegressor   \n",
       "0              CatBoostRegressor   \n",
       "4                  LGBMRegressor   \n",
       "8                   XGBRegressor   \n",
       "2  HistGradientBoostingRegressor   \n",
       "3               LinearRegression   \n",
       "7                 Nystroem Ridge   \n",
       "6                            KNN   \n",
       "\n",
       "                                      MLA Parameters  MLA Train R2  \\\n",
       "1  {'bootstrap': False, 'ccp_alpha': 0.0, 'criter...      1.000000   \n",
       "5  {'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...      0.982560   \n",
       "0  {'loss_function': 'RMSE', 'verbose': False, 'r...      0.874549   \n",
       "4  {'boosting_type': 'gbdt', 'class_weight': None...      0.869327   \n",
       "8  {'objective': 'reg:squarederror', 'base_score'...      0.878170   \n",
       "2  {'categorical_features': None, 'early_stopping...      0.868183   \n",
       "3  {'copy_X': True, 'fit_intercept': True, 'n_job...      0.849782   \n",
       "7  {'memory': None, 'steps': [('scaler', Standard...      0.849782   \n",
       "6  {'memory': None, 'steps': [('scaler', Standard...      0.813004   \n",
       "\n",
       "   MLA Test R2  MLA Time  \n",
       "1     0.876849  4.20 min  \n",
       "5     0.873900  5.46 min  \n",
       "0     0.865113  2.15 min  \n",
       "4     0.864829  2.03 min  \n",
       "8     0.864683  1.80 min  \n",
       "2     0.864578  2.17 min  \n",
       "3     0.849928  0.01 min  \n",
       "7     0.849927  0.01 min  \n",
       "6     0.803755  0.01 min  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "sfs_models = evaluate_models_test_train(models, X, y, sfs_features, k5, f'{experiment_name}_sfs')\n",
    "sfs_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Single Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MonsoonIntensity',\n",
       " 'TopographyDrainage',\n",
       " 'RiverManagement',\n",
       " 'Deforestation',\n",
       " 'Urbanization',\n",
       " 'ClimateChange',\n",
       " 'DamsQuality',\n",
       " 'Siltation',\n",
       " 'AgriculturalPractices',\n",
       " 'Encroachments',\n",
       " 'IneffectiveDisasterPreparedness',\n",
       " 'DrainageSystems',\n",
       " 'CoastalVulnerability',\n",
       " 'Landslides',\n",
       " 'Watersheds',\n",
       " 'DeterioratingInfrastructure',\n",
       " 'PopulationScore',\n",
       " 'WetlandLoss',\n",
       " 'InadequatePlanning',\n",
       " 'PoliticalFactors',\n",
       " 'Sum_All']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = LinearRegression()\n",
    "# model = LGBMRegressor(random_state=5, n_jobs=-1)\n",
    "model = ExtraTreesRegressor(random_state=5)\n",
    "\n",
    "features = sfs_features['ExtraTreesRegressor']\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExtraTreesRegressor(random_state=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesRegressor</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesRegressor(random_state=5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ExtraTreesRegressor(random_state=5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X[features], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57865, 0.45115, 0.44995, ..., 0.6227 , 0.5486 , 0.53625])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test[features])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FloodProbability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.57865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.45115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.44995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.46515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.47535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FloodProbability\n",
       "0           0.57865\n",
       "1           0.45115\n",
       "2           0.44995\n",
       "3           0.46515\n",
       "4           0.47535"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.DataFrame(pred, columns=[TARGET])\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>FloodProbability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1117957</td>\n",
       "      <td>0.57865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1117958</td>\n",
       "      <td>0.45115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1117959</td>\n",
       "      <td>0.44995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1117960</td>\n",
       "      <td>0.46515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1117961</td>\n",
       "      <td>0.47535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  FloodProbability\n",
       "0  1117957           0.57865\n",
       "1  1117958           0.45115\n",
       "2  1117959           0.44995\n",
       "3  1117960           0.46515\n",
       "4  1117961           0.47535"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission_df = pd.concat([submission['id'], pred_df], axis=1)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission_extrat_small_data_0.876849.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get Stacking score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "(119968, 23) (29992, 23) (119968,) (29992,)\n",
      "Starting CatBoostRegressor\n",
      "Starting ExtraTreesRegressor\n",
      "Starting HistGradientBoostingRegressor\n",
      "Starting LinearRegression\n",
      "Starting LGBMRegressor\n",
      "Starting RandomForestRegressor\n",
      "Starting KNN\n",
      "Starting Nystroem Ridge\n",
      "Starting XGBRegressor\n",
      "Fold 2\n",
      "(119968, 23) (29992, 23) (119968,) (29992,)\n",
      "Starting CatBoostRegressor\n",
      "Starting ExtraTreesRegressor\n",
      "Starting HistGradientBoostingRegressor\n",
      "Starting LinearRegression\n",
      "Starting LGBMRegressor\n",
      "Starting RandomForestRegressor\n",
      "Starting KNN\n",
      "Starting Nystroem Ridge\n",
      "Starting XGBRegressor\n",
      "Fold 3\n",
      "(119968, 23) (29992, 23) (119968,) (29992,)\n",
      "Starting CatBoostRegressor\n",
      "Starting ExtraTreesRegressor\n",
      "Starting HistGradientBoostingRegressor\n",
      "Starting LinearRegression\n",
      "Starting LGBMRegressor\n",
      "Starting RandomForestRegressor\n",
      "Starting KNN\n",
      "Starting Nystroem Ridge\n",
      "Starting XGBRegressor\n",
      "Fold 4\n",
      "(119968, 23) (29992, 23) (119968,) (29992,)\n",
      "Starting CatBoostRegressor\n",
      "Starting ExtraTreesRegressor\n",
      "Starting HistGradientBoostingRegressor\n",
      "Starting LinearRegression\n",
      "Starting LGBMRegressor\n",
      "Starting RandomForestRegressor\n",
      "Starting KNN\n",
      "Starting Nystroem Ridge\n",
      "Starting XGBRegressor\n",
      "Fold 5\n",
      "(119968, 23) (29992, 23) (119968,) (29992,)\n",
      "Starting CatBoostRegressor\n",
      "Starting ExtraTreesRegressor\n",
      "Starting HistGradientBoostingRegressor\n",
      "Starting LinearRegression\n",
      "Starting LGBMRegressor\n",
      "Starting RandomForestRegressor\n",
      "Starting KNN\n",
      "Starting Nystroem Ridge\n",
      "Starting XGBRegressor\n",
      "CPU times: total: 36min 37s\n",
      "Wall time: 39min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "meta_scores = []\n",
    "\n",
    "for i, (train_idx, meta_idx) in enumerate(k5.split(X)):\n",
    "    print(f'Fold {i + 1}')\n",
    "    X_train, X_meta = X.iloc[train_idx], X.iloc[meta_idx]\n",
    "    y_train, y_meta = y.iloc[train_idx], y.iloc[meta_idx]\n",
    "\n",
    "    print(X_train.shape, X_meta.shape, y_train.shape, y_meta.shape)\n",
    "    meta_features_fold = np.zeros((X_meta.shape[0], len(models)))\n",
    "    # meta_test_features = np.zeros((y.shape[0], len(models)))\n",
    "    # meta_targets = np.zeros(y.shape[0])\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        model_name = model.__class__.__name__ if not hasattr(model, 'name') else model.name\n",
    "        print(f'Starting {model_name}')\n",
    "        model_features = sfs_features[model_name]\n",
    "        # model_features = baseline_features[model_name]\n",
    "\n",
    "        # Fit model on the selected features\n",
    "        model.fit(X_train[model_features], y_train)\n",
    "        preds = model.predict(X_meta[model_features])\n",
    "        meta_features_fold[:, i] = preds\n",
    "\n",
    "    # Train the meta-model on the predictions from the base models\n",
    "    meta_model.fit(meta_features_fold, y_meta)\n",
    "    \n",
    "    # Predict using the meta-model\n",
    "    final_preds = meta_model.predict(meta_features_fold)\n",
    "    \n",
    "    # Calculate r2_score for the current fold\n",
    "    current_fold_r2_score = r2_score(y_meta, final_preds)\n",
    "    meta_scores.append(current_fold_r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8768246026677646"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the average RMSLE across all folds\n",
    "average_r2 = np.mean(meta_scores)\n",
    "average_r2\n",
    "\n",
    "# 0.843288\n",
    "\n",
    "# 0.84242 - Ridge stack\n",
    "# 0.845440748488788 - LR stack\n",
    "\n",
    "# 0.8768246026677646 - Features w/ LR stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get stacking submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting CatBoostRegressor\n",
      "Starting ExtraTreesRegressor\n",
      "Starting HistGradientBoostingRegressor\n",
      "Starting LinearRegression\n",
      "Starting LGBMRegressor\n",
      "Starting RandomForestRegressor\n",
      "Starting KNN\n",
      "Starting Nystroem Ridge\n",
      "Starting XGBRegressor\n",
      "CPU times: total: 41min 59s\n",
      "Wall time: 23min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Retrain base models on all data\n",
    "all_base_model_predictions = []\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__ if not hasattr(model, 'name') else model.name\n",
    "    print(f'Starting {model_name}')\n",
    "    model_features = sfs_features[model_name]\n",
    "\n",
    "    model.fit(X[model_features], y)\n",
    "    preds = model.predict(test[model_features])\n",
    "    all_base_model_predictions.append(preds.reshape(-1, 1))\n",
    "\n",
    "# Stack predictions for the meta model\n",
    "X_new_meta = np.hstack(all_base_model_predictions)\n",
    "\n",
    "# Use the meta model to make final predictions\n",
    "final_predictions = meta_model.predict(X_new_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CatBoostRegressor',\n",
       " 'ExtraTreesRegressor',\n",
       " 'HistGradientBoostingRegressor',\n",
       " 'LinearRegression',\n",
       " 'LGBMRegressor',\n",
       " 'RandomForestRegressor',\n",
       " 'KNN',\n",
       " 'Nystroem Ridge',\n",
       " 'XGBRegressor']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__ if not hasattr(model, 'name') else model.name\n",
    "    model_names.append(model_name)\n",
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble weights\n",
      "CatBoostRegressor                 0.180837\n",
      "ExtraTreesRegressor               0.768871\n",
      "HistGradientBoostingRegressor    -0.289552\n",
      "LinearRegression                 85.901788\n",
      "LGBMRegressor                     0.381702\n",
      "RandomForestRegressor             0.044886\n",
      "KNN                               0.015027\n",
      "Nystroem Ridge                  -85.943893\n",
      "XGBRegressor                     -0.061552\n",
      "dtype: float64\n",
      "Weights total: 0.9981135550586854\n",
      "Intercept: 0.0006111252766685116\n",
      "\n",
      "Average Stacking RMSLE across all folds: 0.87682\n"
     ]
    }
   ],
   "source": [
    "print('Ensemble weights')\n",
    "weights = pd.Series(meta_model.coef_, index=model_names)\n",
    "print(weights)\n",
    "print(f'Weights total: {weights.sum()}')\n",
    "print(f'Intercept: {meta_model.intercept_}', end='\\n\\n')\n",
    "print(f\"Average Stacking RMSLE across all folds: {average_r2:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FloodProbability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.577797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.451557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.450474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.466101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.475134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FloodProbability\n",
       "0          0.577797\n",
       "1          0.451557\n",
       "2          0.450474\n",
       "3          0.466101\n",
       "4          0.475134"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions_df = pd.DataFrame(final_predictions, columns=[TARGET])\n",
    "final_predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>FloodProbability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1117957</td>\n",
       "      <td>0.577797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1117958</td>\n",
       "      <td>0.451557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1117959</td>\n",
       "      <td>0.450474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1117960</td>\n",
       "      <td>0.466101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1117961</td>\n",
       "      <td>0.475134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  FloodProbability\n",
       "0  1117957          0.577797\n",
       "1  1117958          0.451557\n",
       "2  1117959          0.450474\n",
       "3  1117960          0.466101\n",
       "4  1117961          0.475134"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission_df = pd.concat([submission['id'], final_predictions_df], axis=1)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission_lr_stacking_0.87682.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible features\n",
    "1. (Addition of all features * 0.0056) - 0.0533\n",
    "2. Addition of human activities - ['TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors']\n",
    "3. Addition of natural occurences - ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ofe = OpenFE()\n",
    "ofe.fit(\n",
    "    data=X,\n",
    "    label=y,\n",
    "    # n_data_blocks=2,\n",
    "    # feature_boosting=True,\n",
    "    task='regression',\n",
    "    # stage2_metric='permutation',\n",
    "    # metric='rmse', \n",
    "    n_jobs=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x = transform(X, test, ofe.new_features_list, n_jobs=4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_openfe_features = {}\n",
    "\n",
    "for model in models:\n",
    "    if hasattr(model, 'name'):\n",
    "        model_name = model.name\n",
    "    else:\n",
    "        model_name = model.__class__.__name__\n",
    "\n",
    "    baseline_openfe_features[model_name] = list(train_x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "baseline_openfe_models = evaluate_models_cv(models, X, y, baseline_openfe_features, k5, f'{experiment_name}_openfe')\n",
    "baseline_openfe_models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
