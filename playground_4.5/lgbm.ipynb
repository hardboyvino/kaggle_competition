{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEPS\n",
    "\n",
    "~~ 1. Because the dataset is more than 1 million rows, run a train_test_split to get the R2 test score and get the LB result for the best model~~\n",
    "\n",
    "~~ 2. Get a smaller form of the dataset (about 150,000 rows) and get both a train_test_split and 5CV scores then get the LB results for the best model~~\n",
    "\n",
    "~~ 3. If there is no difference between 1 and 2 then perform SFS on the dataset from 2~~\n",
    "\n",
    "4. Stack the models using either LinearRegression or Ridge\n",
    "5. Hyperparameter tuning on each model 5 times\n",
    "6. Stack all the 54 models\n",
    "7. Perform feature engineering using OpenFE on the dataset from 2\n",
    "8. Perform feature selection using FFS in OpenFE on 7 for each model\n",
    "9. Hyperparameter tune each model from 8 5 times\n",
    "10. Stack all the 54 models from 9\n",
    "11. Stack all 108 models from 5 and 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "import numpy as np\n",
    "from openfe import OpenFE, tree_to_formula, transform, TwoStageFeatureSelector, ForwardFeatureSelector\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor, HistGradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "from sklearn.model_selection import cross_validate, KFold, train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import time\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "experiment_name = 'openfe_smaller_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv('train.csv')\n",
    "train = pd.read_csv('smaller_train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "train.drop('id', axis=1, inplace=True)\n",
    "test.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((149960, 21), (745305, 20))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MonsoonIntensity</th>\n",
       "      <th>TopographyDrainage</th>\n",
       "      <th>RiverManagement</th>\n",
       "      <th>Deforestation</th>\n",
       "      <th>Urbanization</th>\n",
       "      <th>ClimateChange</th>\n",
       "      <th>DamsQuality</th>\n",
       "      <th>Siltation</th>\n",
       "      <th>AgriculturalPractices</th>\n",
       "      <th>Encroachments</th>\n",
       "      <th>IneffectiveDisasterPreparedness</th>\n",
       "      <th>DrainageSystems</th>\n",
       "      <th>CoastalVulnerability</th>\n",
       "      <th>Landslides</th>\n",
       "      <th>Watersheds</th>\n",
       "      <th>DeterioratingInfrastructure</th>\n",
       "      <th>PopulationScore</th>\n",
       "      <th>WetlandLoss</th>\n",
       "      <th>InadequatePlanning</th>\n",
       "      <th>PoliticalFactors</th>\n",
       "      <th>FloodProbability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54198</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82024</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MonsoonIntensity  TopographyDrainage  RiverManagement  Deforestation  \\\n",
       "496                   5                   5                7              6   \n",
       "54198                 8                   3                6              5   \n",
       "82024                 7                   8                5              2   \n",
       "\n",
       "       Urbanization  ClimateChange  DamsQuality  Siltation  \\\n",
       "496               9              3            1          4   \n",
       "54198             4              2            5          5   \n",
       "82024             6              3            5          8   \n",
       "\n",
       "       AgriculturalPractices  Encroachments  IneffectiveDisasterPreparedness  \\\n",
       "496                        6              3                                5   \n",
       "54198                      3              4                                3   \n",
       "82024                      4              5                                6   \n",
       "\n",
       "       DrainageSystems  CoastalVulnerability  Landslides  Watersheds  \\\n",
       "496                  2                     3           2           5   \n",
       "54198                3                     8           5           6   \n",
       "82024                8                     1           6           6   \n",
       "\n",
       "       DeterioratingInfrastructure  PopulationScore  WetlandLoss  \\\n",
       "496                              8                5            3   \n",
       "54198                            5                3            3   \n",
       "82024                            6                4            8   \n",
       "\n",
       "       InadequatePlanning  PoliticalFactors  FloodProbability  \n",
       "496                     6                 6             0.490  \n",
       "54198                   6                10             0.475  \n",
       "82024                   3                 5             0.545  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement',\n",
    "       'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality',\n",
    "       'Siltation', 'AgriculturalPractices', 'Encroachments',\n",
    "       'IneffectiveDisasterPreparedness', 'DrainageSystems',\n",
    "       'CoastalVulnerability', 'Landslides', 'Watersheds',\n",
    "       'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss',\n",
    "       'InadequatePlanning', 'PoliticalFactors', 'FloodProbability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'FloodProbability'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop([TARGET], axis=1)\n",
    "y = train[TARGET]\n",
    "\n",
    "n_splits = 5\n",
    "k5 = KFold(n_splits=n_splits, shuffle=True, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define Models list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipelines\n",
    "knn_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsRegressor(n_neighbors=50))\n",
    "])\n",
    "ridge_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('nystroem', Nystroem(n_components=500, random_state=5)),\n",
    "    ('ridge', Ridge(alpha=0.1, max_iter=1000, random_state=5))\n",
    "])\n",
    "\n",
    "# Manually set pipeline names\n",
    "knn_pipeline.name = 'KNN'\n",
    "ridge_pipeline.name = 'Nystroem Ridge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    CatBoostRegressor(random_state=5, verbose=False, early_stopping_rounds=100),\n",
    "    ExtraTreesRegressor(random_state=5),\n",
    "    HistGradientBoostingRegressor(random_state=5),\n",
    "    LinearRegression(),\n",
    "    LGBMRegressor(random_state=5, n_jobs=-1),\n",
    "    RandomForestRegressor(random_state=5),\n",
    "    knn_pipeline,\n",
    "    ridge_pipeline,\n",
    "    XGBRegressor(random_state=5),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create custom evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models_cv(models, X, y, important_features, cv_split, experiment_name):\n",
    "    MLA_compare = pd.DataFrame(columns=['MLA Name', \n",
    "                                        'MLA Parameters', \n",
    "                                        'MLA Train R2', \n",
    "                                        'MLA Test R2', \n",
    "                                        'MLA Test R2 Std', \n",
    "                                        'MLA Time'])\n",
    "    \n",
    "    def evaluate_model(alg, idx):\n",
    "        if hasattr(alg, 'name'):\n",
    "            MLA_name = alg.name\n",
    "        else:\n",
    "            MLA_name = alg.__class__.__name__\n",
    "        features = important_features.get(MLA_name, [])\n",
    "\n",
    "        # Check if the list of important features is empty\n",
    "        if len(features) == 0:\n",
    "            # If empty, return results with zero values\n",
    "            print(f'Skipping {MLA_name} due to no important features.')\n",
    "            return {\n",
    "                'MLA Name': MLA_name,\n",
    "                'MLA Parameters': str(alg.get_params()),\n",
    "                'MLA Train R2': 0,\n",
    "                'MLA Test R2': 0,\n",
    "                'MLA Test R2 Std': 0,\n",
    "                'MLA Time': \"0 min 0.00 sec\",\n",
    "            }\n",
    "        \n",
    "        cv_results = cross_validate(alg, \n",
    "                                    X[features], \n",
    "                                    y, cv=cv_split, \n",
    "                                    scoring='r2',\n",
    "                                    return_train_score=True, \n",
    "                                    n_jobs=-1)\n",
    "\n",
    "        # Time formatting\n",
    "        mean_fit_time = cv_results['fit_time'].mean()\n",
    "        minutes, seconds = divmod(mean_fit_time, 60)\n",
    "\n",
    "        # Results population\n",
    "        result = {\n",
    "            'MLA Name': MLA_name,\n",
    "            'MLA Parameters': str(alg.get_params()),\n",
    "            'MLA Train R2': cv_results['train_score'].mean(),\n",
    "            'MLA Test R2': cv_results['test_score'].mean(),\n",
    "            'MLA Test R2 Std': cv_results['test_score'].std(),\n",
    "            'MLA Time': f\"{int(minutes)} min {seconds:.2f} sec\",\n",
    "        }\n",
    "\n",
    "        print(f'Done with {MLA_name}.')\n",
    "        return result\n",
    "\n",
    "    results_list = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = [executor.submit(evaluate_model, alg, idx) for idx, alg in enumerate(models)]\n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            results_list.append(result)\n",
    "\n",
    "    MLA_compare = pd.DataFrame(results_list)\n",
    "\n",
    "    MLA_compare.sort_values(by=['MLA Test R2'], ascending=False, inplace=True)\n",
    "    MLA_compare.to_csv(f'{experiment_name}_results.csv', index=False)\n",
    "\n",
    "    return MLA_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models_test_train(models, X, y, important_features, cv_split, experiment_name):\n",
    "    MLA_compare = pd.DataFrame(columns=['MLA Name', \n",
    "                                        'MLA Parameters', \n",
    "                                        'MLA Train R2', \n",
    "                                        'MLA Test R2', \n",
    "                                        'MLA Time'])\n",
    "    \n",
    "    def evaluate_model(alg, idx):\n",
    "        if hasattr(alg, 'name'):\n",
    "            MLA_name = alg.name\n",
    "        else:\n",
    "            MLA_name = alg.__class__.__name__\n",
    "\n",
    "        features = important_features.get(MLA_name, [])\n",
    "\n",
    "        # Check if the list of important features is empty\n",
    "        if len(features) == 0:\n",
    "            # If empty, return results with zero values\n",
    "            print(f'Skipping {MLA_name} due to no important features.')\n",
    "            return {\n",
    "                'MLA Name': MLA_name,\n",
    "                'MLA Parameters': str(alg.get_params()),\n",
    "                'MLA Train R2': 0,\n",
    "                'MLA Test R2': 0,\n",
    "                'MLA Time': \"0 min 0.00 sec\",\n",
    "            }\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X[features],\n",
    "                                                            y,\n",
    "                                                            test_size=0.1,\n",
    "                                                            stratify=y,\n",
    "                                                            shuffle=True,\n",
    "                                                            random_state=5)\n",
    "\n",
    "        start_time = time.time()\n",
    "        alg.fit(X_train, y_train)\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Evaluate the model\n",
    "        train_score = r2_score(y_train, alg.predict(X_train))\n",
    "        test_score = r2_score(y_test, alg.predict(X_test))\n",
    "\n",
    "        # Results population\n",
    "        result = {\n",
    "            'MLA Name': MLA_name,\n",
    "            'MLA Parameters': str(alg.get_params()),\n",
    "            'MLA Train R2': train_score,\n",
    "            'MLA Test R2': test_score,\n",
    "            'MLA Time': f'{(end_time - start_time) / 60:.2f} min',\n",
    "        }\n",
    "\n",
    "        print(f'Done with {MLA_name}.')\n",
    "        return result\n",
    "\n",
    "    results_list = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = [executor.submit(evaluate_model, alg, idx) for idx, alg in enumerate(models)]\n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            results_list.append(result)\n",
    "\n",
    "    MLA_compare = pd.DataFrame(results_list)\n",
    "\n",
    "    MLA_compare.sort_values(by=['MLA Test R2'], ascending=False, inplace=True)\n",
    "    MLA_compare.to_csv(f'{experiment_name}_results.csv', index=False)\n",
    "\n",
    "    return MLA_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_features = {}\n",
    "\n",
    "for model in models:\n",
    "    if hasattr(model, 'name'):\n",
    "        model_name = model.name\n",
    "    else:\n",
    "        model_name = model.__class__.__name__\n",
    "\n",
    "    baseline_features[model_name] = list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with LinearRegression.\n",
      "Done with Nystroem Ridge.\n",
      "Done with KNN.\n",
      "Done with XGBRegressor.\n",
      "Done with CatBoostRegressor.\n",
      "Done with LGBMRegressor.\n",
      "Done with HistGradientBoostingRegressor.\n",
      "Done with ExtraTreesRegressor.\n",
      "Done with RandomForestRegressor.\n",
      "CPU times: total: 13min 32s\n",
      "Wall time: 5min 43s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Parameters</th>\n",
       "      <th>MLA Train R2</th>\n",
       "      <th>MLA Test R2</th>\n",
       "      <th>MLA Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoostRegressor</td>\n",
       "      <td>{'loss_function': 'RMSE', 'verbose': False, 'r...</td>\n",
       "      <td>0.855833</td>\n",
       "      <td>0.844292</td>\n",
       "      <td>2.49 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>{'copy_X': True, 'fit_intercept': True, 'n_job...</td>\n",
       "      <td>0.843541</td>\n",
       "      <td>0.843288</td>\n",
       "      <td>0.04 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nystroem Ridge</td>\n",
       "      <td>{'memory': None, 'steps': [('scaler', Standard...</td>\n",
       "      <td>0.793352</td>\n",
       "      <td>0.792463</td>\n",
       "      <td>0.46 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>{'objective': 'reg:squarederror', 'base_score'...</td>\n",
       "      <td>0.833150</td>\n",
       "      <td>0.791628</td>\n",
       "      <td>2.20 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>{'categorical_features': None, 'early_stopping...</td>\n",
       "      <td>0.786778</td>\n",
       "      <td>0.761517</td>\n",
       "      <td>2.59 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>0.788021</td>\n",
       "      <td>0.760530</td>\n",
       "      <td>2.50 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'criter...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659301</td>\n",
       "      <td>4.24 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...</td>\n",
       "      <td>0.950981</td>\n",
       "      <td>0.652607</td>\n",
       "      <td>5.41 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>{'memory': None, 'steps': [('scaler', Standard...</td>\n",
       "      <td>0.667465</td>\n",
       "      <td>0.651591</td>\n",
       "      <td>0.01 min</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        MLA Name  \\\n",
       "0              CatBoostRegressor   \n",
       "3               LinearRegression   \n",
       "7                 Nystroem Ridge   \n",
       "8                   XGBRegressor   \n",
       "2  HistGradientBoostingRegressor   \n",
       "4                  LGBMRegressor   \n",
       "1            ExtraTreesRegressor   \n",
       "5          RandomForestRegressor   \n",
       "6                            KNN   \n",
       "\n",
       "                                      MLA Parameters  MLA Train R2  \\\n",
       "0  {'loss_function': 'RMSE', 'verbose': False, 'r...      0.855833   \n",
       "3  {'copy_X': True, 'fit_intercept': True, 'n_job...      0.843541   \n",
       "7  {'memory': None, 'steps': [('scaler', Standard...      0.793352   \n",
       "8  {'objective': 'reg:squarederror', 'base_score'...      0.833150   \n",
       "2  {'categorical_features': None, 'early_stopping...      0.786778   \n",
       "4  {'boosting_type': 'gbdt', 'class_weight': None...      0.788021   \n",
       "1  {'bootstrap': False, 'ccp_alpha': 0.0, 'criter...      1.000000   \n",
       "5  {'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...      0.950981   \n",
       "6  {'memory': None, 'steps': [('scaler', Standard...      0.667465   \n",
       "\n",
       "   MLA Test R2  MLA Time  \n",
       "0     0.844292  2.49 min  \n",
       "3     0.843288  0.04 min  \n",
       "7     0.792463  0.46 min  \n",
       "8     0.791628  2.20 min  \n",
       "2     0.761517  2.59 min  \n",
       "4     0.760530  2.50 min  \n",
       "1     0.659301  4.24 min  \n",
       "5     0.652607  5.41 min  \n",
       "6     0.651591  0.01 min  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "baseline_models = evaluate_models_test_train(models, X, y, baseline_features, k5, f'{experiment_name}')\n",
    "baseline_models\n",
    "\n",
    "# Raw train Linear Regression score - 0.845309\n",
    "# Raw train Linear Regression 5CV score - 0.844941 (0.000751)\n",
    "# Smaller train Linear Regression train_test score - 0.843288\n",
    "# Smaller train Linear Regression 5CV score - 0.843459 (0.001384)\n",
    "# Smaller train Linear Regression w/ default OpenFE 5CV score - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Initialize empty dictionary for SFS features\n",
    "sfs_features = {}\n",
    "\n",
    "for model in models:\n",
    "    # set name\n",
    "    if hasattr(model, 'name'):\n",
    "        model_name = model.name\n",
    "    else:\n",
    "        model_name = model.__class__.__name__\n",
    "\n",
    "    try:\n",
    "        features = baseline_features[model_name]\n",
    "\n",
    "        # incase there is no feature that had importance, go to the next model\n",
    "        if len(features) == 0:\n",
    "            continue\n",
    "        \n",
    "        X_sfs = X[features]\n",
    "\n",
    "        print(f'Running backward feature selection with {model_name}')\n",
    "\n",
    "        sfs = SFS(model,\n",
    "            k_features='best',\n",
    "            forward=False,\n",
    "            floating=False,\n",
    "            scoring='r2',\n",
    "            verbose=2,\n",
    "            n_jobs=7,\n",
    "            cv=k5)\n",
    "        \n",
    "        sfs = sfs.fit(X_sfs, y)\n",
    "\n",
    "        # Get the selected features index\n",
    "        selected_sfs_idx = list(sfs.k_feature_idx_)\n",
    "\n",
    "        # Get the feature names\n",
    "        selected_sfs_feats = X_sfs.columns[selected_sfs_idx]\n",
    "\n",
    "        selected_features = list(selected_sfs_feats)\n",
    "\n",
    "        # Reorder selected_features based on the predefined features_list\n",
    "        selected_features_ordered = [feat for feat in features_list if feat in selected_features]\n",
    "\n",
    "        sfs_features[model_name] = selected_features_ordered\n",
    "\n",
    "        print(f'Done with {model_name}', end='\\n\\n')\n",
    "\n",
    "    except KeyError:\n",
    "        print(f'{model_name} not in the dictionary.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sfs_features_baseline.txt', mode='w') as f:\n",
    "    pprint(sfs_features, stream=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Single Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(pred, columns=[TARGET])\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission_df = pd.concat([submission['id'], pred_df], axis=1)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission_lr_small_data_0.843288_0.843459.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get Stacking score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "meta_scores = []\n",
    "meta_model = Ridge()\n",
    "\n",
    "for i, (train_idx, meta_idx) in enumerate(k5.split(X)):\n",
    "    print(f'Fold {i + 1}')\n",
    "    X_train, X_meta = X.iloc[train_idx], X.iloc[meta_idx]\n",
    "    y_train, y_meta = y.iloc[train_idx], y.iloc[meta_idx]\n",
    "\n",
    "    meta_features_fold = np.zeros((X_meta.shape[0], len(models)))\n",
    "    # meta_test_features = np.zeros((y.shape[0], len(models)))\n",
    "    # meta_targets = np.zeros(y.shape[0])\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        model_name = model.__class__.__name__ if not hasattr(model, 'name') else model.name\n",
    "        print(f'Starting {model_name}')\n",
    "        model_features = sfs_features[model_name]\n",
    "\n",
    "        # Fit model on the selected features\n",
    "        model.fit(X_train[model_features], y_train)\n",
    "        preds = model.predict(X_meta[model_features])\n",
    "        meta_features_fold[:, i] = preds\n",
    "\n",
    "    # Train the meta-model on the predictions from the base models\n",
    "    meta_model.fit(meta_features_fold, y_meta)\n",
    "    \n",
    "    # Predict using the meta-model\n",
    "    final_preds = meta_model.predict(meta_features_fold)\n",
    "    \n",
    "    # Calculate RMSLE for the current fold\n",
    "    current_fold_rmsle = rmsle(y_meta, final_preds)\n",
    "    meta_scores.append(current_fold_rmsle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ofe = OpenFE()\n",
    "ofe.fit(\n",
    "    data=X,\n",
    "    label=y,\n",
    "    # n_data_blocks=2,\n",
    "    # feature_boosting=True,\n",
    "    task='regression',\n",
    "    # stage2_metric='permutation',\n",
    "    # metric='rmse', \n",
    "    n_jobs=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x = transform(X, test, ofe.new_features_list, n_jobs=4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_openfe_features = {}\n",
    "\n",
    "for model in models:\n",
    "    if hasattr(model, 'name'):\n",
    "        model_name = model.name\n",
    "    else:\n",
    "        model_name = model.__class__.__name__\n",
    "\n",
    "    baseline_openfe_features[model_name] = list(train_x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "baseline_openfe_models = evaluate_models_cv(models, X, y, baseline_openfe_features, k5, f'{experiment_name}_openfe')\n",
    "baseline_openfe_models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
