{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEPS\n",
    "\n",
    "~~ 1. Because the dataset is more than 1 million rows, run a train_test_split to get the R2 test score and get the LB result for the best model~~\n",
    "\n",
    "~~ 2. Get a smaller form of the dataset (about 150,000 rows) and get both a train_test_split and 5CV scores then get the LB results for the best model~~\n",
    "\n",
    "~~ 3. If there is no difference between 1 and 2 then perform SFS on the dataset from 2~~\n",
    "\n",
    "4. Stack the models using either LinearRegression or Ridge\n",
    "5. Hyperparameter tuning on each model 5 times\n",
    "6. Stack all the 54 models\n",
    "7. Perform feature engineering using OpenFE on the dataset from 2\n",
    "8. Perform feature selection using FFS in OpenFE on 7 for each model\n",
    "9. Hyperparameter tune each model from 8 5 times\n",
    "10. Stack all the 54 models from 9\n",
    "11. Stack all 108 models from 5 and 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "import numpy as np\n",
    "from openfe import OpenFE, tree_to_formula, transform, TwoStageFeatureSelector, ForwardFeatureSelector\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor, HistGradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "from sklearn.model_selection import cross_validate, KFold, train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "experiment_name = 'openfe_smaller_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_big = pd.read_csv('train.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "train.drop('id', axis=1, inplace=True)\n",
    "test.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1117957, 21), (745305, 20))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement',\n",
    "       'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality',\n",
    "       'Siltation', 'AgriculturalPractices', 'Encroachments',\n",
    "       'IneffectiveDisasterPreparedness', 'DrainageSystems',\n",
    "       'CoastalVulnerability', 'Landslides', 'Watersheds',\n",
    "       'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss',\n",
    "       'InadequatePlanning', 'PoliticalFactors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'FloodProbability'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111796, 1006161)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.1, random_state=5)\n",
    "\n",
    "# Get the indices for the validation set\n",
    "for _, test_indx in sss.split(train, train[TARGET]):\n",
    "    valid_train = train.iloc[test_indx]\n",
    "    train_train = train.drop(test_indx)\n",
    "\n",
    "len(valid_train), len(train_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_big['Sum_All_w_Intercept'] = (train_big[features_list].sum(axis=1) * 0.0056) - 0.0533\n",
    "# train['Sum_All_w_Intercept'] = (train[features_list].sum(axis=1) * 0.0056) - 0.0533\n",
    "# test['Sum_All_w_Intercept'] = (test[features_list].sum(axis=1) * 0.0056) - 0.0533\n",
    "\n",
    "# train_big['Sum_All'] = train_big[features_list].sum(axis=1)\n",
    "# train['Sum_All'] = train[features_list].sum(axis=1)\n",
    "# test['Sum_All'] = test[features_list].sum(axis=1)\n",
    "\n",
    "# train_big['Sum_Special'] = (train_big[features_list].sum(axis=1).isin(np.arange(72, 76))).astype(int)\n",
    "# train['Sum_Special'] = (train[features_list].sum(axis=1).isin(np.arange(72, 76))).astype(int)\n",
    "# test['Sum_Special'] = (test[features_list].sum(axis=1).isin(np.arange(72, 76))).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MonsoonIntensity</th>\n",
       "      <th>TopographyDrainage</th>\n",
       "      <th>RiverManagement</th>\n",
       "      <th>Deforestation</th>\n",
       "      <th>Urbanization</th>\n",
       "      <th>ClimateChange</th>\n",
       "      <th>DamsQuality</th>\n",
       "      <th>Siltation</th>\n",
       "      <th>AgriculturalPractices</th>\n",
       "      <th>Encroachments</th>\n",
       "      <th>IneffectiveDisasterPreparedness</th>\n",
       "      <th>DrainageSystems</th>\n",
       "      <th>CoastalVulnerability</th>\n",
       "      <th>Landslides</th>\n",
       "      <th>Watersheds</th>\n",
       "      <th>DeterioratingInfrastructure</th>\n",
       "      <th>PopulationScore</th>\n",
       "      <th>WetlandLoss</th>\n",
       "      <th>InadequatePlanning</th>\n",
       "      <th>PoliticalFactors</th>\n",
       "      <th>FloodProbability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>446789</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677502</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0.505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117917</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MonsoonIntensity  TopographyDrainage  RiverManagement  Deforestation  \\\n",
       "446789                 5                   2                6              8   \n",
       "677502                 8                   4                5              5   \n",
       "117917                 5                   5                5              5   \n",
       "\n",
       "        Urbanization  ClimateChange  DamsQuality  Siltation  \\\n",
       "446789             5              3            4          3   \n",
       "677502             3              4            5          4   \n",
       "117917             5              3            8          6   \n",
       "\n",
       "        AgriculturalPractices  Encroachments  IneffectiveDisasterPreparedness  \\\n",
       "446789                      8              5                               11   \n",
       "677502                      2              5                                5   \n",
       "117917                      3              6                                5   \n",
       "\n",
       "        DrainageSystems  CoastalVulnerability  Landslides  Watersheds  \\\n",
       "446789                3                     8           4           8   \n",
       "677502                5                     4           4           4   \n",
       "117917                7                     4           5           6   \n",
       "\n",
       "        DeterioratingInfrastructure  PopulationScore  WetlandLoss  \\\n",
       "446789                            5                5            8   \n",
       "677502                            5                2            3   \n",
       "117917                            2                2            1   \n",
       "\n",
       "        InadequatePlanning  PoliticalFactors  FloodProbability  \n",
       "446789                   5                 7             0.615  \n",
       "677502                   4                11             0.505  \n",
       "117917                   6                 2             0.505  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MonsoonIntensity</th>\n",
       "      <th>TopographyDrainage</th>\n",
       "      <th>RiverManagement</th>\n",
       "      <th>Deforestation</th>\n",
       "      <th>Urbanization</th>\n",
       "      <th>ClimateChange</th>\n",
       "      <th>DamsQuality</th>\n",
       "      <th>Siltation</th>\n",
       "      <th>AgriculturalPractices</th>\n",
       "      <th>Encroachments</th>\n",
       "      <th>IneffectiveDisasterPreparedness</th>\n",
       "      <th>DrainageSystems</th>\n",
       "      <th>CoastalVulnerability</th>\n",
       "      <th>Landslides</th>\n",
       "      <th>Watersheds</th>\n",
       "      <th>DeterioratingInfrastructure</th>\n",
       "      <th>PopulationScore</th>\n",
       "      <th>WetlandLoss</th>\n",
       "      <th>InadequatePlanning</th>\n",
       "      <th>PoliticalFactors</th>\n",
       "      <th>FloodProbability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91628</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795950</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271686</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MonsoonIntensity  TopographyDrainage  RiverManagement  Deforestation  \\\n",
       "91628                  7                   8                3              9   \n",
       "795950                 5                   5                4              3   \n",
       "271686                 6                   6                5              1   \n",
       "\n",
       "        Urbanization  ClimateChange  DamsQuality  Siltation  \\\n",
       "91628              2              4            5          8   \n",
       "795950             5              5            5          3   \n",
       "271686             7              2            2          5   \n",
       "\n",
       "        AgriculturalPractices  Encroachments  IneffectiveDisasterPreparedness  \\\n",
       "91628                      10              6                                3   \n",
       "795950                      6              6                                5   \n",
       "271686                      9              6                                5   \n",
       "\n",
       "        DrainageSystems  CoastalVulnerability  Landslides  Watersheds  \\\n",
       "91628                 4                     7           6           3   \n",
       "795950                9                     4           6           5   \n",
       "271686                7                     3           5           6   \n",
       "\n",
       "        DeterioratingInfrastructure  PopulationScore  WetlandLoss  \\\n",
       "91628                             4                6            4   \n",
       "795950                            3                2            9   \n",
       "271686                            3                6            7   \n",
       "\n",
       "        InadequatePlanning  PoliticalFactors  FloodProbability  \n",
       "91628                    5                 5             0.570  \n",
       "795950                   7                 3             0.505  \n",
       "271686                   4                 4             0.515  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_train.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FloodProbability\n",
      "0.490    3.874925\n",
      "0.495    3.783866\n",
      "0.520    3.691197\n",
      "0.485    3.681358\n",
      "0.505    3.678675\n",
      "           ...   \n",
      "0.700    0.002862\n",
      "0.725    0.002594\n",
      "0.715    0.002326\n",
      "0.710    0.002057\n",
      "0.285    0.001789\n",
      "Name: count, Length: 83, dtype: float64\n",
      "FloodProbability\n",
      "0.490    3.874927\n",
      "0.495    3.783887\n",
      "0.520    3.691159\n",
      "0.485    3.681319\n",
      "0.505    3.678636\n",
      "           ...   \n",
      "0.700    0.002882\n",
      "0.725    0.002584\n",
      "0.715    0.002286\n",
      "0.710    0.002087\n",
      "0.285    0.001789\n",
      "Name: count, Length: 83, dtype: float64\n",
      "FloodProbability\n",
      "0.490    3.874915\n",
      "0.495    3.783677\n",
      "0.520    3.691545\n",
      "0.485    3.681706\n",
      "0.505    3.679023\n",
      "           ...   \n",
      "0.725    0.002683\n",
      "0.715    0.002683\n",
      "0.700    0.002683\n",
      "0.710    0.001789\n",
      "0.285    0.001789\n",
      "Name: count, Length: 83, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_percentage_of_unique(df, target_variable):\n",
    "    value_counts = df[target_variable].value_counts()\n",
    "\n",
    "    total_count = len(df)\n",
    "\n",
    "    percentage = (value_counts / total_count) * 100\n",
    "\n",
    "    return percentage\n",
    "\n",
    "print(get_percentage_of_unique(train, TARGET)), print(get_percentage_of_unique(train_train, TARGET)), print(get_percentage_of_unique(valid_train, TARGET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = valid_train.drop([TARGET], axis=1)\n",
    "y = valid_train[TARGET]\n",
    "\n",
    "# n_splits = 10\n",
    "k3 = KFold(n_splits=3, shuffle=True, random_state=5)\n",
    "k5 = KFold(n_splits=5, shuffle=True, random_state=5)\n",
    "k10 = KFold(n_splits=10, shuffle=True, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define Models list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipelines\n",
    "knn_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsRegressor(n_neighbors=50))\n",
    "])\n",
    "\n",
    "ridge_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    # ('nystroem', Nystroem(n_components=500, random_state=5)),\n",
    "    ('ridge', Ridge())\n",
    "])\n",
    "\n",
    "linear_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ridge', LinearRegression()),\n",
    "])\n",
    "\n",
    "# Manually set pipeline names\n",
    "knn_pipeline.name = 'KNN'\n",
    "ridge_pipeline.name = 'Nystroem Ridge'\n",
    "linear_pipeline.name = 'LR Pipeline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    CatBoostRegressor(random_state=5, verbose=False, early_stopping_rounds=100),\n",
    "    ExtraTreesRegressor(random_state=5),\n",
    "    HistGradientBoostingRegressor(random_state=5),\n",
    "    LinearRegression(),\n",
    "    linear_pipeline,\n",
    "    LGBMRegressor(random_state=5, n_jobs=-1),\n",
    "    RandomForestRegressor(random_state=5),\n",
    "    knn_pipeline,\n",
    "    ridge_pipeline,\n",
    "    XGBRegressor(random_state=5),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create custom evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def round_to_nearest_005(x):\n",
    "#     return round(round(x / 0.005) * 0.005, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models_cv(models, X, y, important_features, cv_split, experiment_name):\n",
    "    MLA_compare = pd.DataFrame(columns=['MLA Name', \n",
    "                                        'MLA Parameters', \n",
    "                                        'MLA Train R2', \n",
    "                                        'MLA Test R2', \n",
    "                                        'MLA Test R2 Std', \n",
    "                                        'MLA Time'])\n",
    "    \n",
    "    def evaluate_model(alg, idx):\n",
    "        if hasattr(alg, 'name'):\n",
    "            MLA_name = alg.name\n",
    "        else:\n",
    "            MLA_name = alg.__class__.__name__\n",
    "        features = important_features.get(MLA_name, [])\n",
    "\n",
    "        # Check if the list of important features is empty\n",
    "        if len(features) == 0:\n",
    "            # If empty, return results with zero values\n",
    "            print(f'Skipping {MLA_name} due to no important features.')\n",
    "            return {\n",
    "                'MLA Name': MLA_name,\n",
    "                'MLA Parameters': str(alg.get_params()),\n",
    "                'MLA Train R2': 0,\n",
    "                'MLA Test R2': 0,\n",
    "                'MLA Test R2 Std': 0,\n",
    "                'MLA Time': \"0 min 0.00 sec\",\n",
    "            }\n",
    "        \n",
    "        cv_results = cross_validate(alg, \n",
    "                                    X[features], \n",
    "                                    y, cv=cv_split, \n",
    "                                    scoring='r2',\n",
    "                                    return_train_score=True, \n",
    "                                    n_jobs=-1)\n",
    "\n",
    "        # Time formatting\n",
    "        mean_fit_time = cv_results['fit_time'].mean()\n",
    "        minutes, seconds = divmod(mean_fit_time, 60)\n",
    "\n",
    "        # Results population\n",
    "        result = {\n",
    "            'MLA Name': MLA_name,\n",
    "            'MLA Parameters': str(alg.get_params()),\n",
    "            'MLA Train R2': cv_results['train_score'].mean(),\n",
    "            'MLA Test R2': cv_results['test_score'].mean(),\n",
    "            'MLA Test R2 Std': cv_results['test_score'].std(),\n",
    "            'MLA Time': f\"{int(minutes)} min {seconds:.2f} sec\",\n",
    "        }\n",
    "\n",
    "        print(f'Done with {MLA_name}.')\n",
    "        return result\n",
    "\n",
    "    results_list = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=50) as executor:\n",
    "        futures = [executor.submit(evaluate_model, alg, idx) for idx, alg in enumerate(tqdm(models, desc='Models'))]\n",
    "        for future in tqdm(futures, total=len(futures), desc='Progress'):\n",
    "            result = future.result()\n",
    "            results_list.append(result)\n",
    "\n",
    "    MLA_compare = pd.DataFrame(results_list)\n",
    "\n",
    "    MLA_compare.sort_values(by=['MLA Test R2'], ascending=False, inplace=True)\n",
    "    MLA_compare.to_csv(f'{experiment_name}_results.csv', index=False)\n",
    "\n",
    "    return MLA_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models_test_train(models, X, y, important_features, cv_split, experiment_name):\n",
    "    MLA_compare = pd.DataFrame(columns=['MLA Name', \n",
    "                                        'MLA Parameters', \n",
    "                                        'MLA Train R2', \n",
    "                                        'MLA Test R2', \n",
    "                                        'MLA Time'])\n",
    "    \n",
    "    def evaluate_model(alg, idx):\n",
    "        if hasattr(alg, 'name'):\n",
    "            MLA_name = alg.name\n",
    "        else:\n",
    "            MLA_name = alg.__class__.__name__\n",
    "\n",
    "        features = important_features.get(MLA_name, [])\n",
    "\n",
    "        # Check if the list of important features is empty\n",
    "        if len(features) == 0:\n",
    "            # If empty, return results with zero values\n",
    "            print(f'Skipping {MLA_name} due to no important features.')\n",
    "            return {\n",
    "                'MLA Name': MLA_name,\n",
    "                'MLA Parameters': str(alg.get_params()),\n",
    "                'MLA Train R2': 0,\n",
    "                'MLA Test R2': 0,\n",
    "                'MLA Time': \"0 min 0.00 sec\",\n",
    "            }\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X[features],\n",
    "                                                            y,\n",
    "                                                            test_size=0.1,\n",
    "                                                            stratify=y,\n",
    "                                                            shuffle=True,\n",
    "                                                            random_state=5)\n",
    "\n",
    "        start_time = time.time()\n",
    "        alg.fit(X_train, y_train)\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Evaluate the model\n",
    "        train_score = r2_score(y_train, alg.predict(X_train))\n",
    "        test_score = r2_score(y_test, alg.predict(X_test))\n",
    "\n",
    "        # Results population\n",
    "        result = {\n",
    "            'MLA Name': MLA_name,\n",
    "            'MLA Parameters': str(alg.get_params()),\n",
    "            'MLA Train R2': train_score,\n",
    "            'MLA Test R2': test_score,\n",
    "            'MLA Time': f'{(end_time - start_time) / 60:.2f} min',\n",
    "        }\n",
    "\n",
    "        print(f'Done with {MLA_name}.')\n",
    "        return result\n",
    "\n",
    "    results_list = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=50) as executor:\n",
    "        futures = [executor.submit(evaluate_model, alg, idx) for idx, alg in enumerate(tqdm(models, desc='Models'))]\n",
    "        for future in tqdm(futures, total=len(futures), desc='Progress'):\n",
    "            result = future.result()\n",
    "            results_list.append(result)\n",
    "\n",
    "    MLA_compare = pd.DataFrame(results_list)\n",
    "\n",
    "    MLA_compare.sort_values(by=['MLA Test R2'], ascending=False, inplace=True)\n",
    "    MLA_compare.to_csv(f'{experiment_name}_results.csv', index=False)\n",
    "\n",
    "    return MLA_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_features = {}\n",
    "\n",
    "for model in models:\n",
    "    if hasattr(model, 'name'):\n",
    "        model_name = model.name\n",
    "    else:\n",
    "        model_name = model.__class__.__name__\n",
    "\n",
    "    baseline_features[model_name] = list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54164961d0f049098840105a31653948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Models:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "529c0b06cefe457bbfdfb905db204982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with LGBMRegressor.\n",
      "Done with HistGradientBoostingRegressor.\n",
      "Done with XGBRegressor.\n",
      "Done with Nystroem Ridge.\n",
      "Done with CatBoostRegressor.\n",
      "Done with LinearRegression.\n",
      "Done with LR Pipeline.\n",
      "Done with ExtraTreesRegressor.\n",
      "Done with RandomForestRegressor.\n",
      "Done with KNN.\n",
      "CPU times: total: 1.97 s\n",
      "Wall time: 13min 10s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Parameters</th>\n",
       "      <th>MLA Train R2</th>\n",
       "      <th>MLA Test R2</th>\n",
       "      <th>MLA Test R2 Std</th>\n",
       "      <th>MLA Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nystroem Ridge</td>\n",
       "      <td>{'memory': None, 'steps': [('scaler', Standard...</td>\n",
       "      <td>0.845065</td>\n",
       "      <td>0.844951</td>\n",
       "      <td>0.002986</td>\n",
       "      <td>0 min 0.16 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>{'copy_X': True, 'fit_intercept': True, 'n_job...</td>\n",
       "      <td>0.845065</td>\n",
       "      <td>0.844951</td>\n",
       "      <td>0.002986</td>\n",
       "      <td>0 min 0.23 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR Pipeline</td>\n",
       "      <td>{'memory': None, 'steps': [('scaler', Standard...</td>\n",
       "      <td>0.845065</td>\n",
       "      <td>0.844951</td>\n",
       "      <td>0.002986</td>\n",
       "      <td>0 min 0.30 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoostRegressor</td>\n",
       "      <td>{'loss_function': 'RMSE', 'verbose': False, 'r...</td>\n",
       "      <td>0.858355</td>\n",
       "      <td>0.844612</td>\n",
       "      <td>0.002742</td>\n",
       "      <td>0 min 57.84 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>{'objective': 'reg:squarederror', 'base_score'...</td>\n",
       "      <td>0.837789</td>\n",
       "      <td>0.786725</td>\n",
       "      <td>0.003458</td>\n",
       "      <td>0 min 30.13 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>0.792662</td>\n",
       "      <td>0.760542</td>\n",
       "      <td>0.003247</td>\n",
       "      <td>0 min 3.84 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>{'categorical_features': None, 'early_stopping...</td>\n",
       "      <td>0.791109</td>\n",
       "      <td>0.760066</td>\n",
       "      <td>0.003578</td>\n",
       "      <td>0 min 5.60 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN</td>\n",
       "      <td>{'memory': None, 'steps': [('scaler', Standard...</td>\n",
       "      <td>0.662148</td>\n",
       "      <td>0.647916</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>0 min 0.14 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'criter...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.615353</td>\n",
       "      <td>0.003188</td>\n",
       "      <td>2 min 32.38 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...</td>\n",
       "      <td>0.945261</td>\n",
       "      <td>0.613513</td>\n",
       "      <td>0.003396</td>\n",
       "      <td>3 min 5.19 sec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        MLA Name  \\\n",
       "8                 Nystroem Ridge   \n",
       "3               LinearRegression   \n",
       "4                    LR Pipeline   \n",
       "0              CatBoostRegressor   \n",
       "9                   XGBRegressor   \n",
       "5                  LGBMRegressor   \n",
       "2  HistGradientBoostingRegressor   \n",
       "7                            KNN   \n",
       "1            ExtraTreesRegressor   \n",
       "6          RandomForestRegressor   \n",
       "\n",
       "                                      MLA Parameters  MLA Train R2  \\\n",
       "8  {'memory': None, 'steps': [('scaler', Standard...      0.845065   \n",
       "3  {'copy_X': True, 'fit_intercept': True, 'n_job...      0.845065   \n",
       "4  {'memory': None, 'steps': [('scaler', Standard...      0.845065   \n",
       "0  {'loss_function': 'RMSE', 'verbose': False, 'r...      0.858355   \n",
       "9  {'objective': 'reg:squarederror', 'base_score'...      0.837789   \n",
       "5  {'boosting_type': 'gbdt', 'class_weight': None...      0.792662   \n",
       "2  {'categorical_features': None, 'early_stopping...      0.791109   \n",
       "7  {'memory': None, 'steps': [('scaler', Standard...      0.662148   \n",
       "1  {'bootstrap': False, 'ccp_alpha': 0.0, 'criter...      1.000000   \n",
       "6  {'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...      0.945261   \n",
       "\n",
       "   MLA Test R2  MLA Test R2 Std         MLA Time  \n",
       "8     0.844951         0.002986   0 min 0.16 sec  \n",
       "3     0.844951         0.002986   0 min 0.23 sec  \n",
       "4     0.844951         0.002986   0 min 0.30 sec  \n",
       "0     0.844612         0.002742  0 min 57.84 sec  \n",
       "9     0.786725         0.003458  0 min 30.13 sec  \n",
       "5     0.760542         0.003247   0 min 3.84 sec  \n",
       "2     0.760066         0.003578   0 min 5.60 sec  \n",
       "7     0.647916         0.002896   0 min 0.14 sec  \n",
       "1     0.615353         0.003188  2 min 32.38 sec  \n",
       "6     0.613513         0.003396   3 min 5.19 sec  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "baseline_models = evaluate_models_cv(models, X, y, baseline_features, k10, f'{experiment_name}')\n",
    "baseline_models\n",
    "\n",
    "# Raw train Linear Regression score - 0.845309\n",
    "# Raw train Linear Regression 5CV score - 0.844941 (0.000751)\n",
    "# Raw train Linear Regression 10CV score - 0.844941 (0.000817) 32 seconds runtime\n",
    "# SSS train Linear Regression 10CV score - 0.844951 (0.002986) 2 seconds runtime\n",
    "\n",
    "# SSS DATA 10CV RESULTS (13 minutes total runtime)\n",
    "# Nystroem Ridge,0.844950,0.00298,0 min 0.16 sec\n",
    "# LinearRegression,0.844950,0.00298,0 min 0.23 sec\n",
    "# LR Pipeline,0.844950,0.00298,0 min 0.30 sec\n",
    "# CatBoostRegressor,0.844612,0.00274,0 min 57.84 sec\n",
    "# XGBRegressor,0.786724,0.00345,0 min 30.13 sec\n",
    "# LGBMRegressor,0.760541,0.00324,0 min 3.84 sec\n",
    "# HistGradientBoostingRegressor,0.760066,0.00357,0 min 5.60 sec\n",
    "# KNN,0.647916,0.00289,0 min 0.14 sec\n",
    "# ExtraTreesRegressor,0.615353,0.00318,2 min 32.38 sec\n",
    "# RandomForestRegressor,0.613513,0.00339,3 min 5.19 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Initialize empty dictionary for SFS features\n",
    "sfs_features = {}\n",
    "\n",
    "for model in models:\n",
    "    # set name\n",
    "    if hasattr(model, 'name'):\n",
    "        model_name = model.name\n",
    "    else:\n",
    "        model_name = model.__class__.__name__\n",
    "\n",
    "    try:\n",
    "        features = baseline_features[model_name]\n",
    "\n",
    "        # incase there is no feature that had importance, go to the next model\n",
    "        if len(features) == 0:\n",
    "            continue\n",
    "        \n",
    "        X_sfs = X[features]\n",
    "\n",
    "        print(f'Running backward feature selection with {model_name}')\n",
    "\n",
    "        sfs = SFS(model,\n",
    "            k_features='best',\n",
    "            forward=False,\n",
    "            floating=True,\n",
    "            scoring='r2',\n",
    "            verbose=2,\n",
    "            n_jobs=7,\n",
    "            cv=None)\n",
    "        \n",
    "        sfs = sfs.fit(X_sfs, y)\n",
    "\n",
    "        # Get the selected features index\n",
    "        selected_sfs_idx = list(sfs.k_feature_idx_)\n",
    "\n",
    "        # Get the feature names\n",
    "        selected_sfs_feats = X_sfs.columns[selected_sfs_idx]\n",
    "\n",
    "        selected_features = list(selected_sfs_feats)\n",
    "\n",
    "        # # Reorder selected_features based on the predefined features_list\n",
    "        # selected_features_ordered = [feat for feat in features_list if feat in selected_features]\n",
    "\n",
    "        sfs_features[model_name] = selected_features\n",
    "\n",
    "        print(f'Done with {model_name}', end='\\n\\n')\n",
    "\n",
    "    except KeyError:\n",
    "        print(f'{model_name} not in the dictionary.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sfs_features_lgbm.txt', mode='w') as f:\n",
    "    pprint(sfs_features, stream=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_features = {'CatBoostRegressor': ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors', 'Sum_All_w_Intercept', 'Sum_All', 'Sum_Special'],\n",
    "'ExtraTreesRegressor': ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors', 'Sum_All'],\n",
    "'HistGradientBoostingRegressor': ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors', 'Sum_All'],\n",
    "'LinearRegression': ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'InadequatePlanning', 'PoliticalFactors', 'Sum_All_w_Intercept', 'Sum_Special'],\n",
    "'LGBMRegressor': ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors', 'Sum_All'],\n",
    "'RandomForestRegressor': ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors', 'Sum_All_w_Intercept', 'Sum_All', 'Sum_Special'],\n",
    "'KNN': ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors', 'Sum_All_w_Intercept', 'Sum_All', 'Sum_Special'],\n",
    "'Nystroem Ridge': ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'InadequatePlanning', 'PoliticalFactors', 'Sum_All_w_Intercept', 'Sum_Special'],\n",
    "'XGBRegressor': ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors', 'Sum_All'],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "sfs_models = evaluate_models_cv(models, X, y, sfs_features, k3, f'{experiment_name}_sfs')\n",
    "sfs_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Single Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LinearRegression()\n",
    "# model = LGBMRegressor(random_state=5, n_jobs=-1)\n",
    "model = ExtraTreesRegressor(random_state=5)\n",
    "\n",
    "features = sfs_features['ExtraTreesRegressor']\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_big[train_big['Sum_All'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model.fit(train_big[features], train_big[TARGET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test[features])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(pred, columns=[TARGET])\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_df['FloodProbability_rounded'] = pred_df['FloodProbability'].apply(round_to_nearest_005)\n",
    "# pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission_df = pd.concat([submission['id'], pred_df], axis=1)\n",
    "submission_df.columns = ['id', 'FloodProbability']\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission_extrat_0.871479_3cv.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get Stacking score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "meta_scores = []\n",
    "\n",
    "for i, (train_idx, meta_idx) in enumerate(k5.split(X)):\n",
    "    print(f'Fold {i + 1}')\n",
    "    X_train, X_meta = X.iloc[train_idx], X.iloc[meta_idx]\n",
    "    y_train, y_meta = y.iloc[train_idx], y.iloc[meta_idx]\n",
    "\n",
    "    print(X_train.shape, X_meta.shape, y_train.shape, y_meta.shape)\n",
    "    meta_features_fold = np.zeros((X_meta.shape[0], len(models)))\n",
    "    # meta_test_features = np.zeros((y.shape[0], len(models)))\n",
    "    # meta_targets = np.zeros(y.shape[0])\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        model_name = model.__class__.__name__ if not hasattr(model, 'name') else model.name\n",
    "        print(f'Starting {model_name}')\n",
    "        model_features = sfs_features[model_name]\n",
    "        # model_features = baseline_features[model_name]\n",
    "\n",
    "        # Fit model on the selected features\n",
    "        model.fit(X_train[model_features], y_train)\n",
    "        preds = model.predict(X_meta[model_features])\n",
    "        meta_features_fold[:, i] = preds\n",
    "\n",
    "    # Train the meta-model on the predictions from the base models\n",
    "    meta_model.fit(meta_features_fold, y_meta)\n",
    "    \n",
    "    # Predict using the meta-model\n",
    "    final_preds = meta_model.predict(meta_features_fold)\n",
    "    \n",
    "    # Calculate r2_score for the current fold\n",
    "    current_fold_r2_score = r2_score(y_meta, final_preds)\n",
    "    meta_scores.append(current_fold_r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average RMSLE across all folds\n",
    "average_r2 = np.mean(meta_scores)\n",
    "average_r2\n",
    "\n",
    "# 0.843288\n",
    "\n",
    "# 0.84242 - Ridge stack\n",
    "# 0.845440748488788 - LR stack\n",
    "\n",
    "# 0.8768246026677646 - Features w/ LR stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get stacking submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Retrain base models on all data\n",
    "all_base_model_predictions = []\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__ if not hasattr(model, 'name') else model.name\n",
    "    print(f'Starting {model_name}')\n",
    "    model_features = sfs_features[model_name]\n",
    "\n",
    "    model.fit(X[model_features], y)\n",
    "    preds = model.predict(test[model_features])\n",
    "    all_base_model_predictions.append(preds.reshape(-1, 1))\n",
    "\n",
    "# Stack predictions for the meta model\n",
    "X_new_meta = np.hstack(all_base_model_predictions)\n",
    "\n",
    "# Use the meta model to make final predictions\n",
    "final_predictions = meta_model.predict(X_new_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__ if not hasattr(model, 'name') else model.name\n",
    "    model_names.append(model_name)\n",
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Ensemble weights')\n",
    "weights = pd.Series(meta_model.coef_, index=model_names)\n",
    "print(weights)\n",
    "print(f'Weights total: {weights.sum()}')\n",
    "print(f'Intercept: {meta_model.intercept_}', end='\\n\\n')\n",
    "print(f\"Average Stacking R2 across all folds: {average_r2:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions_df = pd.DataFrame(final_predictions, columns=[TARGET])\n",
    "final_predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission_df = pd.concat([submission['id'], final_predictions_df], axis=1)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission_lr_stacking_0.87682.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible features\n",
    "1. (Addition of all features * 0.0056) - 0.0533\n",
    "2. Addition of human activities - ['TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors']\n",
    "3. Addition of natural occurences - ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ofe = OpenFE()\n",
    "ofe.fit(\n",
    "    data=X,\n",
    "    label=y,\n",
    "    # n_data_blocks=2,\n",
    "    # feature_boosting=True,\n",
    "    task='regression',\n",
    "    # stage2_metric='permutation',\n",
    "    # metric='rmse', \n",
    "    n_jobs=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x = transform(X, test, ofe.new_features_list, n_jobs=4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_openfe_features = {}\n",
    "\n",
    "for model in models:\n",
    "    if hasattr(model, 'name'):\n",
    "        model_name = model.name\n",
    "    else:\n",
    "        model_name = model.__class__.__name__\n",
    "\n",
    "    baseline_openfe_features[model_name] = list(train_x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "baseline_openfe_models = evaluate_models_cv(models, X, y, baseline_openfe_features, k5, f'{experiment_name}_openfe')\n",
    "baseline_openfe_models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
