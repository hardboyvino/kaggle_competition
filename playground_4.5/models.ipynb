{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEPS\n",
    "\n",
    "~~ 1. Because the dataset is more than 1 million rows, run a train_test_split to get the R2 test score and get the LB result for the best model~~\n",
    "\n",
    "~~ 2. Get a smaller form of the dataset (about 150,000 rows) and get both a train_test_split and 5CV scores then get the LB results for the best model~~\n",
    "\n",
    "~~ 3. If there is no difference between 1 and 2 then perform SFS on the dataset from 2~~\n",
    "\n",
    "4. Stack the models using either LinearRegression or Ridge\n",
    "5. Hyperparameter tuning on each model 5 times\n",
    "6. Stack all the 54 models\n",
    "7. Perform feature engineering using OpenFE on the dataset from 2\n",
    "8. Perform feature selection using FFS in OpenFE on 7 for each model\n",
    "9. Hyperparameter tune each model from 8 5 times\n",
    "10. Stack all the 54 models from 9\n",
    "11. Stack all 108 models from 5 and 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "import numpy as np\n",
    "from openfe import OpenFE, tree_to_formula, transform, TwoStageFeatureSelector, ForwardFeatureSelector\n",
    "import os\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor, HistGradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "from sklearn.model_selection import cross_validate, KFold, train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "experiment_name = 'openfe_smaller_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_big = pd.read_csv('train.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "train.drop('id', axis=1, inplace=True)\n",
    "test.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1117957, 21), (745305, 20))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement',\n",
    "       'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality',\n",
    "       'Siltation', 'AgriculturalPractices', 'Encroachments',\n",
    "       'IneffectiveDisasterPreparedness', 'DrainageSystems',\n",
    "       'CoastalVulnerability', 'Landslides', 'Watersheds',\n",
    "       'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss',\n",
    "       'InadequatePlanning', 'PoliticalFactors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'FloodProbability'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111796, 1006161)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.1, random_state=5)\n",
    "\n",
    "# Get the indices for the validation set\n",
    "for _, test_indx in sss.split(train, train[TARGET]):\n",
    "    valid_train = train.iloc[test_indx]\n",
    "    train_train = train.drop(test_indx)\n",
    "\n",
    "len(valid_train), len(train_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_big['Sum_All_w_Intercept'] = (train_big[features_list].sum(axis=1) * 0.0056) - 0.0533\n",
    "# train['Sum_All_w_Intercept'] = (train[features_list].sum(axis=1) * 0.0056) - 0.0533\n",
    "# test['Sum_All_w_Intercept'] = (test[features_list].sum(axis=1) * 0.0056) - 0.0533\n",
    "\n",
    "# train_big['Sum_All'] = train_big[features_list].sum(axis=1)\n",
    "# train['Sum_All'] = train[features_list].sum(axis=1)\n",
    "# test['Sum_All'] = test[features_list].sum(axis=1)\n",
    "\n",
    "# train_big['Sum_Special'] = (train_big[features_list].sum(axis=1).isin(np.arange(72, 76))).astype(int)\n",
    "# train['Sum_Special'] = (train[features_list].sum(axis=1).isin(np.arange(72, 76))).astype(int)\n",
    "# test['Sum_Special'] = (test[features_list].sum(axis=1).isin(np.arange(72, 76))).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MonsoonIntensity</th>\n",
       "      <th>TopographyDrainage</th>\n",
       "      <th>RiverManagement</th>\n",
       "      <th>Deforestation</th>\n",
       "      <th>Urbanization</th>\n",
       "      <th>ClimateChange</th>\n",
       "      <th>DamsQuality</th>\n",
       "      <th>Siltation</th>\n",
       "      <th>AgriculturalPractices</th>\n",
       "      <th>Encroachments</th>\n",
       "      <th>IneffectiveDisasterPreparedness</th>\n",
       "      <th>DrainageSystems</th>\n",
       "      <th>CoastalVulnerability</th>\n",
       "      <th>Landslides</th>\n",
       "      <th>Watersheds</th>\n",
       "      <th>DeterioratingInfrastructure</th>\n",
       "      <th>PopulationScore</th>\n",
       "      <th>WetlandLoss</th>\n",
       "      <th>InadequatePlanning</th>\n",
       "      <th>PoliticalFactors</th>\n",
       "      <th>FloodProbability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90092</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933447</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845222</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MonsoonIntensity  TopographyDrainage  RiverManagement  Deforestation  \\\n",
       "90092                  4                   6                5              5   \n",
       "933447                 3                   5                9              8   \n",
       "845222                 6                   5                2              6   \n",
       "\n",
       "        Urbanization  ClimateChange  DamsQuality  Siltation  \\\n",
       "90092              5              3            9          3   \n",
       "933447             3              8            5          5   \n",
       "845222             6              8            2          7   \n",
       "\n",
       "        AgriculturalPractices  Encroachments  IneffectiveDisasterPreparedness  \\\n",
       "90092                       4              6                                4   \n",
       "933447                      9              5                                4   \n",
       "845222                      3              6                                2   \n",
       "\n",
       "        DrainageSystems  CoastalVulnerability  Landslides  Watersheds  \\\n",
       "90092                 4                     5           5           7   \n",
       "933447                9                     8           5           7   \n",
       "845222                6                     4           3           6   \n",
       "\n",
       "        DeterioratingInfrastructure  PopulationScore  WetlandLoss  \\\n",
       "90092                             8                4            4   \n",
       "933447                            5                4            5   \n",
       "845222                            2                1            4   \n",
       "\n",
       "        InadequatePlanning  PoliticalFactors  FloodProbability  \n",
       "90092                    3                 3             0.485  \n",
       "933447                   4                 5             0.590  \n",
       "845222                   3                 8             0.460  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MonsoonIntensity</th>\n",
       "      <th>TopographyDrainage</th>\n",
       "      <th>RiverManagement</th>\n",
       "      <th>Deforestation</th>\n",
       "      <th>Urbanization</th>\n",
       "      <th>ClimateChange</th>\n",
       "      <th>DamsQuality</th>\n",
       "      <th>Siltation</th>\n",
       "      <th>AgriculturalPractices</th>\n",
       "      <th>Encroachments</th>\n",
       "      <th>IneffectiveDisasterPreparedness</th>\n",
       "      <th>DrainageSystems</th>\n",
       "      <th>CoastalVulnerability</th>\n",
       "      <th>Landslides</th>\n",
       "      <th>Watersheds</th>\n",
       "      <th>DeterioratingInfrastructure</th>\n",
       "      <th>PopulationScore</th>\n",
       "      <th>WetlandLoss</th>\n",
       "      <th>InadequatePlanning</th>\n",
       "      <th>PoliticalFactors</th>\n",
       "      <th>FloodProbability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>728225</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014452</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547614</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MonsoonIntensity  TopographyDrainage  RiverManagement  Deforestation  \\\n",
       "728225                  6                   5                2              6   \n",
       "1014452                 8                   5                7              6   \n",
       "547614                  7                   5                7              9   \n",
       "\n",
       "         Urbanization  ClimateChange  DamsQuality  Siltation  \\\n",
       "728225              4              2            7          6   \n",
       "1014452             2              8            6          5   \n",
       "547614              7              7            4          4   \n",
       "\n",
       "         AgriculturalPractices  Encroachments  \\\n",
       "728225                       4              4   \n",
       "1014452                      4              4   \n",
       "547614                       3              3   \n",
       "\n",
       "         IneffectiveDisasterPreparedness  DrainageSystems  \\\n",
       "728225                                 3                5   \n",
       "1014452                                6                3   \n",
       "547614                                 6                5   \n",
       "\n",
       "         CoastalVulnerability  Landslides  Watersheds  \\\n",
       "728225                      3           8           5   \n",
       "1014452                     8           7           3   \n",
       "547614                      5           2           7   \n",
       "\n",
       "         DeterioratingInfrastructure  PopulationScore  WetlandLoss  \\\n",
       "728225                             6                2            4   \n",
       "1014452                            4                6            5   \n",
       "547614                             8                6            4   \n",
       "\n",
       "         InadequatePlanning  PoliticalFactors  FloodProbability  \n",
       "728225                    8                 6             0.500  \n",
       "1014452                   3                 5             0.535  \n",
       "547614                    3                 4             0.545  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_train.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FloodProbability\n",
      "0.490    3.874925\n",
      "0.495    3.783866\n",
      "0.520    3.691197\n",
      "0.485    3.681358\n",
      "0.505    3.678675\n",
      "           ...   \n",
      "0.700    0.002862\n",
      "0.725    0.002594\n",
      "0.715    0.002326\n",
      "0.710    0.002057\n",
      "0.285    0.001789\n",
      "Name: count, Length: 83, dtype: float64\n",
      "FloodProbability\n",
      "0.490    3.874927\n",
      "0.495    3.783887\n",
      "0.520    3.691159\n",
      "0.485    3.681319\n",
      "0.505    3.678636\n",
      "           ...   \n",
      "0.700    0.002882\n",
      "0.725    0.002584\n",
      "0.715    0.002286\n",
      "0.710    0.002087\n",
      "0.285    0.001789\n",
      "Name: count, Length: 83, dtype: float64\n",
      "FloodProbability\n",
      "0.490    3.874915\n",
      "0.495    3.783677\n",
      "0.520    3.691545\n",
      "0.485    3.681706\n",
      "0.505    3.679023\n",
      "           ...   \n",
      "0.725    0.002683\n",
      "0.715    0.002683\n",
      "0.700    0.002683\n",
      "0.710    0.001789\n",
      "0.285    0.001789\n",
      "Name: count, Length: 83, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_percentage_of_unique(df, target_variable):\n",
    "    value_counts = df[target_variable].value_counts()\n",
    "\n",
    "    total_count = len(df)\n",
    "\n",
    "    percentage = (value_counts / total_count) * 100\n",
    "\n",
    "    return percentage\n",
    "\n",
    "print(get_percentage_of_unique(train, TARGET)), print(get_percentage_of_unique(train_train, TARGET)), print(get_percentage_of_unique(valid_train, TARGET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = valid_train.drop([TARGET], axis=1)\n",
    "y = valid_train[TARGET]\n",
    "\n",
    "# n_splits = 10\n",
    "k3 = KFold(n_splits=3, shuffle=True, random_state=5)\n",
    "k5 = KFold(n_splits=5, shuffle=True, random_state=5)\n",
    "k10 = KFold(n_splits=10, shuffle=True, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define Models list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipelines\n",
    "knn_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsRegressor(n_neighbors=50))\n",
    "])\n",
    "\n",
    "ridge_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    # ('nystroem', Nystroem(n_components=500, random_state=5)),\n",
    "    ('ridge', Ridge())\n",
    "])\n",
    "\n",
    "linear_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ridge', LinearRegression()),\n",
    "])\n",
    "\n",
    "# Manually set pipeline names\n",
    "knn_pipeline.name = 'KNN'\n",
    "ridge_pipeline.name = 'Nystroem Ridge'\n",
    "linear_pipeline.name = 'LR Pipeline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    CatBoostRegressor(random_state=5, verbose=False, early_stopping_rounds=100),\n",
    "    ExtraTreesRegressor(random_state=5),\n",
    "    HistGradientBoostingRegressor(random_state=5),\n",
    "    LinearRegression(),\n",
    "    linear_pipeline,\n",
    "    LGBMRegressor(random_state=5, n_jobs=-1),\n",
    "    RandomForestRegressor(random_state=5),\n",
    "    knn_pipeline,\n",
    "    ridge_pipeline,\n",
    "    XGBRegressor(random_state=5),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create custom evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def round_to_nearest_005(x):\n",
    "#     return round(round(x / 0.005) * 0.005, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models_cv(models, X, y, important_features, cv_split, experiment_name):\n",
    "    MLA_compare = pd.DataFrame(columns=['MLA Name', \n",
    "                                        'MLA Parameters', \n",
    "                                        'MLA Train R2', \n",
    "                                        'MLA Test R2', \n",
    "                                        'MLA Test R2 Std', \n",
    "                                        'MLA Time'])\n",
    "    \n",
    "    def evaluate_model(alg, idx):\n",
    "        if hasattr(alg, 'name'):\n",
    "            MLA_name = alg.name\n",
    "        else:\n",
    "            MLA_name = alg.__class__.__name__\n",
    "        features = important_features.get(MLA_name, [])\n",
    "\n",
    "        # Check if the list of important features is empty\n",
    "        if len(features) == 0:\n",
    "            # If empty, return results with zero values\n",
    "            print(f'Skipping {MLA_name} due to no important features.')\n",
    "            return {\n",
    "                'MLA Name': MLA_name,\n",
    "                'MLA Parameters': str(alg.get_params()),\n",
    "                'MLA Train R2': 0,\n",
    "                'MLA Test R2': 0,\n",
    "                'MLA Test R2 Std': 0,\n",
    "                'MLA Time': \"0 min 0.00 sec\",\n",
    "            }\n",
    "        \n",
    "        cv_results = cross_validate(alg, \n",
    "                                    X[features], \n",
    "                                    y, cv=cv_split, \n",
    "                                    scoring='r2',\n",
    "                                    return_train_score=True, \n",
    "                                    n_jobs=-1)\n",
    "\n",
    "        # Time formatting\n",
    "        mean_fit_time = cv_results['fit_time'].mean()\n",
    "        minutes, seconds = divmod(mean_fit_time, 60)\n",
    "\n",
    "        # Results population\n",
    "        result = {\n",
    "            'MLA Name': MLA_name,\n",
    "            'MLA Parameters': str(alg.get_params()),\n",
    "            'MLA Train R2': cv_results['train_score'].mean(),\n",
    "            'MLA Test R2': cv_results['test_score'].mean(),\n",
    "            'MLA Test R2 Std': cv_results['test_score'].std(),\n",
    "            'MLA Time': f\"{int(minutes)} min {seconds:.2f} sec\",\n",
    "        }\n",
    "\n",
    "        print(f'Done with {MLA_name}.')\n",
    "        return result\n",
    "\n",
    "    results_list = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=50) as executor:\n",
    "        futures = [executor.submit(evaluate_model, alg, idx) for idx, alg in enumerate(tqdm(models, desc='Models'))]\n",
    "        for future in tqdm(futures, total=len(futures), desc='Progress'):\n",
    "            result = future.result()\n",
    "            results_list.append(result)\n",
    "\n",
    "    MLA_compare = pd.DataFrame(results_list)\n",
    "\n",
    "    MLA_compare.sort_values(by=['MLA Test R2'], ascending=False, inplace=True)\n",
    "    MLA_compare.to_csv(f'{experiment_name}_results.csv', index=False)\n",
    "\n",
    "    return MLA_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models_test_train(models, X, y, important_features, cv_split, experiment_name):\n",
    "    MLA_compare = pd.DataFrame(columns=['MLA Name', \n",
    "                                        'MLA Parameters', \n",
    "                                        'MLA Train R2', \n",
    "                                        'MLA Test R2', \n",
    "                                        'MLA Time'])\n",
    "    \n",
    "    def evaluate_model(alg, idx):\n",
    "        if hasattr(alg, 'name'):\n",
    "            MLA_name = alg.name\n",
    "        else:\n",
    "            MLA_name = alg.__class__.__name__\n",
    "\n",
    "        features = important_features.get(MLA_name, [])\n",
    "\n",
    "        # Check if the list of important features is empty\n",
    "        if len(features) == 0:\n",
    "            # If empty, return results with zero values\n",
    "            print(f'Skipping {MLA_name} due to no important features.')\n",
    "            return {\n",
    "                'MLA Name': MLA_name,\n",
    "                'MLA Parameters': str(alg.get_params()),\n",
    "                'MLA Train R2': 0,\n",
    "                'MLA Test R2': 0,\n",
    "                'MLA Time': \"0 min 0.00 sec\",\n",
    "            }\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X[features],\n",
    "                                                            y,\n",
    "                                                            test_size=0.1,\n",
    "                                                            stratify=y,\n",
    "                                                            shuffle=True,\n",
    "                                                            random_state=5)\n",
    "\n",
    "        start_time = time.time()\n",
    "        alg.fit(X_train, y_train)\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Evaluate the model\n",
    "        train_score = r2_score(y_train, alg.predict(X_train))\n",
    "        test_score = r2_score(y_test, alg.predict(X_test))\n",
    "\n",
    "        # Results population\n",
    "        result = {\n",
    "            'MLA Name': MLA_name,\n",
    "            'MLA Parameters': str(alg.get_params()),\n",
    "            'MLA Train R2': train_score,\n",
    "            'MLA Test R2': test_score,\n",
    "            'MLA Time': f'{(end_time - start_time) / 60:.2f} min',\n",
    "        }\n",
    "\n",
    "        print(f'Done with {MLA_name}.')\n",
    "        return result\n",
    "\n",
    "    results_list = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=50) as executor:\n",
    "        futures = [executor.submit(evaluate_model, alg, idx) for idx, alg in enumerate(tqdm(models, desc='Models'))]\n",
    "        for future in tqdm(futures, total=len(futures), desc='Progress'):\n",
    "            result = future.result()\n",
    "            results_list.append(result)\n",
    "\n",
    "    MLA_compare = pd.DataFrame(results_list)\n",
    "\n",
    "    MLA_compare.sort_values(by=['MLA Test R2'], ascending=False, inplace=True)\n",
    "    MLA_compare.to_csv(f'{experiment_name}_results.csv', index=False)\n",
    "\n",
    "    return MLA_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_features = {}\n",
    "\n",
    "for model in models:\n",
    "    if hasattr(model, 'name'):\n",
    "        model_name = model.name\n",
    "    else:\n",
    "        model_name = model.__class__.__name__\n",
    "\n",
    "    baseline_features[model_name] = list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "baseline_models = evaluate_models_cv(models, X, y, baseline_features, k10, f'{experiment_name}')\n",
    "baseline_models\n",
    "\n",
    "# Raw train Linear Regression score - 0.845309\n",
    "# Raw train Linear Regression 5CV score - 0.844941 (0.000751)\n",
    "# Raw train Linear Regression 10CV score - 0.844941 (0.000817) 32 seconds runtime\n",
    "# SSS train Linear Regression 10CV score - 0.844951 (0.002986) 2 seconds runtime\n",
    "\n",
    "# SSS DATA 10CV RESULTS (13 minutes total runtime)\n",
    "# Nystroem Ridge,0.844950,0.00298,0 min 0.16 sec\n",
    "# LinearRegression,0.844950,0.00298,0 min 0.23 sec\n",
    "# LR Pipeline,0.844950,0.00298,0 min 0.30 sec\n",
    "# CatBoostRegressor,0.844612,0.00274,0 min 57.84 sec\n",
    "# XGBRegressor,0.786724,0.00345,0 min 30.13 sec\n",
    "# LGBMRegressor,0.760541,0.00324,0 min 3.84 sec\n",
    "# HistGradientBoostingRegressor,0.760066,0.00357,0 min 5.60 sec\n",
    "# KNN,0.647916,0.00289,0 min 0.14 sec\n",
    "# ExtraTreesRegressor,0.615353,0.00318,2 min 32.38 sec\n",
    "# RandomForestRegressor,0.613513,0.00339,3 min 5.19 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111796, 21)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a random feature for X\n",
    "np.random.seed(5)\n",
    "X['random_control_feature'] = np.round(np.random.uniform(1, 20, X.shape[0]), 0)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MonsoonIntensity</th>\n",
       "      <th>TopographyDrainage</th>\n",
       "      <th>RiverManagement</th>\n",
       "      <th>Deforestation</th>\n",
       "      <th>Urbanization</th>\n",
       "      <th>ClimateChange</th>\n",
       "      <th>DamsQuality</th>\n",
       "      <th>Siltation</th>\n",
       "      <th>AgriculturalPractices</th>\n",
       "      <th>Encroachments</th>\n",
       "      <th>IneffectiveDisasterPreparedness</th>\n",
       "      <th>DrainageSystems</th>\n",
       "      <th>CoastalVulnerability</th>\n",
       "      <th>Landslides</th>\n",
       "      <th>Watersheds</th>\n",
       "      <th>DeterioratingInfrastructure</th>\n",
       "      <th>PopulationScore</th>\n",
       "      <th>WetlandLoss</th>\n",
       "      <th>InadequatePlanning</th>\n",
       "      <th>PoliticalFactors</th>\n",
       "      <th>random_control_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>578354</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881804</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262732</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MonsoonIntensity  TopographyDrainage  RiverManagement  Deforestation  \\\n",
       "578354                 5                   8                6              6   \n",
       "881804                 4                   5                5              6   \n",
       "262732                 5                   2                5              3   \n",
       "\n",
       "        Urbanization  ClimateChange  DamsQuality  Siltation  \\\n",
       "578354             3              1            4          3   \n",
       "881804             4              5            4          5   \n",
       "262732             7              2            2          6   \n",
       "\n",
       "        AgriculturalPractices  Encroachments  IneffectiveDisasterPreparedness  \\\n",
       "578354                      4              2                                6   \n",
       "881804                      4              5                                8   \n",
       "262732                      6              5                                6   \n",
       "\n",
       "        DrainageSystems  CoastalVulnerability  Landslides  Watersheds  \\\n",
       "578354                3                     5           5           8   \n",
       "881804                7                     5           8           6   \n",
       "262732               11                     3           4           2   \n",
       "\n",
       "        DeterioratingInfrastructure  PopulationScore  WetlandLoss  \\\n",
       "578354                            5                1            3   \n",
       "881804                            4                5            3   \n",
       "262732                            6                6            9   \n",
       "\n",
       "        InadequatePlanning  PoliticalFactors  random_control_feature  \n",
       "578354                   5                 3                     5.0  \n",
       "881804                   3                 4                     4.0  \n",
       "262732                   3                 3                     6.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with CatBoostRegressor\n",
      "Done with ExtraTreesRegressor\n",
      "HistGradientBoostingRegressor does not have feature_importances_\n",
      "LinearRegression does not have feature_importances_\n",
      "LR Pipeline does not have feature_importances_\n",
      "Done with LGBMRegressor\n",
      "Done with RandomForestRegressor\n",
      "KNN does not have feature_importances_\n",
      "Nystroem Ridge does not have feature_importances_\n",
      "Done with XGBRegressor\n"
     ]
    }
   ],
   "source": [
    "feat_importance_features = {}\n",
    "\n",
    "for model in models:\n",
    "    if hasattr(model, 'name'):\n",
    "        model_name = model.name\n",
    "    else:\n",
    "        model_name = model.__class__.__name__\n",
    "\n",
    "    try:\n",
    "        # Initialize array to store feature importances\n",
    "        feature_importances = np.zeros(X.shape[1])\n",
    "\n",
    "        # Loop through each fold and calculate the feature importances\n",
    "        for train_index, test_index in k3.split(X, y):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Get the feature importances and them to the total\n",
    "            feature_importances += model.feature_importances_\n",
    "\n",
    "        feature_importances /= 3\n",
    "\n",
    "        feature_importances_dict = dict(zip(X.columns, feature_importances))\n",
    "\n",
    "        df = pd.DataFrame.from_dict(feature_importances_dict, orient='index')\n",
    "\n",
    "        # Resetting index with a name for the column\n",
    "        df = df.reset_index().rename(columns={'index': 'Feature', 0: 'Avg_Feat_Importance'})\n",
    "        df.sort_values(by='Avg_Feat_Importance', ascending=False, inplace=True)\n",
    "\n",
    "        # Save to CSV\n",
    "        df.to_csv(f'{model_name}_feature_importances.csv')\n",
    "\n",
    "        fi_threshold = 0\n",
    "\n",
    "        fi_feats = df[df['Avg_Feat_Importance'] > fi_threshold]['Feature'].tolist()\n",
    "\n",
    "        feat_importance_features[model_name] = fi_feats\n",
    "        print(f'Done with {model_name}')\n",
    "\n",
    "    except AttributeError:\n",
    "        feat_importance_features[model_name] = list(X.columns)\n",
    "        print(f'{model_name} does not have feature_importances_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('featimp_features.txt', mode='w') as f:\n",
    "    pprint(feat_importance_features, stream=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Compared to a random control feature, for the models that do have feature_importances_ all the features are higher than zero and are more important than the random control feature*\n",
    "\n",
    "*runtime is 7 minutes for feature importances*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "perm_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=5)\n",
    "\n",
    "perm_importances = {model.__class__.__name__: [] for model in models}\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(perm_cv.split(X, y)):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    for model in models:\n",
    "        if hasattr(model, 'name'):\n",
    "            model_name = model.name\n",
    "        else:\n",
    "            model_name = model.__class__.__name__\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        # Calculate permutation importance\n",
    "        result = permutation_importance(model, X_test, y_test, n_repeats=3, random_state=5, n_jobs=-1, scoring='r2')\n",
    "        perm_importances[model_name].append(result.importances_mean)\n",
    "        print(f'Done with {model_name}.')\n",
    "    \n",
    "    print(f'Done with Fold {i+1}', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Average importances across folds and export to CSV\n",
    "for model_name, importances in perm_importances.items():\n",
    "    avg_importance = np.mean(importances, axis=0)\n",
    "    importance_df = pd.DataFrame({'Feature': df_reduced_spear.columns, 'Importance': avg_importance})\n",
    "    importance_df.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "    # Export to CSV\n",
    "    importance_df.to_csv(f'.\\permutation_importances\\{model_name}_permutation_importance.csv', index=False)\n",
    "\n",
    "print('Done with Permuation Importances', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'permutation_importances'\n",
    "\n",
    "# Initialize a dictionary for the features\n",
    "perm_important_features = {}\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    csv_path = os.path.join(directory, f'{model_name}_permutation_importance.csv')\n",
    "    if os.path.exists(csv_path):\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Check for 'random_control_feature' and its importance\n",
    "        if 'random_control_feature' in df['Feature'].values:\n",
    "            random_feature_importance = df.loc[df['Feature'] == 'random_control_feature', 'Importance'].iloc[0]\n",
    "        else:\n",
    "            random_feature_importance = 0\n",
    "\n",
    "        # Determine the threshold\n",
    "        threshold = max(0, random_feature_importance)\n",
    "\n",
    "        # Filter features where importance is greater than 0\n",
    "        important_feats_filtered = df[df['Importance'] > threshold]['Feature'].tolist()\n",
    "\n",
    "        # Reorder important_feats based on the predefined features_list\n",
    "        important_feats_ordered = [feat for feat in features_list if feat in important_feats_filtered]\n",
    "\n",
    "        # Add to importance dictionary\n",
    "        perm_important_features[model_name] = important_feats_ordered\n",
    "\n",
    "    else:\n",
    "        print(f'CSV file for {model_name} not found.')\n",
    "\n",
    "print('Done getting important features dictionary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop('random_control_feature', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Initialize empty dictionary for SFS features\n",
    "sfs_features = {}\n",
    "\n",
    "for model in models:\n",
    "    # set name\n",
    "    if hasattr(model, 'name'):\n",
    "        model_name = model.name\n",
    "    else:\n",
    "        model_name = model.__class__.__name__\n",
    "\n",
    "    try:\n",
    "        features = baseline_features[model_name]\n",
    "\n",
    "        # incase there is no feature that had importance, go to the next model\n",
    "        if len(features) == 0:\n",
    "            continue\n",
    "        \n",
    "        X_sfs = X[features]\n",
    "\n",
    "        print(f'Running backward feature selection with {model_name}')\n",
    "\n",
    "        sfs = SFS(model,\n",
    "            k_features='best',\n",
    "            forward=False,\n",
    "            floating=True,\n",
    "            scoring='r2',\n",
    "            verbose=2,\n",
    "            n_jobs=-1,\n",
    "            cv=None)\n",
    "        \n",
    "        sfs = sfs.fit(X_sfs, y)\n",
    "\n",
    "        # Get the selected features index\n",
    "        selected_sfs_idx = list(sfs.k_feature_idx_)\n",
    "\n",
    "        # Get the feature names\n",
    "        selected_sfs_feats = X_sfs.columns[selected_sfs_idx]\n",
    "\n",
    "        selected_features = list(selected_sfs_feats)\n",
    "\n",
    "        # # Reorder selected_features based on the predefined features_list\n",
    "        # selected_features_ordered = [feat for feat in features_list if feat in selected_features]\n",
    "\n",
    "        sfs_features[model_name] = selected_features\n",
    "\n",
    "        print(f'Done with {model_name}', end='\\n\\n')\n",
    "\n",
    "    except KeyError:\n",
    "        print(f'{model_name} not in the dictionary.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sfs_features_lgbm.txt', mode='w') as f:\n",
    "    pprint(sfs_features, stream=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_features = {'CatBoostRegressor': ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors', 'Sum_All_w_Intercept', 'Sum_All', 'Sum_Special'],\n",
    "'ExtraTreesRegressor': ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors', 'Sum_All'],\n",
    "'HistGradientBoostingRegressor': ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors', 'Sum_All'],\n",
    "'LinearRegression': ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'InadequatePlanning', 'PoliticalFactors', 'Sum_All_w_Intercept', 'Sum_Special'],\n",
    "'LGBMRegressor': ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors', 'Sum_All'],\n",
    "'RandomForestRegressor': ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors', 'Sum_All_w_Intercept', 'Sum_All', 'Sum_Special'],\n",
    "'KNN': ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors', 'Sum_All_w_Intercept', 'Sum_All', 'Sum_Special'],\n",
    "'Nystroem Ridge': ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'InadequatePlanning', 'PoliticalFactors', 'Sum_All_w_Intercept', 'Sum_Special'],\n",
    "'XGBRegressor': ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors', 'Sum_All'],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "sfs_models = evaluate_models_cv(models, X, y, sfs_features, k3, f'{experiment_name}_sfs')\n",
    "sfs_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Single Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LinearRegression()\n",
    "# model = LGBMRegressor(random_state=5, n_jobs=-1)\n",
    "model = ExtraTreesRegressor(random_state=5)\n",
    "\n",
    "features = sfs_features['ExtraTreesRegressor']\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_big[train_big['Sum_All'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model.fit(train_big[features], train_big[TARGET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test[features])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(pred, columns=[TARGET])\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_df['FloodProbability_rounded'] = pred_df['FloodProbability'].apply(round_to_nearest_005)\n",
    "# pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission_df = pd.concat([submission['id'], pred_df], axis=1)\n",
    "submission_df.columns = ['id', 'FloodProbability']\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission_extrat_0.871479_3cv.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get Stacking score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "meta_scores = []\n",
    "\n",
    "for i, (train_idx, meta_idx) in enumerate(k5.split(X)):\n",
    "    print(f'Fold {i + 1}')\n",
    "    X_train, X_meta = X.iloc[train_idx], X.iloc[meta_idx]\n",
    "    y_train, y_meta = y.iloc[train_idx], y.iloc[meta_idx]\n",
    "\n",
    "    print(X_train.shape, X_meta.shape, y_train.shape, y_meta.shape)\n",
    "    meta_features_fold = np.zeros((X_meta.shape[0], len(models)))\n",
    "    # meta_test_features = np.zeros((y.shape[0], len(models)))\n",
    "    # meta_targets = np.zeros(y.shape[0])\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        model_name = model.__class__.__name__ if not hasattr(model, 'name') else model.name\n",
    "        print(f'Starting {model_name}')\n",
    "        model_features = sfs_features[model_name]\n",
    "        # model_features = baseline_features[model_name]\n",
    "\n",
    "        # Fit model on the selected features\n",
    "        model.fit(X_train[model_features], y_train)\n",
    "        preds = model.predict(X_meta[model_features])\n",
    "        meta_features_fold[:, i] = preds\n",
    "\n",
    "    # Train the meta-model on the predictions from the base models\n",
    "    meta_model.fit(meta_features_fold, y_meta)\n",
    "    \n",
    "    # Predict using the meta-model\n",
    "    final_preds = meta_model.predict(meta_features_fold)\n",
    "    \n",
    "    # Calculate r2_score for the current fold\n",
    "    current_fold_r2_score = r2_score(y_meta, final_preds)\n",
    "    meta_scores.append(current_fold_r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average RMSLE across all folds\n",
    "average_r2 = np.mean(meta_scores)\n",
    "average_r2\n",
    "\n",
    "# 0.843288\n",
    "\n",
    "# 0.84242 - Ridge stack\n",
    "# 0.845440748488788 - LR stack\n",
    "\n",
    "# 0.8768246026677646 - Features w/ LR stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get stacking submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Retrain base models on all data\n",
    "all_base_model_predictions = []\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__ if not hasattr(model, 'name') else model.name\n",
    "    print(f'Starting {model_name}')\n",
    "    model_features = sfs_features[model_name]\n",
    "\n",
    "    model.fit(X[model_features], y)\n",
    "    preds = model.predict(test[model_features])\n",
    "    all_base_model_predictions.append(preds.reshape(-1, 1))\n",
    "\n",
    "# Stack predictions for the meta model\n",
    "X_new_meta = np.hstack(all_base_model_predictions)\n",
    "\n",
    "# Use the meta model to make final predictions\n",
    "final_predictions = meta_model.predict(X_new_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__ if not hasattr(model, 'name') else model.name\n",
    "    model_names.append(model_name)\n",
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Ensemble weights')\n",
    "weights = pd.Series(meta_model.coef_, index=model_names)\n",
    "print(weights)\n",
    "print(f'Weights total: {weights.sum()}')\n",
    "print(f'Intercept: {meta_model.intercept_}', end='\\n\\n')\n",
    "print(f\"Average Stacking R2 across all folds: {average_r2:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions_df = pd.DataFrame(final_predictions, columns=[TARGET])\n",
    "final_predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission_df = pd.concat([submission['id'], final_predictions_df], axis=1)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission_lr_stacking_0.87682.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible features\n",
    "1. (Addition of all features * 0.0056) - 0.0533\n",
    "2. Addition of human activities - ['TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors']\n",
    "3. Addition of natural occurences - ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality', 'Siltation', 'AgriculturalPractices', 'Encroachments', 'IneffectiveDisasterPreparedness', 'DrainageSystems', 'CoastalVulnerability', 'Landslides', 'Watersheds', 'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss', 'InadequatePlanning', 'PoliticalFactors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ofe = OpenFE()\n",
    "ofe.fit(\n",
    "    data=X,\n",
    "    label=y,\n",
    "    # n_data_blocks=2,\n",
    "    # feature_boosting=True,\n",
    "    task='regression',\n",
    "    # stage2_metric='permutation',\n",
    "    # metric='rmse', \n",
    "    n_jobs=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x = transform(X, test, ofe.new_features_list, n_jobs=4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_openfe_features = {}\n",
    "\n",
    "for model in models:\n",
    "    if hasattr(model, 'name'):\n",
    "        model_name = model.name\n",
    "    else:\n",
    "        model_name = model.__class__.__name__\n",
    "\n",
    "    baseline_openfe_features[model_name] = list(train_x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "baseline_openfe_models = evaluate_models_cv(models, X, y, baseline_openfe_features, k5, f'{experiment_name}_openfe')\n",
    "baseline_openfe_models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
