{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from itertools import combinations, permutations\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'gravity', 'ph', 'osmo', 'cond', 'urea', 'calc', 'target'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train and test columns for feature generation\n",
    "\n",
    "train_features = df_train.drop([\"id\", \"target\"], axis=1)\n",
    "test_features = df_test.drop(\"id\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_interactive_features(df, df_features):\n",
    "    \"\"\"\n",
    "    Generate interaction features between the given columns in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame containing the original features.\n",
    "    df_features : list\n",
    "        A list of feature names to be used for generating interaction features.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        The DataFrame with the interaction features added.\n",
    "    \"\"\"\n",
    "    # Get the list of features to create interaction terms\n",
    "    features = [col for col in df.columns if col in df_features]\n",
    "    new_features = []\n",
    "\n",
    "    # Iterate through the features and create interaction terms\n",
    "    for i in range(len(features)):\n",
    "        for j in range(i+1, len(features)):\n",
    "            # Generate a new feature name for the interaction term\n",
    "            new_feature_name = f\"{features[i]}_{features[j]}\"\n",
    "            \n",
    "            # Create the interaction feature by multiplying the values of the two original features\n",
    "            df[new_feature_name] = df[features[i]] * df[features[j]]\n",
    "            \n",
    "            # Add the new feature name to the list of new features\n",
    "            new_features.append(new_feature_name)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_domain_features(df, df_features):\n",
    "    \"\"\"\n",
    "    Generate domain-specific features as ratios between the given columns in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame containing the original features.\n",
    "    df_features : list\n",
    "        A list of feature names to be used for generating domain-specific features.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        The DataFrame with the domain-specific features added.\n",
    "    \"\"\"\n",
    "    # Get the list of features to create domain-specific features\n",
    "    features = [col for col in df.columns if col in df_features]\n",
    "    new_features = []\n",
    "\n",
    "    # Iterate through the features and create domain-specific features as ratios\n",
    "    for i in range(len(features)):\n",
    "        for j in range(len(features)):\n",
    "            # Check if the features are different\n",
    "            if i != j:\n",
    "                # Generate a new feature name for the domain-specific feature\n",
    "                new_feature_name = f\"{features[i]}_{features[j]}_ratio\"\n",
    "                \n",
    "                # Create the domain-specific feature by dividing the values of the two original features\n",
    "                # If the denominator is 0, use a small value (1e-6) to avoid division by zero\n",
    "                df[new_feature_name] = df[features[i]] / np.where(df[features[j]] == 0, 1e-6, df[features[j]])\n",
    "                \n",
    "                # Add the new feature name to the list of new features\n",
    "                new_features.append(new_feature_name)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_polynomial_features(df, degree, df_features):\n",
    "    \"\"\"\n",
    "    Generate polynomial features for the specified columns in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame containing the original features.\n",
    "    degree : int\n",
    "        The degree of the polynomial features to generate.\n",
    "    df_features : list\n",
    "        A list of feature names to be used for generating polynomial features.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        The DataFrame with the polynomial features added.\n",
    "    \"\"\"\n",
    "    # Get the list of features to create polynomial features\n",
    "    features = [col for col in df.columns if col in df_features]\n",
    "\n",
    "    # Create a PolynomialFeatures object with the specified degree, no interaction features, and no bias term\n",
    "    poly = PolynomialFeatures(degree, interaction_only=False, include_bias=False)\n",
    "\n",
    "    # Fit and transform the selected features in the DataFrame\n",
    "    poly_features = poly.fit_transform(df[features])\n",
    "\n",
    "    # Get the feature names for the generated polynomial features\n",
    "    poly_features_names = poly.get_feature_names_out(features)\n",
    "\n",
    "    # Create a new DataFrame with the generated polynomial features\n",
    "    poly_df = pd.DataFrame(poly_features, columns=poly_features_names)\n",
    "\n",
    "    # Keep only the columns with polynomial features of the specified degree\n",
    "    poly_df = poly_df[[f\"{col}^{degree}\" for col in features]]\n",
    "\n",
    "    # Concatenate the original DataFrame and the polynomial features DataFrame\n",
    "    result = pd.concat([df, poly_df], axis=1)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate additional features for the training dataset\n",
    "\n",
    "# Generate interactive features using the specified columns in 'train_features'\n",
    "df_train = generate_interactive_features(df_train, train_features)\n",
    "# Generate polynomial features of degree 2 using the specified columns in 'train_features'\n",
    "df_train = generate_polynomial_features(df_train, 2, train_features)\n",
    "# Generate polynomial features of degree 3 using the specified columns in 'train_features'\n",
    "df_train = generate_polynomial_features(df_train, 3, train_features)\n",
    "# Generate domain-specific features using the specified columns in 'train_features'\n",
    "df_train = generate_domain_features(df_train, train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate additional features for the test dataset\n",
    "\n",
    "# Generate interactive features using the specified columns in 'test_features'\n",
    "df_test = generate_interactive_features(df_test, test_features)\n",
    "# Generate polynomial features of degree 2 using the specified columns in 'test_features'\n",
    "df_test = generate_polynomial_features(df_test, 2, test_features)\n",
    "# Generate polynomial features of degree 3 using the specified columns in 'test_features'\n",
    "df_test = generate_polynomial_features(df_test, 3, test_features)\n",
    "# Generate domain-specific features using the specified columns in 'test_features'\n",
    "df_test = generate_domain_features(df_test, test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode using pd.get_dummies on train and test\n",
    "# Split back after encoding\n",
    "\n",
    "# Tag the data before combining\n",
    "df_train[\"dataset\"] = \"train\"\n",
    "df_test[\"dataset\"] = \"test\"\n",
    "\n",
    "# Combine train and test data\n",
    "df_combined = pd.concat([df_train, df_test], axis=0, ignore_index=True)\n",
    "\n",
    "# One-hot encode the combined data\n",
    "df_encoded = pd.get_dummies(df_combined, columns=[\"gravity\"])\n",
    "\n",
    "# Split the data back into train and test\n",
    "df_train = df_encoded[df_encoded[\"dataset\"] == \"train\"].drop([\"dataset\"], axis=1)\n",
    "df_test = df_encoded[df_encoded[\"dataset\"] == \"test\"].drop([\"dataset\", \"target\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target for train and validation data\n",
    "\n",
    "X_train = df_train.drop([\"id\", \"target\"], axis=1)\n",
    "y_train = df_train[\"target\"]\n",
    "\n",
    "X_test = df_test.drop([\"id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation and calculate the AUC ROC\n",
    "\n",
    "def evaluate_model(model, X, y, n_splits=5):\n",
    "    auc_roc_scores = []\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=5)\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cv, X_test_cv = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train_cv, y_test_cv = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        model.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "        # Predict probabilities for the test (keep only the probability of the positive class)\n",
    "        y_pred_proba_cv = model.predict_proba(X_test_cv)[:, 1]\n",
    "\n",
    "        auc_roc = roc_auc_score(y_test_cv, y_pred_proba_cv)\n",
    "        auc_roc_scores.append(auc_roc)\n",
    "    \n",
    "    return [round(value, 5) for value in auc_roc_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the models\n",
    "\n",
    "models = {\n",
    "    \"LightGBM\": lgb.LGBMClassifier(random_state=5),\n",
    "    \"xGBoost\": xgb.XGBClassifier(random_state=5),\n",
    "    \"CatBoost\": CatBoostClassifier(silent=True, random_state=5),\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=5),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LightGBM\n",
      "AUC ROC Scores: [0.7695, 0.80566, 0.74882, 0.82726, 0.70588]\n",
      "Average AUC ROC: 0.77142\n",
      "Std Deviation: 0.04266\n",
      "\n",
      "Model: xGBoost\n",
      "AUC ROC Scores: [0.74586, 0.78302, 0.74054, 0.80024, 0.65257]\n",
      "Average AUC ROC: 0.74445\n",
      "Std Deviation: 0.05111\n",
      "\n",
      "Model: CatBoost\n",
      "AUC ROC Scores: [0.77128, 0.78994, 0.72813, 0.82902, 0.74449]\n",
      "Average AUC ROC: 0.77257\n",
      "Std Deviation: 0.03536\n",
      "\n",
      "Model: RandomForest\n",
      "AUC ROC Scores: [0.78783, 0.81635, 0.71661, 0.82286, 0.75]\n",
      "Average AUC ROC: 0.77873\n",
      "Std Deviation: 0.04032\n",
      "\n",
      "Model: KNN\n",
      "AUC ROC Scores: [0.61082, 0.69245, 0.57979, 0.66246, 0.53523]\n",
      "Average AUC ROC: 0.61615\n",
      "Std Deviation: 0.05633\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    auc_roc_scores = evaluate_model(model, X_train, y_train)\n",
    "    mean_roc_auc = np.mean(auc_roc_scores)\n",
    "    std = np.std(auc_roc_scores)\n",
    "\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"AUC ROC Scores: {auc_roc_scores}\")\n",
    "    print(f\"Average AUC ROC: {mean_roc_auc:.5f}\")\n",
    "    print(f\"Std Deviation: {std:.5F}\")\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OBSERVATION FOR 5 SPLITS\n",
    "1. Baseline LightGBM is 0.77142 with Std Dev of 0.04266\n",
    "2. Baseline xGBoost is 0.74445 with Std Dev of 0.05111\n",
    "3. Baseline CatBoost is 0.77257 with Std Dev of 0.03536\n",
    "4. Baseline RandomForest is 0.77873 with Std Dev of 0.04032\n",
    "5. Baseline KNN is 0.61615 with Std Dev of 0.05633\n",
    "\n",
    "Run time ~ 46 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LightGBM\n",
      "AUC ROC Scores: [0.64583, 0.75231, 0.77222, 0.83765, 0.72381, 0.7275, 0.76961, 0.85, 0.68873, 0.73775]\n",
      "Average AUC ROC: 0.75054\n",
      "Std Deviation: 0.05875\n",
      "\n",
      "Model: xGBoost\n",
      "AUC ROC Scores: [0.59954, 0.78009, 0.77222, 0.82118, 0.75476, 0.7275, 0.7549, 0.85238, 0.71324, 0.73039]\n",
      "Average AUC ROC: 0.75062\n",
      "Std Deviation: 0.06471\n",
      "\n",
      "Model: CatBoost\n",
      "AUC ROC Scores: [0.65046, 0.83565, 0.76944, 0.85647, 0.7, 0.685, 0.80392, 0.87143, 0.75735, 0.79902]\n",
      "Average AUC ROC: 0.77287\n",
      "Std Deviation: 0.07111\n",
      "\n",
      "Model: RandomForest\n",
      "AUC ROC Scores: [0.61343, 0.875, 0.78889, 0.88235, 0.69762, 0.66, 0.84804, 0.86786, 0.7598, 0.76961]\n",
      "Average AUC ROC: 0.77626\n",
      "Std Deviation: 0.09013\n",
      "\n",
      "Model: KNN\n",
      "AUC ROC Scores: [0.51042, 0.6794, 0.63333, 0.79882, 0.64286, 0.54125, 0.7598, 0.7119, 0.48775, 0.61275]\n",
      "Average AUC ROC: 0.63783\n",
      "Std Deviation: 0.09837\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    auc_roc_scores = evaluate_model(model, X_train, y_train, n_splits=10)\n",
    "    mean_roc_auc = np.mean(auc_roc_scores)\n",
    "    std = np.std(auc_roc_scores)\n",
    "\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"AUC ROC Scores: {auc_roc_scores}\")\n",
    "    print(f\"Average AUC ROC: {mean_roc_auc:.5f}\")\n",
    "    print(f\"Std Deviation: {std:.5F}\")\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OBSERVATION FOR 10 SPLITS\n",
    "1. Baseline LightGBM is 0.75054 with Std Dev of 0.05875\n",
    "2. Baseline xGBoost is 0.75062 with Std Dev of 0.06471\n",
    "3. Baseline CatBoost is 0.77287 with Std Dev of 0.07111\n",
    "4. Baseline RandomForest is 0.77626 with Std Dev of 0.09013\n",
    "5. Baseline KNN is 0.63783 with Std Dev of 0.09837\n",
    "\n",
    "Run time ~ 2 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=5)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predit the final submission with Random Forest\n",
    "\n",
    "y_final = rf.predict_proba(X_test)[:, 1]\n",
    "df_test[\"target\"] = y_final.round(1)\n",
    "\n",
    "df_test[[\"id\", \"target\"]].to_csv(\"submissionrf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x2afe289c700>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = CatBoostClassifier(silent=True, random_state=5)\n",
    "cat.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the final submission with CatBoost\n",
    "\n",
    "y_final = cat.predict_proba(X_test)[:, 1]\n",
    "df_test[\"target\"] = y_final.round(1)\n",
    "\n",
    "df_test[[\"id\", \"target\"]].to_csv(\"submissioncat.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
