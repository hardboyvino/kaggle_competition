{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'clonesize', 'honeybee', 'bumbles', 'andrena', 'osmia',\n",
       "       'MaxOfUpperTRange', 'MinOfUpperTRange', 'AverageOfUpperTRange',\n",
       "       'MaxOfLowerTRange', 'MinOfLowerTRange', 'AverageOfLowerTRange',\n",
       "       'RainingDays', 'AverageRainingDays', 'fruitset', 'fruitmass', 'seeds',\n",
       "       'yield'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the train and test datasets\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target for train and validation data\n",
    "\n",
    "X_train = df_train.drop([\"id\", \"yield\"], axis=1)\n",
    "y_train = df_train[\"yield\"]\n",
    "\n",
    "X_test = df_test.drop([\"id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_drop = ['MinOfUpperTRange', 'AverageOfUpperTRange', 'MaxOfLowerTRange', 'MinOfLowerTRange', 'AverageOfLowerTRange','AverageRainingDays']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the columns that are perfectly correlated with each other from train and test\n",
    "\n",
    "X_train = X_train.drop(column_to_drop, axis=1)\n",
    "X_test = X_test.drop(column_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y, n_splits=5):\n",
    "    \"\"\"\n",
    "    Evaluates the given model using cross-validation and calculates the Mean Absolute Errors.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    model (estimator object): The model to be evaluated.\n",
    "    X (DataFrame): The feature matrix.\n",
    "    y (Series): The target variable.\n",
    "    selected_features (Index): The selected feature names.\n",
    "    n_splits (int): The number of folds for cross-validation.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    mae_scores (list): A list of MAE for each fold.\n",
    "    \"\"\"\n",
    "    # Initialize a list to store the MAE\n",
    "    mae_scores = []\n",
    "\n",
    "    # Create a KFold object for cross-validation\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=5)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        # Split the data into train and test sets for the current fold\n",
    "        X_train_cv, X_test_cv = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train_cv, y_test_cv = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Train the model on the training data\n",
    "        model.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "        # Predict probabilities for the test (keep only the probability of the positive class)\n",
    "        y_pred = model.predict(X_test_cv)\n",
    "\n",
    "        # Calculate the MAE for the current fold\n",
    "        mae = mean_absolute_error(y_test_cv, y_pred)\n",
    "        mae_scores.append(mae)\n",
    "\n",
    "    # Return the MAE, rounded to 5 decimal places\n",
    "    return [round(value, 3) for value in mae_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the models\n",
    "\n",
    "models = {\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"LightGBM\": lgb.LGBMRegressor(random_state=5),\n",
    "    \"RandomForest\": RandomForestRegressor(random_state=5),\n",
    "    \"CatBoost\": CatBoostRegressor(silent=True, random_seed=5),\n",
    "    # \"SVR\": SVR(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Lasso\n",
      "Selected features: Index(['bumbles', 'andrena', 'osmia', 'MaxOfUpperTRange', 'RainingDays',\n",
      "       'fruitset', 'seeds'],\n",
      "      dtype='object')\n",
      "MAE Scores: [379.78, 388.323, 381.612, 375.99, 371.867]\n",
      "Average MAE: 379.514\n",
      "Std Deviation: 5.531\n",
      "\n",
      "Model: LightGBM\n",
      "Selected features: Index(['clonesize', 'honeybee', 'bumbles', 'andrena', 'osmia',\n",
      "       'MaxOfUpperTRange', 'RainingDays', 'fruitset', 'fruitmass', 'seeds'],\n",
      "      dtype='object')\n",
      "MAE Scores: [350.629, 364.375, 354.089, 354.86, 349.107]\n",
      "Average MAE: 354.612\n",
      "Std Deviation: 5.326\n",
      "\n",
      "Model: RandomForest\n",
      "Selected features: Index(['clonesize', 'honeybee', 'bumbles', 'andrena', 'MaxOfUpperTRange',\n",
      "       'RainingDays', 'fruitset', 'fruitmass', 'seeds'],\n",
      "      dtype='object')\n",
      "MAE Scores: [363.8, 374.241, 367.995, 370.352, 366.828]\n",
      "Average MAE: 368.643\n",
      "Std Deviation: 3.505\n",
      "\n",
      "Model: CatBoost\n",
      "Selected features: Index(['honeybee', 'MaxOfUpperTRange', 'fruitset', 'seeds'], dtype='object')\n",
      "MAE Scores: [354.261, 367.668, 356.221, 355.998, 352.664]\n",
      "Average MAE: 357.362\n",
      "Std Deviation: 5.312\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate each model using the best subset of features\n",
    "for name, model in models.items():\n",
    "    \"\"\"\n",
    "    Loops through each model, and evaluates the model using cross-validation. \n",
    "    Prints the MAE scores, average MAE, and standard deviation\n",
    "    for each model.\n",
    "    \"\"\"\n",
    "    #Initialize SFS with the current model\n",
    "    sfs = SFS(model,\n",
    "              k_features=\"best\",\n",
    "              forward=True,\n",
    "              floating=False,\n",
    "              scoring=\"neg_mean_absolute_error\",\n",
    "              cv=3,\n",
    "              n_jobs=-1)\n",
    "    \n",
    "    # Perform SFS on the training data\n",
    "    sfs = sfs.fit(X_train, y_train)\n",
    "\n",
    "    # Get the selected features\n",
    "    selected_features = X_train.columns[list(sfs.k_feature_idx_)]\n",
    "\n",
    "    #Print the results for the current model\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Selected features: {selected_features}\")\n",
    "\n",
    "    # Evaluate the model using cross-validation with the selected features\n",
    "    mae_scores = evaluate_model(model, X_train[selected_features], y_train)\n",
    "    mean_mae = np.mean(mae_scores)\n",
    "    std = np.std(mae_scores)\n",
    "\n",
    "    # Train the model on the training set\n",
    "    model.fit(X_train[selected_features], y_train)\n",
    "\n",
    "    # Predict for the test set\n",
    "    y_test_pred = model.predict(X_test[selected_features])\n",
    "\n",
    "    df_test[\"yield\"] = y_test_pred.round(3)\n",
    "\n",
    "    # Save the output DataFrame to a CSV file\n",
    "    df_test[[\"id\", \"yield\"]].to_csv(f\"submission_{name}.csv\", index=False)\n",
    "\n",
    "    # Print the results for the current model\n",
    "    # print(f\"Model: {name}\")\n",
    "    print(f\"MAE Scores: {mae_scores}\")\n",
    "    print(f\"Average MAE: {mean_mae:.3f}\")\n",
    "    print(f\"Std Deviation: {std:.3f}\")\n",
    "\n",
    "    # try:\n",
    "    #     plt.figure(figsize=(10, 7))\n",
    "    #     plt.plot(model.feature_importances_, label=name)\n",
    "    #     plt.xticks(np.arange(X_train.shape[1]), X_train.columns.tolist(), rotation=90)\n",
    "    #     plt.legend()\n",
    "    \n",
    "    # except AttributeError: # Incase the model does not have \"feature_importances_\"\n",
    "    #     pass\n",
    "\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE\n",
    "Took 15 minutes for code to run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
