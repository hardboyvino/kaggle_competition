{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adeniyi Babalola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dask\\dataframe\\_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder, MinMaxScaler, RobustScaler, QuantileTransformer, MaxAbsScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.metrics import make_scorer, log_loss\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.feature_selection import RFECV, mutual_info_regression\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "experiment_name = 'baseline'\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>N_Days</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ascites</th>\n",
       "      <th>Hepatomegaly</th>\n",
       "      <th>Spiders</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Copper</th>\n",
       "      <th>Alk_Phos</th>\n",
       "      <th>SGOT</th>\n",
       "      <th>Tryglicerides</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Prothrombin</th>\n",
       "      <th>Stage</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>D-penicillamine</td>\n",
       "      <td>21532</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>2.3</td>\n",
       "      <td>316.0</td>\n",
       "      <td>3.35</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1601.0</td>\n",
       "      <td>179.80</td>\n",
       "      <td>63.0</td>\n",
       "      <td>394.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2574</td>\n",
       "      <td>Placebo</td>\n",
       "      <td>19237</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.9</td>\n",
       "      <td>364.0</td>\n",
       "      <td>3.54</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>134.85</td>\n",
       "      <td>88.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3428</td>\n",
       "      <td>Placebo</td>\n",
       "      <td>13727</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>3.3</td>\n",
       "      <td>299.0</td>\n",
       "      <td>3.55</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>119.35</td>\n",
       "      <td>50.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  N_Days             Drug    Age Sex Ascites Hepatomegaly Spiders Edema  \\\n",
       "0   0     999  D-penicillamine  21532   M       N            N       N     N   \n",
       "1   1    2574          Placebo  19237   F       N            N       N     N   \n",
       "2   2    3428          Placebo  13727   F       N            Y       Y     Y   \n",
       "\n",
       "   Bilirubin  Cholesterol  Albumin  Copper  Alk_Phos    SGOT  Tryglicerides  \\\n",
       "0        2.3        316.0     3.35   172.0    1601.0  179.80           63.0   \n",
       "1        0.9        364.0     3.54    63.0    1440.0  134.85           88.0   \n",
       "2        3.3        299.0     3.55   131.0    1029.0  119.35           50.0   \n",
       "\n",
       "   Platelets  Prothrombin  Stage Status  \n",
       "0      394.0          9.7    3.0      D  \n",
       "1      361.0         11.0    3.0      C  \n",
       "2      199.0         11.7    4.0      D  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(r'.\\train.csv')\n",
    "test = pd.read_csv(r'.\\test.csv')\n",
    "\n",
    "# original = pd.read_csv(r'.\\validation_data.csv')\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'Status'\n",
    "binary_cols = ['Ascites', 'Hepatomegaly', 'Spiders']\n",
    "categorical_cols = ['Drug', 'Sex', 'Stage', 'Edema']\n",
    "drop_cols = ['id', TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['N_Days', 'Age', 'Bilirubin', 'Cholesterol', 'Albumin', 'Copper',\n",
       "       'Alk_Phos', 'SGOT', 'Tryglicerides', 'Platelets', 'Prothrombin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_cols = train.drop(categorical_cols + binary_cols + drop_cols, axis=1).select_dtypes(include=np.number).columns\n",
    "numerical_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ascites_Y</th>\n",
       "      <th>Hepatomegaly_Y</th>\n",
       "      <th>Spiders_Y</th>\n",
       "      <th>Drug_D-penicillamine</th>\n",
       "      <th>Drug_Placebo</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_M</th>\n",
       "      <th>Stage_1.0</th>\n",
       "      <th>Stage_2.0</th>\n",
       "      <th>Stage_3.0</th>\n",
       "      <th>Stage_4.0</th>\n",
       "      <th>Edema_N</th>\n",
       "      <th>Edema_S</th>\n",
       "      <th>Edema_Y</th>\n",
       "      <th>N_Days</th>\n",
       "      <th>Age</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Copper</th>\n",
       "      <th>Alk_Phos</th>\n",
       "      <th>SGOT</th>\n",
       "      <th>Tryglicerides</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Prothrombin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>21532.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>316.0</td>\n",
       "      <td>3.35</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1601.0</td>\n",
       "      <td>179.80</td>\n",
       "      <td>63.0</td>\n",
       "      <td>394.0</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2574.0</td>\n",
       "      <td>19237.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>364.0</td>\n",
       "      <td>3.54</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>134.85</td>\n",
       "      <td>88.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3428.0</td>\n",
       "      <td>13727.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>299.0</td>\n",
       "      <td>3.55</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>119.35</td>\n",
       "      <td>50.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2576.0</td>\n",
       "      <td>18460.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>256.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1653.0</td>\n",
       "      <td>71.30</td>\n",
       "      <td>96.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>788.0</td>\n",
       "      <td>16658.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>346.0</td>\n",
       "      <td>3.65</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>125.55</td>\n",
       "      <td>96.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ascites_Y  Hepatomegaly_Y  Spiders_Y  Drug_D-penicillamine  Drug_Placebo  \\\n",
       "0        0.0             0.0        0.0                   1.0           0.0   \n",
       "1        0.0             0.0        0.0                   0.0           1.0   \n",
       "2        0.0             1.0        1.0                   0.0           1.0   \n",
       "3        0.0             0.0        0.0                   0.0           1.0   \n",
       "4        0.0             1.0        0.0                   0.0           1.0   \n",
       "\n",
       "   Sex_F  Sex_M  Stage_1.0  Stage_2.0  Stage_3.0  Stage_4.0  Edema_N  Edema_S  \\\n",
       "0    0.0    1.0        0.0        0.0        1.0        0.0      1.0      0.0   \n",
       "1    1.0    0.0        0.0        0.0        1.0        0.0      1.0      0.0   \n",
       "2    1.0    0.0        0.0        0.0        0.0        1.0      0.0      0.0   \n",
       "3    1.0    0.0        0.0        0.0        1.0        0.0      1.0      0.0   \n",
       "4    1.0    0.0        0.0        0.0        0.0        1.0      1.0      0.0   \n",
       "\n",
       "   Edema_Y  N_Days      Age  Bilirubin  Cholesterol  Albumin  Copper  \\\n",
       "0      0.0   999.0  21532.0        2.3        316.0     3.35   172.0   \n",
       "1      0.0  2574.0  19237.0        0.9        364.0     3.54    63.0   \n",
       "2      1.0  3428.0  13727.0        3.3        299.0     3.55   131.0   \n",
       "3      0.0  2576.0  18460.0        0.6        256.0     3.50    58.0   \n",
       "4      0.0   788.0  16658.0        1.1        346.0     3.65    63.0   \n",
       "\n",
       "   Alk_Phos    SGOT  Tryglicerides  Platelets  Prothrombin  \n",
       "0    1601.0  179.80           63.0      394.0          9.7  \n",
       "1    1440.0  134.85           88.0      361.0         11.0  \n",
       "2    1029.0  119.35           50.0      199.0         11.7  \n",
       "3    1653.0   71.30           96.0      269.0         10.7  \n",
       "4    1181.0  125.55           96.0      298.0         10.6  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = make_column_transformer(\n",
    "    (OneHotEncoder(sparse=False, handle_unknown='infrequent_if_exist', drop='if_binary'), binary_cols),\n",
    "    (OneHotEncoder(sparse=False, handle_unknown='infrequent_if_exist'), categorical_cols),\n",
    "    remainder='passthrough')\n",
    "\n",
    "df_to_ohe = train.drop(drop_cols, axis=1)\n",
    "test = test.drop('id', axis=1)\n",
    "\n",
    "transformed = transformer.fit_transform(df_to_ohe)\n",
    "\n",
    "# Get the transformed feature names\n",
    "transformed_feat_names = [name.split('__')[-1] for name in transformer.get_feature_names_out()]\n",
    "\n",
    "# Create DataFrame of the transformed features\n",
    "df_to_ohe_transformed = pd.DataFrame(transformed, columns=transformed_feat_names)\n",
    "df_to_ohe_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ascites_Y</th>\n",
       "      <th>Hepatomegaly_Y</th>\n",
       "      <th>Spiders_Y</th>\n",
       "      <th>Drug_D-penicillamine</th>\n",
       "      <th>Drug_Placebo</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_M</th>\n",
       "      <th>Stage_1.0</th>\n",
       "      <th>Stage_2.0</th>\n",
       "      <th>Stage_3.0</th>\n",
       "      <th>Stage_4.0</th>\n",
       "      <th>Edema_N</th>\n",
       "      <th>Edema_S</th>\n",
       "      <th>Edema_Y</th>\n",
       "      <th>N_Days</th>\n",
       "      <th>Age</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Copper</th>\n",
       "      <th>Alk_Phos</th>\n",
       "      <th>SGOT</th>\n",
       "      <th>Tryglicerides</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Prothrombin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3839.0</td>\n",
       "      <td>19724.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>546.0</td>\n",
       "      <td>3.37</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1636.0</td>\n",
       "      <td>151.90</td>\n",
       "      <td>90.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2468.0</td>\n",
       "      <td>14975.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>4.22</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1257.0</td>\n",
       "      <td>151.90</td>\n",
       "      <td>155.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>13149.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>2.96</td>\n",
       "      <td>46.0</td>\n",
       "      <td>961.0</td>\n",
       "      <td>69.75</td>\n",
       "      <td>101.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ascites_Y  Hepatomegaly_Y  Spiders_Y  Drug_D-penicillamine  Drug_Placebo  \\\n",
       "0        0.0             1.0        0.0                   1.0           0.0   \n",
       "1        0.0             0.0        0.0                   1.0           0.0   \n",
       "2        0.0             1.0        0.0                   0.0           1.0   \n",
       "\n",
       "   Sex_F  Sex_M  Stage_1.0  Stage_2.0  Stage_3.0  Stage_4.0  Edema_N  Edema_S  \\\n",
       "0    1.0    0.0        0.0        1.0        0.0        0.0      1.0      0.0   \n",
       "1    1.0    0.0        0.0        1.0        0.0        0.0      1.0      0.0   \n",
       "2    1.0    0.0        0.0        0.0        0.0        1.0      0.0      0.0   \n",
       "\n",
       "   Edema_Y  N_Days      Age  Bilirubin  Cholesterol  Albumin  Copper  \\\n",
       "0      0.0  3839.0  19724.0        1.2        546.0     3.37    65.0   \n",
       "1      0.0  2468.0  14975.0        1.1        660.0     4.22    94.0   \n",
       "2      1.0    51.0  13149.0        2.0        151.0     2.96    46.0   \n",
       "\n",
       "   Alk_Phos    SGOT  Tryglicerides  Platelets  Prothrombin  \n",
       "0    1636.0  151.90           90.0      430.0         10.6  \n",
       "1    1257.0  151.90          155.0      227.0         10.0  \n",
       "2     961.0   69.75          101.0      213.0         13.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_new_data = transformer.transform(test)\n",
    "\n",
    "# # Get the transformed feature names\n",
    "# transformed_feat_names = [name.split('__')[-1] for name in transformer.get_feature_names_out()]\n",
    "\n",
    "# Create DataFrame of the transformed features\n",
    "test_transformed = pd.DataFrame(transformed_new_data, columns=transformed_feat_names)\n",
    "test_transformed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ascites_Y</th>\n",
       "      <th>Hepatomegaly_Y</th>\n",
       "      <th>Spiders_Y</th>\n",
       "      <th>Drug_D-penicillamine</th>\n",
       "      <th>Drug_Placebo</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_M</th>\n",
       "      <th>Stage_1.0</th>\n",
       "      <th>Stage_2.0</th>\n",
       "      <th>Stage_3.0</th>\n",
       "      <th>Stage_4.0</th>\n",
       "      <th>Edema_N</th>\n",
       "      <th>Edema_S</th>\n",
       "      <th>Edema_Y</th>\n",
       "      <th>N_Days</th>\n",
       "      <th>Age</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Copper</th>\n",
       "      <th>Alk_Phos</th>\n",
       "      <th>SGOT</th>\n",
       "      <th>Tryglicerides</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Prothrombin</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>21532.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>316.0</td>\n",
       "      <td>3.35</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1601.0</td>\n",
       "      <td>179.80</td>\n",
       "      <td>63.0</td>\n",
       "      <td>394.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2574.0</td>\n",
       "      <td>19237.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>364.0</td>\n",
       "      <td>3.54</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>134.85</td>\n",
       "      <td>88.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3428.0</td>\n",
       "      <td>13727.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>299.0</td>\n",
       "      <td>3.55</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>119.35</td>\n",
       "      <td>50.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2576.0</td>\n",
       "      <td>18460.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>256.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1653.0</td>\n",
       "      <td>71.30</td>\n",
       "      <td>96.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>788.0</td>\n",
       "      <td>16658.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>346.0</td>\n",
       "      <td>3.65</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>125.55</td>\n",
       "      <td>96.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ascites_Y  Hepatomegaly_Y  Spiders_Y  Drug_D-penicillamine  Drug_Placebo  \\\n",
       "0        0.0             0.0        0.0                   1.0           0.0   \n",
       "1        0.0             0.0        0.0                   0.0           1.0   \n",
       "2        0.0             1.0        1.0                   0.0           1.0   \n",
       "3        0.0             0.0        0.0                   0.0           1.0   \n",
       "4        0.0             1.0        0.0                   0.0           1.0   \n",
       "\n",
       "   Sex_F  Sex_M  Stage_1.0  Stage_2.0  Stage_3.0  Stage_4.0  Edema_N  Edema_S  \\\n",
       "0    0.0    1.0        0.0        0.0        1.0        0.0      1.0      0.0   \n",
       "1    1.0    0.0        0.0        0.0        1.0        0.0      1.0      0.0   \n",
       "2    1.0    0.0        0.0        0.0        0.0        1.0      0.0      0.0   \n",
       "3    1.0    0.0        0.0        0.0        1.0        0.0      1.0      0.0   \n",
       "4    1.0    0.0        0.0        0.0        0.0        1.0      1.0      0.0   \n",
       "\n",
       "   Edema_Y  N_Days      Age  Bilirubin  Cholesterol  Albumin  Copper  \\\n",
       "0      0.0   999.0  21532.0        2.3        316.0     3.35   172.0   \n",
       "1      0.0  2574.0  19237.0        0.9        364.0     3.54    63.0   \n",
       "2      1.0  3428.0  13727.0        3.3        299.0     3.55   131.0   \n",
       "3      0.0  2576.0  18460.0        0.6        256.0     3.50    58.0   \n",
       "4      0.0   788.0  16658.0        1.1        346.0     3.65    63.0   \n",
       "\n",
       "   Alk_Phos    SGOT  Tryglicerides  Platelets  Prothrombin  Status  \n",
       "0    1601.0  179.80           63.0      394.0          9.7       2  \n",
       "1    1440.0  134.85           88.0      361.0         11.0       0  \n",
       "2    1029.0  119.35           50.0      199.0         11.7       2  \n",
       "3    1653.0   71.30           96.0      269.0         10.7       0  \n",
       "4    1181.0  125.55           96.0      298.0         10.6       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoder.fit(train[TARGET])\n",
    "\n",
    "df_to_ohe_transformed[TARGET] = label_encoder.transform(train[TARGET])\n",
    "\n",
    "df_to_ohe_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ascites_Y</th>\n",
       "      <th>Hepatomegaly_Y</th>\n",
       "      <th>Spiders_Y</th>\n",
       "      <th>Drug_D-penicillamine</th>\n",
       "      <th>Drug_Placebo</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_M</th>\n",
       "      <th>Stage_1.0</th>\n",
       "      <th>Stage_2.0</th>\n",
       "      <th>Stage_3.0</th>\n",
       "      <th>Stage_4.0</th>\n",
       "      <th>Edema_N</th>\n",
       "      <th>Edema_S</th>\n",
       "      <th>Edema_Y</th>\n",
       "      <th>N_Days</th>\n",
       "      <th>Age</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Copper</th>\n",
       "      <th>Alk_Phos</th>\n",
       "      <th>SGOT</th>\n",
       "      <th>Tryglicerides</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Prothrombin</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>21532.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>316.0</td>\n",
       "      <td>3.35</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1601.0</td>\n",
       "      <td>179.80</td>\n",
       "      <td>63.0</td>\n",
       "      <td>394.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2574.0</td>\n",
       "      <td>19237.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>364.0</td>\n",
       "      <td>3.54</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>134.85</td>\n",
       "      <td>88.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3428.0</td>\n",
       "      <td>13727.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>299.0</td>\n",
       "      <td>3.55</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>119.35</td>\n",
       "      <td>50.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2576.0</td>\n",
       "      <td>18460.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>256.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1653.0</td>\n",
       "      <td>71.30</td>\n",
       "      <td>96.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>788.0</td>\n",
       "      <td>16658.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>346.0</td>\n",
       "      <td>3.65</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>125.55</td>\n",
       "      <td>96.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ascites_Y  Hepatomegaly_Y  Spiders_Y  Drug_D-penicillamine  Drug_Placebo  \\\n",
       "0        0.0             0.0        0.0                   1.0           0.0   \n",
       "1        0.0             0.0        0.0                   0.0           1.0   \n",
       "2        0.0             1.0        1.0                   0.0           1.0   \n",
       "3        0.0             0.0        0.0                   0.0           1.0   \n",
       "4        0.0             1.0        0.0                   0.0           1.0   \n",
       "\n",
       "   Sex_F  Sex_M  Stage_1.0  Stage_2.0  Stage_3.0  Stage_4.0  Edema_N  Edema_S  \\\n",
       "0    0.0    1.0        0.0        0.0        1.0        0.0      1.0      0.0   \n",
       "1    1.0    0.0        0.0        0.0        1.0        0.0      1.0      0.0   \n",
       "2    1.0    0.0        0.0        0.0        0.0        1.0      0.0      0.0   \n",
       "3    1.0    0.0        0.0        0.0        1.0        0.0      1.0      0.0   \n",
       "4    1.0    0.0        0.0        0.0        0.0        1.0      1.0      0.0   \n",
       "\n",
       "   Edema_Y  N_Days      Age  Bilirubin  Cholesterol  Albumin  Copper  \\\n",
       "0      0.0   999.0  21532.0        2.3        316.0     3.35   172.0   \n",
       "1      0.0  2574.0  19237.0        0.9        364.0     3.54    63.0   \n",
       "2      1.0  3428.0  13727.0        3.3        299.0     3.55   131.0   \n",
       "3      0.0  2576.0  18460.0        0.6        256.0     3.50    58.0   \n",
       "4      0.0   788.0  16658.0        1.1        346.0     3.65    63.0   \n",
       "\n",
       "   Alk_Phos    SGOT  Tryglicerides  Platelets  Prothrombin  Status  \n",
       "0    1601.0  179.80           63.0      394.0          9.7       2  \n",
       "1    1440.0  134.85           88.0      361.0         11.0       0  \n",
       "2    1029.0  119.35           50.0      199.0         11.7       2  \n",
       "3    1653.0   71.30           96.0      269.0         10.7       0  \n",
       "4    1181.0  125.55           96.0      298.0         10.6       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert object type columns back to numeric if they were originally numeric\n",
    "for col in df_to_ohe_transformed.columns:\n",
    "    if df_to_ohe_transformed[col].dtype == 'object':\n",
    "        df_to_ohe_transformed[col] = pd.to_numeric(df_to_ohe_transformed[col], errors='coerce')\n",
    "\n",
    "# Check the first few rows of the DataFrame\n",
    "df_to_ohe_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7905 entries, 0 to 7904\n",
      "Data columns (total 26 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Ascites_Y             7905 non-null   float64\n",
      " 1   Hepatomegaly_Y        7905 non-null   float64\n",
      " 2   Spiders_Y             7905 non-null   float64\n",
      " 3   Drug_D-penicillamine  7905 non-null   float64\n",
      " 4   Drug_Placebo          7905 non-null   float64\n",
      " 5   Sex_F                 7905 non-null   float64\n",
      " 6   Sex_M                 7905 non-null   float64\n",
      " 7   Stage_1.0             7905 non-null   float64\n",
      " 8   Stage_2.0             7905 non-null   float64\n",
      " 9   Stage_3.0             7905 non-null   float64\n",
      " 10  Stage_4.0             7905 non-null   float64\n",
      " 11  Edema_N               7905 non-null   float64\n",
      " 12  Edema_S               7905 non-null   float64\n",
      " 13  Edema_Y               7905 non-null   float64\n",
      " 14  N_Days                7905 non-null   float64\n",
      " 15  Age                   7905 non-null   float64\n",
      " 16  Bilirubin             7905 non-null   float64\n",
      " 17  Cholesterol           7905 non-null   float64\n",
      " 18  Albumin               7905 non-null   float64\n",
      " 19  Copper                7905 non-null   float64\n",
      " 20  Alk_Phos              7905 non-null   float64\n",
      " 21  SGOT                  7905 non-null   float64\n",
      " 22  Tryglicerides         7905 non-null   float64\n",
      " 23  Platelets             7905 non-null   float64\n",
      " 24  Prothrombin           7905 non-null   float64\n",
      " 25  Status                7905 non-null   int32  \n",
      "dtypes: float64(25), int32(1)\n",
      "memory usage: 1.5 MB\n"
     ]
    }
   ],
   "source": [
    "df_to_ohe_transformed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5271 entries, 0 to 5270\n",
      "Data columns (total 25 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Ascites_Y             5271 non-null   float64\n",
      " 1   Hepatomegaly_Y        5271 non-null   float64\n",
      " 2   Spiders_Y             5271 non-null   float64\n",
      " 3   Drug_D-penicillamine  5271 non-null   float64\n",
      " 4   Drug_Placebo          5271 non-null   float64\n",
      " 5   Sex_F                 5271 non-null   float64\n",
      " 6   Sex_M                 5271 non-null   float64\n",
      " 7   Stage_1.0             5271 non-null   float64\n",
      " 8   Stage_2.0             5271 non-null   float64\n",
      " 9   Stage_3.0             5271 non-null   float64\n",
      " 10  Stage_4.0             5271 non-null   float64\n",
      " 11  Edema_N               5271 non-null   float64\n",
      " 12  Edema_S               5271 non-null   float64\n",
      " 13  Edema_Y               5271 non-null   float64\n",
      " 14  N_Days                5271 non-null   float64\n",
      " 15  Age                   5271 non-null   float64\n",
      " 16  Bilirubin             5271 non-null   float64\n",
      " 17  Cholesterol           5271 non-null   float64\n",
      " 18  Albumin               5271 non-null   float64\n",
      " 19  Copper                5271 non-null   float64\n",
      " 20  Alk_Phos              5271 non-null   float64\n",
      " 21  SGOT                  5271 non-null   float64\n",
      " 22  Tryglicerides         5271 non-null   float64\n",
      " 23  Platelets             5271 non-null   float64\n",
      " 24  Prothrombin           5271 non-null   float64\n",
      "dtypes: float64(25)\n",
      "memory usage: 1.0 MB\n"
     ]
    }
   ],
   "source": [
    "test_transformed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_to_ohe_transformed.drop(TARGET, axis=1)\n",
    "y = df_to_ohe_transformed[TARGET]\n",
    "test_features = test_transformed.copy()\n",
    "\n",
    "sk = StratifiedKFold(n_splits=10, shuffle=True, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasClassifierWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, epochs=100, batch_size=32):\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.model = self.create_model()\n",
    "\n",
    "    def create_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, input_dim=len(X.columns), activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dense(3, activation='softmax'))  # Output layer for 3 classes\n",
    "        model.compile(optimizer='adam', \n",
    "                      loss='categorical_crossentropy', \n",
    "                      metrics=[tf.keras.metrics.CategoricalCrossentropy(name='log_loss')])\n",
    "        return model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # self.model = self.create_model()\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True, mode='min')\n",
    "        reduce_LR = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=5, min_lr=0.00001, factor=0.8)\n",
    "\n",
    "        self.model.fit(X, to_categorical(y), \n",
    "                       epochs=self.epochs, \n",
    "                       batch_size=self.batch_size, \n",
    "                       verbose=0, \n",
    "                       validation_split=0.1, \n",
    "                       callbacks=[early_stopping, reduce_LR])\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict_proba(X)\n",
    "        return -log_loss(to_categorical(y), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model(): \n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(128, input_dim=len(X.columns), activation='relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dense(64, activation='relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dense(32, activation='relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dense(3, activation='softmax'))  # Output layer for 3 classes\n",
    "\n",
    "#     model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_crossentropy'])\n",
    "#     return model\n",
    "\n",
    "# def fit_predict(model, X_train, y_train, X_test):\n",
    "#     early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True, mode='min')\n",
    "#     reduce_LR = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=5, min_lr=0.00001, factor=0.8)\n",
    "\n",
    "#     model.fit(X_train, to_categorical(y_train), epochs=100, \n",
    "#               batch_size=32, verbose=0, validation_split=0.2, \n",
    "#               callbacks=[early_stopping, reduce_LR])\n",
    "    \n",
    "#     y_pred = model.predict(X_test)\n",
    "    \n",
    "#     return y_pred\n",
    "\n",
    "# # Custom scorer function\n",
    "# def custom_log_loss(y_true, y_pred):\n",
    "#     return log_loss(to_categorical(y_true), y_pred)\n",
    "\n",
    "# # Cross-validation\n",
    "# log_loss_scores = []\n",
    "\n",
    "# for train, test in sk.split(X, y):\n",
    "#     model = create_model()\n",
    "#     y_pred = fit_predict(model, X.iloc[train], y.iloc[train], X.iloc[test])\n",
    "#     score = custom_log_loss(y.iloc[test], y_pred)\n",
    "#     log_loss_scores.append(score)\n",
    "\n",
    "# # Print the results\n",
    "# print(\"Log Loss: %.2f (%.2f)\" % (np.mean(log_loss_scores), np.std(log_loss_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "\t# Ensemble and Tree Methods\n",
    "\tAdaBoostClassifier(random_state=5),\n",
    "\tBaggingClassifier(random_state=5),\n",
    "\tExtraTreesClassifier(random_state=5),\n",
    "\tGradientBoostingClassifier(random_state=5),\n",
    "\tHistGradientBoostingClassifier(random_state=5),\n",
    "\tRandomForestClassifier(random_state=5),\n",
    "    \n",
    "\tXGBClassifier(random_state=5),\n",
    "\tLGBMClassifier(n_jobs=-1, random_state=5),\n",
    "\tCatBoostClassifier(random_state=5, verbose=False, early_stopping_rounds=100),\n",
    "    \n",
    "\t# Liner Models\n",
    "    LogisticRegression(multi_class='multinomial', solver='lbfgs'),\n",
    "    \n",
    "\t# Support Vector Machine\n",
    "    SVC(probability=True),\n",
    "    \n",
    "\t# KNeighbors & Naive Models\n",
    "\tKNeighborsClassifier(),\n",
    "    GaussianNB(),\n",
    "    \n",
    "\t# NeuralNet\n",
    "\tKerasClassifierWrapper(),\n",
    "    ]\n",
    "\n",
    "# # create table to compare MLA metrics\n",
    "# MLA_columns = ['MLA Name', 'MLA Parameters', 'MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD', 'MLA Time']\n",
    "# MLA_compare = pd.DataFrame(columns = MLA_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(models, X, y, important_features, cv_split, experiment_name):\n",
    "    # Create a DataFrame to store comparison results\n",
    "    MLA_compare = pd.DataFrame(columns=['MLA Name', \n",
    "                                        'MLA Parameters', \n",
    "                                        'MLA Train Log Loss', \n",
    "                                        'MLA Test Log Loss', \n",
    "                                        'MLA Time'])\n",
    "    \n",
    "    def evaluate_model(alg, idx):\n",
    "        MLA_name = alg.__class__.__name__\n",
    "        features = important_features.get(MLA_name, [])\n",
    "\n",
    "        if not features:\n",
    "            return None\n",
    "\n",
    "        # Perform cross-validation\n",
    "        log_loss_scorer = make_scorer(log_loss, greater_is_better=False, needs_proba=True)\n",
    "        \n",
    "        cv_results = cross_validate(alg, X[features], y, \n",
    "                                    cv=cv_split, \n",
    "                                    scoring={'Log Loss': log_loss_scorer}, \n",
    "                                    return_train_score=True, \n",
    "                                    n_jobs=-1)\n",
    "\n",
    "        # Format time\n",
    "        mean_fit_time = cv_results['fit_time'].mean()\n",
    "        minutes, seconds = divmod(mean_fit_time, 60)\n",
    "\n",
    "        print(f'Done with {MLA_name}.')\n",
    "        \n",
    "        # Populate results\n",
    "        return {\n",
    "            'MLA Name': MLA_name,\n",
    "            'MLA Parameters': str(alg.get_params()),\n",
    "            'MLA Train Log Loss': -cv_results['train_Log Loss'].mean(),\n",
    "            'MLA Test Log Loss': -cv_results['test_Log Loss'].mean(),\n",
    "            'MLA Time': f\"{int(minutes)} min {seconds:.2f} sec\",\n",
    "        }\n",
    "\n",
    "    results_list = []\n",
    "\n",
    "    # Use ThreadPoolExecutor for parallel execution\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = [executor.submit(evaluate_model, alg, idx) for idx, alg in enumerate(models)]\n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                results_list.append(result)\n",
    "\n",
    "    # Create a DataFrame from the list of dictionaries\n",
    "    MLA_compare = pd.DataFrame(results_list)\n",
    "\n",
    "    # Sort and save results\n",
    "    MLA_compare.sort_values(by=['MLA Test Log Loss'], ascending=True, inplace=True)\n",
    "    MLA_compare.to_csv(f'{experiment_name}_results.csv', index=False)\n",
    "\n",
    "    return MLA_compare\n",
    "\n",
    "# Usage:\n",
    "# models = [list of your models]\n",
    "# MLA_compare = evaluate_models(models, X, y, important_features, cv_split, 'experiment_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_features = {}\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "\n",
    "    baseline_features[model_name] = list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with LGBMClassifier.\n",
      "Done with AdaBoostClassifier.\n",
      "Done with CatBoostClassifier.\n",
      "Done with BaggingClassifier.\n",
      "Done with HistGradientBoostingClassifier.\n",
      "Done with ExtraTreesClassifier.\n",
      "Done with LogisticRegression.\n",
      "Done with RandomForestClassifier.\n",
      "Done with GradientBoostingClassifier.\n",
      "Done with XGBClassifier.\n",
      "Done with GaussianNB.\n",
      "Done with KNeighborsClassifier.\n",
      "Done with SVC.\n",
      "Done with KerasClassifierWrapper.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Parameters</th>\n",
       "      <th>MLA Train Log Loss</th>\n",
       "      <th>MLA Test Log Loss</th>\n",
       "      <th>MLA Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
       "      <td>3.685708e-01</td>\n",
       "      <td>0.450019</td>\n",
       "      <td>0 min 12.18 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>{'verbose': False, 'random_state': 5, 'early_s...</td>\n",
       "      <td>1.726042e-01</td>\n",
       "      <td>0.461763</td>\n",
       "      <td>0 min 42.25 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>1.632736e-01</td>\n",
       "      <td>0.463957</td>\n",
       "      <td>0 min 1.04 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>{'categorical_features': None, 'early_stopping...</td>\n",
       "      <td>1.111534e-01</td>\n",
       "      <td>0.487657</td>\n",
       "      <td>0 min 4.46 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>{'objective': 'binary:logistic', 'use_label_en...</td>\n",
       "      <td>7.704598e-02</td>\n",
       "      <td>0.501359</td>\n",
       "      <td>0 min 8.84 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KerasClassifierWrapper</td>\n",
       "      <td>{'batch_size': 32, 'epochs': 100}</td>\n",
       "      <td>4.757771e-01</td>\n",
       "      <td>0.522538</td>\n",
       "      <td>4 min 21.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>1.132907e-01</td>\n",
       "      <td>0.542660</td>\n",
       "      <td>0 min 2.84 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
       "      <td>2.109424e-15</td>\n",
       "      <td>0.557769</td>\n",
       "      <td>0 min 2.48 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>6.245248e-01</td>\n",
       "      <td>0.626359</td>\n",
       "      <td>0 min 0.40 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVC</td>\n",
       "      <td>{'C': 1.0, 'break_ties': False, 'cache_size': ...</td>\n",
       "      <td>6.602190e-01</td>\n",
       "      <td>0.662001</td>\n",
       "      <td>0 min 50.00 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "      <td>1.050916e+00</td>\n",
       "      <td>1.052196</td>\n",
       "      <td>0 min 1.04 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
       "      <td>1.191830e-01</td>\n",
       "      <td>1.490676</td>\n",
       "      <td>0 min 1.26 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>{'priors': None, 'var_smoothing': 1e-09}</td>\n",
       "      <td>1.798831e+00</td>\n",
       "      <td>1.820922</td>\n",
       "      <td>0 min 0.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>3.822432e-01</td>\n",
       "      <td>3.096902</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          MLA Name  \\\n",
       "3       GradientBoostingClassifier   \n",
       "8               CatBoostClassifier   \n",
       "7                   LGBMClassifier   \n",
       "4   HistGradientBoostingClassifier   \n",
       "6                    XGBClassifier   \n",
       "13          KerasClassifierWrapper   \n",
       "5           RandomForestClassifier   \n",
       "2             ExtraTreesClassifier   \n",
       "9               LogisticRegression   \n",
       "10                             SVC   \n",
       "0               AdaBoostClassifier   \n",
       "1                BaggingClassifier   \n",
       "12                      GaussianNB   \n",
       "11            KNeighborsClassifier   \n",
       "\n",
       "                                       MLA Parameters  MLA Train Log Loss  \\\n",
       "3   {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...        3.685708e-01   \n",
       "8   {'verbose': False, 'random_state': 5, 'early_s...        1.726042e-01   \n",
       "7   {'boosting_type': 'gbdt', 'class_weight': None...        1.632736e-01   \n",
       "4   {'categorical_features': None, 'early_stopping...        1.111534e-01   \n",
       "6   {'objective': 'binary:logistic', 'use_label_en...        7.704598e-02   \n",
       "13                  {'batch_size': 32, 'epochs': 100}        4.757771e-01   \n",
       "5   {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...        1.132907e-01   \n",
       "2   {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...        2.109424e-15   \n",
       "9   {'C': 1.0, 'class_weight': None, 'dual': False...        6.245248e-01   \n",
       "10  {'C': 1.0, 'break_ties': False, 'cache_size': ...        6.602190e-01   \n",
       "0   {'algorithm': 'SAMME.R', 'base_estimator': Non...        1.050916e+00   \n",
       "1   {'base_estimator': None, 'bootstrap': True, 'b...        1.191830e-01   \n",
       "12           {'priors': None, 'var_smoothing': 1e-09}        1.798831e+00   \n",
       "11  {'algorithm': 'auto', 'leaf_size': 30, 'metric...        3.822432e-01   \n",
       "\n",
       "    MLA Test Log Loss         MLA Time  \n",
       "3            0.450019  0 min 12.18 sec  \n",
       "8            0.461763  0 min 42.25 sec  \n",
       "7            0.463957   0 min 1.04 sec  \n",
       "4            0.487657   0 min 4.46 sec  \n",
       "6            0.501359   0 min 8.84 sec  \n",
       "13           0.522538  4 min 21.02 sec  \n",
       "5            0.542660   0 min 2.84 sec  \n",
       "2            0.557769   0 min 2.48 sec  \n",
       "9            0.626359   0 min 0.40 sec  \n",
       "10           0.662001  0 min 50.00 sec  \n",
       "0            1.052196   0 min 1.04 sec  \n",
       "1            1.490676   0 min 1.26 sec  \n",
       "12           1.820922   0 min 0.02 sec  \n",
       "11           3.096902   0 min 0.01 sec  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "baseline_models = evaluate_models(models, X, y, baseline_features, sk, f'{experiment_name}')\n",
    "baseline_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hill_climbing(x, y, x_test):\n",
    "#     le = LabelEncoder()\n",
    "#     y_encoded = le.fit_transform(y)\n",
    "#     y_one_hot = pd.get_dummies(y_encoded)\n",
    "\n",
    "#     # Evaluating out-of-fold predictions\n",
    "#     scores = {}\n",
    "#     for col in x.columns:\n",
    "#         scores[col] = log_loss(y_one_hot, x[[col]])\n",
    "\n",
    "#     # Sorting the model scores in ascending order\n",
    "#     scores = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1])}\n",
    "#     print(scores)\n",
    "\n",
    "#     # Sort x and x_test based on scores\n",
    "#     x = x[list(scores.keys())]\n",
    "#     x_test = x_test[list(scores.keys())]\n",
    "\n",
    "#     # Initialize weights\n",
    "#     weights = {col: 1 if i == 0 else 0 for i, col in enumerate(x.columns)}\n",
    "\n",
    "#     STOP = False\n",
    "#     current_best_ensemble = x.iloc[:,0]\n",
    "#     current_best_test_ensemble = x_test.iloc[:,0]\n",
    "#     MODELS = x.iloc[:,1:]\n",
    "#     weight_range = np.arange(-0.5, 0.51, 0.01) \n",
    "#     history = [log_loss(y_one_hot, current_best_ensemble)]\n",
    "\n",
    "#     while not STOP:\n",
    "#         potential_new_best_cv_score = log_loss(y_one_hot, current_best_ensemble)\n",
    "#         k_best, wgt_best = None, None\n",
    "#         for k in MODELS:\n",
    "#             for wgt in weight_range:\n",
    "#                 potential_ensemble = (1 - wgt) * current_best_ensemble + wgt * MODELS[k]\n",
    "#                 cv_score = log_loss(y_one_hot, potential_ensemble)\n",
    "#                 if cv_score < potential_new_best_cv_score:\n",
    "#                     potential_new_best_cv_score = cv_score\n",
    "#                     k_best, wgt_best = k, wgt\n",
    "\n",
    "#         if k_best is not None:\n",
    "#             # Update weights\n",
    "#             weights = {col: (1 - wgt_best) * weights[col] if col != k_best else wgt_best for col in weights}\n",
    "#             current_best_ensemble = (1 - wgt_best) * current_best_ensemble + wgt_best * MODELS[k_best]\n",
    "#             current_best_test_ensemble = (1 - wgt_best) * current_best_test_ensemble + wgt_best * x_test[k_best]\n",
    "#             MODELS.drop(k_best, axis=1, inplace=True)\n",
    "            \n",
    "#             if MODELS.shape[1] == 0:\n",
    "#                 STOP = True\n",
    "#             history.append(potential_new_best_cv_score)\n",
    "#         else:\n",
    "#             STOP = True\n",
    "        \n",
    "#     hill_ens_pred = current_best_ensemble\n",
    "#     hill_ens_pred_test = current_best_test_ensemble\n",
    "    \n",
    "#     return hill_ens_pred, hill_ens_pred_test, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_scores = []\n",
    "# model_fold_scores = []\n",
    "# models_dict = {}\n",
    "\n",
    "# for idx, model_name in enumerate(model_names):\n",
    "    \n",
    "#     pred_cols = [f\"pred_{response_col}_{c}_{model_name}\" for c in response_col_order]\n",
    "    \n",
    "#     print(\"=\"*25)\n",
    "#     print(f\"Starting training, validation and prediction for model {model_name} [MODEL {idx+1}/{len(model_names)}]\")\n",
    "#     print(\"=\"*25)\n",
    "    \n",
    "#     print(\"-\"*25)\n",
    "#     print(f\"Training model:\")\n",
    "#     print(\"-\"*25)\n",
    "    \n",
    "#     start_time = time.process_time()\n",
    "    \n",
    "#     trainer = KFoldTrainer(\n",
    "#         seed = CFG.seed,\n",
    "#         model_name = model_name,\n",
    "#         model_params = model_params_dict[model_name],\n",
    "#     )\n",
    "#     # training\n",
    "#     trainer.train_by_fold(df_combined, feature_names, verbose=True)\n",
    "#     print(\"-\"*25)\n",
    "    \n",
    "#     models_dict[model_name] = trainer.get_saved_models()\n",
    "    \n",
    "#     # validation\n",
    "#     pred_train, metric, fold_metrics, mean_fold_metric, sd_fold_metric = \\\n",
    "#         trainer.get_oof_predictions_and_metric(df_combined, feature_names)\n",
    "    \n",
    "#     df_combined[pred_cols] = pred_train\n",
    "    \n",
    "#     for fold in range(CFG.n_folds):\n",
    "#         print(f\"LOSS for FOLD {fold}: {fold_metrics[fold]:6f}\")\n",
    "#     print()\n",
    "#     print(f\"OOF LOSS for {model_name}: {metric:.6f}\")\n",
    "#     print(f\"Mean/SD LOSS for {model_name}: {mean_fold_metric:.6f} ± {sd_fold_metric:.6f}\")\n",
    "    \n",
    "#     # for plotting later on\n",
    "#     model_scores.append({\n",
    "#         'model_name': model_name,\n",
    "#         'score': metric,\n",
    "#     })\n",
    "#     model_fold_scores.extend([{\n",
    "#         'model_name': model_name,\n",
    "#         'fold': fold,\n",
    "#         'score': fold_metrics[fold]\n",
    "#     } for fold in range(CFG.n_folds)])\n",
    "    \n",
    "#     # prediction (test set)\n",
    "#     print(\"-\"*25)\n",
    "#     print(f\"Predicting test set with model:\")\n",
    "#     print(\"-\"*25)\n",
    "#     df_test[pred_cols] = trainer.predict(df_test, feature_names, verbose=True)\n",
    "    \n",
    "#     # cleanup\n",
    "#     del trainer, pred_train, metric, fold_metrics, mean_fold_metric, sd_fold_metric\n",
    "#     gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# hill_climb_scores = []\n",
    "# hc_test_scores = []\n",
    "# hill_climb_weights = []\n",
    "# final_predictions = []\n",
    "# final_hc_predictions = []\n",
    "# avg_predictions_scores = []\n",
    "# optuna_weights_scores = []\n",
    "# stacked_scores = []\n",
    "# optuna_weights_scores_stack = []\n",
    "\n",
    "# labels = list(range(y.nunique()))\n",
    "\n",
    "# for i, (train_index, test_index) in enumerate(sk.split(X, y)):\n",
    "#     X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "#     y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "#     print(f'Fold {i+1}')\n",
    "    \n",
    "#     MLA_cv_train_preds = []\n",
    "#     MLA_cv_preds = []\n",
    "#     MLA_cv_preds_dict = {}\n",
    "#     MLA_cv_preds_test_dict = {}\n",
    "#     MLA_names = []\n",
    "    \n",
    "#     for alg in models:\n",
    "#         MLA_name = alg.__class__.__name__\n",
    "        \n",
    "#         predictor = alg.fit(X_train, y_train)\n",
    "#         pred_result = predictor.predict_proba(X_test)\n",
    "#         test_result = predictor.predict_proba(test_features)\n",
    "\n",
    "#         # MLA_cv_preds.append(pred_result)\n",
    "#         # final_predictions.append(test_result)\n",
    "\n",
    "#         # MLA_cv_preds_dict[MLA_name] = pred_result\n",
    "#         # MLA_cv_preds_test_dict[MLA_name] = test_result\n",
    "\n",
    "#         # Store each class's predictions separately\n",
    "#         for class_index in range(pred_result.shape[1]):\n",
    "#             class_name = f'{MLA_name}_class_{class_index}'\n",
    "#             MLA_cv_preds_dict[class_name] = pred_result[:, class_index]\n",
    "#             MLA_cv_preds_test_dict[class_name] = test_result[:, class_index]\n",
    "\n",
    "\n",
    "#         MLA_names.append(MLA_name)\n",
    "\n",
    "#         print(f'Done with {MLA_name}')\n",
    "\n",
    "#     print(MLA_cv_preds_dict)\n",
    "#     print(MLA_cv_preds_test_dict)\n",
    "    \n",
    "#     #################\n",
    "#     ### Averaging ###\n",
    "#     #################\n",
    "#     avg_prediction = np.mean(MLA_cv_preds, axis=0)\n",
    "#     avg_prediction_score = log_loss(y_test, avg_prediction)\n",
    "#     avg_predictions_scores.append(avg_prediction_score)\n",
    "#     print(f'The Fold {i+1} average prediction log loss is {avg_prediction_score}')\n",
    "\n",
    "#     print(MLA_cv_preds_dict)\n",
    "#     print(MLA_cv_preds_test_dict)\n",
    "\n",
    "#     ##################\n",
    "#     ### Hill Climb ###\n",
    "#     ##################\n",
    "#     hill_climb_pred, hill_climb_final_pred, hill_climb_weight = hill_climbing(pd.DataFrame(MLA_cv_preds_dict), y_test, pd.DataFrame(MLA_cv_preds_test_dict))\n",
    "    \n",
    "#     hill_climb_score = log_loss(y_test, hill_climb_pred)\n",
    "#     # hc_test_score = mean_absolute_error(test_target, hill_climb_final_pred)\n",
    "#     hill_climb_scores.append(hill_climb_score)\n",
    "#     # hc_test_scores.append(hc_test_score)\n",
    "#     final_hc_predictions.append(hill_climb_final_pred)\n",
    "#     hill_climb_weights.append(hill_climb_weight)\n",
    "    \n",
    "#     print(f'The Fold {i+1} Hill Climb CV Log Loss Score is {hill_climb_score}')\n",
    "#     # print(f'The Fold {i+1} Hill Climb Actual Data Score is {hc_test_score}')\n",
    "#     print(f'The Fold {i+1} weight are {hill_climb_weight}')\n",
    "\n",
    "#     print()\n",
    "\n",
    "# print()\n",
    "# print(f'The average prediction CV log loss is ==> {np.mean(avg_predictions_scores)}')\n",
    "# print(f'The Hill Climbing CV log loss is ==> {np.mean(hill_climb_scores)}')\n",
    "# # print(f'The Hill Climbing Test CV score is ==> {np.mean(hc_test_scores)}')\n",
    "# print(f'The Hill Climbing weights are ==> {hill_climb_weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set seeds for reproducibility\n",
    "# np.random.seed(42)\n",
    "# tf.random.set_seed(42)\n",
    "# random.seed(42)\n",
    "\n",
    "# ensemble_log_losses = []\n",
    "# fold_weights = []  # To store weights for each fold\n",
    "# weight_range = np.arange(-0.5, 0.51, 0.01)\n",
    "\n",
    "# for train_index, test_index in sk.split(X, y):\n",
    "#     X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "#     y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "#     # Storing predictions\n",
    "#     model_predictions_train = {}\n",
    "#     model_predictions_test = {}\n",
    "\n",
    "#     for model in models:\n",
    "#         model_name = model.__class__.__name__\n",
    "#         model.fit(X_train, y_train)\n",
    "#         model_predictions_train[model_name] = model.predict_proba(X_test)\n",
    "#         model_predictions_test[model_name] = model.predict_proba(X_test)\n",
    "#         print(f'Done with {model_name}', end='\\n')\n",
    "\n",
    "#     # Initialize ensemble with the first model\n",
    "#     first_model_name = next(iter(model_predictions_train.keys()))\n",
    "#     current_best_ensemble = model_predictions_train[first_model_name]\n",
    "#     current_best_test_ensemble = model_predictions_test[first_model_name]\n",
    "\n",
    "#     # Initialize weights\n",
    "#     model_weights = {model_name: 0 for model_name in model_predictions_train.keys()}\n",
    "#     model_weights[first_model_name] = 1.0\n",
    "\n",
    "#     # Remove the first model from the list\n",
    "#     MODELS = list(model_predictions_train.keys())[1:]\n",
    "#     STOP = False\n",
    "#     history = [log_loss(y_test, current_best_ensemble)]\n",
    "#     fold_weights_current = [model_weights.copy()]\n",
    "\n",
    "#     while not STOP:\n",
    "#         potential_new_best_cv_score = log_loss(y_test, current_best_ensemble)\n",
    "#         k_best, wgt_best = None, None\n",
    "#         for k in MODELS:\n",
    "#             for wgt in weight_range:\n",
    "#                 potential_ensemble = (1 - wgt) * current_best_ensemble + wgt * model_predictions_train[k]\n",
    "#                 cv_score = log_loss(y_test, potential_ensemble)\n",
    "#                 if cv_score < potential_new_best_cv_score:\n",
    "#                     potential_new_best_cv_score = cv_score\n",
    "#                     k_best, wgt_best = k, wgt\n",
    "\n",
    "#         if k_best is not None:\n",
    "#             # Update ensemble\n",
    "#             current_best_ensemble = (1 - wgt_best) * current_best_ensemble + wgt_best * model_predictions_train[k_best]\n",
    "#             current_best_test_ensemble = (1 - wgt_best) * current_best_test_ensemble + wgt_best * model_predictions_test[k_best]\n",
    "            \n",
    "#             # Update weights\n",
    "#             model_weights = {model_name: (1 - wgt_best) * model_weights[model_name] if model_name != k_best else wgt_best for model_name in model_weights}\n",
    "#             fold_weights_current.append(model_weights.copy())\n",
    "#             MODELS.remove(k_best)\n",
    "\n",
    "#             if len(MODELS) == 0:\n",
    "#                 STOP = True\n",
    "#             history.append(potential_new_best_cv_score)\n",
    "#         else:\n",
    "#             STOP = True\n",
    "\n",
    "#     # Calculate log loss for the optimized ensemble on the test set and store weights\n",
    "#     loss = log_loss(y_test, current_best_ensemble)\n",
    "#     print(loss)\n",
    "#     ensemble_log_losses.append(loss)\n",
    "#     fold_weights.append(fold_weights_current[-1])  # Store final weights of this fold\n",
    "\n",
    "# # Average log loss across all folds\n",
    "# average_log_loss = np.mean(ensemble_log_losses)\n",
    "# print(f\"Ensemble Average Log Loss: {average_log_loss}\")\n",
    "# print(\"Weights per fold:\", fold_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set seeds for reproducibility\n",
    "# np.random.seed(42)\n",
    "# tf.random.set_seed(42)\n",
    "# random.seed(42)\n",
    "\n",
    "# ensemble_log_losses = []\n",
    "# weight_range = np.arange(-0.5, 0.6, 0.01)\n",
    "\n",
    "# for train_index, test_index in sk.split(X, y):\n",
    "#     X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "#     y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "#     # Storing predictions and calculating individual log losses\n",
    "#     model_predictions = {}\n",
    "#     model_log_losses = {}\n",
    "\n",
    "#     for model in models:\n",
    "#         model_name = model.__class__.__name__\n",
    "#         model.fit(X_train, y_train)\n",
    "#         probas = model.predict_proba(X_test)\n",
    "#         model_predictions[model_name] = probas\n",
    "#         model_log_losses[model_name] = log_loss(y_test, probas)\n",
    "#         print(f'Done with {model_name}', end='\\n')\n",
    "\n",
    "#     # Sorting models by their log loss\n",
    "#     sorted_models = sorted(model_log_losses, key=model_log_losses.get)\n",
    "\n",
    "#     # Initialize model weights: best model gets weight 1, others get 0\n",
    "#     model_weights = {model: 1 if model == sorted_models[0] else 0 for model in model_log_losses.keys()}\n",
    "\n",
    "#     # Hill Climbing for optimizing weights\n",
    "#     best_loss = model_log_losses[sorted_models[0]]\n",
    "#     for model_name in model_weights.keys():\n",
    "#         for wgt in weight_range:\n",
    "#             temp_weights = model_weights.copy()\n",
    "#             temp_weights[model_name] = wgt\n",
    "#             remaining_weight = 1 - wgt\n",
    "#             for other_model in temp_weights:\n",
    "#                 if other_model != model_name:\n",
    "#                     temp_weights[other_model] = remaining_weight / (len(models) - 1)\n",
    "\n",
    "#             combined_preds = np.zeros_like(next(iter(model_predictions.values())))\n",
    "#             for m_name, m_probas in model_predictions.items():\n",
    "#                 combined_preds += temp_weights[m_name] * m_probas\n",
    "\n",
    "#             current_loss = log_loss(y_test, combined_preds / combined_preds.sum(axis=1, keepdims=True))\n",
    "#             if current_loss < best_loss:\n",
    "#                 best_loss = current_loss\n",
    "#                 model_weights = temp_weights.copy()\n",
    "\n",
    "#     # Calculate log loss with optimized weights\n",
    "#     optimized_preds = np.zeros_like(next(iter(model_predictions.values())))\n",
    "#     for m_name, m_probas in model_predictions.items():\n",
    "#         optimized_preds += model_weights[m_name] * m_probas\n",
    "\n",
    "#     loss = log_loss(y_test, optimized_preds / optimized_preds.sum(axis=1, keepdims=True))\n",
    "#     ensemble_log_losses.append(loss)\n",
    "\n",
    "# # Average log loss across all folds\n",
    "# average_log_loss = np.mean(ensemble_log_losses)\n",
    "# print(f\"Ensemble Average Log Loss: {average_log_loss}\")\n",
    "# print(sum(model_weights.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set seeds for reproducibility\n",
    "# np.random.seed(42)\n",
    "# tf.random.set_seed(42)\n",
    "# random.seed(42)\n",
    "\n",
    "# ensemble_log_losses = []\n",
    "# weight_range = np.arange(-0.5, 0.6, 0.01)\n",
    "\n",
    "# for train_index, test_index in sk.split(X, y):\n",
    "#     X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "#     y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "#     # Storing predictions and calculating individual log losses\n",
    "#     model_predictions = {}\n",
    "#     model_log_losses = {}\n",
    "\n",
    "#     for model in models:\n",
    "#         model_name = model.__class__.__name__\n",
    "#         model.fit(X_train, y_train)\n",
    "#         probas = model.predict_proba(X_test)\n",
    "#         model_predictions[model_name] = probas\n",
    "#         model_log_losses[model_name] = log_loss(y_test, probas)\n",
    "#         print(f'Done with {model_name}', end='\\n')\n",
    "\n",
    "#     # Sorting models by their log loss\n",
    "#     sorted_models = sorted(model_log_losses, key=model_log_losses.get)\n",
    "\n",
    "#     # Initialize model weights: best model gets weight 1, others get 0\n",
    "#     model_weights = {model: 1 if model == sorted_models[0] else 0 for model in model_log_losses.keys()}\n",
    "\n",
    "#     # Hill Climbing for optimizing weights\n",
    "#     best_loss = model_log_losses[sorted_models[0]]\n",
    "#     for model_name, probas in model_predictions.items():\n",
    "#         for wgt in weight_range:\n",
    "#             combined_preds = np.zeros_like(probas)\n",
    "#             for m_name, m_probas in model_predictions.items():\n",
    "#                 weight = wgt if m_name == model_name else model_weights[m_name]\n",
    "#                 combined_preds += weight * m_probas\n",
    "\n",
    "#             current_loss = log_loss(y_test, combined_preds / combined_preds.sum(axis=1, keepdims=True))\n",
    "#             if current_loss < best_loss:\n",
    "#                 best_loss = current_loss\n",
    "#                 model_weights[model_name] = wgt\n",
    "\n",
    "#     # Calculate log loss with optimized weights\n",
    "#     optimized_preds = np.zeros_like(probas)\n",
    "#     for m_name, m_probas in model_predictions.items():\n",
    "#         optimized_preds += model_weights[m_name] * m_probas\n",
    "\n",
    "#     loss = log_loss(y_test, optimized_preds / optimized_preds.sum(axis=1, keepdims=True))\n",
    "#     ensemble_log_losses.append(loss)\n",
    "\n",
    "# # Average log loss across all folds\n",
    "# average_log_loss = np.mean(ensemble_log_losses)\n",
    "# print(f\"Ensemble Average Log Loss: {average_log_loss}\")\n",
    "# print(sum(model_weights.values()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
