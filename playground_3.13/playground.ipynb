{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train and test datasets\n",
    "\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target variable using LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on the 'prognosis' column of the training DataFrame and transform it\n",
    "df_train[\"prognosis\"] = le.fit_transform(df_train[\"prognosis\"])\n",
    "\n",
    "# Get the class names from the encoder, which correspond to the unique target variable values\n",
    "# This will be useful later when we need to convert the numerical labels back to their original textual labels\n",
    "target_names = le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sudden_fever</th>\n",
       "      <th>headache</th>\n",
       "      <th>mouth_bleed</th>\n",
       "      <th>nose_bleed</th>\n",
       "      <th>muscle_pain</th>\n",
       "      <th>joint_pain</th>\n",
       "      <th>vomiting</th>\n",
       "      <th>rash</th>\n",
       "      <th>diarrhea</th>\n",
       "      <th>...</th>\n",
       "      <th>breathing_restriction</th>\n",
       "      <th>toe_inflammation</th>\n",
       "      <th>finger_inflammation</th>\n",
       "      <th>lips_irritation</th>\n",
       "      <th>itchiness</th>\n",
       "      <th>ulcers</th>\n",
       "      <th>toenail_loss</th>\n",
       "      <th>speech_problem</th>\n",
       "      <th>bullseye_rash</th>\n",
       "      <th>prognosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  sudden_fever  headache  mouth_bleed  nose_bleed  muscle_pain  \\\n",
       "0   0           1.0       1.0          0.0         1.0          1.0   \n",
       "1   1           0.0       0.0          0.0         0.0          0.0   \n",
       "2   2           0.0       1.0          1.0         1.0          0.0   \n",
       "3   3           0.0       0.0          1.0         1.0          1.0   \n",
       "4   4           0.0       0.0          0.0         0.0          0.0   \n",
       "\n",
       "   joint_pain  vomiting  rash  diarrhea  ...  breathing_restriction  \\\n",
       "0         1.0       1.0   0.0       1.0  ...                    0.0   \n",
       "1         0.0       1.0   0.0       1.0  ...                    0.0   \n",
       "2         1.0       1.0   1.0       1.0  ...                    1.0   \n",
       "3         1.0       0.0   1.0       0.0  ...                    0.0   \n",
       "4         0.0       0.0   0.0       1.0  ...                    0.0   \n",
       "\n",
       "   toe_inflammation  finger_inflammation  lips_irritation  itchiness  ulcers  \\\n",
       "0               0.0                  0.0              0.0        0.0     0.0   \n",
       "1               0.0                  0.0              0.0        0.0     0.0   \n",
       "2               1.0                  1.0              1.0        1.0     0.0   \n",
       "3               0.0                  0.0              0.0        0.0     0.0   \n",
       "4               1.0                  0.0              0.0        1.0     1.0   \n",
       "\n",
       "   toenail_loss  speech_problem  bullseye_rash  prognosis  \n",
       "0           0.0             0.0            0.0          3  \n",
       "1           0.0             0.0            0.0          7  \n",
       "2           1.0             1.0            1.0          3  \n",
       "3           0.0             0.0            0.0         10  \n",
       "4           1.0             0.0            0.0          6  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Chikungunya', 'Dengue', 'Japanese_encephalitis', 'Lyme_disease',\n",
       "       'Malaria', 'Plague', 'Rift_Valley_fever', 'Tungiasis',\n",
       "       'West_Nile_fever', 'Yellow_Fever', 'Zika'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the RandomForest classifier\n",
    "# Drop the id and target variable\n",
    "X = df_train.drop([\"id\", \"prognosis\"], axis=1)\n",
    "y = df_train[\"prognosis\"]\n",
    "\n",
    "# Drop the id column\n",
    "X_test = df_test.drop(\"id\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sudden_fever', 'headache', 'mouth_bleed', 'nose_bleed', 'muscle_pain',\n",
       "       'joint_pain', 'vomiting', 'rash', 'diarrhea', 'hypotension',\n",
       "       'pleural_effusion', 'ascites', 'gastro_bleeding', 'swelling', 'nausea',\n",
       "       'chills', 'myalgia', 'digestion_trouble', 'fatigue', 'skin_lesions',\n",
       "       'stomach_pain', 'orbital_pain', 'neck_pain', 'weakness', 'back_pain',\n",
       "       'weight_loss', 'gum_bleed', 'jaundice', 'coma', 'diziness',\n",
       "       'inflammation', 'red_eyes', 'loss_of_appetite', 'urination_loss',\n",
       "       'slow_heart_rate', 'abdominal_pain', 'light_sensitivity', 'yellow_skin',\n",
       "       'yellow_eyes', 'facial_distortion', 'microcephaly', 'rigor',\n",
       "       'bitter_tongue', 'convulsion', 'anemia', 'cocacola_urine',\n",
       "       'hypoglycemia', 'prostraction', 'hyperpyrexia', 'stiff_neck',\n",
       "       'irritability', 'confusion', 'tremor', 'paralysis', 'lymph_swells',\n",
       "       'breathing_restriction', 'toe_inflammation', 'finger_inflammation',\n",
       "       'lips_irritation', 'itchiness', 'ulcers', 'toenail_loss',\n",
       "       'speech_problem', 'bullseye_rash'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_precision(y_true_row, pred_indices, k=3):\n",
    "    \"\"\"\n",
    "    Calculate the average precision of the predicted labels for a single sample.\n",
    "    \n",
    "    Args:\n",
    "    y_true_row (numpy.ndarray): A 1D binary array representing the true target labels\n",
    "                                for a single sample, where 1 indicates the correct class.\n",
    "    pred_indices (list): A list of indices representing the top k predictions in descending\n",
    "                         order of probability for a single sample.\n",
    "    k (int, optional): The number of top predictions to consider for the average precision\n",
    "                       calculation. Default is 3.\n",
    "\n",
    "    Returns:\n",
    "    float: The average precision for the given sample.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize variables to track the number of correct predictions and the sum of precisions\n",
    "    num_correct = 0\n",
    "    precision_sum = 0\n",
    "    \n",
    "    # Loop through the top k predicted indices\n",
    "    for i, idx in enumerate(pred_indices):\n",
    "        \n",
    "        # Check if the predicted index corresponds to the correct class (y_true_row[idx] == 1)\n",
    "        if y_true_row[idx] == 1:\n",
    "            \n",
    "            # If the prediction is correct, increment the number of correct predictions\n",
    "            num_correct += 1\n",
    "            \n",
    "            # Add the precision of the current prediction to the precision sum\n",
    "            precision_sum += num_correct / (i + 1)\n",
    "    \n",
    "    # Calculate the average precision by dividing the precision sum by the minimum of k\n",
    "    # and the number of non-zero elements in the true target row\n",
    "    return precision_sum / min(k, np.count_nonzero(y_true_row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, X, y, X_test, n_splits=10):\n",
    "    \"\"\"\n",
    "    Perform cross-validation, calculate the MAP@3, and generate a submission file for each fold.\n",
    "    \n",
    "    Args:\n",
    "    name (str): A string to be used as a prefix for the submission file name.\n",
    "    model (sklearn.base.BaseEstimator): The model to be used for training and prediction.\n",
    "    X (pandas.DataFrame): The training input data.\n",
    "    y (pandas.Series): The training target data.\n",
    "    X_test (pandas.DataFrame): The test input data.\n",
    "    n_splits (int, optional): The number of cross-validation splits to be performed. Default is 10.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of MAP@3 values for each fold, rounded to 5 decimal places.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize a list to store MAP@3, Precision, Recall and F1 Score values for each fold\n",
    "    map3s, precisions, recalls, f1s = [], [], [], []\n",
    "    \n",
    "    # Create a StratifiedKFold object for performing cross-validation\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=500)\n",
    "\n",
    "    # Perform cross-validation by iterating through the splits\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        \n",
    "        # Split the data into training and test sets for the current fold\n",
    "        X_train_cv, X_test_cv = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train_cv, y_test_cv = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Train the model on the training set\n",
    "        model.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "        # Predict probabilities for the test set\n",
    "        y_pred_proba = model.predict_proba(X_test_cv)\n",
    "\n",
    "        # Convert the true target labels into a one-hot encoded format\n",
    "        y_true_one_hot = pd.get_dummies(y_test_cv).to_numpy()\n",
    "\n",
    "        # Get the top 3 most likely target indices for the test set\n",
    "        top_3_indices = np.argsort(-y_pred_proba, axis=1)[:, :3]\n",
    "\n",
    "        # Get the top 1 most likely target indices for the test set\n",
    "        top_1_indices = np.argsort(-y_pred_proba, axis=1)[:, :1]\n",
    "\n",
    "        # Calculate precision, recall, and F1 score\n",
    "        precision = precision_score(y_test_cv, top_1_indices, average=\"weighted\")\n",
    "        recall = recall_score(y_test_cv, top_1_indices, average=\"weighted\")\n",
    "        f1 = f1_score(y_test_cv, top_1_indices, average=\"weighted\")\n",
    "\n",
    "        # Calculate the average precision for each sample in the test set\n",
    "        average_precisions = np.array([average_precision(y_true_one_hot[i], top_3_indices[i]) for i in range(len(y_true_one_hot))])\n",
    "\n",
    "        # Calculate the mean average precision (MAP@3) for the test set\n",
    "        map3 = average_precisions.mean()\n",
    "\n",
    "        # Append the MAP@3 to the list of MAP@3 values\n",
    "        map3s.append(map3)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "    \n",
    "    # Return the list of MAP@3 values for each fold, rounded to 5 decimal places\n",
    "    return [round(value, 5) for value in map3s], np.mean(precisions), np.mean(recalls), np.mean(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiliaze the models\n",
    "\n",
    "input_dim = X.shape[1]\n",
    "\n",
    "models = {\n",
    "    \"LightGBM\": LGBMClassifier(random_state=500),\n",
    "    \"XGBoost\": XGBClassifier(random_state=500),\n",
    "    \"CatBoost\": CatBoostClassifier(silent=True, random_state=500),\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=500),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"MLP\": MLPClassifier(random_state=500),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LightGBM\n",
      "MAP@3 Scores: [0.36854, 0.3615, 0.46479, 0.42019, 0.38263, 0.39906, 0.37559, 0.39762, 0.37857, 0.45952]\n",
      "Average MAP@3: 0.40080\n",
      "Std. Deviation: 0.03461\n",
      "Precision Score: 0.25412\n",
      "Recall Score: 0.27577\n",
      "F1 Score: 0.25703\n",
      "\n",
      "Model: XGBoost\n",
      "MAP@3 Scores: [0.35915, 0.40845, 0.45775, 0.40376, 0.40845, 0.38263, 0.38028, 0.39762, 0.41429, 0.45238]\n",
      "Average MAP@3: 0.40648\n",
      "Std. Deviation: 0.02896\n",
      "Precision Score: 0.25799\n",
      "Recall Score: 0.27730\n",
      "F1 Score: 0.26070\n",
      "\n",
      "Model: CatBoost\n",
      "MAP@3 Scores: [0.44131, 0.41549, 0.51174, 0.40845, 0.46009, 0.47887, 0.33568, 0.35476, 0.41429, 0.48571]\n",
      "Average MAP@3: 0.43064\n",
      "Std. Deviation: 0.05356\n",
      "Precision Score: 0.29863\n",
      "Recall Score: 0.31256\n",
      "F1 Score: 0.29010\n",
      "\n",
      "Model: RandomForest\n",
      "MAP@3 Scores: [0.39437, 0.42488, 0.47653, 0.43192, 0.40376, 0.50469, 0.40845, 0.39762, 0.41905, 0.46667]\n",
      "Average MAP@3: 0.43279\n",
      "Std. Deviation: 0.03554\n",
      "Precision Score: 0.27262\n",
      "Recall Score: 0.30692\n",
      "F1 Score: 0.28031\n",
      "\n",
      "Model: KNN\n",
      "MAP@3 Scores: [0.34742, 0.34977, 0.41784, 0.35915, 0.39437, 0.41549, 0.35681, 0.30952, 0.36429, 0.39286]\n",
      "Average MAP@3: 0.37075\n",
      "Std. Deviation: 0.03220\n",
      "Precision Score: 0.24521\n",
      "Recall Score: 0.26865\n",
      "F1 Score: 0.22804\n",
      "\n",
      "Model: MLP\n",
      "MAP@3 Scores: [0.43897, 0.38967, 0.46714, 0.40845, 0.41315, 0.45305, 0.34272, 0.34286, 0.45238, 0.47381]\n",
      "Average MAP@3: 0.41822\n",
      "Std. Deviation: 0.04540\n",
      "Precision Score: 0.30001\n",
      "Recall Score: 0.29710\n",
      "F1 Score: 0.28501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    map3_scores, precision, recall, f1 = evaluate_model(name, model, X, y, X_test)\n",
    "    mean_map3 = np.mean(map3_scores)\n",
    "    std = np.std(map3_scores)\n",
    "\n",
    "    # Train the model on the training set\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # # Get feature importances\n",
    "    # importances = model.feature_importances_\n",
    "    # feature_importances = pd.Series(importances, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "    # Predict probabilities for the test set\n",
    "    y_test_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "    # Get the top 3 most likely target indices\n",
    "    top3_indices = np.argsort(-y_test_pred_proba, axis=1)[:, :3]\n",
    "\n",
    "    # Convert the indices back to the original target label\n",
    "    transformed_labels = np.array([le.inverse_transform(row) for row in top3_indices])\n",
    "\n",
    "    # Create a new DataFrame with the id and top 3 targets\n",
    "    results_df = pd.DataFrame({\"id\": df_test[\"id\"], \"prognosis\": [\" \".join(targets) for targets in transformed_labels]})\n",
    "\n",
    "    # Save the output DataFrame to a CSV file\n",
    "    results_df.to_csv(f\"submissions_{name}.csv\", index=False)\n",
    "\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"MAP@3 Scores: {map3_scores}\")\n",
    "    print(f\"Average MAP@3: {mean_map3:.5f}\")\n",
    "    print(f\"Std. Deviation: {std:.5f}\")\n",
    "    print(f\"Precision Score: {precision:.5f}\")\n",
    "    print(f\"Recall Score: {recall:.5f}\")\n",
    "    print(f\"F1 Score: {f1:.5f}\")\n",
    "    # print(f\"Feature Importance: {feature_importances}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
