{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21252159-55dc-410c-9c35-b979dccfdfbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "import re\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82abad9-38c1-4bb5-a18e-af8fb91f0e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer, log_loss\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from pprint import pprint\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "experiment_name = 'pytorch_bert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50bf547-a099-4295-8e18-30bdd8a89fcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "print(f'Train shape: {df.shape}'), print(f'Test shape: {df_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a9218f-c590-4b90-a3d4-2b8f1adc5202",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-large-uncased')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('google-bert/bert-large-uncased', num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c069a4fd-9c18-4192-81f4-8789f97f3c15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['encoded_labels'] = label_encoder.fit_transform(df['author'])  # Convert string labels to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2020c0-325a-413d-ac94-f0a39aa22a8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len=512):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.iloc[idx]['text']\n",
    "        label = self.data.iloc[idx]['encoded_labels']\n",
    "        encoding = tokenizer(text, return_tensors='pt', padding='max_length', truncation=True, max_length=self.max_len)\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),  # Remove batch dimension\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Assume df is your DataFrame containing 'text' and 'label'\n",
    "dataset = CustomDataset(df, tokenizer, max_len=512)\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=50,\n",
    "    learning_rate=2e-5,\n",
    "    seed=5,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149a7d4b-cfd3-49ad-b445-148471c69aa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the finetuned model for further use (rename as appropraite)\n",
    "\n",
    "model.save_pretrained('./trained_model')\n",
    "tokenizer.save_pretrained('./trained_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e57600-5a6b-443d-924e-04c2d0771bfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the pretrained model for embedding the training and test data\n",
    "\n",
    "%%time\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('./trained_model')\n",
    "model = AutoModel.from_pretrained('./trained_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c8df74-e8e9-4d51-861a-f7a3acf4152e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_bert_embeddings(sentences):\n",
    "    model.eval()  # Put the model in evaluation mode\n",
    "    batch_size = 64  # Adjust based on your memory availability\n",
    "    embeddings = []\n",
    "    \n",
    "    # Wrap the range generator with tqdm for a progress bar\n",
    "    for i in tqdm(range(0, len(sentences), batch_size), desc=\"Processing batches\"):\n",
    "        batch = sentences[i:i+batch_size]\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        embeddings.append(outputs.last_hidden_state[:, 0, :].detach().numpy())\n",
    "    \n",
    "    # Concatenate all batch embeddings\n",
    "    embeddings = np.concatenate(embeddings, axis=0)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c9791f-ac6c-49b3-a3ad-84c0c6e3fc92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the text column in to a list\n",
    "\n",
    "documents_train = df['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1f2869-6d80-434f-ae6b-a6def25e83bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "bert_embeddings = get_bert_embeddings(documents_train)\n",
    "bert_df_train = pd.DataFrame(bert_embeddings)\n",
    "bert_df_train.columns = ['bert_' + str(col) for col in bert_df_train.columns]\n",
    "bert_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63b406f-0009-47dc-9194-8582b9610406",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the NLP embedding into a CSV which can be used the training data\n",
    "\n",
    "bert_df_train.to_csv('pytorch_bert_large_uncased_finetuned_valid.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m121",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m121"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
