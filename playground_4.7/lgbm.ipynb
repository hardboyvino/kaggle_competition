{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import ast\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from category_encoders import TargetEncoder\n",
    "from collections import defaultdict\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from lightgbm import LGBMClassifier\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif, RFECV\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold, cross_val_score, StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "experiment_name = 'baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11504798, 12), (7669866, 11))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(r'data\\train.csv')\n",
    "test = pd.read_csv(r'data\\test.csv')\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Vehicle_Age</th>\n",
       "      <th>Vehicle_Damage</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4428844</th>\n",
       "      <td>4428844</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>24573.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7344254</th>\n",
       "      <td>7344254</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4271212</th>\n",
       "      <td>4271212</td>\n",
       "      <td>Male</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>39711.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  Gender  Age  Driving_License  Region_Code  \\\n",
       "4428844  4428844    Male   38                1         17.0   \n",
       "7344254  7344254  Female   38                1         37.0   \n",
       "4271212  4271212    Male   55                1         28.0   \n",
       "\n",
       "         Previously_Insured Vehicle_Age Vehicle_Damage  Annual_Premium  \\\n",
       "4428844                   0    1-2 Year            Yes         24573.0   \n",
       "7344254                   0    1-2 Year            Yes          2630.0   \n",
       "4271212                   1    1-2 Year             No         39711.0   \n",
       "\n",
       "         Policy_Sales_Channel  Vintage  Response  \n",
       "4428844                 124.0      117         1  \n",
       "7344254                 157.0      260         0  \n",
       "4271212                  26.0       78         0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the different feature types and target\n",
    "cat_cols = ['Vehicle_Age']\n",
    "num_cols = ['Age', 'Annual_Premium', 'Vintage']\n",
    "ord_cols = []\n",
    "bin_cols = ['Gender', 'Driving_License', 'Previously_Insured', 'Vehicle_Damage', 'Region_Code', 'Policy_Sales_Channel']\n",
    "needs_dummies = ['Gender', 'Vehicle_Age', 'Vehicle_Damage']\n",
    "drop_cols = ['id']\n",
    "TARGET = 'Response'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Response</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Vehicle_Age_&lt; 1 Year</th>\n",
       "      <th>Vehicle_Age_&gt; 2 Years</th>\n",
       "      <th>Vehicle_Damage_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>65101.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>58911.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>288</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38043.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>31951.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Age  Driving_License  Region_Code  Previously_Insured  Annual_Premium  \\\n",
       "0   0   21                1         35.0                   0         65101.0   \n",
       "1   1   43                1         28.0                   0         58911.0   \n",
       "2   2   25                1         14.0                   1         38043.0   \n",
       "3   3   35                1          1.0                   0          2630.0   \n",
       "4   4   36                1         15.0                   1         31951.0   \n",
       "\n",
       "   Policy_Sales_Channel  Vintage  Response  Gender_Male  Vehicle_Age_< 1 Year  \\\n",
       "0                 124.0      187         0            1                     0   \n",
       "1                  26.0      288         1            1                     0   \n",
       "2                 152.0      254         0            0                     1   \n",
       "3                 156.0       76         0            0                     0   \n",
       "4                 152.0      294         0            0                     0   \n",
       "\n",
       "   Vehicle_Age_> 2 Years  Vehicle_Damage_Yes  \n",
       "0                      0                   1  \n",
       "1                      1                   1  \n",
       "2                      0                   0  \n",
       "3                      0                   1  \n",
       "4                      0                   0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = pd.get_dummies(train, columns=needs_dummies, drop_first=True, dtype='int')\n",
    "ohe_test = pd.get_dummies(test, columns=needs_dummies, drop_first=True, dtype='int')\n",
    "ohe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the features not required\n",
    "ohe_drop = ohe.drop(drop_cols, axis=1)\n",
    "ohe_drop_test = ohe_test.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11504798, 12), (7669866, 11))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_drop.shape, ohe_drop_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11504798 entries, 0 to 11504797\n",
      "Data columns (total 12 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   Age                    int64  \n",
      " 1   Driving_License        int64  \n",
      " 2   Region_Code            float64\n",
      " 3   Previously_Insured     int64  \n",
      " 4   Annual_Premium         float64\n",
      " 5   Policy_Sales_Channel   float64\n",
      " 6   Vintage                int64  \n",
      " 7   Response               int64  \n",
      " 8   Gender_Male            int32  \n",
      " 9   Vehicle_Age_< 1 Year   int32  \n",
      " 10  Vehicle_Age_> 2 Years  int32  \n",
      " 11  Vehicle_Damage_Yes     int32  \n",
      "dtypes: float64(3), int32(4), int64(5)\n",
      "memory usage: 877.7 MB\n"
     ]
    }
   ],
   "source": [
    "ohe_drop.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((575240, 12), (10929558, 12))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize ShuffleSplit\n",
    "# Get 5% of the data as the training data and rest as test\n",
    "sss = StratifiedShuffleSplit(test_size=0.05, random_state=5)\n",
    "\n",
    "# Get indices for the split\n",
    "# Stratification is done on target variable\n",
    "for train_index, test_index in sss.split(ohe_drop, ohe_drop[TARGET]):\n",
    "    train_data = ohe_drop.iloc[test_index]\n",
    "    test_data = ohe_drop.iloc[train_index]\n",
    "\n",
    "train_data.shape, test_data.shape\n",
    "\n",
    "# 1 minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((575240, 11), (575240,), (10929558, 11), (10929558,), (7669866, 11))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign X and y\n",
    "X = train_data.drop(TARGET, axis=1)\n",
    "y = train_data[TARGET]\n",
    "\n",
    "val_X = test_data.drop(TARGET, axis=1)\n",
    "val_y = test_data[TARGET]\n",
    "\n",
    "test_X = ohe_drop_test.copy()\n",
    "\n",
    "X.shape, y.shape, val_X.shape, val_y.shape, test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 10\n",
    "\n",
    "sk10 = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classification models\n",
    "classif_models = [\n",
    "    LGBMClassifier(n_jobs=-1, random_state=5, objective='binary', metric='auc'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classif_evaluate_models(models, X, y, important_features, cv_split, experiment_name):\n",
    "    Model_compare = pd.DataFrame(columns=['Model Name', \n",
    "                                        'Model Parameters', \n",
    "                                        'Model Train ROC AUC', \n",
    "                                        'Model Test ROC AUC', \n",
    "                                        'Model Test ROC AUC Std', \n",
    "                                        'Model Time'])\n",
    "    \n",
    "    def evaluate_model(alg, idx):\n",
    "        if hasattr(alg, 'name'):\n",
    "            model_name = alg.name\n",
    "        else:\n",
    "            model_name = alg.__class__.__name__\n",
    "        features = important_features.get(model_name, [])\n",
    "\n",
    "        # Check if the list of important features is empty\n",
    "        if len(features) == 0:\n",
    "            # If empty, return results with zero values\n",
    "            print(f'Skipping {model_name} due to no important features.')\n",
    "            return {\n",
    "                'Model Name': model_name,\n",
    "                'Model Parameters': str(alg.get_params()),\n",
    "                'Model Train ROC AUC': 0,\n",
    "                'Model Test ROC AUC': 0,\n",
    "                'Model Test ROC AUC Std': 0,\n",
    "                'Model Time': \"0 min 0.00 sec\",\n",
    "            }\n",
    "        \n",
    "        cv_results = cross_validate(alg, \n",
    "                                    X[features], \n",
    "                                    y, cv=cv_split, \n",
    "                                    scoring='roc_auc', \n",
    "                                    return_train_score=True, \n",
    "                                    n_jobs=-1)\n",
    "\n",
    "        # Time formatting\n",
    "        mean_fit_time = cv_results['fit_time'].mean()\n",
    "        minutes, seconds = divmod(mean_fit_time, 60)\n",
    "\n",
    "        # Results population\n",
    "        result = {\n",
    "            'Model Name': model_name,\n",
    "            'Model Parameters': str(alg.get_params()),\n",
    "            'Model Train ROC AUC': cv_results['train_score'].mean(),\n",
    "            'Model Test ROC AUC': cv_results['test_score'].mean(),\n",
    "            'Model Test ROC AUC Std': cv_results['test_score'].std(),\n",
    "            'Model Time': f\"{int(minutes)} min {seconds:.2f} sec\",\n",
    "        }\n",
    "\n",
    "        print(f'Done with {model_name}.')\n",
    "        return result\n",
    "\n",
    "    results_list = []\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(evaluate_model, alg, idx) for idx, alg in enumerate(tqdm(models, desc='Models'))]\n",
    "        for future in tqdm(futures, total=len(futures), desc='Progress'):\n",
    "            result = future.result()\n",
    "            results_list.append(result)\n",
    "\n",
    "    model_compare = pd.DataFrame(results_list)\n",
    "\n",
    "    model_compare.sort_values(by=['Model Test ROC AUC'], ascending=False, inplace=True)\n",
    "    model_compare.to_csv(f'results\\{experiment_name}.csv', index=False)\n",
    "\n",
    "    return model_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_features_classif = {}\n",
    "\n",
    "for model in classif_models:\n",
    "    if hasattr(model, 'name'):\n",
    "        model_name = model.name\n",
    "    else:\n",
    "        model_name = model.__class__.__name__\n",
    "\n",
    "    baseline_features_classif[model_name] = list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11151c2b1ba4738b8eadd58fd6f7ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c46f6f47f4574d949ddea5a48c384f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with LGBMClassifier.\n",
      "CPU times: total: 281 ms\n",
      "Wall time: 40.1 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Model Parameters</th>\n",
       "      <th>Model Train ROC AUC</th>\n",
       "      <th>Model Test ROC AUC</th>\n",
       "      <th>Model Test ROC AUC Std</th>\n",
       "      <th>Model Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>0.875302</td>\n",
       "      <td>0.872437</td>\n",
       "      <td>0.001456</td>\n",
       "      <td>0 min 13.13 sec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model Name                                   Model Parameters  \\\n",
       "0  LGBMClassifier  {'boosting_type': 'gbdt', 'class_weight': None...   \n",
       "\n",
       "   Model Train ROC AUC  Model Test ROC AUC  Model Test ROC AUC Std  \\\n",
       "0             0.875302            0.872437                0.001456   \n",
       "\n",
       "        Model Time  \n",
       "0  0 min 13.13 sec  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "baseline_models_classif = classif_evaluate_models(classif_models, X, y, baseline_features_classif, sk10, f'{experiment_name}')\n",
    "baseline_models_classif\n",
    "\n",
    "# 1 minute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575240, 13)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To ensure the same randomness everytime\n",
    "np.random.seed(5)\n",
    "\n",
    "X_mi = X.copy()\n",
    "\n",
    "# Add random features\n",
    "X_mi['random_feature_continous'] = np.round(np.random.uniform(-2, 2, X.shape[0]), 6)\n",
    "X_mi['random_feature_categorical'] = np.random.randint(1, 8, X.shape[0])\n",
    "X_mi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "random_states = [5, 42, 100, 500]\n",
    "n_neighbors_list = [3, 5, 7, 10, 20]\n",
    "results = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575240, 14)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_and_y = pd.concat([X_mi, y], axis=1)\n",
    "X_and_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with Random State - 5 and N Neighbors - 3\n",
      "Done with Random State - 5 and N Neighbors - 5\n",
      "Done with Random State - 5 and N Neighbors - 7\n",
      "Done with Random State - 5 and N Neighbors - 10\n",
      "Done with Random State - 5 and N Neighbors - 20\n",
      "Done with Random State - 42 and N Neighbors - 3\n",
      "Done with Random State - 42 and N Neighbors - 5\n",
      "Done with Random State - 42 and N Neighbors - 7\n",
      "Done with Random State - 42 and N Neighbors - 10\n",
      "Done with Random State - 42 and N Neighbors - 20\n",
      "Done with Random State - 100 and N Neighbors - 3\n",
      "Done with Random State - 100 and N Neighbors - 5\n",
      "Done with Random State - 100 and N Neighbors - 7\n",
      "Done with Random State - 100 and N Neighbors - 10\n",
      "Done with Random State - 100 and N Neighbors - 20\n",
      "Done with Random State - 500 and N Neighbors - 3\n",
      "Done with Random State - 500 and N Neighbors - 5\n",
      "Done with Random State - 500 and N Neighbors - 7\n",
      "Done with Random State - 500 and N Neighbors - 10\n",
      "Done with Random State - 500 and N Neighbors - 20\n"
     ]
    }
   ],
   "source": [
    "# Calculate MI for each combination of random_state and n_neighbors\n",
    "for random_state in random_states:\n",
    "    for n_neighbors in n_neighbors_list:        \n",
    "        # Calculate MI\n",
    "        mi = mutual_info_classif(X_and_y, y, n_neighbors=n_neighbors, random_state=random_state)\n",
    "        \n",
    "        # Store results if the target has the highest MI score\n",
    "        mi_dict = dict(zip(X_and_y.columns, mi))\n",
    "        if mi_dict[TARGET] == max(mi_dict.values()):\n",
    "            for feature, score in mi_dict.items():\n",
    "                results[feature].append(score)\n",
    "\n",
    "        print(f'Done with Random State - {random_state} and N Neighbors - {n_neighbors}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': 0.034032485249745406,\n",
       " 'Driving_License': 0.04775086363187272,\n",
       " 'Region_Code': 0.015439309607458545,\n",
       " 'Previously_Insured': 0.09483027811047715,\n",
       " 'Annual_Premium': 0.026824669302801373,\n",
       " 'Policy_Sales_Channel': 0.05523408957309643,\n",
       " 'Vintage': 0.013713151325547462,\n",
       " 'Response': 0.3737521932232421,\n",
       " 'Gender_Male': 0.015030648357397609,\n",
       " 'Vehicle_Age_< 1 Year': 0.03723742899271379,\n",
       " 'Vehicle_Age_> 2 Years': 0.004823074203718708,\n",
       " 'Vehicle_Damage_Yes': 0.09153486381832095,\n",
       " 'random_feature_continous': 1.1862574026544337e-05,\n",
       " 'random_feature_categorical': 0.005912755934634073}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average MI scores across valid combinations\n",
    "average_mi = {feature: np.mean(scores) for feature, scores in results.items() if scores}\n",
    "average_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MI scores: [('Response', 0.3737521932232421), ('Previously_Insured', 0.09483027811047715), ('Vehicle_Damage_Yes', 0.09153486381832095), ('Policy_Sales_Channel', 0.05523408957309643), ('Driving_License', 0.04775086363187272), ('Vehicle_Age_< 1 Year', 0.03723742899271379), ('Age', 0.034032485249745406), ('Annual_Premium', 0.026824669302801373), ('Region_Code', 0.015439309607458545), ('Gender_Male', 0.015030648357397609), ('Vintage', 0.013713151325547462), ('random_feature_categorical', 0.005912755934634073), ('Vehicle_Age_> 2 Years', 0.004823074203718708), ('random_feature_continous', 1.1862574026544337e-05)]\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "sorted_mi = sorted(average_mi.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"Average MI scores:\", sorted_mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mutual_info_scores_classif.txt', mode='w') as f:\n",
    "    pprint(sorted_mi, stream=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005912755934634073"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine higher MI between 0 and random_feature\n",
    "higher_threshold = max(0, average_mi.get('random_feature_categorical', 0), average_mi.get('random_feature_continous', 0))\n",
    "higher_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Previously_Insured',\n",
       " 'Vehicle_Damage_Yes',\n",
       " 'Policy_Sales_Channel',\n",
       " 'Driving_License',\n",
       " 'Vehicle_Age_< 1 Year',\n",
       " 'Age',\n",
       " 'Annual_Premium',\n",
       " 'Region_Code',\n",
       " 'Gender_Male',\n",
       " 'Vintage']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List features with MI higher than the threshold, excluding the target\n",
    "mi_features_list = [feature for feature, score in sorted_mi if feature != TARGET and score > higher_threshold]\n",
    "mi_features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_features_reg = {}\n",
    "\n",
    "for model in classif_models:\n",
    "    if hasattr(model, 'name'):\n",
    "        model_name = model.name\n",
    "    else:\n",
    "        model_name = model.__class__.__name__\n",
    "\n",
    "    mi_features_reg[model_name] = mi_features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "042d49c33b7b477aa2c9151440e8f25b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0717c87ae39748d8b53c421d1e1d4e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with LGBMClassifier.\n",
      "CPU times: total: 156 ms\n",
      "Wall time: 34.2 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Model Parameters</th>\n",
       "      <th>Model Train ROC AUC</th>\n",
       "      <th>Model Test ROC AUC</th>\n",
       "      <th>Model Test ROC AUC Std</th>\n",
       "      <th>Model Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>0.873752</td>\n",
       "      <td>0.870728</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0 min 10.29 sec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model Name                                   Model Parameters  \\\n",
       "0  LGBMClassifier  {'boosting_type': 'gbdt', 'class_weight': None...   \n",
       "\n",
       "   Model Train ROC AUC  Model Test ROC AUC  Model Test ROC AUC Std  \\\n",
       "0             0.873752            0.870728                0.001579   \n",
       "\n",
       "        Model Time  \n",
       "0  0 min 10.29 sec  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mi_models_classif = classif_evaluate_models(classif_models, X, y, mi_features_reg, sk10, f'{experiment_name}')\n",
    "mi_models_classif\n",
    "\n",
    "# 1 minute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575240, 13)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To ensure the same randomness everytime\n",
    "np.random.seed(5)\n",
    "\n",
    "X_pi = X.copy()\n",
    "\n",
    "# Add random features\n",
    "X_pi['random_feature_continous'] = np.round(np.random.uniform(-2, 2, X.shape[0]), 6)\n",
    "X_pi['random_feature_categorical'] = np.random.randint(1, 8, X.shape[0])\n",
    "X_pi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with LGBMClassifier.\n",
      "Done with Fold 1\n",
      "\n",
      "Done with LGBMClassifier.\n",
      "Done with Fold 2\n",
      "\n",
      "Done with LGBMClassifier.\n",
      "Done with Fold 3\n",
      "\n",
      "Done with LGBMClassifier.\n",
      "Done with Fold 4\n",
      "\n",
      "Done with LGBMClassifier.\n",
      "Done with Fold 5\n",
      "\n",
      "Done with LGBMClassifier.\n",
      "Done with Fold 6\n",
      "\n",
      "Done with LGBMClassifier.\n",
      "Done with Fold 7\n",
      "\n",
      "Done with LGBMClassifier.\n",
      "Done with Fold 8\n",
      "\n",
      "Done with LGBMClassifier.\n",
      "Done with Fold 9\n",
      "\n",
      "Done with LGBMClassifier.\n",
      "Done with Fold 10\n",
      "\n",
      "CPU times: total: 6min 29s\n",
      "Wall time: 3min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "perm_importances = {model.name if hasattr(model, 'name') else model.__class__.__name__: [] for model in classif_models}\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(sk10.split(X_pi, y)):\n",
    "    X_train, X_test = X_pi.iloc[train_idx], X_pi.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    for model in classif_models:\n",
    "        if hasattr(model, 'name'):\n",
    "            model_name = model.name\n",
    "        else:\n",
    "            model_name = model.__class__.__name__\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        # Calculate permutation importance\n",
    "        result = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=5, scoring='roc_auc')\n",
    "        perm_importances[model_name].append(result.importances_mean)\n",
    "        print(f'Done with {model_name}.')\n",
    "    \n",
    "    print(f'Done with Fold {i+1}', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with Permuation Importances\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 16 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Average importances across folds and export to CSV\n",
    "for model_name, importances in perm_importances.items():\n",
    "    avg_importance = np.mean(importances, axis=0)\n",
    "    importance_df = pd.DataFrame({'Feature': X_pi.columns, 'Importance': avg_importance})\n",
    "    importance_df.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "    \n",
    "    # Export to CSV\n",
    "    importance_df.to_csv(f'.\\permutation_importances\\{model_name}_permutation_importance.csv', index=False)\n",
    "\n",
    "print('Done with Permuation Importances', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LGBMClassifier\n",
      "-3.4111162701040424e-05\n",
      "-2.8302888270164144e-05\n",
      "Threshold: 0\n",
      "Done getting important features dictionary\n"
     ]
    }
   ],
   "source": [
    "directory = 'permutation_importances'\n",
    "\n",
    "# Initialize a dictionary for the features\n",
    "perm_important_features = {}\n",
    "\n",
    "for model in classif_models:\n",
    "    if hasattr(model, 'name'):\n",
    "        model_name = model.name\n",
    "    else:\n",
    "        model_name = model.__class__.__name__\n",
    "    print(f'Model: {model_name}')\n",
    "\n",
    "    csv_path = os.path.join(directory, f'{model_name}_permutation_importance.csv')\n",
    "    if os.path.exists(csv_path):\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Initialize importance variables\n",
    "        random_feature_importance_cont = 0\n",
    "        random_feature_importance_cat = 0\n",
    "        \n",
    "        # Check for 'random_feature_continous' and its importance\n",
    "        if 'random_feature_continous' in df['Feature'].values:\n",
    "            random_feature_importance_cont = df.loc[df['Feature'] == 'random_feature_continous', 'Importance'].iloc[0]\n",
    "            print(random_feature_importance_cont)\n",
    "        if 'random_feature_categorical' in df['Feature'].values:\n",
    "            random_feature_importance_cat = df.loc[df['Feature'] == 'random_feature_categorical', 'Importance'].iloc[0]\n",
    "            print(random_feature_importance_cat)\n",
    "        else:\n",
    "            random_feature_importance = 0\n",
    "\n",
    "        # Determine the threshold\n",
    "        threshold = max(0, random_feature_importance_cont, random_feature_importance_cat)\n",
    "        print(f'Threshold: {threshold}')\n",
    "\n",
    "        # Filter features where importance is greater than 0\n",
    "        important_feats_filtered = df[df['Importance'] > threshold]['Feature'].tolist()\n",
    "\n",
    "        # # Reorder important_feats based on the predefined features_list\n",
    "        # important_feats_ordered = [feat for feat in features_list if feat in important_feats_filtered]\n",
    "\n",
    "        # Add to importance dictionary\n",
    "        perm_important_features[model_name] = important_feats_filtered\n",
    "\n",
    "    else:\n",
    "        print(f'CSV file for {model_name} not found.')\n",
    "\n",
    "print('Done getting important features dictionary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('perm_important_features.txt', mode='w') as f:\n",
    "    pprint(perm_important_features, stream=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bccb0ce831e4f8cb5b6951dfa804b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef46fe146514be3a25ad78755d17232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with LGBMClassifier.\n",
      "CPU times: total: 234 ms\n",
      "Wall time: 32 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Model Parameters</th>\n",
       "      <th>Model Train ROC AUC</th>\n",
       "      <th>Model Test ROC AUC</th>\n",
       "      <th>Model Test ROC AUC Std</th>\n",
       "      <th>Model Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>0.875291</td>\n",
       "      <td>0.872451</td>\n",
       "      <td>0.001403</td>\n",
       "      <td>0 min 9.99 sec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model Name                                   Model Parameters  \\\n",
       "0  LGBMClassifier  {'boosting_type': 'gbdt', 'class_weight': None...   \n",
       "\n",
       "   Model Train ROC AUC  Model Test ROC AUC  Model Test ROC AUC Std  \\\n",
       "0             0.875291            0.872451                0.001403   \n",
       "\n",
       "       Model Time  \n",
       "0  0 min 9.99 sec  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pi_models_classif = classif_evaluate_models(classif_models, X, y, perm_important_features, sk10, f'{experiment_name}_pi')\n",
    "pi_models_classif\n",
    "\n",
    "# 1 minute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with LGBMClassifier\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Done with LGBMClassifier\n",
      "\n",
      "CPU times: total: 7min 34s\n",
      "Wall time: 3min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Initialize empty dictionary for RFECV features\n",
    "rfecv_features = {}\n",
    "\n",
    "for model in classif_models:\n",
    "    if hasattr(model, 'name'):\n",
    "        model_name = model.name\n",
    "    else:\n",
    "        model_name = model.__class__.__name__\n",
    "\t\t\n",
    "    features = baseline_features_classif[model_name]\n",
    "\n",
    "    # incase there is no feature that had importance, go to the next model\n",
    "    if len(features) == 0:\n",
    "        continue\n",
    "\t\n",
    "    X_rfecv = X[features]\n",
    "\n",
    "    try:\n",
    "        print(f'Starting with {model_name}')\n",
    "        # Create the RFECV object and rank each feature\n",
    "        selector = RFECV(model, cv=sk10, step=1, scoring='roc_auc', verbose=2)\n",
    "        selector = selector.fit(X_rfecv, y)\n",
    "\n",
    "        selected_features = list(X_rfecv.columns[selector.support_])\n",
    "\n",
    "        # # Reorder selected_features based on the predefined features_list\n",
    "        # selected_features_ordered = [feat for feat in features_list if feat in selected_features]\n",
    "\n",
    "        rfecv_features[model_name] = selected_features\n",
    "\n",
    "        print(f'Done with {model_name}', end='\\n\\n')\n",
    "    \n",
    "    except ValueError:\n",
    "        # In case of an error, keep the original order but filtered by features_list\n",
    "        features_filtered = [feat for feat in features_list if feat in features]\n",
    "        rfecv_features[model_name] = features_filtered\n",
    "        print(f'{model_name} does not have coef_ or feature_importances_', end='\\n\\n')\n",
    "\n",
    "# 5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rfecv_features.txt', mode='w') as f:\n",
    "    pprint(rfecv_features, stream=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e81ffb58a42246e6a7608ed8796ceaa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53baba94a07b4dd99c6db6c92313d7b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with LGBMClassifier.\n",
      "CPU times: total: 266 ms\n",
      "Wall time: 35.8 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Model Parameters</th>\n",
       "      <th>Model Train ROC AUC</th>\n",
       "      <th>Model Test ROC AUC</th>\n",
       "      <th>Model Test ROC AUC Std</th>\n",
       "      <th>Model Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>0.875302</td>\n",
       "      <td>0.872437</td>\n",
       "      <td>0.001456</td>\n",
       "      <td>0 min 11.10 sec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model Name                                   Model Parameters  \\\n",
       "0  LGBMClassifier  {'boosting_type': 'gbdt', 'class_weight': None...   \n",
       "\n",
       "   Model Train ROC AUC  Model Test ROC AUC  Model Test ROC AUC Std  \\\n",
       "0             0.875302            0.872437                0.001456   \n",
       "\n",
       "        Model Time  \n",
       "0  0 min 11.10 sec  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rfecv_models_classif = classif_evaluate_models(classif_models, X, y, rfecv_features, sk10, f'{experiment_name}_rfecv')\n",
    "rfecv_models_classif\n",
    "\n",
    "# 1 minute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM Validation\n",
    "\n",
    "*Proven to be close to the PL on Kaggle*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(metric=&#x27;auc&#x27;, objective=&#x27;binary&#x27;, random_state=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(metric=&#x27;auc&#x27;, objective=&#x27;binary&#x27;, random_state=5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(metric='auc', objective='binary', random_state=5)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMClassifier(n_jobs=-1, random_state=5, objective='binary', metric='auc')\n",
    "\n",
    "model.fit(X[rfecv_features['LGBMClassifier']], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8721405023726595"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred = model.predict_proba(val_X[rfecv_features['LGBMClassifier']])[:, 1]\n",
    "val_score = roc_auc_score(val_y, val_pred)\n",
    "val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM Submission Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(metric=&#x27;auc&#x27;, objective=&#x27;binary&#x27;, random_state=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(metric=&#x27;auc&#x27;, objective=&#x27;binary&#x27;, random_state=5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(metric='auc', objective='binary', random_state=5)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMClassifier(n_jobs=-1, random_state=5, objective='binary', metric='auc')\n",
    "\n",
    "model.fit(ohe_drop.drop(TARGET, axis=1)[perm_important_features['LGBMClassifier']], ohe_drop[TARGET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_proba(test_X[perm_important_features['LGBMClassifier']])[:, 1]\n",
    "pred_df = pd.DataFrame(pred, columns=[TARGET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.364148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.261249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.035330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Response\n",
       "0  0.014201\n",
       "1  0.364148\n",
       "2  0.261249\n",
       "3  0.000212\n",
       "4  0.035330"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([test['id'], pred_df[TARGET]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7669861</th>\n",
       "      <td>19174659</td>\n",
       "      <td>0.203239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7669862</th>\n",
       "      <td>19174660</td>\n",
       "      <td>0.000288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7669863</th>\n",
       "      <td>19174661</td>\n",
       "      <td>0.000448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7669864</th>\n",
       "      <td>19174662</td>\n",
       "      <td>0.545714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7669865</th>\n",
       "      <td>19174663</td>\n",
       "      <td>0.000227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  Response\n",
       "7669861  19174659  0.203239\n",
       "7669862  19174660  0.000288\n",
       "7669863  19174661  0.000448\n",
       "7669864  19174662  0.545714\n",
       "7669865  19174663  0.000227"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check winning_route.txt for what the result steps are\n",
    "submission.to_csv(r'submissions/experiment_2_lgbm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the different feature types and target\n",
    "cat_cols = ['Vehicle_Age']\n",
    "num_cols = ['Age', 'Annual_Premium', 'Vintage']\n",
    "ord_cols = []\n",
    "bin_cols = ['Gender', 'Driving_License', 'Previously_Insured', 'Vehicle_Damage', 'Region_Code', 'Policy_Sales_Channel']\n",
    "needs_dummies = ['Gender', 'Vehicle_Age', 'Vehicle_Damage']\n",
    "drop_cols = ['id']\n",
    "TARGET = 'Response'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575240, 12)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize ShuffleSplit\n",
    "# Get 5% of the data as the training data and rest as test\n",
    "sss = StratifiedShuffleSplit(test_size=0.05, random_state=5)\n",
    "\n",
    "# Get indices for the split\n",
    "# Stratification is done on target variable\n",
    "for train_index, test_index in sss.split(train, train[TARGET]):\n",
    "    autogluon_train_data = train.iloc[test_index]\n",
    "    # test_data = ohe_drop.iloc[train_index]\n",
    "\n",
    "train_data.shape\n",
    "# 1 minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Vehicle_Age</th>\n",
       "      <th>Vehicle_Damage</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2698469</th>\n",
       "      <td>Male</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>43134.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7618126</th>\n",
       "      <td>Male</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>44346.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10678</th>\n",
       "      <td>Male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>27173.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10177923</th>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>52740.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5137129</th>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>26127.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Gender  Age Driving_License Region_Code Previously_Insured  \\\n",
       "2698469     Male   53               1        28.0                  1   \n",
       "7618126     Male   52               1        28.0                  0   \n",
       "10678       Male   22               1        28.0                  0   \n",
       "10177923  Female   42               1        28.0                  0   \n",
       "5137129     Male   27               1         6.0                  1   \n",
       "\n",
       "         Vehicle_Age Vehicle_Damage  Annual_Premium Policy_Sales_Channel  \\\n",
       "2698469     1-2 Year             No         43134.0                 26.0   \n",
       "7618126     1-2 Year            Yes         44346.0                 26.0   \n",
       "10678       < 1 Year            Yes         27173.0                152.0   \n",
       "10177923    1-2 Year            Yes         52740.0                 26.0   \n",
       "5137129     < 1 Year             No         26127.0                152.0   \n",
       "\n",
       "          Vintage  Response  \n",
       "2698469       107         0  \n",
       "7618126       258         0  \n",
       "10678         271         0  \n",
       "10177923       98         0  \n",
       "5137129       254         0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop Unneeded column\n",
    "autogluon_train_data = autogluon_train_data.drop(drop_cols, axis=1)\n",
    "autogluon_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force convert to categorical\n",
    "for col in cat_cols + bin_cols:\n",
    "    autogluon_train_data[col] = autogluon_train_data[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 575240 entries, 2698469 to 4633953\n",
      "Data columns (total 11 columns):\n",
      " #   Column                Non-Null Count   Dtype   \n",
      "---  ------                --------------   -----   \n",
      " 0   Gender                575240 non-null  category\n",
      " 1   Age                   575240 non-null  int64   \n",
      " 2   Driving_License       575240 non-null  category\n",
      " 3   Region_Code           575240 non-null  category\n",
      " 4   Previously_Insured    575240 non-null  category\n",
      " 5   Vehicle_Age           575240 non-null  category\n",
      " 6   Vehicle_Damage        575240 non-null  category\n",
      " 7   Annual_Premium        575240 non-null  float64 \n",
      " 8   Policy_Sales_Channel  575240 non-null  category\n",
      " 9   Vintage               575240 non-null  int64   \n",
      " 10  Response              575240 non-null  int64   \n",
      "dtypes: category(7), float64(1), int64(3)\n",
      "memory usage: 26.3 MB\n"
     ]
    }
   ],
   "source": [
    "autogluon_train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_LIMIT = 60\n",
    "\n",
    "def delete_autogluon_file():\n",
    "    directory = 'AutogluonModels'\n",
    "    filelist = [f for f in os.listdir(directory)]\n",
    "    for file in filelist:\n",
    "        file_path = os.path.join(directory, file)\n",
    "        # Check if the file is a regular file\n",
    "        if os.path.isfile(file_path):\n",
    "            # Delete the file\n",
    "            os.remove(file_path)\n",
    "        # Check if the file is a directory\n",
    "        elif os.path.isdir(file_path):\n",
    "            # Delete the directory and its contents recursively\n",
    "            shutil.rmtree(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_columns = set(X.columns) - set(test_X.columns)\n",
    "missing_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11504798, 12), (7669866, 11), (575240, 12), (10929558, 12))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_drop.shape, ohe_drop_test.shape, train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20240716_172437\\\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Train data shape: (517716, 11), Test data shape: (57524, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tWarning: Reducing model 'n_estimators' from 300 -> 226 due to low memory. Expected memory usage reduced from 19.9% -> 15.0% of available memory...\n",
      "\tWarning: Reducing model 'n_estimators' from 226 -> 184 due to low time. Expected time usage reduced from 56.5s -> 46.1s...\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 214 due to low memory. Expected memory usage reduced from 21.0% -> 15.0% of available memory...\n",
      "\tWarning: Model is expected to require 68.8s to train, which exceeds the maximum time limit of 9.9s, skipping model...\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 219 due to low memory. Expected memory usage reduced from 20.53% -> 15.0% of available memory...\n",
      "\tWarning: Model is expected to require 30.8s to train, which exceeds the maximum time limit of 0.4s, skipping model...\n",
      "Insufficient time to train even a single feature pruning model (remaining: 0, needed: 4.104083776473999). Skipping feature pruning.\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Adeniyi Babalola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:173\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, None, None), 1)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m predictor\u001b[38;5;241m.\u001b[39mfit(train_data\u001b[38;5;241m=\u001b[39mauto_train_data,\n\u001b[0;32m     17\u001b[0m               presets\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedium_quality\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m               time_limit\u001b[38;5;241m=\u001b[39mTIME_LIMIT,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m               feature_prune_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforce_prune\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Get the prediction\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m performance \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauto_train_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTARGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Calculate roc\u001b[39;00m\n\u001b[0;32m     29\u001b[0m roc \u001b[38;5;241m=\u001b[39m roc_auc_score(auto_test_data[TARGET], performance)\n",
      "File \u001b[1;32mc:\\Users\\Adeniyi Babalola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Adeniyi Babalola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3817\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> 3817\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_indexing_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3818\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Adeniyi Babalola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6059\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   6055\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   6056\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   6057\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   6058\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 6059\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(None, None, None), 1)"
     ]
    }
   ],
   "source": [
    "autogluon_roc_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(sk10.split(X, y)):\n",
    "    # Split the dataset into train and test sets\n",
    "    auto_train_data = autogluon_train_data.iloc[train_index]\n",
    "    auto_test_data = autogluon_train_data.iloc[test_index]\n",
    "\n",
    "    # Print the shapes of train and test data for debugging\n",
    "    print(f'Fold {fold + 1} - Train data shape: {auto_train_data.shape}, Test data shape: {auto_test_data.shape}')\n",
    "\n",
    "    predictor = TabularPredictor(problem_type='binary', \n",
    "                                 label=TARGET, \n",
    "                                 eval_metric='roc_auc', \n",
    "                                 verbosity=1)\n",
    "\n",
    "    predictor.fit(train_data=auto_train_data,\n",
    "                  presets='medium_quality',\n",
    "                  time_limit=TIME_LIMIT,\n",
    "                  # num_bag_folds=5, \n",
    "                  # num_bag_sets=1, \n",
    "                  # num_stack_levels=3,\n",
    "                  feature_prune_kwargs={'force_prune': True}\n",
    "    )\n",
    "\n",
    "    # Get the prediction\n",
    "    performance = predictor.predict_proba(auto_train_data.drop(TARGET, axis=1))[:, 1]\n",
    "\n",
    "    # Calculate roc\n",
    "    roc = roc_auc_score(auto_test_data[TARGET], performance)\n",
    "\n",
    "    print(f'Autogluon Fold {fold + 1} - ROC: {roc}')\n",
    "    print()\n",
    "\n",
    "    autogluon_roc_scores.append(roc)\n",
    "\n",
    "    # Delete the models because of memory\n",
    "    delete_autogluon_file()\n",
    "\n",
    "# Print the ROC AUC scores for each fold\n",
    "print('Autogluon ROC Mean:', np.mean(autogluon_roc_scores))\n",
    "print('Autogluon ROC STD:', np.std(autogluon_roc_scores))\n",
    "\n",
    "# Autogluon Fold 1 - roc: \n",
    "# Autogluon Fold 2 - roc: \n",
    "# Autogluon Fold 3 - roc: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
