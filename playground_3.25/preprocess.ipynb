{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import median_absolute_error, make_scorer\n",
    "\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor, GradientBoostingRegressor, RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.linear_model import LogisticRegression, RidgeCV, PassiveAggressiveRegressor, SGDRegressor, Perceptron, LinearRegression, TheilSenRegressor, HuberRegressor, RANSACRegressor, Lasso, ElasticNet, Lars, LassoLars, OrthogonalMatchingPursuit, BayesianRidge, ARDRegression, TweedieRegressor, PoissonRegressor, GammaRegressor, LassoLars\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "experiment = 'add_pre_extratress_model'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <th>density_Total</th>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <th>val_e_Average</th>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <th>zaratio_Average</th>\n",
       "      <th>density_Average</th>\n",
       "      <th>Hardness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.841611</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>20.612526</td>\n",
       "      <td>11.08810</td>\n",
       "      <td>2.766</td>\n",
       "      <td>1.732</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.496070</td>\n",
       "      <td>0.91457</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.558488</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>20.298893</td>\n",
       "      <td>12.04083</td>\n",
       "      <td>2.755</td>\n",
       "      <td>1.631</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.492719</td>\n",
       "      <td>0.71760</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>76.0</td>\n",
       "      <td>8.885992</td>\n",
       "      <td>15.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>33.739258</td>\n",
       "      <td>12.08630</td>\n",
       "      <td>2.828</td>\n",
       "      <td>1.788</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.481478</td>\n",
       "      <td>1.50633</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.795296</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>20.213349</td>\n",
       "      <td>10.94850</td>\n",
       "      <td>2.648</td>\n",
       "      <td>1.626</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.489272</td>\n",
       "      <td>0.78937</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>9.577996</td>\n",
       "      <td>11.6</td>\n",
       "      <td>4.8</td>\n",
       "      <td>24.988133</td>\n",
       "      <td>11.82448</td>\n",
       "      <td>2.766</td>\n",
       "      <td>1.682</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.492736</td>\n",
       "      <td>1.86481</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  allelectrons_Total  density_Total  allelectrons_Average  val_e_Average  \\\n",
       "0   0               100.0       0.841611                  10.0            4.8   \n",
       "1   1               100.0       7.558488                  10.0            4.8   \n",
       "2   2                76.0       8.885992                  15.6            5.6   \n",
       "3   3               100.0       8.795296                  10.0            4.8   \n",
       "4   4               116.0       9.577996                  11.6            4.8   \n",
       "\n",
       "   atomicweight_Average  ionenergy_Average  el_neg_chi_Average  \\\n",
       "0             20.612526           11.08810               2.766   \n",
       "1             20.298893           12.04083               2.755   \n",
       "2             33.739258           12.08630               2.828   \n",
       "3             20.213349           10.94850               2.648   \n",
       "4             24.988133           11.82448               2.766   \n",
       "\n",
       "   R_vdw_element_Average  R_cov_element_Average  zaratio_Average  \\\n",
       "0                  1.732                  0.860         0.496070   \n",
       "1                  1.631                  0.910         0.492719   \n",
       "2                  1.788                  0.864         0.481478   \n",
       "3                  1.626                  0.936         0.489272   \n",
       "4                  1.682                  0.896         0.492736   \n",
       "\n",
       "   density_Average  Hardness  \n",
       "0          0.91457       6.0  \n",
       "1          0.71760       6.5  \n",
       "2          1.50633       2.5  \n",
       "3          0.78937       6.0  \n",
       "4          1.86481       6.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "artificial = pd.read_csv('Artificial_Crystals_Dataset.csv')\n",
    "mineral = pd.read_csv('Mineral_Dataset_Supplementary_Info.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hardness</th>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <th>density_Total</th>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <th>val_e_Average</th>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <th>zaratio_Average</th>\n",
       "      <th>density_Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.5</td>\n",
       "      <td>167.0</td>\n",
       "      <td>23.907992</td>\n",
       "      <td>18.555556</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>41.609136</td>\n",
       "      <td>11.693844</td>\n",
       "      <td>2.938889</td>\n",
       "      <td>1.711111</td>\n",
       "      <td>0.884444</td>\n",
       "      <td>0.477830</td>\n",
       "      <td>2.656444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.740168</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>8.773227</td>\n",
       "      <td>11.614333</td>\n",
       "      <td>1.903333</td>\n",
       "      <td>1.310000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.825990</td>\n",
       "      <td>0.580056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.5</td>\n",
       "      <td>102.0</td>\n",
       "      <td>8.511159</td>\n",
       "      <td>4.434783</td>\n",
       "      <td>3.304348</td>\n",
       "      <td>8.440584</td>\n",
       "      <td>13.176622</td>\n",
       "      <td>2.672609</td>\n",
       "      <td>1.379130</td>\n",
       "      <td>0.530870</td>\n",
       "      <td>0.713850</td>\n",
       "      <td>0.370050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.5</td>\n",
       "      <td>78.0</td>\n",
       "      <td>8.109328</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>27.448814</td>\n",
       "      <td>11.826400</td>\n",
       "      <td>2.960000</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.488163</td>\n",
       "      <td>1.351555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.5</td>\n",
       "      <td>164.0</td>\n",
       "      <td>19.921324</td>\n",
       "      <td>14.909091</td>\n",
       "      <td>5.090909</td>\n",
       "      <td>32.012361</td>\n",
       "      <td>11.255573</td>\n",
       "      <td>2.881818</td>\n",
       "      <td>1.640909</td>\n",
       "      <td>0.841818</td>\n",
       "      <td>0.483480</td>\n",
       "      <td>1.811029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hardness  allelectrons_Total  density_Total  allelectrons_Average  \\\n",
       "0       4.5               167.0      23.907992             18.555556   \n",
       "1       4.0                14.0       1.740168              4.666667   \n",
       "2       2.5               102.0       8.511159              4.434783   \n",
       "3       5.5                78.0       8.109328             13.000000   \n",
       "4       6.5               164.0      19.921324             14.909091   \n",
       "\n",
       "   val_e_Average  atomicweight_Average  ionenergy_Average  el_neg_chi_Average  \\\n",
       "0       5.000000             41.609136          11.693844            2.938889   \n",
       "1       1.333333              8.773227          11.614333            1.903333   \n",
       "2       3.304348              8.440584          13.176622            2.672609   \n",
       "3       5.333333             27.448814          11.826400            2.960000   \n",
       "4       5.090909             32.012361          11.255573            2.881818   \n",
       "\n",
       "   R_vdw_element_Average  R_cov_element_Average  zaratio_Average  \\\n",
       "0               1.711111               0.884444         0.477830   \n",
       "1               1.310000               0.680000         0.825990   \n",
       "2               1.379130               0.530870         0.713850   \n",
       "3               1.625000               0.813333         0.488163   \n",
       "4               1.640909               0.841818         0.483480   \n",
       "\n",
       "   density_Average  \n",
       "0         2.656444  \n",
       "1         0.580056  \n",
       "2         0.370050  \n",
       "3         1.351555  \n",
       "4         1.811029  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename hardness in artifical dataset and drop columns not required\n",
    "artificial.rename(columns={'Hardness (Mohs)': 'Hardness'}, inplace=True)\n",
    "artificial.drop(['Formula', 'Crystal structure', 'Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "artificial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hardness</th>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <th>density_Total</th>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <th>val_e_Average</th>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <th>zaratio_Average</th>\n",
       "      <th>density_Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.3</td>\n",
       "      <td>110.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>36.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>82.598467</td>\n",
       "      <td>8.504133</td>\n",
       "      <td>2.146667</td>\n",
       "      <td>2.006667</td>\n",
       "      <td>1.253333</td>\n",
       "      <td>0.456803</td>\n",
       "      <td>7.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.5</td>\n",
       "      <td>406.0</td>\n",
       "      <td>30.472136</td>\n",
       "      <td>9.902439</td>\n",
       "      <td>4.682927</td>\n",
       "      <td>19.813180</td>\n",
       "      <td>11.456151</td>\n",
       "      <td>2.700244</td>\n",
       "      <td>1.676829</td>\n",
       "      <td>0.868293</td>\n",
       "      <td>0.522909</td>\n",
       "      <td>0.743223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.5</td>\n",
       "      <td>406.0</td>\n",
       "      <td>30.472464</td>\n",
       "      <td>10.410256</td>\n",
       "      <td>4.923077</td>\n",
       "      <td>20.931371</td>\n",
       "      <td>11.541405</td>\n",
       "      <td>2.753590</td>\n",
       "      <td>1.703846</td>\n",
       "      <td>0.894359</td>\n",
       "      <td>0.497498</td>\n",
       "      <td>0.781345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.5</td>\n",
       "      <td>476.0</td>\n",
       "      <td>61.142136</td>\n",
       "      <td>11.609756</td>\n",
       "      <td>4.682927</td>\n",
       "      <td>23.659644</td>\n",
       "      <td>11.487395</td>\n",
       "      <td>2.763659</td>\n",
       "      <td>1.714634</td>\n",
       "      <td>0.848780</td>\n",
       "      <td>0.519474</td>\n",
       "      <td>1.491272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.5</td>\n",
       "      <td>476.0</td>\n",
       "      <td>61.142464</td>\n",
       "      <td>12.205128</td>\n",
       "      <td>4.923077</td>\n",
       "      <td>24.975089</td>\n",
       "      <td>11.574251</td>\n",
       "      <td>2.820256</td>\n",
       "      <td>1.743590</td>\n",
       "      <td>0.873846</td>\n",
       "      <td>0.493887</td>\n",
       "      <td>1.567755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hardness  allelectrons_Total  density_Total  allelectrons_Average  \\\n",
       "0       2.3               110.0      23.000000             36.666667   \n",
       "1       5.5               406.0      30.472136              9.902439   \n",
       "2       5.5               406.0      30.472464             10.410256   \n",
       "3       5.5               476.0      61.142136             11.609756   \n",
       "4       5.5               476.0      61.142464             12.205128   \n",
       "\n",
       "   val_e_Average  atomicweight_Average  ionenergy_Average  el_neg_chi_Average  \\\n",
       "0       2.666667             82.598467           8.504133            2.146667   \n",
       "1       4.682927             19.813180          11.456151            2.700244   \n",
       "2       4.923077             20.931371          11.541405            2.753590   \n",
       "3       4.682927             23.659644          11.487395            2.763659   \n",
       "4       4.923077             24.975089          11.574251            2.820256   \n",
       "\n",
       "   R_vdw_element_Average  R_cov_element_Average  zaratio_Average  \\\n",
       "0               2.006667               1.253333         0.456803   \n",
       "1               1.676829               0.868293         0.522909   \n",
       "2               1.703846               0.894359         0.497498   \n",
       "3               1.714634               0.848780         0.519474   \n",
       "4               1.743590               0.873846         0.493887   \n",
       "\n",
       "   density_Average  \n",
       "0         7.666667  \n",
       "1         0.743223  \n",
       "2         0.781345  \n",
       "3         1.491272  \n",
       "4         1.567755  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unneeded columns\n",
    "mineral.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "mineral.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10407, 13), (52, 12), (622, 12))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, artificial.shape, mineral.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.concat([train, artificial, mineral], axis=0)\n",
    "# train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <th>density_Total</th>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <th>val_e_Average</th>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <th>zaratio_Average</th>\n",
       "      <th>density_Average</th>\n",
       "      <th>Hardness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10402</th>\n",
       "      <td>10402</td>\n",
       "      <td>128.0</td>\n",
       "      <td>7.558488</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>26.385218</td>\n",
       "      <td>11.330440</td>\n",
       "      <td>2.644000</td>\n",
       "      <td>1.631000</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.496070</td>\n",
       "      <td>1.79607</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10403</th>\n",
       "      <td>10403</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.743160</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>20.766935</td>\n",
       "      <td>14.163933</td>\n",
       "      <td>3.090000</td>\n",
       "      <td>1.556667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.480390</td>\n",
       "      <td>0.81480</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10404</th>\n",
       "      <td>10404</td>\n",
       "      <td>196.0</td>\n",
       "      <td>30.920000</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>53.490297</td>\n",
       "      <td>10.074300</td>\n",
       "      <td>2.295000</td>\n",
       "      <td>1.545000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>0.469715</td>\n",
       "      <td>2.11540</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10405</th>\n",
       "      <td>10405</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.553160</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>26.621687</td>\n",
       "      <td>11.290033</td>\n",
       "      <td>2.743333</td>\n",
       "      <td>1.756667</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.486507</td>\n",
       "      <td>0.77755</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10406</th>\n",
       "      <td>10406</td>\n",
       "      <td>288.0</td>\n",
       "      <td>24.655328</td>\n",
       "      <td>11.142857</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>22.536126</td>\n",
       "      <td>10.960357</td>\n",
       "      <td>2.792143</td>\n",
       "      <td>1.772857</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.493919</td>\n",
       "      <td>0.97737</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  allelectrons_Total  density_Total  allelectrons_Average  \\\n",
       "10402  10402               128.0       7.558488             12.000000   \n",
       "10403  10403                30.0       1.743160             10.000000   \n",
       "10404  10404               196.0      30.920000             24.500000   \n",
       "10405  10405                38.0       1.553160             12.666667   \n",
       "10406  10406               288.0      24.655328             11.142857   \n",
       "\n",
       "       val_e_Average  atomicweight_Average  ionenergy_Average  \\\n",
       "10402       4.000000             26.385218          11.330440   \n",
       "10403       5.333333             20.766935          14.163933   \n",
       "10404       5.500000             53.490297          10.074300   \n",
       "10405       4.666667             26.621687          11.290033   \n",
       "10406       4.571429             22.536126          10.960357   \n",
       "\n",
       "       el_neg_chi_Average  R_vdw_element_Average  R_cov_element_Average  \\\n",
       "10402            2.644000               1.631000               0.892000   \n",
       "10403            3.090000               1.556667               0.866667   \n",
       "10404            2.295000               1.545000               1.120000   \n",
       "10405            2.743333               1.756667               0.980000   \n",
       "10406            2.792143               1.772857               0.940000   \n",
       "\n",
       "       zaratio_Average  density_Average  Hardness  \n",
       "10402         0.496070          1.79607       4.0  \n",
       "10403         0.480390          0.81480       5.0  \n",
       "10404         0.469715          2.11540       1.8  \n",
       "10405         0.486507          0.77755       6.0  \n",
       "10406         0.493919          0.97737       6.5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>1%</th>\n",
       "      <th>50%</th>\n",
       "      <th>99%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>5203.000000</td>\n",
       "      <td>3004.386460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.060000</td>\n",
       "      <td>5203.000000</td>\n",
       "      <td>10301.940000</td>\n",
       "      <td>10406.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>128.053516</td>\n",
       "      <td>224.123776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>719.400000</td>\n",
       "      <td>15300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density_Total</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>14.491342</td>\n",
       "      <td>15.972877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.739942</td>\n",
       "      <td>10.650000</td>\n",
       "      <td>75.098979</td>\n",
       "      <td>643.093804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>17.033222</td>\n",
       "      <td>10.468734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_e_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>4.546789</td>\n",
       "      <td>0.690864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>37.507703</td>\n",
       "      <td>26.012313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.773227</td>\n",
       "      <td>26.203827</td>\n",
       "      <td>119.629500</td>\n",
       "      <td>167.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>10.938308</td>\n",
       "      <td>1.408276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.054000</td>\n",
       "      <td>11.202760</td>\n",
       "      <td>13.512520</td>\n",
       "      <td>15.245810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>2.607662</td>\n",
       "      <td>0.334906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>2.706000</td>\n",
       "      <td>2.980000</td>\n",
       "      <td>3.443000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>1.731330</td>\n",
       "      <td>0.192481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.318667</td>\n",
       "      <td>1.732727</td>\n",
       "      <td>2.055000</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>0.944132</td>\n",
       "      <td>0.180017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.505333</td>\n",
       "      <td>0.915556</td>\n",
       "      <td>1.390000</td>\n",
       "      <td>1.615840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zaratio_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>0.493349</td>\n",
       "      <td>0.063080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.405373</td>\n",
       "      <td>0.488550</td>\n",
       "      <td>0.707253</td>\n",
       "      <td>0.825990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>2.132984</td>\n",
       "      <td>1.936656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132734</td>\n",
       "      <td>1.351550</td>\n",
       "      <td>7.986670</td>\n",
       "      <td>10.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hardness</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>4.647126</td>\n",
       "      <td>1.680525</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>8.288000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count         mean          std  min          1%  \\\n",
       "id                     10407.0  5203.000000  3004.386460  0.0  104.060000   \n",
       "allelectrons_Total     10407.0   128.053516   224.123776  0.0    6.000000   \n",
       "density_Total          10407.0    14.491342    15.972877  0.0    0.739942   \n",
       "allelectrons_Average   10407.0    17.033222    10.468734  0.0    4.666667   \n",
       "val_e_Average          10407.0     4.546789     0.690864  0.0    2.000000   \n",
       "atomicweight_Average   10407.0    37.507703    26.012313  0.0    8.773227   \n",
       "ionenergy_Average      10407.0    10.938308     1.408276  0.0    8.054000   \n",
       "el_neg_chi_Average     10407.0     2.607662     0.334906  0.0    1.790000   \n",
       "R_vdw_element_Average  10407.0     1.731330     0.192481  0.0    1.318667   \n",
       "R_cov_element_Average  10407.0     0.944132     0.180017  0.0    0.505333   \n",
       "zaratio_Average        10407.0     0.493349     0.063080  0.0    0.405373   \n",
       "density_Average        10407.0     2.132984     1.936656  0.0    0.132734   \n",
       "Hardness               10407.0     4.647126     1.680525  1.0    1.500000   \n",
       "\n",
       "                               50%           99%           max  \n",
       "id                     5203.000000  10301.940000  10406.000000  \n",
       "allelectrons_Total      100.000000    719.400000  15300.000000  \n",
       "density_Total            10.650000     75.098979    643.093804  \n",
       "allelectrons_Average     12.600000     50.000000     67.000000  \n",
       "val_e_Average             4.714286      5.666667      6.000000  \n",
       "atomicweight_Average     26.203827    119.629500    167.400000  \n",
       "ionenergy_Average        11.202760     13.512520     15.245810  \n",
       "el_neg_chi_Average        2.706000      2.980000      3.443000  \n",
       "R_vdw_element_Average     1.732727      2.055000      2.250000  \n",
       "R_cov_element_Average     0.915556      1.390000      1.615840  \n",
       "zaratio_Average           0.488550      0.707253      0.825990  \n",
       "density_Average           1.351550      7.986670     10.970000  \n",
       "Hardness                  5.500000      8.288000     10.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe([0.01, 0.99]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "TARGET = 'Hardness'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['allelectrons_Total', 'density_Total', 'allelectrons_Average',\n",
      "       'val_e_Average', 'atomicweight_Average', 'ionenergy_Average',\n",
      "       'el_neg_chi_Average', 'R_vdw_element_Average', 'R_cov_element_Average',\n",
      "       'zaratio_Average', 'density_Average'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Selecting numerical variables from the train dataset, excluding 'id' and TARGET\n",
    "num_var = train.drop(['id', TARGET], axis=1).select_dtypes(include=np.number).columns\n",
    "print(num_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining train and test datasets for comparative analysis\n",
    "# 'Source' column is added to label data from each dataset\n",
    "df = pd.concat([\n",
    "    train[num_var].assign(Source='Train'), \n",
    "    test[num_var].assign(Source='Test')\n",
    "], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature name: allelectrons_Total\n",
      "Low Limit: -1064.1000000000076\n",
      "Upper Limit: 1789.5000000000127\n",
      "\n",
      "Feature name: density_Total\n",
      "Low Limit: -109.70094011562419\n",
      "Upper Limit: 184.80760706937366\n",
      "\n",
      "Feature name: allelectrons_Average\n",
      "Low Limit: -63.333333333333336\n",
      "Upper Limit: 118.0\n",
      "\n",
      "Feature name: val_e_Average\n",
      "Low Limit: -3.5000000000000018\n",
      "Upper Limit: 11.16666666666667\n",
      "\n",
      "Feature name: atomicweight_Average\n",
      "Low Limit: -157.51118333333332\n",
      "Upper Limit: 285.91391\n",
      "\n",
      "Feature name: ionenergy_Average\n",
      "Low Limit: -0.1337799999999998\n",
      "Upper Limit: 21.7003\n",
      "\n",
      "Feature name: el_neg_chi_Average\n",
      "Low Limit: 0.0050000000000001155\n",
      "Upper Limit: 4.765\n",
      "\n",
      "Feature name: R_vdw_element_Average\n",
      "Low Limit: 0.37229797979797974\n",
      "Upper Limit: 3.0646212121212124\n",
      "\n",
      "Feature name: R_cov_element_Average\n",
      "Low Limit: -0.6014419504643963\n",
      "Upper Limit: 2.5848651702786376\n",
      "\n",
      "Feature name: zaratio_Average\n",
      "Low Limit: 0.005794696969696755\n",
      "Upper Limit: 1.1281555050505054\n",
      "\n",
      "Feature name: density_Average\n",
      "Low Limit: -11.638980000000002\n",
      "Upper Limit: 19.76206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for outliers\n",
    "def outlier_thresholds(dataframe, col_name, q1=0.01, q3=0.99):\n",
    "    quartile1 = dataframe[col_name].quantile(q1)\n",
    "    quartile3 = dataframe[col_name].quantile(q3)\n",
    "    IQR = quartile3 - quartile1\n",
    "    up_limit = quartile3 + 1.5 * IQR\n",
    "    low_limit = quartile1 - 1.5 * IQR\n",
    "    print(f'Feature name: {col_name}')\n",
    "    print(f'Low Limit: {low_limit}')\n",
    "    print(f'Upper Limit: {up_limit}')\n",
    "    print()\n",
    "    return low_limit, up_limit\n",
    "\n",
    "\n",
    "def remove_outlier(dataframe, col_name):\n",
    "    \"\"\"\n",
    "    Example Usage:\n",
    "    for col in num_cols:\n",
    "    new_df = remove_outlier(titanic, col)\n",
    "    \"\"\"\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n",
    "    df_without_outliers = dataframe[~((dataframe[col_name] < low_limit) | (dataframe[col_name] > up_limit))]    \n",
    "    return df_without_outliers\n",
    "\n",
    "def cap_outliers(dataframe, col_name):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n",
    "\n",
    "    dataframe[col_name] = np.where(dataframe[col_name] > up_limit, up_limit, \n",
    "                                   np.where(dataframe[col_name] < low_limit, low_limit, dataframe[col_name]))\n",
    "    return dataframe\n",
    "\n",
    "df_outliers = train.copy()\n",
    "for col in num_var:\n",
    "    df_outliers = remove_outlier(df_outliers, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>1%</th>\n",
       "      <th>50%</th>\n",
       "      <th>99%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>5201.192420</td>\n",
       "      <td>3005.129652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>106.150000</td>\n",
       "      <td>5201.500000</td>\n",
       "      <td>10300.850000</td>\n",
       "      <td>10406.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>124.139079</td>\n",
       "      <td>109.999695</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>622.000000</td>\n",
       "      <td>1266.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density_Total</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>14.469886</td>\n",
       "      <td>14.249258</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.973995</td>\n",
       "      <td>10.803992</td>\n",
       "      <td>73.958979</td>\n",
       "      <td>178.74200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>17.161600</td>\n",
       "      <td>10.400841</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>5.520000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>67.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_e_Average</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>4.578703</td>\n",
       "      <td>0.580486</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>6.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>37.792042</td>\n",
       "      <td>25.897682</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>10.895366</td>\n",
       "      <td>26.203827</td>\n",
       "      <td>119.629500</td>\n",
       "      <td>167.40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>11.017059</td>\n",
       "      <td>1.058323</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>8.213150</td>\n",
       "      <td>11.217767</td>\n",
       "      <td>13.512520</td>\n",
       "      <td>15.24581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>2.625121</td>\n",
       "      <td>0.260140</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>2.706000</td>\n",
       "      <td>2.980000</td>\n",
       "      <td>3.44300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>1.742674</td>\n",
       "      <td>0.131928</td>\n",
       "      <td>1.028000</td>\n",
       "      <td>1.385714</td>\n",
       "      <td>1.733958</td>\n",
       "      <td>2.055000</td>\n",
       "      <td>2.25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>0.951067</td>\n",
       "      <td>0.161130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.612174</td>\n",
       "      <td>0.918000</td>\n",
       "      <td>1.390000</td>\n",
       "      <td>1.61584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zaratio_Average</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>0.496283</td>\n",
       "      <td>0.050363</td>\n",
       "      <td>0.401635</td>\n",
       "      <td>0.426680</td>\n",
       "      <td>0.488550</td>\n",
       "      <td>0.707270</td>\n",
       "      <td>0.82599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density_Average</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>2.146405</td>\n",
       "      <td>1.938989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136410</td>\n",
       "      <td>1.363050</td>\n",
       "      <td>7.986670</td>\n",
       "      <td>10.97000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hardness</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>4.662606</td>\n",
       "      <td>1.671795</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>8.470000</td>\n",
       "      <td>10.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count         mean          std       min  \\\n",
       "id                     10316.0  5201.192420  3005.129652  0.000000   \n",
       "allelectrons_Total     10316.0   124.139079   109.999695  0.001000   \n",
       "density_Total          10316.0    14.469886    14.249258  0.001000   \n",
       "allelectrons_Average   10316.0    17.161600    10.400841  0.001000   \n",
       "val_e_Average          10316.0     4.578703     0.580486  1.333333   \n",
       "atomicweight_Average   10316.0    37.792042    25.897682  0.001000   \n",
       "ionenergy_Average      10316.0    11.017059     1.058323  0.000167   \n",
       "el_neg_chi_Average     10316.0     2.625121     0.260140  1.666667   \n",
       "R_vdw_element_Average  10316.0     1.742674     0.131928  1.028000   \n",
       "R_cov_element_Average  10316.0     0.951067     0.161130  0.000000   \n",
       "zaratio_Average        10316.0     0.496283     0.050363  0.401635   \n",
       "density_Average        10316.0     2.146405     1.938989  0.000000   \n",
       "Hardness               10316.0     4.662606     1.671795  1.000000   \n",
       "\n",
       "                               1%          50%           99%          max  \n",
       "id                     106.150000  5201.500000  10300.850000  10406.00000  \n",
       "allelectrons_Total      20.000000   100.000000    622.000000   1266.00000  \n",
       "density_Total            0.973995    10.803992     73.958979    178.74200  \n",
       "allelectrons_Average     5.520000    12.600000     50.000000     67.00000  \n",
       "val_e_Average            2.666667     4.750000      5.666667      6.00000  \n",
       "atomicweight_Average    10.895366    26.203827    119.629500    167.40000  \n",
       "ionenergy_Average        8.213150    11.217767     13.512520     15.24581  \n",
       "el_neg_chi_Average       1.950000     2.706000      2.980000      3.44300  \n",
       "R_vdw_element_Average    1.385714     1.733958      2.055000      2.25000  \n",
       "R_cov_element_Average    0.612174     0.918000      1.390000      1.61584  \n",
       "zaratio_Average          0.426680     0.488550      0.707270      0.82599  \n",
       "density_Average          0.136410     1.363050      7.986670     10.97000  \n",
       "Hardness                 1.500000     5.500000      8.470000     10.00000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_outliers.describe([0.01, 0.99]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No missing data in the both train and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL CROSS-VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y_true, y_pred):\n",
    "    return tfp.stats.percentile(tf.abs(y_true - y_pred), q=50)\n",
    "\n",
    "def metric_fn(y_true, y_pred):\n",
    "    return tfp.stats.percentile(tf.abs(y_true - y_pred), q=100) - tfp.stats.percentile(tf.abs(y_true - y_pred), q=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pre = ExtraTreesRegressor(random_state=5)\n",
    "model_pre.fit(train[num_var], train[TARGET])\n",
    "\n",
    "train_new = train[num_var].copy()\n",
    "test_new = test[num_var].copy()\n",
    "train_new['Hardness_pred'] = model_pre.predict(train[num_var])\n",
    "test_new['Hardness_pred'] = model_pre.predict(test[num_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['allelectrons_Total', 'density_Total', 'allelectrons_Average',\n",
       "       'val_e_Average', 'atomicweight_Average', 'ionenergy_Average',\n",
       "       'el_neg_chi_Average', 'R_vdw_element_Average', 'R_cov_element_Average',\n",
       "       'zaratio_Average', 'density_Average', 'Hardness_pred'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True, mode='min')\n",
    "reduce_LR = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=5, min_lr=0.00001,factor=0.8)\n",
    "terminate = tf.keras.callbacks.TerminateOnNaN()\n",
    "\n",
    "class KerasRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, epochs=100, batch_size=32):\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.InputLayer(input_shape=(len(train_new.columns),)),\n",
    "            tf.keras.layers.BatchNormalization(epsilon=0.00001),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(0.013, beta_1=0.5),\n",
    "                    loss=loss_fn,\n",
    "                      metrics=[metric_fn])\n",
    "        return model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y, epochs=self.epochs, \n",
    "                       batch_size=self.batch_size, \n",
    "                       verbose=0,\n",
    "                    #    class_weight=model_pre.class_weight,\n",
    "                       callbacks=[early_stopping,reduce_LR], \n",
    "                       validation_split=0.1)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MLA = [\n",
    "\t# Trial Models\n",
    "\tMLPRegressor(random_state=5),\n",
    "\tTheilSenRegressor(random_state=5),\n",
    "\tHuberRegressor(),\n",
    "\tRANSACRegressor(random_state=5),\n",
    "\tLasso(random_state=5),\n",
    "\tElasticNet(random_state=5),\n",
    "\tLars(random_state=5),\n",
    "\tLassoLars(random_state=5),\n",
    "\tOrthogonalMatchingPursuit(),\n",
    "\tBayesianRidge(),\n",
    "\tARDRegression(),\n",
    "    TweedieRegressor(power=1.5, alpha=0.5),\n",
    "    PoissonRegressor(alpha=0.5),\n",
    "    GammaRegressor(alpha=0.5),\n",
    "    LassoLars(alpha=0.1, random_state=5),\n",
    "\n",
    "\t# GLM\n",
    "\tLinearRegression(),\n",
    "\tPassiveAggressiveRegressor(random_state=5),\n",
    "\tRidgeCV(),\n",
    "\n",
    "\t# Trees    \n",
    "\tDecisionTreeRegressor(random_state=5),\n",
    "\tExtraTreeRegressor(random_state=5),\n",
    "\n",
    "\tXGBRegressor(random_state=5),\n",
    "\tLGBMRegressor(n_jobs=-1, random_state=5),\n",
    "\tCatBoostRegressor(random_state=5, verbose=False, early_stopping_rounds=100),\n",
    "\t\n",
    "\t# KNeighbors\n",
    "\tKNeighborsRegressor(),\n",
    "\tKNeighborsRegressor(n_neighbors=2),\n",
    "\tKNeighborsRegressor(n_neighbors=4),\n",
    "\tKNeighborsRegressor(n_neighbors=8),\n",
    "\tKNeighborsRegressor(n_neighbors=16),\n",
    "\tKNeighborsRegressor(n_neighbors=32),\n",
    "\tKNeighborsRegressor(n_neighbors=64),\n",
    "\tKNeighborsRegressor(n_neighbors=128),\n",
    "\tKNeighborsRegressor(n_neighbors=256),\n",
    "\tKNeighborsRegressor(n_neighbors=512),\n",
    "\tKNeighborsRegressor(n_neighbors=1024),\n",
    "\n",
    "\t# Ensemble Methods\n",
    "\tAdaBoostRegressor(random_state=5),\n",
    "\tBaggingRegressor(random_state=5),\n",
    "\tExtraTreesRegressor(random_state=5),\n",
    "\tGradientBoostingRegressor(random_state=5),\n",
    "\tHistGradientBoostingRegressor(random_state=5),\n",
    "\tRandomForestRegressor(random_state=5),\n",
    "    \n",
    "\t# Neural Networks\n",
    "\tKerasRegressor(epochs=100, batch_size=32),\n",
    "    ]\n",
    "\n",
    "\n",
    "# split dataset in cross-validation with splitter class\n",
    "# cv_split could KFold, StratifiedKFold or RepeatedKFold depending on the problem\n",
    "cv_split = KFold(n_splits=10, shuffle=True, random_state=5)\n",
    "cv_split_trial = KFold(n_splits=3, shuffle=True, random_state=5) # For quick trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with MLPRegressor\n",
      "Done with TheilSenRegressor\n",
      "Done with HuberRegressor\n",
      "Done with RANSACRegressor\n",
      "Done with Lasso\n",
      "Done with ElasticNet\n",
      "Done with Lars\n",
      "Done with LassoLars\n",
      "Done with OrthogonalMatchingPursuit\n",
      "Done with BayesianRidge\n",
      "Done with ARDRegression\n",
      "Done with TweedieRegressor\n",
      "Done with PoissonRegressor\n",
      "Done with GammaRegressor\n",
      "Done with LassoLars_1\n",
      "Done with LinearRegression\n",
      "Done with PassiveAggressiveRegressor\n",
      "Done with RidgeCV\n",
      "Done with DecisionTreeRegressor\n",
      "Done with ExtraTreeRegressor\n",
      "Done with XGBRegressor\n",
      "Done with LGBMRegressor\n",
      "Done with CatBoostRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor_1\n",
      "Done with KNeighborsRegressor_2\n",
      "Done with KNeighborsRegressor_3\n",
      "Done with KNeighborsRegressor_4\n",
      "Done with KNeighborsRegressor_5\n",
      "Done with KNeighborsRegressor_6\n",
      "Done with KNeighborsRegressor_7\n",
      "Done with KNeighborsRegressor_8\n",
      "Done with KNeighborsRegressor_9\n",
      "Done with KNeighborsRegressor_10\n",
      "Done with AdaBoostRegressor\n",
      "Done with BaggingRegressor\n",
      "Done with ExtraTreesRegressor\n",
      "Done with GradientBoostingRegressor\n",
      "Done with HistGradientBoostingRegressor\n",
      "Done with RandomForestRegressor\n",
      "109/109 [==============================] - 1s 3ms/step\n",
      "217/217 [==============================] - 1s 2ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "217/217 [==============================] - 1s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "217/217 [==============================] - 1s 3ms/step\n",
      "Done with KerasRegressor\n",
      "CPU times: total: 2min\n",
      "Wall time: 4min 40s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Parameters</th>\n",
       "      <th>MLA Train Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy 3*STD</th>\n",
       "      <th>MLA Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ExtraTreeRegressor</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'squared_error...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 min 2.86 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 min 0.29 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'squared_error...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 min 0.06 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'criter...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 min 0.86 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TheilSenRegressor</td>\n",
       "      <td>{'copy_X': True, 'fit_intercept': True, 'max_i...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 min 4.80 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>{'objective': 'reg:squarederror', 'base_score'...</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0 min 0.72 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>{'categorical_features': None, 'early_stopping...</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0 min 1.63 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>{'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': ...</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0 min 2.14 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>{'copy_X': True, 'fit_intercept': True, 'n_job...</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RANSACRegressor</td>\n",
       "      <td>{'base_estimator': 'deprecated', 'estimator': ...</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0 min 0.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BayesianRidge</td>\n",
       "      <td>{'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_in...</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lars</td>\n",
       "      <td>{'copy_X': True, 'eps': 2.220446049250313e-16,...</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OrthogonalMatchingPursuit</td>\n",
       "      <td>{'fit_intercept': True, 'n_nonzero_coefs': Non...</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ARDRegression</td>\n",
       "      <td>{'alpha_1': 1e-06, 'alpha_2': 1e-06, 'compute_...</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>{'alpha_per_target': False, 'alphas': (0.1, 1....</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0 min 0.38 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CatBoostRegressor</td>\n",
       "      <td>{'loss_function': 'RMSE', 'verbose': False, 'r...</td>\n",
       "      <td>0.002178</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0 min 7.05 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HuberRegressor</td>\n",
       "      <td>{'alpha': 0.0001, 'epsilon': 1.35, 'fit_interc...</td>\n",
       "      <td>0.003422</td>\n",
       "      <td>0.003458</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0 min 0.32 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PassiveAggressiveRegressor</td>\n",
       "      <td>{'C': 1.0, 'average': False, 'early_stopping':...</td>\n",
       "      <td>0.02727</td>\n",
       "      <td>0.027477</td>\n",
       "      <td>0.007448</td>\n",
       "      <td>0 min 0.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>KerasRegressor</td>\n",
       "      <td>{'batch_size': 32, 'epochs': 100}</td>\n",
       "      <td>0.090148</td>\n",
       "      <td>0.088865</td>\n",
       "      <td>0.007799</td>\n",
       "      <td>0 min 53.49 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>{'base_estimator': None, 'learning_rate': 1.0,...</td>\n",
       "      <td>0.121754</td>\n",
       "      <td>0.121754</td>\n",
       "      <td>0.043615</td>\n",
       "      <td>0 min 0.60 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PoissonRegressor</td>\n",
       "      <td>{'alpha': 0.5, 'fit_intercept': True, 'max_ite...</td>\n",
       "      <td>0.207476</td>\n",
       "      <td>0.206104</td>\n",
       "      <td>0.023477</td>\n",
       "      <td>0 min 0.09 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>KNeighborsRegressor_1</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 min 0.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>KNeighborsRegressor_2</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.035355</td>\n",
       "      <td>0 min 0.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 min 0.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>KNeighborsRegressor_3</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.061237</td>\n",
       "      <td>0 min 0.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>{'alpha': 1.0, 'copy_X': True, 'fit_intercept'...</td>\n",
       "      <td>0.375806</td>\n",
       "      <td>0.376122</td>\n",
       "      <td>0.006165</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>KNeighborsRegressor_4</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.448958</td>\n",
       "      <td>0.042159</td>\n",
       "      <td>0 min 0.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>{'alpha': 1.0, 'copy_X': True, 'fit_intercept'...</td>\n",
       "      <td>0.455696</td>\n",
       "      <td>0.45595</td>\n",
       "      <td>0.007007</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>KNeighborsRegressor_5</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.529167</td>\n",
       "      <td>0.554167</td>\n",
       "      <td>0.024606</td>\n",
       "      <td>0 min 0.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'batch...</td>\n",
       "      <td>0.584833</td>\n",
       "      <td>0.603251</td>\n",
       "      <td>1.774314</td>\n",
       "      <td>0 min 2.97 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>KNeighborsRegressor_6</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.654427</td>\n",
       "      <td>0.670833</td>\n",
       "      <td>0.082562</td>\n",
       "      <td>0 min 0.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>KNeighborsRegressor_7</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.815104</td>\n",
       "      <td>0.825521</td>\n",
       "      <td>0.090416</td>\n",
       "      <td>0 min 0.03 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>KNeighborsRegressor_8</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.918952</td>\n",
       "      <td>0.920443</td>\n",
       "      <td>0.042923</td>\n",
       "      <td>0 min 0.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>KNeighborsRegressor_9</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>1.010921</td>\n",
       "      <td>1.011497</td>\n",
       "      <td>0.085477</td>\n",
       "      <td>0 min 0.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>KNeighborsRegressor_10</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>1.104574</td>\n",
       "      <td>1.109831</td>\n",
       "      <td>0.072249</td>\n",
       "      <td>0 min 0.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LassoLars</td>\n",
       "      <td>{'alpha': 1.0, 'copy_X': True, 'eps': 2.220446...</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>0.022821</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LassoLars_1</td>\n",
       "      <td>{'alpha': 0.1, 'copy_X': True, 'eps': 2.220446...</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>0.022821</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TweedieRegressor</td>\n",
       "      <td>{'alpha': 0.5, 'fit_intercept': True, 'link': ...</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>0.022821</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GammaRegressor</td>\n",
       "      <td>{'alpha': 0.5, 'fit_intercept': True, 'max_ite...</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>0.022821</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         MLA Name  \\\n",
       "19             ExtraTreeRegressor   \n",
       "39          RandomForestRegressor   \n",
       "35               BaggingRegressor   \n",
       "18          DecisionTreeRegressor   \n",
       "36            ExtraTreesRegressor   \n",
       "1               TheilSenRegressor   \n",
       "20                   XGBRegressor   \n",
       "38  HistGradientBoostingRegressor   \n",
       "37      GradientBoostingRegressor   \n",
       "15               LinearRegression   \n",
       "3                 RANSACRegressor   \n",
       "9                   BayesianRidge   \n",
       "6                            Lars   \n",
       "8       OrthogonalMatchingPursuit   \n",
       "10                  ARDRegression   \n",
       "17                        RidgeCV   \n",
       "21                  LGBMRegressor   \n",
       "22              CatBoostRegressor   \n",
       "2                  HuberRegressor   \n",
       "16     PassiveAggressiveRegressor   \n",
       "40                 KerasRegressor   \n",
       "34              AdaBoostRegressor   \n",
       "12               PoissonRegressor   \n",
       "24          KNeighborsRegressor_1   \n",
       "25          KNeighborsRegressor_2   \n",
       "23            KNeighborsRegressor   \n",
       "26          KNeighborsRegressor_3   \n",
       "5                      ElasticNet   \n",
       "27          KNeighborsRegressor_4   \n",
       "4                           Lasso   \n",
       "28          KNeighborsRegressor_5   \n",
       "0                    MLPRegressor   \n",
       "29          KNeighborsRegressor_6   \n",
       "30          KNeighborsRegressor_7   \n",
       "31          KNeighborsRegressor_8   \n",
       "32          KNeighborsRegressor_9   \n",
       "33         KNeighborsRegressor_10   \n",
       "7                       LassoLars   \n",
       "14                    LassoLars_1   \n",
       "11               TweedieRegressor   \n",
       "13                 GammaRegressor   \n",
       "\n",
       "                                       MLA Parameters MLA Train Accuracy Mean  \\\n",
       "19  {'ccp_alpha': 0.0, 'criterion': 'squared_error...                    -0.0   \n",
       "39  {'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...                    -0.0   \n",
       "35  {'base_estimator': None, 'bootstrap': True, 'b...                    -0.0   \n",
       "18  {'ccp_alpha': 0.0, 'criterion': 'squared_error...                    -0.0   \n",
       "36  {'bootstrap': False, 'ccp_alpha': 0.0, 'criter...                    -0.0   \n",
       "1   {'copy_X': True, 'fit_intercept': True, 'max_i...                     0.0   \n",
       "20  {'objective': 'reg:squarederror', 'base_score'...                0.000012   \n",
       "38  {'categorical_features': None, 'early_stopping...                0.000049   \n",
       "37  {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': ...                0.000075   \n",
       "15  {'copy_X': True, 'fit_intercept': True, 'n_job...                0.000078   \n",
       "3   {'base_estimator': 'deprecated', 'estimator': ...                0.000078   \n",
       "9   {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_in...                0.000078   \n",
       "6   {'copy_X': True, 'eps': 2.220446049250313e-16,...                0.000077   \n",
       "8   {'fit_intercept': True, 'n_nonzero_coefs': Non...                0.000082   \n",
       "10  {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'compute_...                0.000082   \n",
       "17  {'alpha_per_target': False, 'alphas': (0.1, 1....                 0.00008   \n",
       "21  {'boosting_type': 'gbdt', 'class_weight': None...                0.000314   \n",
       "22  {'loss_function': 'RMSE', 'verbose': False, 'r...                0.002178   \n",
       "2   {'alpha': 0.0001, 'epsilon': 1.35, 'fit_interc...                0.003422   \n",
       "16  {'C': 1.0, 'average': False, 'early_stopping':...                 0.02727   \n",
       "40                  {'batch_size': 32, 'epochs': 100}                0.090148   \n",
       "34  {'base_estimator': None, 'learning_rate': 1.0,...                0.121754   \n",
       "12  {'alpha': 0.5, 'fit_intercept': True, 'max_ite...                0.207476   \n",
       "24  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                    0.15   \n",
       "25  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                    0.25   \n",
       "23  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                    0.26   \n",
       "26  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                   0.325   \n",
       "5   {'alpha': 1.0, 'copy_X': True, 'fit_intercept'...                0.375806   \n",
       "27  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                0.416667   \n",
       "4   {'alpha': 1.0, 'copy_X': True, 'fit_intercept'...                0.455696   \n",
       "28  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                0.529167   \n",
       "0   {'activation': 'relu', 'alpha': 0.0001, 'batch...                0.584833   \n",
       "29  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                0.654427   \n",
       "30  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                0.815104   \n",
       "31  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                0.918952   \n",
       "32  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                1.010921   \n",
       "33  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                1.104574   \n",
       "7   {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446...                1.352874   \n",
       "14  {'alpha': 0.1, 'copy_X': True, 'eps': 2.220446...                1.352874   \n",
       "11  {'alpha': 0.5, 'fit_intercept': True, 'link': ...                1.352874   \n",
       "13  {'alpha': 0.5, 'fit_intercept': True, 'max_ite...                1.352874   \n",
       "\n",
       "   MLA Test Accuracy Mean MLA Test Accuracy 3*STD         MLA Time  \n",
       "19                   -0.0                     0.0   0 min 0.01 sec  \n",
       "39                   -0.0                     0.0   0 min 2.86 sec  \n",
       "35                   -0.0                     0.0   0 min 0.29 sec  \n",
       "18                   -0.0                     0.0   0 min 0.06 sec  \n",
       "36                   -0.0                     0.0   0 min 0.86 sec  \n",
       "1                     0.0                     0.0   0 min 4.80 sec  \n",
       "20               0.000012                0.000008   0 min 0.72 sec  \n",
       "38               0.000049                0.000016   0 min 1.63 sec  \n",
       "37               0.000075                0.000039   0 min 2.14 sec  \n",
       "15               0.000079                0.000168   0 min 0.01 sec  \n",
       "3                0.000079                0.000168   0 min 0.02 sec  \n",
       "9                0.000079                0.000168   0 min 0.01 sec  \n",
       "6                 0.00008                0.000169   0 min 0.01 sec  \n",
       "8                0.000082                0.000174   0 min 0.01 sec  \n",
       "10               0.000082                0.000174   0 min 0.01 sec  \n",
       "17               0.000082                0.000161   0 min 0.01 sec  \n",
       "21               0.000316                0.000285   0 min 0.38 sec  \n",
       "22               0.002515                0.000465   0 min 7.05 sec  \n",
       "2                0.003458                0.000317   0 min 0.32 sec  \n",
       "16               0.027477                0.007448   0 min 0.02 sec  \n",
       "40               0.088865                0.007799  0 min 53.49 sec  \n",
       "34               0.121754                0.043615   0 min 0.60 sec  \n",
       "12               0.206104                0.023477   0 min 0.09 sec  \n",
       "24                    0.3                     0.0   0 min 0.02 sec  \n",
       "25               0.333333                0.035355   0 min 0.02 sec  \n",
       "23                   0.34                     0.0   0 min 0.02 sec  \n",
       "26                  0.375                0.061237   0 min 0.02 sec  \n",
       "5                0.376122                0.006165   0 min 0.01 sec  \n",
       "27               0.448958                0.042159   0 min 0.02 sec  \n",
       "4                 0.45595                0.007007   0 min 0.01 sec  \n",
       "28               0.554167                0.024606   0 min 0.02 sec  \n",
       "0                0.603251                1.774314   0 min 2.97 sec  \n",
       "29               0.670833                0.082562   0 min 0.02 sec  \n",
       "30               0.825521                0.090416   0 min 0.03 sec  \n",
       "31               0.920443                0.042923   0 min 0.02 sec  \n",
       "32               1.011497                0.085477   0 min 0.02 sec  \n",
       "33               1.109831                0.072249   0 min 0.02 sec  \n",
       "7                1.352874                0.022821   0 min 0.01 sec  \n",
       "14               1.352874                0.022821   0 min 0.01 sec  \n",
       "11               1.352874                0.022821   0 min 0.01 sec  \n",
       "13               1.352874                0.022821   0 min 0.01 sec  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# create table to compare MLA metrics\n",
    "MLA_columns = ['MLA Name', 'MLA Parameters', 'MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD', 'MLA Time']\n",
    "MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "\n",
    "# create table to compare MLA predictions\n",
    "MLA_predict = {}\n",
    "\n",
    "# index through MLA and save performance to table\n",
    "row_index = 0\n",
    "scoring = median_abs_error_scorer = make_scorer(median_absolute_error, greater_is_better=False)\n",
    "\n",
    "for alg in MLA:\n",
    "\n",
    "\t# set name and parameters\n",
    "\tMLA_name = alg.__class__.__name__\n",
    "\n",
    "\t# Add suffix if name already exists\n",
    "\tsuffix = 1\n",
    "\toriginal_MLA_name = MLA_name\n",
    "\twhile MLA_compare['MLA Name'].str.contains(MLA_name).any():\n",
    "\t\tMLA_name = f\"{original_MLA_name}_{suffix}\"\n",
    "\t\tsuffix += 1\n",
    "\t\t\n",
    "\tMLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
    "\tMLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
    "\n",
    "\t\"\"\"score model with cross validation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\"\"\"\n",
    "\n",
    "\tcv_results = cross_validate(alg, train_new, train[TARGET], cv=cv_split_trial, scoring=scoring, return_train_score=True)\n",
    "\n",
    "\t# Calculate mean time in seconds\n",
    "\tmean_fit_time = cv_results['fit_time'].mean()\n",
    "\n",
    "\t# Convert mean time to minutes and seconds\n",
    "\tminutes = int(mean_fit_time // 60)\n",
    "\tseconds = mean_fit_time % 60\n",
    "\n",
    "\t# Format the time and assign it\n",
    "\tMLA_compare.loc[row_index, 'MLA Time'] = f\"{minutes} min {seconds:.2f} sec\"\n",
    "\tMLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean() * -1\n",
    "\tMLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean() * -1\n",
    "\t#if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\n",
    "\tMLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   #let's know the worst that can happen!\n",
    "\n",
    "\t# # #save MLA predictions - see section 6 for usage\n",
    "\t# alg.fit(data1[data1_x_bin], data1[Target])\n",
    "\t# MLA_predict[MLA_name] = alg.predict(data1[data1_x_bin])\n",
    "\tprint(f'Done with {MLA_name}')\n",
    "\trow_index+=1\n",
    "\n",
    "\n",
    "#print and sort table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html\n",
    "MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = True, inplace = True)\n",
    "MLA_compare.to_csv(f'{experiment}_results.csv', index=False)\n",
    "MLA_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Algorithm')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n",
    "\n",
    "#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\n",
    "plt.title('Machine Learning Algorithm Accuracy Score \\n')\n",
    "plt.xlabel('Accuracy Score (%)')\n",
    "plt.ylabel('Algorithm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENSEMBLE CROSS-VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hill Climbing inspired by code from Kaggle\n",
    "def hill_climbing(x, y):\n",
    "    \n",
    "    # Evaluating oof predictions\n",
    "    scores = {}\n",
    "    for col in x.columns:\n",
    "        scores[col] = median_absolute_error(y, x[col])\n",
    "\n",
    "    # Sorting the model scores in ascending order\n",
    "    scores = {k: v for k, v in sorted(scores.items(), key = lambda item: item[1], reverse = False)}\n",
    "\n",
    "    # Sort oof_df\n",
    "    x = x[list(scores.keys())]\n",
    "\n",
    "    # Initialize weights\n",
    "    weights = {col: 1 if i == 0 else 0 for i, col in enumerate(x.columns)}\n",
    "\n",
    "    STOP = False\n",
    "    current_best_ensemble = x.iloc[:,0]\n",
    "    MODELS = x.iloc[:,1:]\n",
    "    weight_range = np.arange(-0.5, 0.51, 0.01) \n",
    "    history = [median_absolute_error(y, current_best_ensemble)]\n",
    "    j = 0\n",
    "\n",
    "    while not STOP:\n",
    "        j += 1\n",
    "        potential_new_best_cv_score = median_absolute_error(y, current_best_ensemble)\n",
    "        k_best, wgt_best = None, None\n",
    "        for k in MODELS:\n",
    "            for wgt in weight_range:\n",
    "                potential_ensemble = (1 - wgt) * current_best_ensemble + wgt * MODELS[k]\n",
    "                cv_score = median_absolute_error(y, potential_ensemble)\n",
    "                if cv_score < potential_new_best_cv_score:\n",
    "                    potential_new_best_cv_score = cv_score\n",
    "                    k_best, wgt_best = k, wgt\n",
    "\n",
    "        if k_best is not None:\n",
    "            # Update weights\n",
    "            weights = {col: (1 - wgt_best) * weights[col] if col != k_best else wgt_best for col in weights}\n",
    "            current_best_ensemble = (1 - wgt_best) * current_best_ensemble + wgt_best * MODELS[k_best]\n",
    "            MODELS.drop(k_best, axis = 1, inplace = True)\n",
    "            if MODELS.shape[1] == 0:\n",
    "                STOP = True\n",
    "            history.append(potential_new_best_cv_score)\n",
    "        else:\n",
    "            STOP = True\n",
    "        \n",
    "    hill_ens_pred = current_best_ensemble\n",
    "    \n",
    "    return hill_ens_pred, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission_file(ids, predictions, filename):\n",
    "    submission = pd.DataFrame({'id': ids, 'Hardness': predictions})\n",
    "    submission.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "217/217 [==============================] - 1s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "The Fold 1 Hill Climb is 0.0\n",
      "The Fold 1 weight is {'DecisionTreeRegressor': 1, 'ExtraTreeRegressor': 0, 'BaggingRegressor': 0, 'ExtraTreesRegressor': 0, 'RandomForestRegressor': 0, 'TheilSenRegressor': 0, 'XGBRegressor': 0, 'HistGradientBoostingRegressor': 0, 'GradientBoostingRegressor': 0, 'RANSACRegressor': 0, 'LinearRegression': 0, 'BayesianRidge': 0, 'Lars': 0, 'OrthogonalMatchingPursuit': 0, 'ARDRegression': 0, 'RidgeCV': 0, 'LGBMRegressor': 0, 'CatBoostRegressor': 0, 'HuberRegressor': 0, 'PassiveAggressiveRegressor': 0, 'KerasRegressor': 0, 'AdaBoostRegressor': 0, 'PoissonRegressor': 0, 'KNeighborsRegressor_2': 0, 'KNeighborsRegressor': 0, 'KNeighborsRegressor_3': 0, 'ElasticNet': 0, 'KNeighborsRegressor_4': 0, 'Lasso': 0, 'KNeighborsRegressor_5': 0, 'KNeighborsRegressor_6': 0, 'KNeighborsRegressor_7': 0, 'KNeighborsRegressor_8': 0, 'KNeighborsRegressor_9': 0, 'KNeighborsRegressor_10': 0, 'KNeighborsRegressor_11': 0, 'LassoLars': 0, 'TweedieRegressor': 0, 'GammaRegressor': 0, 'LassoLars_1': 0, 'MLPRegressor': 0}\n",
      "\n",
      "Fold 2\n",
      "217/217 [==============================] - 1s 3ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "The Fold 2 Hill Climb is 0.0\n",
      "The Fold 2 weight is {'DecisionTreeRegressor': 1, 'ExtraTreeRegressor': 0, 'BaggingRegressor': 0, 'ExtraTreesRegressor': 0, 'RandomForestRegressor': 0, 'TheilSenRegressor': 0, 'XGBRegressor': 0, 'HistGradientBoostingRegressor': 0, 'GradientBoostingRegressor': 0, 'Lars': 0, 'RidgeCV': 0, 'LinearRegression': 0, 'RANSACRegressor': 0, 'BayesianRidge': 0, 'ARDRegression': 0, 'OrthogonalMatchingPursuit': 0, 'LGBMRegressor': 0, 'CatBoostRegressor': 0, 'HuberRegressor': 0, 'PassiveAggressiveRegressor': 0, 'MLPRegressor': 0, 'KerasRegressor': 0, 'AdaBoostRegressor': 0, 'PoissonRegressor': 0, 'KNeighborsRegressor_2': 0, 'KNeighborsRegressor_3': 0, 'KNeighborsRegressor': 0, 'KNeighborsRegressor_4': 0, 'ElasticNet': 0, 'KNeighborsRegressor_5': 0, 'Lasso': 0, 'KNeighborsRegressor_6': 0, 'KNeighborsRegressor_7': 0, 'KNeighborsRegressor_8': 0, 'KNeighborsRegressor_9': 0, 'KNeighborsRegressor_10': 0, 'KNeighborsRegressor_11': 0, 'LassoLars': 0, 'LassoLars_1': 0, 'TweedieRegressor': 0, 'GammaRegressor': 0}\n",
      "\n",
      "Fold 3\n",
      "217/217 [==============================] - 1s 3ms/step\n",
      "109/109 [==============================] - 1s 5ms/step\n",
      "The Fold 3 Hill Climb is 0.0\n",
      "The Fold 3 weight is {'DecisionTreeRegressor': 1, 'ExtraTreeRegressor': 0, 'BaggingRegressor': 0, 'ExtraTreesRegressor': 0, 'RandomForestRegressor': 0, 'Lars': 0, 'OrthogonalMatchingPursuit': 0, 'LinearRegression': 0, 'RANSACRegressor': 0, 'ARDRegression': 0, 'TheilSenRegressor': 0, 'BayesianRidge': 0, 'RidgeCV': 0, 'XGBRegressor': 0, 'HistGradientBoostingRegressor': 0, 'GradientBoostingRegressor': 0, 'LGBMRegressor': 0, 'CatBoostRegressor': 0, 'HuberRegressor': 0, 'PassiveAggressiveRegressor': 0, 'KerasRegressor': 0, 'AdaBoostRegressor': 0, 'PoissonRegressor': 0, 'KNeighborsRegressor_2': 0, 'KNeighborsRegressor_3': 0, 'MLPRegressor': 0, 'KNeighborsRegressor': 0, 'KNeighborsRegressor_4': 0, 'ElasticNet': 0, 'KNeighborsRegressor_5': 0, 'Lasso': 0, 'KNeighborsRegressor_6': 0, 'KNeighborsRegressor_7': 0, 'KNeighborsRegressor_8': 0, 'KNeighborsRegressor_9': 0, 'KNeighborsRegressor_10': 0, 'KNeighborsRegressor_11': 0, 'LassoLars': 0, 'TweedieRegressor': 0, 'GammaRegressor': 0, 'LassoLars_1': 0}\n",
      "\n",
      "\n",
      "The Hill Climbing CV score is ==> 0.0\n",
      "The Hill Climbing weights are ==> [{'DecisionTreeRegressor': 1, 'ExtraTreeRegressor': 0, 'BaggingRegressor': 0, 'ExtraTreesRegressor': 0, 'RandomForestRegressor': 0, 'TheilSenRegressor': 0, 'XGBRegressor': 0, 'HistGradientBoostingRegressor': 0, 'GradientBoostingRegressor': 0, 'RANSACRegressor': 0, 'LinearRegression': 0, 'BayesianRidge': 0, 'Lars': 0, 'OrthogonalMatchingPursuit': 0, 'ARDRegression': 0, 'RidgeCV': 0, 'LGBMRegressor': 0, 'CatBoostRegressor': 0, 'HuberRegressor': 0, 'PassiveAggressiveRegressor': 0, 'KerasRegressor': 0, 'AdaBoostRegressor': 0, 'PoissonRegressor': 0, 'KNeighborsRegressor_2': 0, 'KNeighborsRegressor': 0, 'KNeighborsRegressor_3': 0, 'ElasticNet': 0, 'KNeighborsRegressor_4': 0, 'Lasso': 0, 'KNeighborsRegressor_5': 0, 'KNeighborsRegressor_6': 0, 'KNeighborsRegressor_7': 0, 'KNeighborsRegressor_8': 0, 'KNeighborsRegressor_9': 0, 'KNeighborsRegressor_10': 0, 'KNeighborsRegressor_11': 0, 'LassoLars': 0, 'TweedieRegressor': 0, 'GammaRegressor': 0, 'LassoLars_1': 0, 'MLPRegressor': 0}, {'DecisionTreeRegressor': 1, 'ExtraTreeRegressor': 0, 'BaggingRegressor': 0, 'ExtraTreesRegressor': 0, 'RandomForestRegressor': 0, 'TheilSenRegressor': 0, 'XGBRegressor': 0, 'HistGradientBoostingRegressor': 0, 'GradientBoostingRegressor': 0, 'Lars': 0, 'RidgeCV': 0, 'LinearRegression': 0, 'RANSACRegressor': 0, 'BayesianRidge': 0, 'ARDRegression': 0, 'OrthogonalMatchingPursuit': 0, 'LGBMRegressor': 0, 'CatBoostRegressor': 0, 'HuberRegressor': 0, 'PassiveAggressiveRegressor': 0, 'MLPRegressor': 0, 'KerasRegressor': 0, 'AdaBoostRegressor': 0, 'PoissonRegressor': 0, 'KNeighborsRegressor_2': 0, 'KNeighborsRegressor_3': 0, 'KNeighborsRegressor': 0, 'KNeighborsRegressor_4': 0, 'ElasticNet': 0, 'KNeighborsRegressor_5': 0, 'Lasso': 0, 'KNeighborsRegressor_6': 0, 'KNeighborsRegressor_7': 0, 'KNeighborsRegressor_8': 0, 'KNeighborsRegressor_9': 0, 'KNeighborsRegressor_10': 0, 'KNeighborsRegressor_11': 0, 'LassoLars': 0, 'LassoLars_1': 0, 'TweedieRegressor': 0, 'GammaRegressor': 0}, {'DecisionTreeRegressor': 1, 'ExtraTreeRegressor': 0, 'BaggingRegressor': 0, 'ExtraTreesRegressor': 0, 'RandomForestRegressor': 0, 'Lars': 0, 'OrthogonalMatchingPursuit': 0, 'LinearRegression': 0, 'RANSACRegressor': 0, 'ARDRegression': 0, 'TheilSenRegressor': 0, 'BayesianRidge': 0, 'RidgeCV': 0, 'XGBRegressor': 0, 'HistGradientBoostingRegressor': 0, 'GradientBoostingRegressor': 0, 'LGBMRegressor': 0, 'CatBoostRegressor': 0, 'HuberRegressor': 0, 'PassiveAggressiveRegressor': 0, 'KerasRegressor': 0, 'AdaBoostRegressor': 0, 'PoissonRegressor': 0, 'KNeighborsRegressor_2': 0, 'KNeighborsRegressor_3': 0, 'MLPRegressor': 0, 'KNeighborsRegressor': 0, 'KNeighborsRegressor_4': 0, 'ElasticNet': 0, 'KNeighborsRegressor_5': 0, 'Lasso': 0, 'KNeighborsRegressor_6': 0, 'KNeighborsRegressor_7': 0, 'KNeighborsRegressor_8': 0, 'KNeighborsRegressor_9': 0, 'KNeighborsRegressor_10': 0, 'KNeighborsRegressor_11': 0, 'LassoLars': 0, 'TweedieRegressor': 0, 'GammaRegressor': 0, 'LassoLars_1': 0}]\n",
      "CPU times: total: 1min 41s\n",
      "Wall time: 4min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "avg_predictions_scores = []\n",
    "optuna_weights_scores = []\n",
    "hill_climb_scores = []\n",
    "stacked_scores = []\n",
    "optuna_weights_scores_stack = []\n",
    "hill_climb_weights = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(cv_split_trial.split(train_new, train[TARGET])):\n",
    "    X_train, X_test = train_new.iloc[train_index], train_new.iloc[test_index]\n",
    "    y_train, y_test = train[TARGET].iloc[train_index], train[TARGET].iloc[test_index]\n",
    "\n",
    "    print(f'Fold {i+1}')\n",
    "    \n",
    "    MLA_cv_train_preds = []\n",
    "    MLA_cv_preds = []\n",
    "    MLA_cv_preds_dict = {}\n",
    "    MLA_names = []\n",
    "    \n",
    "    suffix = 1\n",
    "    for alg in MLA:\n",
    "        MLA_name = alg.__class__.__name__\n",
    "\n",
    "        # Add suffix if name already exists\n",
    "\n",
    "        original_MLA_name = MLA_name\n",
    "        if MLA_name in MLA_names:\n",
    "        # while MLA_cv_preds.str.contains(MLA_name).any():\n",
    "            MLA_name = f\"{original_MLA_name}_{suffix}\"\n",
    "            suffix += 1\n",
    "            \n",
    "        predictor = alg.fit(X_train, y_train)\n",
    "        pred_train_result = predictor.predict(X_train)\n",
    "        pred_result = predictor.predict(X_test)\n",
    "\n",
    "        MLA_cv_train_preds.append(pred_train_result)\n",
    "        MLA_cv_preds.append(pred_result)\n",
    "        MLA_cv_preds_dict[MLA_name] = pred_result\n",
    "        MLA_names.append(MLA_name)\n",
    "\n",
    "    ##################\n",
    "    ### Hill Climb ###\n",
    "    ##################\n",
    "    hill_climb_pred, hill_climb_weight = hill_climbing(pd.DataFrame(MLA_cv_preds_dict), y_test)\n",
    "    hill_climb_score = median_absolute_error(y_test, hill_climb_pred)\n",
    "    hill_climb_scores.append(hill_climb_score)\n",
    "    hill_climb_weights.append(hill_climb_weight)\n",
    "    print(f'The Fold {i+1} Hill Climb is {hill_climb_score}')\n",
    "    print(f'The Fold {i+1} weight is {hill_climb_weight}')\n",
    "    print()\n",
    "\n",
    "print()\n",
    "print(f'The Hill Climbing CV score is ==> {np.mean(hill_climb_scores)}')\n",
    "print(f'The Hill Climbing weights are ==> {hill_climb_weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'DecisionTreeRegressor': 1.0,\n",
       "  'ExtraTreeRegressor': 0.0,\n",
       "  'BaggingRegressor': 0.0,\n",
       "  'ExtraTreesRegressor': 0.0,\n",
       "  'RandomForestRegressor': 0.0,\n",
       "  'TheilSenRegressor': 0.0,\n",
       "  'XGBRegressor': 0.0,\n",
       "  'HistGradientBoostingRegressor': 0.0,\n",
       "  'GradientBoostingRegressor': 0.0,\n",
       "  'RANSACRegressor': 0.0,\n",
       "  'LinearRegression': 0.0,\n",
       "  'BayesianRidge': 0.0,\n",
       "  'Lars': 0.0,\n",
       "  'OrthogonalMatchingPursuit': 0.0,\n",
       "  'ARDRegression': 0.0,\n",
       "  'RidgeCV': 0.0,\n",
       "  'LGBMRegressor': 0.0,\n",
       "  'CatBoostRegressor': 0.0,\n",
       "  'HuberRegressor': 0.0,\n",
       "  'PassiveAggressiveRegressor': 0.0,\n",
       "  'KerasRegressor': 0.0,\n",
       "  'AdaBoostRegressor': 0.0,\n",
       "  'PoissonRegressor': 0.0,\n",
       "  'KNeighborsRegressor_2': 0.0,\n",
       "  'KNeighborsRegressor': 0.0,\n",
       "  'KNeighborsRegressor_3': 0.0,\n",
       "  'ElasticNet': 0.0,\n",
       "  'KNeighborsRegressor_4': 0.0,\n",
       "  'Lasso': 0.0,\n",
       "  'KNeighborsRegressor_5': 0.0,\n",
       "  'KNeighborsRegressor_6': 0.0,\n",
       "  'KNeighborsRegressor_7': 0.0,\n",
       "  'KNeighborsRegressor_8': 0.0,\n",
       "  'KNeighborsRegressor_9': 0.0,\n",
       "  'KNeighborsRegressor_10': 0.0,\n",
       "  'KNeighborsRegressor_11': 0.0,\n",
       "  'LassoLars': 0.0,\n",
       "  'TweedieRegressor': 0.0,\n",
       "  'GammaRegressor': 0.0,\n",
       "  'LassoLars_1': 0.0,\n",
       "  'MLPRegressor': 0.0},\n",
       " 1.0,\n",
       " 41)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get average weights for the models from all the folds\n",
    "\n",
    "average_values = {}\n",
    "\n",
    "for model in hill_climb_weights:\n",
    "    for key, value in model.items():\n",
    "        if key in average_values:\n",
    "            average_values[key] += value\n",
    "        else:\n",
    "            average_values[key] = value\n",
    "\n",
    "num_models = len(hill_climb_weights)\n",
    "average_values = {k: v / num_models for k, v in average_values.items()}\n",
    "\n",
    "# Ensure the new weights sum up to 1\n",
    "sum = 0\n",
    "\n",
    "for k, v in average_values.items():\n",
    "    sum += v\n",
    "\n",
    "average_values, sum, len(average_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MLPRegressor': 0.0,\n",
       " 'TheilSenRegressor': 0.0,\n",
       " 'HuberRegressor': 0.0,\n",
       " 'RANSACRegressor': 0.0,\n",
       " 'Lasso': 0.0,\n",
       " 'ElasticNet': 0.0,\n",
       " 'Lars': 0.0,\n",
       " 'LassoLars': 0.0,\n",
       " 'OrthogonalMatchingPursuit': 0.0,\n",
       " 'BayesianRidge': 0.0,\n",
       " 'ARDRegression': 0.0,\n",
       " 'TweedieRegressor': 0.0,\n",
       " 'PoissonRegressor': 0.0,\n",
       " 'GammaRegressor': 0.0,\n",
       " 'LassoLars_1': 0.0,\n",
       " 'LinearRegression': 0.0,\n",
       " 'PassiveAggressiveRegressor': 0.0,\n",
       " 'RidgeCV': 0.0,\n",
       " 'DecisionTreeRegressor': 1.0,\n",
       " 'ExtraTreeRegressor': 0.0,\n",
       " 'XGBRegressor': 0.0,\n",
       " 'LGBMRegressor': 0.0,\n",
       " 'CatBoostRegressor': 0.0,\n",
       " 'KNeighborsRegressor': 0.0,\n",
       " 'KNeighborsRegressor_2': 0.0,\n",
       " 'KNeighborsRegressor_3': 0.0,\n",
       " 'KNeighborsRegressor_4': 0.0,\n",
       " 'KNeighborsRegressor_5': 0.0,\n",
       " 'KNeighborsRegressor_6': 0.0,\n",
       " 'KNeighborsRegressor_7': 0.0,\n",
       " 'KNeighborsRegressor_8': 0.0,\n",
       " 'KNeighborsRegressor_9': 0.0,\n",
       " 'KNeighborsRegressor_10': 0.0,\n",
       " 'KNeighborsRegressor_11': 0.0,\n",
       " 'AdaBoostRegressor': 0.0,\n",
       " 'BaggingRegressor': 0.0,\n",
       " 'ExtraTreesRegressor': 0.0,\n",
       " 'GradientBoostingRegressor': 0.0,\n",
       " 'HistGradientBoostingRegressor': 0.0,\n",
       " 'RandomForestRegressor': 0.0,\n",
       " 'KerasRegressor': 0.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an ordered dictionary based on the order of models in MLA\n",
    "ordered_average_values = {}\n",
    "final_mlas = []\n",
    "\n",
    "for model_name in MLA_names:        \n",
    "    if model_name in average_values:\n",
    "        ordered_average_values[model_name] = average_values[model_name]\n",
    "    else:\n",
    "        # Handle case where a model might not be in average_values\n",
    "        ordered_average_values[model_name] = None\n",
    "\n",
    "# Now ordered_average_values has the averages in the same order as MLA\n",
    "ordered_average_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the ordered weights values as a list to be used for final submission\n",
    "hill_climb_final_weights = []\n",
    "\n",
    "for value in ordered_average_values.values():\n",
    "    hill_climb_final_weights.append(value)\n",
    "\n",
    "hill_climb_final_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with MLPRegressor\n",
      "Done with TheilSenRegressor\n",
      "Done with HuberRegressor\n",
      "Done with RANSACRegressor\n",
      "Done with Lasso\n",
      "Done with ElasticNet\n",
      "Done with Lars\n",
      "Done with LassoLars\n",
      "Done with OrthogonalMatchingPursuit\n",
      "Done with BayesianRidge\n",
      "Done with ARDRegression\n",
      "Done with TweedieRegressor\n",
      "Done with PoissonRegressor\n",
      "Done with GammaRegressor\n",
      "Done with LassoLars\n",
      "Done with LinearRegression\n",
      "Done with PassiveAggressiveRegressor\n",
      "Done with RidgeCV\n",
      "Done with DecisionTreeRegressor\n",
      "Done with ExtraTreeRegressor\n",
      "Done with XGBRegressor\n",
      "Done with LGBMRegressor\n",
      "Done with CatBoostRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with AdaBoostRegressor\n",
      "Done with BaggingRegressor\n",
      "Done with ExtraTreesRegressor\n",
      "Done with GradientBoostingRegressor\n",
      "Done with HistGradientBoostingRegressor\n",
      "Done with RandomForestRegressor\n",
      "217/217 [==============================] - 1s 3ms/step\n",
      "Done with KerasRegressor\n",
      "CPU times: total: 41 s\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_predictions = []\n",
    "# Make predictions on test set\n",
    "for alg in MLA:\n",
    "        MLA_name = alg.__class__.__name__\n",
    "                \n",
    "        predictor = alg.fit(train_new, train[TARGET])\n",
    "        pred_result = predictor.predict(test_new)\n",
    "\n",
    "        test_predictions.append(pred_result)\n",
    "        print(f'Done with {MLA_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 41)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check that the weights and predictions are the same length\n",
    "len(test_predictions), len(hill_climb_final_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_avg_predictions = np.average(test_predictions, axis=0, weights=hill_climb_final_weights)\n",
    "create_submission_file(test['id'], weighted_avg_predictions, f'submission_{experiment}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
