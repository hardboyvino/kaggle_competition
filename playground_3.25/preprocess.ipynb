{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import median_absolute_error, make_scorer\n",
    "\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor, GradientBoostingRegressor, RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.linear_model import LogisticRegression, RidgeCV, PassiveAggressiveRegressor, SGDRegressor, Perceptron, LinearRegression, TheilSenRegressor, HuberRegressor, RANSACRegressor, Lasso, ElasticNet, Lars, LassoLars, OrthogonalMatchingPursuit, BayesianRidge, ARDRegression, TweedieRegressor, PoissonRegressor, GammaRegressor, LassoLars\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "experiment = 'add_pre_randomforest_model'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <th>density_Total</th>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <th>val_e_Average</th>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <th>zaratio_Average</th>\n",
       "      <th>density_Average</th>\n",
       "      <th>Hardness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.841611</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>20.612526</td>\n",
       "      <td>11.08810</td>\n",
       "      <td>2.766</td>\n",
       "      <td>1.732</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.496070</td>\n",
       "      <td>0.91457</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.558488</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>20.298893</td>\n",
       "      <td>12.04083</td>\n",
       "      <td>2.755</td>\n",
       "      <td>1.631</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.492719</td>\n",
       "      <td>0.71760</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>76.0</td>\n",
       "      <td>8.885992</td>\n",
       "      <td>15.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>33.739258</td>\n",
       "      <td>12.08630</td>\n",
       "      <td>2.828</td>\n",
       "      <td>1.788</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.481478</td>\n",
       "      <td>1.50633</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.795296</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>20.213349</td>\n",
       "      <td>10.94850</td>\n",
       "      <td>2.648</td>\n",
       "      <td>1.626</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.489272</td>\n",
       "      <td>0.78937</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>9.577996</td>\n",
       "      <td>11.6</td>\n",
       "      <td>4.8</td>\n",
       "      <td>24.988133</td>\n",
       "      <td>11.82448</td>\n",
       "      <td>2.766</td>\n",
       "      <td>1.682</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.492736</td>\n",
       "      <td>1.86481</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  allelectrons_Total  density_Total  allelectrons_Average  val_e_Average  \\\n",
       "0   0               100.0       0.841611                  10.0            4.8   \n",
       "1   1               100.0       7.558488                  10.0            4.8   \n",
       "2   2                76.0       8.885992                  15.6            5.6   \n",
       "3   3               100.0       8.795296                  10.0            4.8   \n",
       "4   4               116.0       9.577996                  11.6            4.8   \n",
       "\n",
       "   atomicweight_Average  ionenergy_Average  el_neg_chi_Average  \\\n",
       "0             20.612526           11.08810               2.766   \n",
       "1             20.298893           12.04083               2.755   \n",
       "2             33.739258           12.08630               2.828   \n",
       "3             20.213349           10.94850               2.648   \n",
       "4             24.988133           11.82448               2.766   \n",
       "\n",
       "   R_vdw_element_Average  R_cov_element_Average  zaratio_Average  \\\n",
       "0                  1.732                  0.860         0.496070   \n",
       "1                  1.631                  0.910         0.492719   \n",
       "2                  1.788                  0.864         0.481478   \n",
       "3                  1.626                  0.936         0.489272   \n",
       "4                  1.682                  0.896         0.492736   \n",
       "\n",
       "   density_Average  Hardness  \n",
       "0          0.91457       6.0  \n",
       "1          0.71760       6.5  \n",
       "2          1.50633       2.5  \n",
       "3          0.78937       6.0  \n",
       "4          1.86481       6.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "artificial = pd.read_csv('Artificial_Crystals_Dataset.csv')\n",
    "mineral = pd.read_csv('Mineral_Dataset_Supplementary_Info.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hardness</th>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <th>density_Total</th>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <th>val_e_Average</th>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <th>zaratio_Average</th>\n",
       "      <th>density_Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.5</td>\n",
       "      <td>167.0</td>\n",
       "      <td>23.907992</td>\n",
       "      <td>18.555556</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>41.609136</td>\n",
       "      <td>11.693844</td>\n",
       "      <td>2.938889</td>\n",
       "      <td>1.711111</td>\n",
       "      <td>0.884444</td>\n",
       "      <td>0.477830</td>\n",
       "      <td>2.656444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.740168</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>8.773227</td>\n",
       "      <td>11.614333</td>\n",
       "      <td>1.903333</td>\n",
       "      <td>1.310000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.825990</td>\n",
       "      <td>0.580056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.5</td>\n",
       "      <td>102.0</td>\n",
       "      <td>8.511159</td>\n",
       "      <td>4.434783</td>\n",
       "      <td>3.304348</td>\n",
       "      <td>8.440584</td>\n",
       "      <td>13.176622</td>\n",
       "      <td>2.672609</td>\n",
       "      <td>1.379130</td>\n",
       "      <td>0.530870</td>\n",
       "      <td>0.713850</td>\n",
       "      <td>0.370050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.5</td>\n",
       "      <td>78.0</td>\n",
       "      <td>8.109328</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>27.448814</td>\n",
       "      <td>11.826400</td>\n",
       "      <td>2.960000</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.488163</td>\n",
       "      <td>1.351555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.5</td>\n",
       "      <td>164.0</td>\n",
       "      <td>19.921324</td>\n",
       "      <td>14.909091</td>\n",
       "      <td>5.090909</td>\n",
       "      <td>32.012361</td>\n",
       "      <td>11.255573</td>\n",
       "      <td>2.881818</td>\n",
       "      <td>1.640909</td>\n",
       "      <td>0.841818</td>\n",
       "      <td>0.483480</td>\n",
       "      <td>1.811029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hardness  allelectrons_Total  density_Total  allelectrons_Average  \\\n",
       "0       4.5               167.0      23.907992             18.555556   \n",
       "1       4.0                14.0       1.740168              4.666667   \n",
       "2       2.5               102.0       8.511159              4.434783   \n",
       "3       5.5                78.0       8.109328             13.000000   \n",
       "4       6.5               164.0      19.921324             14.909091   \n",
       "\n",
       "   val_e_Average  atomicweight_Average  ionenergy_Average  el_neg_chi_Average  \\\n",
       "0       5.000000             41.609136          11.693844            2.938889   \n",
       "1       1.333333              8.773227          11.614333            1.903333   \n",
       "2       3.304348              8.440584          13.176622            2.672609   \n",
       "3       5.333333             27.448814          11.826400            2.960000   \n",
       "4       5.090909             32.012361          11.255573            2.881818   \n",
       "\n",
       "   R_vdw_element_Average  R_cov_element_Average  zaratio_Average  \\\n",
       "0               1.711111               0.884444         0.477830   \n",
       "1               1.310000               0.680000         0.825990   \n",
       "2               1.379130               0.530870         0.713850   \n",
       "3               1.625000               0.813333         0.488163   \n",
       "4               1.640909               0.841818         0.483480   \n",
       "\n",
       "   density_Average  \n",
       "0         2.656444  \n",
       "1         0.580056  \n",
       "2         0.370050  \n",
       "3         1.351555  \n",
       "4         1.811029  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename hardness in artifical dataset and drop columns not required\n",
    "artificial.rename(columns={'Hardness (Mohs)': 'Hardness'}, inplace=True)\n",
    "artificial.drop(['Formula', 'Crystal structure', 'Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "artificial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hardness</th>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <th>density_Total</th>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <th>val_e_Average</th>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <th>zaratio_Average</th>\n",
       "      <th>density_Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.3</td>\n",
       "      <td>110.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>36.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>82.598467</td>\n",
       "      <td>8.504133</td>\n",
       "      <td>2.146667</td>\n",
       "      <td>2.006667</td>\n",
       "      <td>1.253333</td>\n",
       "      <td>0.456803</td>\n",
       "      <td>7.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.5</td>\n",
       "      <td>406.0</td>\n",
       "      <td>30.472136</td>\n",
       "      <td>9.902439</td>\n",
       "      <td>4.682927</td>\n",
       "      <td>19.813180</td>\n",
       "      <td>11.456151</td>\n",
       "      <td>2.700244</td>\n",
       "      <td>1.676829</td>\n",
       "      <td>0.868293</td>\n",
       "      <td>0.522909</td>\n",
       "      <td>0.743223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.5</td>\n",
       "      <td>406.0</td>\n",
       "      <td>30.472464</td>\n",
       "      <td>10.410256</td>\n",
       "      <td>4.923077</td>\n",
       "      <td>20.931371</td>\n",
       "      <td>11.541405</td>\n",
       "      <td>2.753590</td>\n",
       "      <td>1.703846</td>\n",
       "      <td>0.894359</td>\n",
       "      <td>0.497498</td>\n",
       "      <td>0.781345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.5</td>\n",
       "      <td>476.0</td>\n",
       "      <td>61.142136</td>\n",
       "      <td>11.609756</td>\n",
       "      <td>4.682927</td>\n",
       "      <td>23.659644</td>\n",
       "      <td>11.487395</td>\n",
       "      <td>2.763659</td>\n",
       "      <td>1.714634</td>\n",
       "      <td>0.848780</td>\n",
       "      <td>0.519474</td>\n",
       "      <td>1.491272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.5</td>\n",
       "      <td>476.0</td>\n",
       "      <td>61.142464</td>\n",
       "      <td>12.205128</td>\n",
       "      <td>4.923077</td>\n",
       "      <td>24.975089</td>\n",
       "      <td>11.574251</td>\n",
       "      <td>2.820256</td>\n",
       "      <td>1.743590</td>\n",
       "      <td>0.873846</td>\n",
       "      <td>0.493887</td>\n",
       "      <td>1.567755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hardness  allelectrons_Total  density_Total  allelectrons_Average  \\\n",
       "0       2.3               110.0      23.000000             36.666667   \n",
       "1       5.5               406.0      30.472136              9.902439   \n",
       "2       5.5               406.0      30.472464             10.410256   \n",
       "3       5.5               476.0      61.142136             11.609756   \n",
       "4       5.5               476.0      61.142464             12.205128   \n",
       "\n",
       "   val_e_Average  atomicweight_Average  ionenergy_Average  el_neg_chi_Average  \\\n",
       "0       2.666667             82.598467           8.504133            2.146667   \n",
       "1       4.682927             19.813180          11.456151            2.700244   \n",
       "2       4.923077             20.931371          11.541405            2.753590   \n",
       "3       4.682927             23.659644          11.487395            2.763659   \n",
       "4       4.923077             24.975089          11.574251            2.820256   \n",
       "\n",
       "   R_vdw_element_Average  R_cov_element_Average  zaratio_Average  \\\n",
       "0               2.006667               1.253333         0.456803   \n",
       "1               1.676829               0.868293         0.522909   \n",
       "2               1.703846               0.894359         0.497498   \n",
       "3               1.714634               0.848780         0.519474   \n",
       "4               1.743590               0.873846         0.493887   \n",
       "\n",
       "   density_Average  \n",
       "0         7.666667  \n",
       "1         0.743223  \n",
       "2         0.781345  \n",
       "3         1.491272  \n",
       "4         1.567755  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unneeded columns\n",
    "mineral.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "mineral.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10407, 13), (52, 12), (622, 12))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, artificial.shape, mineral.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.concat([train, artificial, mineral], axis=0)\n",
    "# train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <th>density_Total</th>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <th>val_e_Average</th>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <th>zaratio_Average</th>\n",
       "      <th>density_Average</th>\n",
       "      <th>Hardness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10402</th>\n",
       "      <td>10402</td>\n",
       "      <td>128.0</td>\n",
       "      <td>7.558488</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>26.385218</td>\n",
       "      <td>11.330440</td>\n",
       "      <td>2.644000</td>\n",
       "      <td>1.631000</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.496070</td>\n",
       "      <td>1.79607</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10403</th>\n",
       "      <td>10403</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.743160</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>20.766935</td>\n",
       "      <td>14.163933</td>\n",
       "      <td>3.090000</td>\n",
       "      <td>1.556667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.480390</td>\n",
       "      <td>0.81480</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10404</th>\n",
       "      <td>10404</td>\n",
       "      <td>196.0</td>\n",
       "      <td>30.920000</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>53.490297</td>\n",
       "      <td>10.074300</td>\n",
       "      <td>2.295000</td>\n",
       "      <td>1.545000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>0.469715</td>\n",
       "      <td>2.11540</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10405</th>\n",
       "      <td>10405</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.553160</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>26.621687</td>\n",
       "      <td>11.290033</td>\n",
       "      <td>2.743333</td>\n",
       "      <td>1.756667</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.486507</td>\n",
       "      <td>0.77755</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10406</th>\n",
       "      <td>10406</td>\n",
       "      <td>288.0</td>\n",
       "      <td>24.655328</td>\n",
       "      <td>11.142857</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>22.536126</td>\n",
       "      <td>10.960357</td>\n",
       "      <td>2.792143</td>\n",
       "      <td>1.772857</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.493919</td>\n",
       "      <td>0.97737</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  allelectrons_Total  density_Total  allelectrons_Average  \\\n",
       "10402  10402               128.0       7.558488             12.000000   \n",
       "10403  10403                30.0       1.743160             10.000000   \n",
       "10404  10404               196.0      30.920000             24.500000   \n",
       "10405  10405                38.0       1.553160             12.666667   \n",
       "10406  10406               288.0      24.655328             11.142857   \n",
       "\n",
       "       val_e_Average  atomicweight_Average  ionenergy_Average  \\\n",
       "10402       4.000000             26.385218          11.330440   \n",
       "10403       5.333333             20.766935          14.163933   \n",
       "10404       5.500000             53.490297          10.074300   \n",
       "10405       4.666667             26.621687          11.290033   \n",
       "10406       4.571429             22.536126          10.960357   \n",
       "\n",
       "       el_neg_chi_Average  R_vdw_element_Average  R_cov_element_Average  \\\n",
       "10402            2.644000               1.631000               0.892000   \n",
       "10403            3.090000               1.556667               0.866667   \n",
       "10404            2.295000               1.545000               1.120000   \n",
       "10405            2.743333               1.756667               0.980000   \n",
       "10406            2.792143               1.772857               0.940000   \n",
       "\n",
       "       zaratio_Average  density_Average  Hardness  \n",
       "10402         0.496070          1.79607       4.0  \n",
       "10403         0.480390          0.81480       5.0  \n",
       "10404         0.469715          2.11540       1.8  \n",
       "10405         0.486507          0.77755       6.0  \n",
       "10406         0.493919          0.97737       6.5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>1%</th>\n",
       "      <th>50%</th>\n",
       "      <th>99%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>5203.000000</td>\n",
       "      <td>3004.386460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.060000</td>\n",
       "      <td>5203.000000</td>\n",
       "      <td>10301.940000</td>\n",
       "      <td>10406.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>128.053516</td>\n",
       "      <td>224.123776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>719.400000</td>\n",
       "      <td>15300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density_Total</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>14.491342</td>\n",
       "      <td>15.972877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.739942</td>\n",
       "      <td>10.650000</td>\n",
       "      <td>75.098979</td>\n",
       "      <td>643.093804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>17.033222</td>\n",
       "      <td>10.468734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_e_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>4.546789</td>\n",
       "      <td>0.690864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>37.507703</td>\n",
       "      <td>26.012313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.773227</td>\n",
       "      <td>26.203827</td>\n",
       "      <td>119.629500</td>\n",
       "      <td>167.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>10.938308</td>\n",
       "      <td>1.408276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.054000</td>\n",
       "      <td>11.202760</td>\n",
       "      <td>13.512520</td>\n",
       "      <td>15.245810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>2.607662</td>\n",
       "      <td>0.334906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>2.706000</td>\n",
       "      <td>2.980000</td>\n",
       "      <td>3.443000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>1.731330</td>\n",
       "      <td>0.192481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.318667</td>\n",
       "      <td>1.732727</td>\n",
       "      <td>2.055000</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>0.944132</td>\n",
       "      <td>0.180017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.505333</td>\n",
       "      <td>0.915556</td>\n",
       "      <td>1.390000</td>\n",
       "      <td>1.615840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zaratio_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>0.493349</td>\n",
       "      <td>0.063080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.405373</td>\n",
       "      <td>0.488550</td>\n",
       "      <td>0.707253</td>\n",
       "      <td>0.825990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>2.132984</td>\n",
       "      <td>1.936656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132734</td>\n",
       "      <td>1.351550</td>\n",
       "      <td>7.986670</td>\n",
       "      <td>10.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hardness</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>4.647126</td>\n",
       "      <td>1.680525</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>8.288000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count         mean          std  min          1%  \\\n",
       "id                     10407.0  5203.000000  3004.386460  0.0  104.060000   \n",
       "allelectrons_Total     10407.0   128.053516   224.123776  0.0    6.000000   \n",
       "density_Total          10407.0    14.491342    15.972877  0.0    0.739942   \n",
       "allelectrons_Average   10407.0    17.033222    10.468734  0.0    4.666667   \n",
       "val_e_Average          10407.0     4.546789     0.690864  0.0    2.000000   \n",
       "atomicweight_Average   10407.0    37.507703    26.012313  0.0    8.773227   \n",
       "ionenergy_Average      10407.0    10.938308     1.408276  0.0    8.054000   \n",
       "el_neg_chi_Average     10407.0     2.607662     0.334906  0.0    1.790000   \n",
       "R_vdw_element_Average  10407.0     1.731330     0.192481  0.0    1.318667   \n",
       "R_cov_element_Average  10407.0     0.944132     0.180017  0.0    0.505333   \n",
       "zaratio_Average        10407.0     0.493349     0.063080  0.0    0.405373   \n",
       "density_Average        10407.0     2.132984     1.936656  0.0    0.132734   \n",
       "Hardness               10407.0     4.647126     1.680525  1.0    1.500000   \n",
       "\n",
       "                               50%           99%           max  \n",
       "id                     5203.000000  10301.940000  10406.000000  \n",
       "allelectrons_Total      100.000000    719.400000  15300.000000  \n",
       "density_Total            10.650000     75.098979    643.093804  \n",
       "allelectrons_Average     12.600000     50.000000     67.000000  \n",
       "val_e_Average             4.714286      5.666667      6.000000  \n",
       "atomicweight_Average     26.203827    119.629500    167.400000  \n",
       "ionenergy_Average        11.202760     13.512520     15.245810  \n",
       "el_neg_chi_Average        2.706000      2.980000      3.443000  \n",
       "R_vdw_element_Average     1.732727      2.055000      2.250000  \n",
       "R_cov_element_Average     0.915556      1.390000      1.615840  \n",
       "zaratio_Average           0.488550      0.707253      0.825990  \n",
       "density_Average           1.351550      7.986670     10.970000  \n",
       "Hardness                  5.500000      8.288000     10.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe([0.01, 0.99]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "TARGET = 'Hardness'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['allelectrons_Total', 'density_Total', 'allelectrons_Average',\n",
      "       'val_e_Average', 'atomicweight_Average', 'ionenergy_Average',\n",
      "       'el_neg_chi_Average', 'R_vdw_element_Average', 'R_cov_element_Average',\n",
      "       'zaratio_Average', 'density_Average'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Selecting numerical variables from the train dataset, excluding 'id' and TARGET\n",
    "num_var = train.drop(['id', TARGET], axis=1).select_dtypes(include=np.number).columns\n",
    "print(num_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining train and test datasets for comparative analysis\n",
    "# 'Source' column is added to label data from each dataset\n",
    "df = pd.concat([\n",
    "    train[num_var].assign(Source='Train'), \n",
    "    test[num_var].assign(Source='Test')\n",
    "], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature name: allelectrons_Total\n",
      "Low Limit: -1064.1000000000076\n",
      "Upper Limit: 1789.5000000000127\n",
      "\n",
      "Feature name: density_Total\n",
      "Low Limit: -109.70094011562419\n",
      "Upper Limit: 184.80760706937366\n",
      "\n",
      "Feature name: allelectrons_Average\n",
      "Low Limit: -63.333333333333336\n",
      "Upper Limit: 118.0\n",
      "\n",
      "Feature name: val_e_Average\n",
      "Low Limit: -3.5000000000000018\n",
      "Upper Limit: 11.16666666666667\n",
      "\n",
      "Feature name: atomicweight_Average\n",
      "Low Limit: -157.51118333333332\n",
      "Upper Limit: 285.91391\n",
      "\n",
      "Feature name: ionenergy_Average\n",
      "Low Limit: -0.1337799999999998\n",
      "Upper Limit: 21.7003\n",
      "\n",
      "Feature name: el_neg_chi_Average\n",
      "Low Limit: 0.0050000000000001155\n",
      "Upper Limit: 4.765\n",
      "\n",
      "Feature name: R_vdw_element_Average\n",
      "Low Limit: 0.37229797979797974\n",
      "Upper Limit: 3.0646212121212124\n",
      "\n",
      "Feature name: R_cov_element_Average\n",
      "Low Limit: -0.6014419504643963\n",
      "Upper Limit: 2.5848651702786376\n",
      "\n",
      "Feature name: zaratio_Average\n",
      "Low Limit: 0.005794696969696755\n",
      "Upper Limit: 1.1281555050505054\n",
      "\n",
      "Feature name: density_Average\n",
      "Low Limit: -11.638980000000002\n",
      "Upper Limit: 19.76206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for outliers\n",
    "def outlier_thresholds(dataframe, col_name, q1=0.01, q3=0.99):\n",
    "    quartile1 = dataframe[col_name].quantile(q1)\n",
    "    quartile3 = dataframe[col_name].quantile(q3)\n",
    "    IQR = quartile3 - quartile1\n",
    "    up_limit = quartile3 + 1.5 * IQR\n",
    "    low_limit = quartile1 - 1.5 * IQR\n",
    "    print(f'Feature name: {col_name}')\n",
    "    print(f'Low Limit: {low_limit}')\n",
    "    print(f'Upper Limit: {up_limit}')\n",
    "    print()\n",
    "    return low_limit, up_limit\n",
    "\n",
    "\n",
    "def remove_outlier(dataframe, col_name):\n",
    "    \"\"\"\n",
    "    Example Usage:\n",
    "    for col in num_cols:\n",
    "    new_df = remove_outlier(titanic, col)\n",
    "    \"\"\"\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n",
    "    df_without_outliers = dataframe[~((dataframe[col_name] < low_limit) | (dataframe[col_name] > up_limit))]    \n",
    "    return df_without_outliers\n",
    "\n",
    "def cap_outliers(dataframe, col_name):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n",
    "\n",
    "    dataframe[col_name] = np.where(dataframe[col_name] > up_limit, up_limit, \n",
    "                                   np.where(dataframe[col_name] < low_limit, low_limit, dataframe[col_name]))\n",
    "    return dataframe\n",
    "\n",
    "df_outliers = train.copy()\n",
    "for col in num_var:\n",
    "    df_outliers = remove_outlier(df_outliers, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>1%</th>\n",
       "      <th>50%</th>\n",
       "      <th>99%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>5201.192420</td>\n",
       "      <td>3005.129652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>106.150000</td>\n",
       "      <td>5201.500000</td>\n",
       "      <td>10300.850000</td>\n",
       "      <td>10406.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>124.139079</td>\n",
       "      <td>109.999695</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>622.000000</td>\n",
       "      <td>1266.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density_Total</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>14.469886</td>\n",
       "      <td>14.249258</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.973995</td>\n",
       "      <td>10.803992</td>\n",
       "      <td>73.958979</td>\n",
       "      <td>178.74200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>17.161600</td>\n",
       "      <td>10.400841</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>5.520000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>67.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_e_Average</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>4.578703</td>\n",
       "      <td>0.580486</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>6.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>37.792042</td>\n",
       "      <td>25.897682</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>10.895366</td>\n",
       "      <td>26.203827</td>\n",
       "      <td>119.629500</td>\n",
       "      <td>167.40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>11.017059</td>\n",
       "      <td>1.058323</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>8.213150</td>\n",
       "      <td>11.217767</td>\n",
       "      <td>13.512520</td>\n",
       "      <td>15.24581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>2.625121</td>\n",
       "      <td>0.260140</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>2.706000</td>\n",
       "      <td>2.980000</td>\n",
       "      <td>3.44300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>1.742674</td>\n",
       "      <td>0.131928</td>\n",
       "      <td>1.028000</td>\n",
       "      <td>1.385714</td>\n",
       "      <td>1.733958</td>\n",
       "      <td>2.055000</td>\n",
       "      <td>2.25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>0.951067</td>\n",
       "      <td>0.161130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.612174</td>\n",
       "      <td>0.918000</td>\n",
       "      <td>1.390000</td>\n",
       "      <td>1.61584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zaratio_Average</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>0.496283</td>\n",
       "      <td>0.050363</td>\n",
       "      <td>0.401635</td>\n",
       "      <td>0.426680</td>\n",
       "      <td>0.488550</td>\n",
       "      <td>0.707270</td>\n",
       "      <td>0.82599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density_Average</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>2.146405</td>\n",
       "      <td>1.938989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136410</td>\n",
       "      <td>1.363050</td>\n",
       "      <td>7.986670</td>\n",
       "      <td>10.97000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hardness</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>4.662606</td>\n",
       "      <td>1.671795</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>8.470000</td>\n",
       "      <td>10.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count         mean          std       min  \\\n",
       "id                     10316.0  5201.192420  3005.129652  0.000000   \n",
       "allelectrons_Total     10316.0   124.139079   109.999695  0.001000   \n",
       "density_Total          10316.0    14.469886    14.249258  0.001000   \n",
       "allelectrons_Average   10316.0    17.161600    10.400841  0.001000   \n",
       "val_e_Average          10316.0     4.578703     0.580486  1.333333   \n",
       "atomicweight_Average   10316.0    37.792042    25.897682  0.001000   \n",
       "ionenergy_Average      10316.0    11.017059     1.058323  0.000167   \n",
       "el_neg_chi_Average     10316.0     2.625121     0.260140  1.666667   \n",
       "R_vdw_element_Average  10316.0     1.742674     0.131928  1.028000   \n",
       "R_cov_element_Average  10316.0     0.951067     0.161130  0.000000   \n",
       "zaratio_Average        10316.0     0.496283     0.050363  0.401635   \n",
       "density_Average        10316.0     2.146405     1.938989  0.000000   \n",
       "Hardness               10316.0     4.662606     1.671795  1.000000   \n",
       "\n",
       "                               1%          50%           99%          max  \n",
       "id                     106.150000  5201.500000  10300.850000  10406.00000  \n",
       "allelectrons_Total      20.000000   100.000000    622.000000   1266.00000  \n",
       "density_Total            0.973995    10.803992     73.958979    178.74200  \n",
       "allelectrons_Average     5.520000    12.600000     50.000000     67.00000  \n",
       "val_e_Average            2.666667     4.750000      5.666667      6.00000  \n",
       "atomicweight_Average    10.895366    26.203827    119.629500    167.40000  \n",
       "ionenergy_Average        8.213150    11.217767     13.512520     15.24581  \n",
       "el_neg_chi_Average       1.950000     2.706000      2.980000      3.44300  \n",
       "R_vdw_element_Average    1.385714     1.733958      2.055000      2.25000  \n",
       "R_cov_element_Average    0.612174     0.918000      1.390000      1.61584  \n",
       "zaratio_Average          0.426680     0.488550      0.707270      0.82599  \n",
       "density_Average          0.136410     1.363050      7.986670     10.97000  \n",
       "Hardness                 1.500000     5.500000      8.470000     10.00000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_outliers.describe([0.01, 0.99]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No missing data in the both train and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL CROSS-VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y_true, y_pred):\n",
    "    return tfp.stats.percentile(tf.abs(y_true - y_pred), q=50)\n",
    "\n",
    "def metric_fn(y_true, y_pred):\n",
    "    return tfp.stats.percentile(tf.abs(y_true - y_pred), q=100) - tfp.stats.percentile(tf.abs(y_true - y_pred), q=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pre = RandomForestRegressor(random_state=5)\n",
    "model_pre.fit(train[num_var], train[TARGET])\n",
    "\n",
    "train_new = train[num_var].copy()\n",
    "test_new = test[num_var].copy()\n",
    "train_new['Hardness_pred'] = model_pre.predict(train[num_var])\n",
    "test_new['Hardness_pred'] = model_pre.predict(test[num_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['allelectrons_Total', 'density_Total', 'allelectrons_Average',\n",
       "       'val_e_Average', 'atomicweight_Average', 'ionenergy_Average',\n",
       "       'el_neg_chi_Average', 'R_vdw_element_Average', 'R_cov_element_Average',\n",
       "       'zaratio_Average', 'density_Average', 'Hardness_pred'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True, mode='min')\n",
    "reduce_LR = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=5, min_lr=0.00001,factor=0.8)\n",
    "terminate = tf.keras.callbacks.TerminateOnNaN()\n",
    "\n",
    "class KerasRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, epochs=100, batch_size=32):\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.InputLayer(input_shape=(len(train_new.columns),)),\n",
    "            tf.keras.layers.BatchNormalization(epsilon=0.00001),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(0.013, beta_1=0.5),\n",
    "                    loss=loss_fn,\n",
    "                      metrics=[metric_fn])\n",
    "        return model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y, epochs=self.epochs, \n",
    "                       batch_size=self.batch_size, \n",
    "                       verbose=0,\n",
    "                    #    class_weight=model_pre.class_weight,\n",
    "                       callbacks=[early_stopping,reduce_LR], \n",
    "                       validation_split=0.1)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MLA = [\n",
    "\t# Trial Models\n",
    "\tMLPRegressor(random_state=5),\n",
    "\tTheilSenRegressor(random_state=5),\n",
    "\tHuberRegressor(),\n",
    "\tRANSACRegressor(random_state=5),\n",
    "\tLasso(random_state=5),\n",
    "\tElasticNet(random_state=5),\n",
    "\tLars(random_state=5),\n",
    "\tLassoLars(random_state=5),\n",
    "\tOrthogonalMatchingPursuit(),\n",
    "\tBayesianRidge(),\n",
    "\tARDRegression(),\n",
    "    TweedieRegressor(power=1.5, alpha=0.5),\n",
    "    PoissonRegressor(alpha=0.5),\n",
    "    GammaRegressor(alpha=0.5),\n",
    "    LassoLars(alpha=0.1, random_state=5),\n",
    "\n",
    "\t# GLM\n",
    "\tLinearRegression(),\n",
    "\tPassiveAggressiveRegressor(random_state=5),\n",
    "\tRidgeCV(),\n",
    "\n",
    "\t# Trees    \n",
    "\tDecisionTreeRegressor(random_state=5),\n",
    "\tExtraTreeRegressor(random_state=5),\n",
    "\n",
    "\tXGBRegressor(random_state=5),\n",
    "\tLGBMRegressor(n_jobs=-1, random_state=5),\n",
    "\tCatBoostRegressor(random_state=5, verbose=False, early_stopping_rounds=100),\n",
    "\t\n",
    "\t# KNeighbors\n",
    "\tKNeighborsRegressor(),\n",
    "\tKNeighborsRegressor(n_neighbors=2),\n",
    "\tKNeighborsRegressor(n_neighbors=4),\n",
    "\tKNeighborsRegressor(n_neighbors=8),\n",
    "\tKNeighborsRegressor(n_neighbors=16),\n",
    "\tKNeighborsRegressor(n_neighbors=32),\n",
    "\tKNeighborsRegressor(n_neighbors=64),\n",
    "\tKNeighborsRegressor(n_neighbors=128),\n",
    "\tKNeighborsRegressor(n_neighbors=256),\n",
    "\tKNeighborsRegressor(n_neighbors=512),\n",
    "\tKNeighborsRegressor(n_neighbors=1024),\n",
    "\n",
    "\t# Ensemble Methods\n",
    "\tAdaBoostRegressor(random_state=5),\n",
    "\tBaggingRegressor(random_state=5),\n",
    "\tExtraTreesRegressor(random_state=5),\n",
    "\tGradientBoostingRegressor(random_state=5),\n",
    "\tHistGradientBoostingRegressor(random_state=5),\n",
    "\tRandomForestRegressor(random_state=5),\n",
    "    \n",
    "\t# Neural Networks\n",
    "\tKerasRegressor(epochs=100, batch_size=32),\n",
    "    ]\n",
    "\n",
    "\n",
    "# split dataset in cross-validation with splitter class\n",
    "# cv_split could KFold, StratifiedKFold or RepeatedKFold depending on the problem\n",
    "cv_split = KFold(n_splits=10, shuffle=True, random_state=5)\n",
    "cv_split_trial = KFold(n_splits=3, shuffle=True, random_state=5) # For quick trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with MLPRegressor\n",
      "Done with TheilSenRegressor\n",
      "Done with HuberRegressor\n",
      "Done with RANSACRegressor\n",
      "Done with Lasso\n",
      "Done with ElasticNet\n",
      "Done with Lars\n",
      "Done with LassoLars\n",
      "Done with OrthogonalMatchingPursuit\n",
      "Done with BayesianRidge\n",
      "Done with ARDRegression\n",
      "Done with TweedieRegressor\n",
      "Done with PoissonRegressor\n",
      "Done with GammaRegressor\n",
      "Done with LassoLars_1\n",
      "Done with LinearRegression\n",
      "Done with PassiveAggressiveRegressor\n",
      "Done with RidgeCV\n",
      "Done with DecisionTreeRegressor\n",
      "Done with ExtraTreeRegressor\n",
      "Done with XGBRegressor\n",
      "Done with LGBMRegressor\n",
      "Done with CatBoostRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor_1\n",
      "Done with KNeighborsRegressor_2\n",
      "Done with KNeighborsRegressor_3\n",
      "Done with KNeighborsRegressor_4\n",
      "Done with KNeighborsRegressor_5\n",
      "Done with KNeighborsRegressor_6\n",
      "Done with KNeighborsRegressor_7\n",
      "Done with KNeighborsRegressor_8\n",
      "Done with KNeighborsRegressor_9\n",
      "Done with KNeighborsRegressor_10\n",
      "Done with AdaBoostRegressor\n",
      "Done with BaggingRegressor\n",
      "Done with ExtraTreesRegressor\n",
      "Done with GradientBoostingRegressor\n",
      "Done with HistGradientBoostingRegressor\n",
      "Done with RandomForestRegressor\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "217/217 [==============================] - 0s 2ms/step\n",
      "109/109 [==============================] - 0s 2ms/step\n",
      "217/217 [==============================] - 1s 3ms/step\n",
      "109/109 [==============================] - 0s 2ms/step\n",
      "217/217 [==============================] - 1s 2ms/step\n",
      "Done with KerasRegressor\n",
      "CPU times: total: 2min 1s\n",
      "Wall time: 4min 22s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Parameters</th>\n",
       "      <th>MLA Train Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy 3*STD</th>\n",
       "      <th>MLA Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'criter...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.113333</td>\n",
       "      <td>0.011045</td>\n",
       "      <td>0 min 2.60 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...</td>\n",
       "      <td>0.042333</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.006481</td>\n",
       "      <td>0 min 6.58 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.123333</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>0 min 0.69 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>{'categorical_features': None, 'early_stopping...</td>\n",
       "      <td>0.09721</td>\n",
       "      <td>0.123615</td>\n",
       "      <td>0.003827</td>\n",
       "      <td>0 min 1.61 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>0.097827</td>\n",
       "      <td>0.126971</td>\n",
       "      <td>0.005401</td>\n",
       "      <td>0 min 0.31 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CatBoostRegressor</td>\n",
       "      <td>{'loss_function': 'RMSE', 'verbose': False, 'r...</td>\n",
       "      <td>0.091618</td>\n",
       "      <td>0.127041</td>\n",
       "      <td>0.008348</td>\n",
       "      <td>0 min 5.91 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>{'objective': 'reg:squarederror', 'base_score'...</td>\n",
       "      <td>0.055485</td>\n",
       "      <td>0.127186</td>\n",
       "      <td>0.007569</td>\n",
       "      <td>0 min 1.38 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>{'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': ...</td>\n",
       "      <td>0.132206</td>\n",
       "      <td>0.141814</td>\n",
       "      <td>0.004909</td>\n",
       "      <td>0 min 2.23 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'squared_error...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 min 0.15 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ExtraTreeRegressor</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'squared_error...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 min 0.04 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BayesianRidge</td>\n",
       "      <td>{'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_in...</td>\n",
       "      <td>0.202363</td>\n",
       "      <td>0.202958</td>\n",
       "      <td>0.013107</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>{'alpha_per_target': False, 'alphas': (0.1, 1....</td>\n",
       "      <td>0.202405</td>\n",
       "      <td>0.20303</td>\n",
       "      <td>0.012125</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ARDRegression</td>\n",
       "      <td>{'alpha_1': 1e-06, 'alpha_2': 1e-06, 'compute_...</td>\n",
       "      <td>0.202566</td>\n",
       "      <td>0.203066</td>\n",
       "      <td>0.01367</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>{'copy_X': True, 'fit_intercept': True, 'n_job...</td>\n",
       "      <td>0.202156</td>\n",
       "      <td>0.203256</td>\n",
       "      <td>0.012694</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lars</td>\n",
       "      <td>{'copy_X': True, 'eps': 2.220446049250313e-16,...</td>\n",
       "      <td>0.202835</td>\n",
       "      <td>0.204278</td>\n",
       "      <td>0.017033</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HuberRegressor</td>\n",
       "      <td>{'alpha': 0.0001, 'epsilon': 1.35, 'fit_interc...</td>\n",
       "      <td>0.204438</td>\n",
       "      <td>0.205358</td>\n",
       "      <td>0.008902</td>\n",
       "      <td>0 min 0.23 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TheilSenRegressor</td>\n",
       "      <td>{'copy_X': True, 'fit_intercept': True, 'max_i...</td>\n",
       "      <td>0.207403</td>\n",
       "      <td>0.207852</td>\n",
       "      <td>0.010148</td>\n",
       "      <td>0 min 5.09 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RANSACRegressor</td>\n",
       "      <td>{'base_estimator': 'deprecated', 'estimator': ...</td>\n",
       "      <td>0.213607</td>\n",
       "      <td>0.212984</td>\n",
       "      <td>0.013558</td>\n",
       "      <td>0 min 0.11 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>KerasRegressor</td>\n",
       "      <td>{'batch_size': 32, 'epochs': 100}</td>\n",
       "      <td>0.220206</td>\n",
       "      <td>0.220564</td>\n",
       "      <td>0.034648</td>\n",
       "      <td>0 min 44.06 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OrthogonalMatchingPursuit</td>\n",
       "      <td>{'fit_intercept': True, 'n_nonzero_coefs': Non...</td>\n",
       "      <td>0.227198</td>\n",
       "      <td>0.227061</td>\n",
       "      <td>0.010764</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>{'base_estimator': None, 'learning_rate': 1.0,...</td>\n",
       "      <td>0.306473</td>\n",
       "      <td>0.308401</td>\n",
       "      <td>0.119662</td>\n",
       "      <td>0 min 0.84 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PoissonRegressor</td>\n",
       "      <td>{'alpha': 0.5, 'fit_intercept': True, 'max_ite...</td>\n",
       "      <td>0.308123</td>\n",
       "      <td>0.308804</td>\n",
       "      <td>0.019578</td>\n",
       "      <td>0 min 0.08 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'batch...</td>\n",
       "      <td>0.371609</td>\n",
       "      <td>0.362704</td>\n",
       "      <td>0.320896</td>\n",
       "      <td>0 min 2.51 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>KNeighborsRegressor_2</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.441667</td>\n",
       "      <td>0.035355</td>\n",
       "      <td>0 min 0.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.028284</td>\n",
       "      <td>0 min 0.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>KNeighborsRegressor_3</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.046771</td>\n",
       "      <td>0 min 0.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>KNeighborsRegressor_1</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 min 0.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>{'alpha': 1.0, 'copy_X': True, 'fit_intercept'...</td>\n",
       "      <td>0.527084</td>\n",
       "      <td>0.528179</td>\n",
       "      <td>0.020105</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>KNeighborsRegressor_4</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.502083</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.015309</td>\n",
       "      <td>0 min 0.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>{'alpha': 1.0, 'copy_X': True, 'fit_intercept'...</td>\n",
       "      <td>0.616158</td>\n",
       "      <td>0.616956</td>\n",
       "      <td>0.016824</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>KNeighborsRegressor_5</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.601042</td>\n",
       "      <td>0.630208</td>\n",
       "      <td>0.038528</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PassiveAggressiveRegressor</td>\n",
       "      <td>{'C': 1.0, 'average': False, 'early_stopping':...</td>\n",
       "      <td>0.733627</td>\n",
       "      <td>0.738873</td>\n",
       "      <td>1.016316</td>\n",
       "      <td>0 min 0.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>KNeighborsRegressor_6</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.720833</td>\n",
       "      <td>0.739063</td>\n",
       "      <td>0.07451</td>\n",
       "      <td>0 min 0.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>KNeighborsRegressor_7</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.856771</td>\n",
       "      <td>0.865104</td>\n",
       "      <td>0.081288</td>\n",
       "      <td>0 min 0.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>KNeighborsRegressor_8</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.936979</td>\n",
       "      <td>0.942448</td>\n",
       "      <td>0.033257</td>\n",
       "      <td>0 min 0.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>KNeighborsRegressor_9</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>1.020814</td>\n",
       "      <td>1.022005</td>\n",
       "      <td>0.074232</td>\n",
       "      <td>0 min 0.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>KNeighborsRegressor_10</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>1.108146</td>\n",
       "      <td>1.113981</td>\n",
       "      <td>0.068469</td>\n",
       "      <td>0 min 0.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LassoLars</td>\n",
       "      <td>{'alpha': 1.0, 'copy_X': True, 'eps': 2.220446...</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>0.022821</td>\n",
       "      <td>0 min 0.00 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LassoLars_1</td>\n",
       "      <td>{'alpha': 0.1, 'copy_X': True, 'eps': 2.220446...</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>0.022821</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TweedieRegressor</td>\n",
       "      <td>{'alpha': 0.5, 'fit_intercept': True, 'link': ...</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>0.022821</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GammaRegressor</td>\n",
       "      <td>{'alpha': 0.5, 'fit_intercept': True, 'max_ite...</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>0.022821</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         MLA Name  \\\n",
       "36            ExtraTreesRegressor   \n",
       "39          RandomForestRegressor   \n",
       "35               BaggingRegressor   \n",
       "38  HistGradientBoostingRegressor   \n",
       "21                  LGBMRegressor   \n",
       "22              CatBoostRegressor   \n",
       "20                   XGBRegressor   \n",
       "37      GradientBoostingRegressor   \n",
       "18          DecisionTreeRegressor   \n",
       "19             ExtraTreeRegressor   \n",
       "9                   BayesianRidge   \n",
       "17                        RidgeCV   \n",
       "10                  ARDRegression   \n",
       "15               LinearRegression   \n",
       "6                            Lars   \n",
       "2                  HuberRegressor   \n",
       "1               TheilSenRegressor   \n",
       "3                 RANSACRegressor   \n",
       "40                 KerasRegressor   \n",
       "8       OrthogonalMatchingPursuit   \n",
       "34              AdaBoostRegressor   \n",
       "12               PoissonRegressor   \n",
       "0                    MLPRegressor   \n",
       "25          KNeighborsRegressor_2   \n",
       "23            KNeighborsRegressor   \n",
       "26          KNeighborsRegressor_3   \n",
       "24          KNeighborsRegressor_1   \n",
       "5                      ElasticNet   \n",
       "27          KNeighborsRegressor_4   \n",
       "4                           Lasso   \n",
       "28          KNeighborsRegressor_5   \n",
       "16     PassiveAggressiveRegressor   \n",
       "29          KNeighborsRegressor_6   \n",
       "30          KNeighborsRegressor_7   \n",
       "31          KNeighborsRegressor_8   \n",
       "32          KNeighborsRegressor_9   \n",
       "33         KNeighborsRegressor_10   \n",
       "7                       LassoLars   \n",
       "14                    LassoLars_1   \n",
       "11               TweedieRegressor   \n",
       "13                 GammaRegressor   \n",
       "\n",
       "                                       MLA Parameters MLA Train Accuracy Mean  \\\n",
       "36  {'bootstrap': False, 'ccp_alpha': 0.0, 'criter...                    -0.0   \n",
       "39  {'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...                0.042333   \n",
       "35  {'base_estimator': None, 'bootstrap': True, 'b...                    0.05   \n",
       "38  {'categorical_features': None, 'early_stopping...                 0.09721   \n",
       "21  {'boosting_type': 'gbdt', 'class_weight': None...                0.097827   \n",
       "22  {'loss_function': 'RMSE', 'verbose': False, 'r...                0.091618   \n",
       "20  {'objective': 'reg:squarederror', 'base_score'...                0.055485   \n",
       "37  {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': ...                0.132206   \n",
       "18  {'ccp_alpha': 0.0, 'criterion': 'squared_error...                    -0.0   \n",
       "19  {'ccp_alpha': 0.0, 'criterion': 'squared_error...                    -0.0   \n",
       "9   {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_in...                0.202363   \n",
       "17  {'alpha_per_target': False, 'alphas': (0.1, 1....                0.202405   \n",
       "10  {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'compute_...                0.202566   \n",
       "15  {'copy_X': True, 'fit_intercept': True, 'n_job...                0.202156   \n",
       "6   {'copy_X': True, 'eps': 2.220446049250313e-16,...                0.202835   \n",
       "2   {'alpha': 0.0001, 'epsilon': 1.35, 'fit_interc...                0.204438   \n",
       "1   {'copy_X': True, 'fit_intercept': True, 'max_i...                0.207403   \n",
       "3   {'base_estimator': 'deprecated', 'estimator': ...                0.213607   \n",
       "40                  {'batch_size': 32, 'epochs': 100}                0.220206   \n",
       "8   {'fit_intercept': True, 'n_nonzero_coefs': Non...                0.227198   \n",
       "34  {'base_estimator': None, 'learning_rate': 1.0,...                0.306473   \n",
       "12  {'alpha': 0.5, 'fit_intercept': True, 'max_ite...                0.308123   \n",
       "0   {'activation': 'relu', 'alpha': 0.0001, 'batch...                0.371609   \n",
       "25  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                   0.325   \n",
       "23  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                    0.36   \n",
       "26  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                  0.4125   \n",
       "24  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                    0.25   \n",
       "5   {'alpha': 1.0, 'copy_X': True, 'fit_intercept'...                0.527084   \n",
       "27  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                0.502083   \n",
       "4   {'alpha': 1.0, 'copy_X': True, 'fit_intercept'...                0.616158   \n",
       "28  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                0.601042   \n",
       "16  {'C': 1.0, 'average': False, 'early_stopping':...                0.733627   \n",
       "29  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                0.720833   \n",
       "30  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                0.856771   \n",
       "31  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                0.936979   \n",
       "32  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                1.020814   \n",
       "33  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                1.108146   \n",
       "7   {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446...                1.352874   \n",
       "14  {'alpha': 0.1, 'copy_X': True, 'eps': 2.220446...                1.352874   \n",
       "11  {'alpha': 0.5, 'fit_intercept': True, 'link': ...                1.352874   \n",
       "13  {'alpha': 0.5, 'fit_intercept': True, 'max_ite...                1.352874   \n",
       "\n",
       "   MLA Test Accuracy Mean MLA Test Accuracy 3*STD         MLA Time  \n",
       "36               0.113333                0.011045   0 min 2.60 sec  \n",
       "39                  0.114                0.006481   0 min 6.58 sec  \n",
       "35               0.123333                0.014142   0 min 0.69 sec  \n",
       "38               0.123615                0.003827   0 min 1.61 sec  \n",
       "21               0.126971                0.005401   0 min 0.31 sec  \n",
       "22               0.127041                0.008348   0 min 5.91 sec  \n",
       "20               0.127186                0.007569   0 min 1.38 sec  \n",
       "37               0.141814                0.004909   0 min 2.23 sec  \n",
       "18                    0.2                     0.0   0 min 0.15 sec  \n",
       "19                    0.2                     0.0   0 min 0.04 sec  \n",
       "9                0.202958                0.013107   0 min 0.01 sec  \n",
       "17                0.20303                0.012125   0 min 0.01 sec  \n",
       "10               0.203066                 0.01367   0 min 0.01 sec  \n",
       "15               0.203256                0.012694   0 min 0.01 sec  \n",
       "6                0.204278                0.017033   0 min 0.01 sec  \n",
       "2                0.205358                0.008902   0 min 0.23 sec  \n",
       "1                0.207852                0.010148   0 min 5.09 sec  \n",
       "3                0.212984                0.013558   0 min 0.11 sec  \n",
       "40               0.220564                0.034648  0 min 44.06 sec  \n",
       "8                0.227061                0.010764   0 min 0.01 sec  \n",
       "34               0.308401                0.119662   0 min 0.84 sec  \n",
       "12               0.308804                0.019578   0 min 0.08 sec  \n",
       "0                0.362704                0.320896   0 min 2.51 sec  \n",
       "25               0.441667                0.035355   0 min 0.02 sec  \n",
       "23               0.453333                0.028284   0 min 0.02 sec  \n",
       "26               0.483333                0.046771   0 min 0.02 sec  \n",
       "24                    0.5                     0.0   0 min 0.02 sec  \n",
       "5                0.528179                0.020105   0 min 0.01 sec  \n",
       "27                   0.55                0.015309   0 min 0.02 sec  \n",
       "4                0.616956                0.016824   0 min 0.01 sec  \n",
       "28               0.630208                0.038528   0 min 0.01 sec  \n",
       "16               0.738873                1.016316   0 min 0.02 sec  \n",
       "29               0.739063                 0.07451   0 min 0.02 sec  \n",
       "30               0.865104                0.081288   0 min 0.02 sec  \n",
       "31               0.942448                0.033257   0 min 0.02 sec  \n",
       "32               1.022005                0.074232   0 min 0.02 sec  \n",
       "33               1.113981                0.068469   0 min 0.02 sec  \n",
       "7                1.352874                0.022821   0 min 0.00 sec  \n",
       "14               1.352874                0.022821   0 min 0.01 sec  \n",
       "11               1.352874                0.022821   0 min 0.01 sec  \n",
       "13               1.352874                0.022821   0 min 0.01 sec  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# create table to compare MLA metrics\n",
    "MLA_columns = ['MLA Name', 'MLA Parameters', 'MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD', 'MLA Time']\n",
    "MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "\n",
    "# create table to compare MLA predictions\n",
    "MLA_predict = {}\n",
    "\n",
    "# index through MLA and save performance to table\n",
    "row_index = 0\n",
    "scoring = median_abs_error_scorer = make_scorer(median_absolute_error, greater_is_better=False)\n",
    "\n",
    "for alg in MLA:\n",
    "\n",
    "\t# set name and parameters\n",
    "\tMLA_name = alg.__class__.__name__\n",
    "\n",
    "\t# Add suffix if name already exists\n",
    "\tsuffix = 1\n",
    "\toriginal_MLA_name = MLA_name\n",
    "\twhile MLA_compare['MLA Name'].str.contains(MLA_name).any():\n",
    "\t\tMLA_name = f\"{original_MLA_name}_{suffix}\"\n",
    "\t\tsuffix += 1\n",
    "\t\t\n",
    "\tMLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
    "\tMLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
    "\n",
    "\t\"\"\"score model with cross validation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\"\"\"\n",
    "\n",
    "\tcv_results = cross_validate(alg, train_new, train[TARGET], cv=cv_split_trial, scoring=scoring, return_train_score=True)\n",
    "\n",
    "\t# Calculate mean time in seconds\n",
    "\tmean_fit_time = cv_results['fit_time'].mean()\n",
    "\n",
    "\t# Convert mean time to minutes and seconds\n",
    "\tminutes = int(mean_fit_time // 60)\n",
    "\tseconds = mean_fit_time % 60\n",
    "\n",
    "\t# Format the time and assign it\n",
    "\tMLA_compare.loc[row_index, 'MLA Time'] = f\"{minutes} min {seconds:.2f} sec\"\n",
    "\tMLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean() * -1\n",
    "\tMLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean() * -1\n",
    "\t#if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\n",
    "\tMLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   #let's know the worst that can happen!\n",
    "\n",
    "\t# # #save MLA predictions - see section 6 for usage\n",
    "\t# alg.fit(data1[data1_x_bin], data1[Target])\n",
    "\t# MLA_predict[MLA_name] = alg.predict(data1[data1_x_bin])\n",
    "\tprint(f'Done with {MLA_name}')\n",
    "\trow_index+=1\n",
    "\n",
    "\n",
    "#print and sort table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html\n",
    "MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = True, inplace = True)\n",
    "MLA_compare.to_csv(f'{experiment}_results.csv', index=False)\n",
    "MLA_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Algorithm')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n",
    "\n",
    "#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\n",
    "plt.title('Machine Learning Algorithm Accuracy Score \\n')\n",
    "plt.xlabel('Accuracy Score (%)')\n",
    "plt.ylabel('Algorithm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENSEMBLE CROSS-VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hill Climbing inspired by code from Kaggle\n",
    "def hill_climbing(x, y):\n",
    "    \n",
    "    # Evaluating oof predictions\n",
    "    scores = {}\n",
    "    for col in x.columns:\n",
    "        scores[col] = median_absolute_error(y, x[col])\n",
    "\n",
    "    # Sorting the model scores in ascending order\n",
    "    scores = {k: v for k, v in sorted(scores.items(), key = lambda item: item[1], reverse = False)}\n",
    "\n",
    "    # Sort oof_df\n",
    "    x = x[list(scores.keys())]\n",
    "\n",
    "    # Initialize weights\n",
    "    weights = {col: 1 if i == 0 else 0 for i, col in enumerate(x.columns)}\n",
    "\n",
    "    STOP = False\n",
    "    current_best_ensemble = x.iloc[:,0]\n",
    "    MODELS = x.iloc[:,1:]\n",
    "    weight_range = np.arange(-0.5, 0.51, 0.01) \n",
    "    history = [median_absolute_error(y, current_best_ensemble)]\n",
    "    j = 0\n",
    "\n",
    "    while not STOP:\n",
    "        j += 1\n",
    "        potential_new_best_cv_score = median_absolute_error(y, current_best_ensemble)\n",
    "        k_best, wgt_best = None, None\n",
    "        for k in MODELS:\n",
    "            for wgt in weight_range:\n",
    "                potential_ensemble = (1 - wgt) * current_best_ensemble + wgt * MODELS[k]\n",
    "                cv_score = median_absolute_error(y, potential_ensemble)\n",
    "                if cv_score < potential_new_best_cv_score:\n",
    "                    potential_new_best_cv_score = cv_score\n",
    "                    k_best, wgt_best = k, wgt\n",
    "\n",
    "        if k_best is not None:\n",
    "            # Update weights\n",
    "            weights = {col: (1 - wgt_best) * weights[col] if col != k_best else wgt_best for col in weights}\n",
    "            current_best_ensemble = (1 - wgt_best) * current_best_ensemble + wgt_best * MODELS[k_best]\n",
    "            MODELS.drop(k_best, axis = 1, inplace = True)\n",
    "            if MODELS.shape[1] == 0:\n",
    "                STOP = True\n",
    "            history.append(potential_new_best_cv_score)\n",
    "        else:\n",
    "            STOP = True\n",
    "        \n",
    "    hill_ens_pred = current_best_ensemble\n",
    "    \n",
    "    return hill_ens_pred, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission_file(ids, predictions, filename):\n",
    "    submission = pd.DataFrame({'id': ids, 'Hardness': predictions})\n",
    "    submission.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "217/217 [==============================] - 1s 2ms/step\n",
      "109/109 [==============================] - 0s 2ms/step\n",
      "The Fold 1 Hill Climb is 0.10806171794494945\n",
      "The Fold 1 weight is {'RandomForestRegressor': 0.6653840605824665, 'ExtraTreesRegressor': 0.28516459739248723, 'HistGradientBoostingRegressor': 0.1056165175527734, 'XGBRegressor': 0.06741479843794068, 'LGBMRegressor': -0.020195999999999374, 'CatBoostRegressor': -0.019999999999999397, 'BaggingRegressor': 0.010200000000000368, 'GradientBoostingRegressor': -0.07350523194167893, 'DecisionTreeRegressor': 0.0, 'ExtraTreeRegressor': 0.02143009677600027, 'HuberRegressor': -0.030899879999999293, 'RidgeCV': 0.0, 'BayesianRidge': 0.0, 'LinearRegression': 0.0, 'ARDRegression': 0.0, 'TheilSenRegressor': 0.0, 'Lars': 0.0, 'RANSACRegressor': 0.0, 'OrthogonalMatchingPursuit': 0.0, 'KerasRegressor': -0.01060895879999943, 'PoissonRegressor': 0.0, 'AdaBoostRegressor': 0.0, 'MLPRegressor': 0.0, 'KNeighborsRegressor_3': 4.4408920985006084e-16, 'KNeighborsRegressor': 4.4408920985006104e-16, 'KNeighborsRegressor_2': 4.4408920985006124e-16, 'KNeighborsRegressor_4': 4.4408920985006143e-16, 'ElasticNet': 4.4408920985006163e-16, 'KNeighborsRegressor_5': 4.4408920985006183e-16, 'Lasso': 4.44089209850062e-16, 'KNeighborsRegressor_6': 4.440892098500622e-16, 'KNeighborsRegressor_7': 4.440892098500624e-16, 'KNeighborsRegressor_8': 4.440892098500626e-16, 'KNeighborsRegressor_9': 4.4408920985005946e-16, 'KNeighborsRegressor_10': 4.4408920985005966e-16, 'KNeighborsRegressor_11': 4.4408920985005986e-16, 'PassiveAggressiveRegressor': 0.0, 'LassoLars': 4.4408920985006005e-16, 'TweedieRegressor': 4.4408920985006025e-16, 'GammaRegressor': 4.4408920985006045e-16, 'LassoLars_1': 4.4408920985006064e-16}\n",
      "\n",
      "Fold 2\n",
      "217/217 [==============================] - 1s 2ms/step\n",
      "109/109 [==============================] - 0s 2ms/step\n",
      "The Fold 2 Hill Climb is 0.10289264439080537\n",
      "The Fold 2 weight is {'ExtraTreesRegressor': 0.674225639999998, 'RandomForestRegressor': 0.0, 'BaggingRegressor': 0.050985000000000454, 'CatBoostRegressor': 0.4494837600000002, 'HistGradientBoostingRegressor': 0.010300000000000462, 'LGBMRegressor': 0.0, 'XGBRegressor': 0.0, 'GradientBoostingRegressor': -0.15499439999999948, 'ARDRegression': 0.0, 'DecisionTreeRegressor': 0.0, 'ExtraTreeRegressor': 0.0, 'BayesianRidge': 0.0, 'Lars': 0.0, 'LinearRegression': 0.0, 'RidgeCV': 0.0, 'HuberRegressor': 0.0, 'TheilSenRegressor': 0.0, 'KerasRegressor': -0.029999999999999583, 'RANSACRegressor': 0.0, 'MLPRegressor': 0.0, 'OrthogonalMatchingPursuit': 0.0, 'AdaBoostRegressor': 0.0, 'PoissonRegressor': 0.0, 'KNeighborsRegressor_3': 0.0, 'KNeighborsRegressor': 0.0, 'KNeighborsRegressor_4': 0.0, 'PassiveAggressiveRegressor': 0.0, 'KNeighborsRegressor_2': 0.0, 'ElasticNet': 0.0, 'KNeighborsRegressor_5': 0.0, 'Lasso': 0.0, 'KNeighborsRegressor_6': 0.0, 'KNeighborsRegressor_7': 0.0, 'KNeighborsRegressor_8': 0.0, 'KNeighborsRegressor_9': 0.0, 'KNeighborsRegressor_10': 0.0, 'KNeighborsRegressor_11': 0.0, 'LassoLars': 0.0, 'LassoLars_1': 0.0, 'TweedieRegressor': 0.0, 'GammaRegressor': 0.0}\n",
      "\n",
      "Fold 3\n",
      "217/217 [==============================] - 1s 2ms/step\n",
      "109/109 [==============================] - 0s 2ms/step\n",
      "The Fold 3 Hill Climb is 0.10231261072150577\n",
      "The Fold 3 weight is {'ExtraTreesRegressor': 0.58167101404597, 'RandomForestRegressor': 0.08710660536538024, 'BaggingRegressor': 0.0, 'HistGradientBoostingRegressor': 0.010098990000000412, 'XGBRegressor': 0.21513859423618154, 'LGBMRegressor': 0.0, 'CatBoostRegressor': 0.19823457713674192, 'GradientBoostingRegressor': -0.18618175806218873, 'BayesianRidge': 0.0, 'RidgeCV': 0.0, 'DecisionTreeRegressor': 0.14972657611138104, 'ExtraTreeRegressor': 0.009898020099000395, 'Lars': 0.0, 'LinearRegression': 0.0, 'ARDRegression': 0.0, 'HuberRegressor': 0.0, 'RANSACRegressor': -0.009899999999999534, 'TheilSenRegressor': 0.0, 'KerasRegressor': 0.0, 'OrthogonalMatchingPursuit': 0.0, 'PoissonRegressor': 0.010000000000000422, 'AdaBoostRegressor': -0.065791619032471, 'KNeighborsRegressor_3': 4.4408920985006163e-16, 'KNeighborsRegressor': 4.4408920985006183e-16, 'MLPRegressor': 0.0, 'KNeighborsRegressor_4': 0.0, 'KNeighborsRegressor_2': -0.009998999999999524, 'PassiveAggressiveRegressor': 0.0, 'ElasticNet': 0.0, 'KNeighborsRegressor_5': 0.0, 'Lasso': 0.0, 'KNeighborsRegressor_6': 0.0, 'KNeighborsRegressor_7': 0.0, 'KNeighborsRegressor_8': 0.0, 'KNeighborsRegressor_9': 0.0, 'KNeighborsRegressor_10': 0.0, 'KNeighborsRegressor_11': 0.009998000100000402, 'LassoLars': 4.44089209850062e-16, 'TweedieRegressor': 4.440892098500622e-16, 'GammaRegressor': 4.440892098500624e-16, 'LassoLars_1': 4.440892098500626e-16}\n",
      "\n",
      "\n",
      "The Hill Climbing CV score is ==> 0.1044223243524202\n",
      "The Hill Climbing weights are ==> [{'RandomForestRegressor': 0.6653840605824665, 'ExtraTreesRegressor': 0.28516459739248723, 'HistGradientBoostingRegressor': 0.1056165175527734, 'XGBRegressor': 0.06741479843794068, 'LGBMRegressor': -0.020195999999999374, 'CatBoostRegressor': -0.019999999999999397, 'BaggingRegressor': 0.010200000000000368, 'GradientBoostingRegressor': -0.07350523194167893, 'DecisionTreeRegressor': 0.0, 'ExtraTreeRegressor': 0.02143009677600027, 'HuberRegressor': -0.030899879999999293, 'RidgeCV': 0.0, 'BayesianRidge': 0.0, 'LinearRegression': 0.0, 'ARDRegression': 0.0, 'TheilSenRegressor': 0.0, 'Lars': 0.0, 'RANSACRegressor': 0.0, 'OrthogonalMatchingPursuit': 0.0, 'KerasRegressor': -0.01060895879999943, 'PoissonRegressor': 0.0, 'AdaBoostRegressor': 0.0, 'MLPRegressor': 0.0, 'KNeighborsRegressor_3': 4.4408920985006084e-16, 'KNeighborsRegressor': 4.4408920985006104e-16, 'KNeighborsRegressor_2': 4.4408920985006124e-16, 'KNeighborsRegressor_4': 4.4408920985006143e-16, 'ElasticNet': 4.4408920985006163e-16, 'KNeighborsRegressor_5': 4.4408920985006183e-16, 'Lasso': 4.44089209850062e-16, 'KNeighborsRegressor_6': 4.440892098500622e-16, 'KNeighborsRegressor_7': 4.440892098500624e-16, 'KNeighborsRegressor_8': 4.440892098500626e-16, 'KNeighborsRegressor_9': 4.4408920985005946e-16, 'KNeighborsRegressor_10': 4.4408920985005966e-16, 'KNeighborsRegressor_11': 4.4408920985005986e-16, 'PassiveAggressiveRegressor': 0.0, 'LassoLars': 4.4408920985006005e-16, 'TweedieRegressor': 4.4408920985006025e-16, 'GammaRegressor': 4.4408920985006045e-16, 'LassoLars_1': 4.4408920985006064e-16}, {'ExtraTreesRegressor': 0.674225639999998, 'RandomForestRegressor': 0.0, 'BaggingRegressor': 0.050985000000000454, 'CatBoostRegressor': 0.4494837600000002, 'HistGradientBoostingRegressor': 0.010300000000000462, 'LGBMRegressor': 0.0, 'XGBRegressor': 0.0, 'GradientBoostingRegressor': -0.15499439999999948, 'ARDRegression': 0.0, 'DecisionTreeRegressor': 0.0, 'ExtraTreeRegressor': 0.0, 'BayesianRidge': 0.0, 'Lars': 0.0, 'LinearRegression': 0.0, 'RidgeCV': 0.0, 'HuberRegressor': 0.0, 'TheilSenRegressor': 0.0, 'KerasRegressor': -0.029999999999999583, 'RANSACRegressor': 0.0, 'MLPRegressor': 0.0, 'OrthogonalMatchingPursuit': 0.0, 'AdaBoostRegressor': 0.0, 'PoissonRegressor': 0.0, 'KNeighborsRegressor_3': 0.0, 'KNeighborsRegressor': 0.0, 'KNeighborsRegressor_4': 0.0, 'PassiveAggressiveRegressor': 0.0, 'KNeighborsRegressor_2': 0.0, 'ElasticNet': 0.0, 'KNeighborsRegressor_5': 0.0, 'Lasso': 0.0, 'KNeighborsRegressor_6': 0.0, 'KNeighborsRegressor_7': 0.0, 'KNeighborsRegressor_8': 0.0, 'KNeighborsRegressor_9': 0.0, 'KNeighborsRegressor_10': 0.0, 'KNeighborsRegressor_11': 0.0, 'LassoLars': 0.0, 'LassoLars_1': 0.0, 'TweedieRegressor': 0.0, 'GammaRegressor': 0.0}, {'ExtraTreesRegressor': 0.58167101404597, 'RandomForestRegressor': 0.08710660536538024, 'BaggingRegressor': 0.0, 'HistGradientBoostingRegressor': 0.010098990000000412, 'XGBRegressor': 0.21513859423618154, 'LGBMRegressor': 0.0, 'CatBoostRegressor': 0.19823457713674192, 'GradientBoostingRegressor': -0.18618175806218873, 'BayesianRidge': 0.0, 'RidgeCV': 0.0, 'DecisionTreeRegressor': 0.14972657611138104, 'ExtraTreeRegressor': 0.009898020099000395, 'Lars': 0.0, 'LinearRegression': 0.0, 'ARDRegression': 0.0, 'HuberRegressor': 0.0, 'RANSACRegressor': -0.009899999999999534, 'TheilSenRegressor': 0.0, 'KerasRegressor': 0.0, 'OrthogonalMatchingPursuit': 0.0, 'PoissonRegressor': 0.010000000000000422, 'AdaBoostRegressor': -0.065791619032471, 'KNeighborsRegressor_3': 4.4408920985006163e-16, 'KNeighborsRegressor': 4.4408920985006183e-16, 'MLPRegressor': 0.0, 'KNeighborsRegressor_4': 0.0, 'KNeighborsRegressor_2': -0.009998999999999524, 'PassiveAggressiveRegressor': 0.0, 'ElasticNet': 0.0, 'KNeighborsRegressor_5': 0.0, 'Lasso': 0.0, 'KNeighborsRegressor_6': 0.0, 'KNeighborsRegressor_7': 0.0, 'KNeighborsRegressor_8': 0.0, 'KNeighborsRegressor_9': 0.0, 'KNeighborsRegressor_10': 0.0, 'KNeighborsRegressor_11': 0.009998000100000402, 'LassoLars': 4.44089209850062e-16, 'TweedieRegressor': 4.440892098500622e-16, 'GammaRegressor': 4.440892098500624e-16, 'LassoLars_1': 4.440892098500626e-16}]\n",
      "CPU times: total: 2min 50s\n",
      "Wall time: 6min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "avg_predictions_scores = []\n",
    "optuna_weights_scores = []\n",
    "hill_climb_scores = []\n",
    "stacked_scores = []\n",
    "optuna_weights_scores_stack = []\n",
    "hill_climb_weights = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(cv_split_trial.split(train_new, train[TARGET])):\n",
    "    X_train, X_test = train_new.iloc[train_index], train_new.iloc[test_index]\n",
    "    y_train, y_test = train[TARGET].iloc[train_index], train[TARGET].iloc[test_index]\n",
    "\n",
    "    print(f'Fold {i+1}')\n",
    "    \n",
    "    MLA_cv_train_preds = []\n",
    "    MLA_cv_preds = []\n",
    "    MLA_cv_preds_dict = {}\n",
    "    MLA_names = []\n",
    "    \n",
    "    suffix = 1\n",
    "    for alg in MLA:\n",
    "        MLA_name = alg.__class__.__name__\n",
    "\n",
    "        # Add suffix if name already exists\n",
    "\n",
    "        original_MLA_name = MLA_name\n",
    "        if MLA_name in MLA_names:\n",
    "        # while MLA_cv_preds.str.contains(MLA_name).any():\n",
    "            MLA_name = f\"{original_MLA_name}_{suffix}\"\n",
    "            suffix += 1\n",
    "            \n",
    "        predictor = alg.fit(X_train, y_train)\n",
    "        pred_train_result = predictor.predict(X_train)\n",
    "        pred_result = predictor.predict(X_test)\n",
    "\n",
    "        if original_MLA_name == 'KerasRegressor':\n",
    "            keras_score = median_absolute_error(y_test, pred_result)\n",
    "            print(f'The Fold {i+1} Keras score is {keras_score}')\n",
    "\n",
    "        MLA_cv_train_preds.append(pred_train_result)\n",
    "        MLA_cv_preds.append(pred_result)\n",
    "        MLA_cv_preds_dict[MLA_name] = pred_result\n",
    "        MLA_names.append(MLA_name)\n",
    "\n",
    "    ##################\n",
    "    ### Hill Climb ###\n",
    "    ##################\n",
    "    hill_climb_pred, hill_climb_weight = hill_climbing(pd.DataFrame(MLA_cv_preds_dict), y_test)\n",
    "    hill_climb_score = median_absolute_error(y_test, hill_climb_pred)\n",
    "    hill_climb_scores.append(hill_climb_score)\n",
    "    hill_climb_weights.append(hill_climb_weight)\n",
    "    print(f'The Fold {i+1} Hill Climb is {hill_climb_score}')\n",
    "    print(f'The Fold {i+1} weight is {hill_climb_weight}')\n",
    "    print()\n",
    "\n",
    "print()\n",
    "print(f'The Hill Climbing CV score is ==> {np.mean(hill_climb_scores)}')\n",
    "print(f'The Hill Climbing weights are ==> {hill_climb_weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'RandomForestRegressor': 0.25083022198261556,\n",
       "  'ExtraTreesRegressor': 0.5136870838128184,\n",
       "  'HistGradientBoostingRegressor': 0.04200516918425809,\n",
       "  'XGBRegressor': 0.0941844642247074,\n",
       "  'LGBMRegressor': -0.006731999999999791,\n",
       "  'CatBoostRegressor': 0.2092394457122476,\n",
       "  'BaggingRegressor': 0.020395000000000274,\n",
       "  'GradientBoostingRegressor': -0.13822713000128906,\n",
       "  'DecisionTreeRegressor': 0.04990885870379368,\n",
       "  'ExtraTreeRegressor': 0.010442705625000222,\n",
       "  'HuberRegressor': -0.010299959999999764,\n",
       "  'RidgeCV': 0.0,\n",
       "  'BayesianRidge': 0.0,\n",
       "  'LinearRegression': 0.0,\n",
       "  'ARDRegression': 0.0,\n",
       "  'TheilSenRegressor': 0.0,\n",
       "  'Lars': 0.0,\n",
       "  'RANSACRegressor': -0.0032999999999998447,\n",
       "  'OrthogonalMatchingPursuit': 0.0,\n",
       "  'KerasRegressor': -0.013536319599999671,\n",
       "  'PoissonRegressor': 0.003333333333333474,\n",
       "  'AdaBoostRegressor': -0.02193053967749033,\n",
       "  'MLPRegressor': 0.0,\n",
       "  'KNeighborsRegressor_3': 2.9605947323337417e-16,\n",
       "  'KNeighborsRegressor': 2.9605947323337427e-16,\n",
       "  'KNeighborsRegressor_2': -0.0033329999999996934,\n",
       "  'KNeighborsRegressor_4': 1.4802973661668714e-16,\n",
       "  'ElasticNet': 1.480297366166872e-16,\n",
       "  'KNeighborsRegressor_5': 1.4802973661668728e-16,\n",
       "  'Lasso': 1.4802973661668733e-16,\n",
       "  'KNeighborsRegressor_6': 1.480297366166874e-16,\n",
       "  'KNeighborsRegressor_7': 1.4802973661668748e-16,\n",
       "  'KNeighborsRegressor_8': 1.4802973661668753e-16,\n",
       "  'KNeighborsRegressor_9': 1.480297366166865e-16,\n",
       "  'KNeighborsRegressor_10': 1.4802973661668654e-16,\n",
       "  'KNeighborsRegressor_11': 0.003332666700000282,\n",
       "  'PassiveAggressiveRegressor': 0.0,\n",
       "  'LassoLars': 2.9605947323337403e-16,\n",
       "  'TweedieRegressor': 2.9605947323337417e-16,\n",
       "  'GammaRegressor': 2.9605947323337427e-16,\n",
       "  'LassoLars_1': 2.960594732333744e-16},\n",
       " 0.9999999999999997,\n",
       " 41)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get average weights for the models from all the folds\n",
    "\n",
    "average_values = {}\n",
    "\n",
    "for model in hill_climb_weights:\n",
    "    for key, value in model.items():\n",
    "        if key in average_values:\n",
    "            average_values[key] += value\n",
    "        else:\n",
    "            average_values[key] = value\n",
    "\n",
    "num_models = len(hill_climb_weights)\n",
    "average_values = {k: v / num_models for k, v in average_values.items()}\n",
    "\n",
    "# Ensure the new weights sum up to 1\n",
    "sum = 0\n",
    "\n",
    "for k, v in average_values.items():\n",
    "    sum += v\n",
    "\n",
    "average_values, sum, len(average_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MLPRegressor': 0.0,\n",
       " 'TheilSenRegressor': 0.0,\n",
       " 'HuberRegressor': -0.010299959999999764,\n",
       " 'RANSACRegressor': -0.0032999999999998447,\n",
       " 'Lasso': 1.4802973661668733e-16,\n",
       " 'ElasticNet': 1.480297366166872e-16,\n",
       " 'Lars': 0.0,\n",
       " 'LassoLars': 2.9605947323337403e-16,\n",
       " 'OrthogonalMatchingPursuit': 0.0,\n",
       " 'BayesianRidge': 0.0,\n",
       " 'ARDRegression': 0.0,\n",
       " 'TweedieRegressor': 2.9605947323337417e-16,\n",
       " 'PoissonRegressor': 0.003333333333333474,\n",
       " 'GammaRegressor': 2.9605947323337427e-16,\n",
       " 'LassoLars_1': 2.960594732333744e-16,\n",
       " 'LinearRegression': 0.0,\n",
       " 'PassiveAggressiveRegressor': 0.0,\n",
       " 'RidgeCV': 0.0,\n",
       " 'DecisionTreeRegressor': 0.04990885870379368,\n",
       " 'ExtraTreeRegressor': 0.010442705625000222,\n",
       " 'XGBRegressor': 0.0941844642247074,\n",
       " 'LGBMRegressor': -0.006731999999999791,\n",
       " 'CatBoostRegressor': 0.2092394457122476,\n",
       " 'KNeighborsRegressor': 2.9605947323337427e-16,\n",
       " 'KNeighborsRegressor_2': -0.0033329999999996934,\n",
       " 'KNeighborsRegressor_3': 2.9605947323337417e-16,\n",
       " 'KNeighborsRegressor_4': 1.4802973661668714e-16,\n",
       " 'KNeighborsRegressor_5': 1.4802973661668728e-16,\n",
       " 'KNeighborsRegressor_6': 1.480297366166874e-16,\n",
       " 'KNeighborsRegressor_7': 1.4802973661668748e-16,\n",
       " 'KNeighborsRegressor_8': 1.4802973661668753e-16,\n",
       " 'KNeighborsRegressor_9': 1.480297366166865e-16,\n",
       " 'KNeighborsRegressor_10': 1.4802973661668654e-16,\n",
       " 'KNeighborsRegressor_11': 0.003332666700000282,\n",
       " 'AdaBoostRegressor': -0.02193053967749033,\n",
       " 'BaggingRegressor': 0.020395000000000274,\n",
       " 'ExtraTreesRegressor': 0.5136870838128184,\n",
       " 'GradientBoostingRegressor': -0.13822713000128906,\n",
       " 'HistGradientBoostingRegressor': 0.04200516918425809,\n",
       " 'RandomForestRegressor': 0.25083022198261556,\n",
       " 'KerasRegressor': -0.013536319599999671}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an ordered dictionary based on the order of models in MLA\n",
    "ordered_average_values = {}\n",
    "final_mlas = []\n",
    "\n",
    "for model_name in MLA_names:        \n",
    "    if model_name in average_values:\n",
    "        ordered_average_values[model_name] = average_values[model_name]\n",
    "    else:\n",
    "        # Handle case where a model might not be in average_values\n",
    "        ordered_average_values[model_name] = None\n",
    "\n",
    "# Now ordered_average_values has the averages in the same order as MLA\n",
    "ordered_average_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " -0.010299959999999764,\n",
       " -0.0032999999999998447,\n",
       " 1.4802973661668733e-16,\n",
       " 1.480297366166872e-16,\n",
       " 0.0,\n",
       " 2.9605947323337403e-16,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 2.9605947323337417e-16,\n",
       " 0.003333333333333474,\n",
       " 2.9605947323337427e-16,\n",
       " 2.960594732333744e-16,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.04990885870379368,\n",
       " 0.010442705625000222,\n",
       " 0.0941844642247074,\n",
       " -0.006731999999999791,\n",
       " 0.2092394457122476,\n",
       " 2.9605947323337427e-16,\n",
       " -0.0033329999999996934,\n",
       " 2.9605947323337417e-16,\n",
       " 1.4802973661668714e-16,\n",
       " 1.4802973661668728e-16,\n",
       " 1.480297366166874e-16,\n",
       " 1.4802973661668748e-16,\n",
       " 1.4802973661668753e-16,\n",
       " 1.480297366166865e-16,\n",
       " 1.4802973661668654e-16,\n",
       " 0.003332666700000282,\n",
       " -0.02193053967749033,\n",
       " 0.020395000000000274,\n",
       " 0.5136870838128184,\n",
       " -0.13822713000128906,\n",
       " 0.04200516918425809,\n",
       " 0.25083022198261556,\n",
       " -0.013536319599999671]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the ordered weights values as a list to be used for final submission\n",
    "hill_climb_final_weights = []\n",
    "\n",
    "for value in ordered_average_values.values():\n",
    "    hill_climb_final_weights.append(value)\n",
    "\n",
    "hill_climb_final_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with MLPRegressor\n",
      "Done with TheilSenRegressor\n",
      "Done with HuberRegressor\n",
      "Done with RANSACRegressor\n",
      "Done with Lasso\n",
      "Done with ElasticNet\n",
      "Done with Lars\n",
      "Done with LassoLars\n",
      "Done with OrthogonalMatchingPursuit\n",
      "Done with BayesianRidge\n",
      "Done with ARDRegression\n",
      "Done with TweedieRegressor\n",
      "Done with PoissonRegressor\n",
      "Done with GammaRegressor\n",
      "Done with LassoLars\n",
      "Done with LinearRegression\n",
      "Done with PassiveAggressiveRegressor\n",
      "Done with RidgeCV\n",
      "Done with DecisionTreeRegressor\n",
      "Done with ExtraTreeRegressor\n",
      "Done with XGBRegressor\n",
      "Done with LGBMRegressor\n",
      "Done with CatBoostRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with AdaBoostRegressor\n",
      "Done with BaggingRegressor\n",
      "Done with ExtraTreesRegressor\n",
      "Done with GradientBoostingRegressor\n",
      "Done with HistGradientBoostingRegressor\n",
      "Done with RandomForestRegressor\n",
      "217/217 [==============================] - 0s 2ms/step\n",
      "Done with KerasRegressor\n",
      "CPU times: total: 47 s\n",
      "Wall time: 2min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_predictions = []\n",
    "# Make predictions on test set\n",
    "for alg in MLA:\n",
    "        MLA_name = alg.__class__.__name__\n",
    "                \n",
    "        predictor = alg.fit(train_new, train[TARGET])\n",
    "        pred_result = predictor.predict(test_new)\n",
    "\n",
    "        test_predictions.append(pred_result)\n",
    "        print(f'Done with {MLA_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 41)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check that the weights and predictions are the same length\n",
    "len(test_predictions), len(hill_climb_final_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_avg_predictions = np.average(test_predictions, axis=0, weights=hill_climb_final_weights)\n",
    "create_submission_file(test['id'], weighted_avg_predictions, f'submission_{experiment}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217/217 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Get NeuralNetwork only submission\n",
    "predictor = KerasRegressor(epochs=100, batch_size=32).fit(train_new, train[TARGET])\n",
    "predictions = predictor.predict(test_new)\n",
    "create_submission_file(test['id'], predictions, f'submission_keras_model.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
