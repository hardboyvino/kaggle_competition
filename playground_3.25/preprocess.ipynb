{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adeniyi Babalola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import median_absolute_error, make_scorer\n",
    "\n",
    "import optuna\n",
    "# Set the Optuna logger to output only warnings or higher level messages\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "experiment = 'baseline_with_neural_net_cv3'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <th>density_Total</th>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <th>val_e_Average</th>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <th>zaratio_Average</th>\n",
       "      <th>density_Average</th>\n",
       "      <th>Hardness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.841611</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>20.612526</td>\n",
       "      <td>11.08810</td>\n",
       "      <td>2.766</td>\n",
       "      <td>1.732</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.496070</td>\n",
       "      <td>0.91457</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.558488</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>20.298893</td>\n",
       "      <td>12.04083</td>\n",
       "      <td>2.755</td>\n",
       "      <td>1.631</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.492719</td>\n",
       "      <td>0.71760</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>76.0</td>\n",
       "      <td>8.885992</td>\n",
       "      <td>15.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>33.739258</td>\n",
       "      <td>12.08630</td>\n",
       "      <td>2.828</td>\n",
       "      <td>1.788</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.481478</td>\n",
       "      <td>1.50633</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.795296</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>20.213349</td>\n",
       "      <td>10.94850</td>\n",
       "      <td>2.648</td>\n",
       "      <td>1.626</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.489272</td>\n",
       "      <td>0.78937</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>9.577996</td>\n",
       "      <td>11.6</td>\n",
       "      <td>4.8</td>\n",
       "      <td>24.988133</td>\n",
       "      <td>11.82448</td>\n",
       "      <td>2.766</td>\n",
       "      <td>1.682</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.492736</td>\n",
       "      <td>1.86481</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  allelectrons_Total  density_Total  allelectrons_Average  val_e_Average  \\\n",
       "0   0               100.0       0.841611                  10.0            4.8   \n",
       "1   1               100.0       7.558488                  10.0            4.8   \n",
       "2   2                76.0       8.885992                  15.6            5.6   \n",
       "3   3               100.0       8.795296                  10.0            4.8   \n",
       "4   4               116.0       9.577996                  11.6            4.8   \n",
       "\n",
       "   atomicweight_Average  ionenergy_Average  el_neg_chi_Average  \\\n",
       "0             20.612526           11.08810               2.766   \n",
       "1             20.298893           12.04083               2.755   \n",
       "2             33.739258           12.08630               2.828   \n",
       "3             20.213349           10.94850               2.648   \n",
       "4             24.988133           11.82448               2.766   \n",
       "\n",
       "   R_vdw_element_Average  R_cov_element_Average  zaratio_Average  \\\n",
       "0                  1.732                  0.860         0.496070   \n",
       "1                  1.631                  0.910         0.492719   \n",
       "2                  1.788                  0.864         0.481478   \n",
       "3                  1.626                  0.936         0.489272   \n",
       "4                  1.682                  0.896         0.492736   \n",
       "\n",
       "   density_Average  Hardness  \n",
       "0          0.91457       6.0  \n",
       "1          0.71760       6.5  \n",
       "2          1.50633       2.5  \n",
       "3          0.78937       6.0  \n",
       "4          1.86481       6.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "artificial = pd.read_csv('Artificial_Crystals_Dataset.csv')\n",
    "mineral = pd.read_csv('Mineral_Dataset_Supplementary_Info.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hardness</th>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <th>density_Total</th>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <th>val_e_Average</th>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <th>zaratio_Average</th>\n",
       "      <th>density_Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.5</td>\n",
       "      <td>167.0</td>\n",
       "      <td>23.907992</td>\n",
       "      <td>18.555556</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>41.609136</td>\n",
       "      <td>11.693844</td>\n",
       "      <td>2.938889</td>\n",
       "      <td>1.711111</td>\n",
       "      <td>0.884444</td>\n",
       "      <td>0.477830</td>\n",
       "      <td>2.656444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.740168</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>8.773227</td>\n",
       "      <td>11.614333</td>\n",
       "      <td>1.903333</td>\n",
       "      <td>1.310000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.825990</td>\n",
       "      <td>0.580056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.5</td>\n",
       "      <td>102.0</td>\n",
       "      <td>8.511159</td>\n",
       "      <td>4.434783</td>\n",
       "      <td>3.304348</td>\n",
       "      <td>8.440584</td>\n",
       "      <td>13.176622</td>\n",
       "      <td>2.672609</td>\n",
       "      <td>1.379130</td>\n",
       "      <td>0.530870</td>\n",
       "      <td>0.713850</td>\n",
       "      <td>0.370050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.5</td>\n",
       "      <td>78.0</td>\n",
       "      <td>8.109328</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>27.448814</td>\n",
       "      <td>11.826400</td>\n",
       "      <td>2.960000</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.488163</td>\n",
       "      <td>1.351555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.5</td>\n",
       "      <td>164.0</td>\n",
       "      <td>19.921324</td>\n",
       "      <td>14.909091</td>\n",
       "      <td>5.090909</td>\n",
       "      <td>32.012361</td>\n",
       "      <td>11.255573</td>\n",
       "      <td>2.881818</td>\n",
       "      <td>1.640909</td>\n",
       "      <td>0.841818</td>\n",
       "      <td>0.483480</td>\n",
       "      <td>1.811029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hardness  allelectrons_Total  density_Total  allelectrons_Average  \\\n",
       "0       4.5               167.0      23.907992             18.555556   \n",
       "1       4.0                14.0       1.740168              4.666667   \n",
       "2       2.5               102.0       8.511159              4.434783   \n",
       "3       5.5                78.0       8.109328             13.000000   \n",
       "4       6.5               164.0      19.921324             14.909091   \n",
       "\n",
       "   val_e_Average  atomicweight_Average  ionenergy_Average  el_neg_chi_Average  \\\n",
       "0       5.000000             41.609136          11.693844            2.938889   \n",
       "1       1.333333              8.773227          11.614333            1.903333   \n",
       "2       3.304348              8.440584          13.176622            2.672609   \n",
       "3       5.333333             27.448814          11.826400            2.960000   \n",
       "4       5.090909             32.012361          11.255573            2.881818   \n",
       "\n",
       "   R_vdw_element_Average  R_cov_element_Average  zaratio_Average  \\\n",
       "0               1.711111               0.884444         0.477830   \n",
       "1               1.310000               0.680000         0.825990   \n",
       "2               1.379130               0.530870         0.713850   \n",
       "3               1.625000               0.813333         0.488163   \n",
       "4               1.640909               0.841818         0.483480   \n",
       "\n",
       "   density_Average  \n",
       "0         2.656444  \n",
       "1         0.580056  \n",
       "2         0.370050  \n",
       "3         1.351555  \n",
       "4         1.811029  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename hardness in artifical dataset and drop columns not required\n",
    "artificial.rename(columns={'Hardness (Mohs)': 'Hardness'}, inplace=True)\n",
    "artificial.drop(['Formula', 'Crystal structure', 'Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "artificial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hardness</th>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <th>density_Total</th>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <th>val_e_Average</th>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <th>zaratio_Average</th>\n",
       "      <th>density_Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.3</td>\n",
       "      <td>110.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>36.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>82.598467</td>\n",
       "      <td>8.504133</td>\n",
       "      <td>2.146667</td>\n",
       "      <td>2.006667</td>\n",
       "      <td>1.253333</td>\n",
       "      <td>0.456803</td>\n",
       "      <td>7.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.5</td>\n",
       "      <td>406.0</td>\n",
       "      <td>30.472136</td>\n",
       "      <td>9.902439</td>\n",
       "      <td>4.682927</td>\n",
       "      <td>19.813180</td>\n",
       "      <td>11.456151</td>\n",
       "      <td>2.700244</td>\n",
       "      <td>1.676829</td>\n",
       "      <td>0.868293</td>\n",
       "      <td>0.522909</td>\n",
       "      <td>0.743223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.5</td>\n",
       "      <td>406.0</td>\n",
       "      <td>30.472464</td>\n",
       "      <td>10.410256</td>\n",
       "      <td>4.923077</td>\n",
       "      <td>20.931371</td>\n",
       "      <td>11.541405</td>\n",
       "      <td>2.753590</td>\n",
       "      <td>1.703846</td>\n",
       "      <td>0.894359</td>\n",
       "      <td>0.497498</td>\n",
       "      <td>0.781345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.5</td>\n",
       "      <td>476.0</td>\n",
       "      <td>61.142136</td>\n",
       "      <td>11.609756</td>\n",
       "      <td>4.682927</td>\n",
       "      <td>23.659644</td>\n",
       "      <td>11.487395</td>\n",
       "      <td>2.763659</td>\n",
       "      <td>1.714634</td>\n",
       "      <td>0.848780</td>\n",
       "      <td>0.519474</td>\n",
       "      <td>1.491272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.5</td>\n",
       "      <td>476.0</td>\n",
       "      <td>61.142464</td>\n",
       "      <td>12.205128</td>\n",
       "      <td>4.923077</td>\n",
       "      <td>24.975089</td>\n",
       "      <td>11.574251</td>\n",
       "      <td>2.820256</td>\n",
       "      <td>1.743590</td>\n",
       "      <td>0.873846</td>\n",
       "      <td>0.493887</td>\n",
       "      <td>1.567755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hardness  allelectrons_Total  density_Total  allelectrons_Average  \\\n",
       "0       2.3               110.0      23.000000             36.666667   \n",
       "1       5.5               406.0      30.472136              9.902439   \n",
       "2       5.5               406.0      30.472464             10.410256   \n",
       "3       5.5               476.0      61.142136             11.609756   \n",
       "4       5.5               476.0      61.142464             12.205128   \n",
       "\n",
       "   val_e_Average  atomicweight_Average  ionenergy_Average  el_neg_chi_Average  \\\n",
       "0       2.666667             82.598467           8.504133            2.146667   \n",
       "1       4.682927             19.813180          11.456151            2.700244   \n",
       "2       4.923077             20.931371          11.541405            2.753590   \n",
       "3       4.682927             23.659644          11.487395            2.763659   \n",
       "4       4.923077             24.975089          11.574251            2.820256   \n",
       "\n",
       "   R_vdw_element_Average  R_cov_element_Average  zaratio_Average  \\\n",
       "0               2.006667               1.253333         0.456803   \n",
       "1               1.676829               0.868293         0.522909   \n",
       "2               1.703846               0.894359         0.497498   \n",
       "3               1.714634               0.848780         0.519474   \n",
       "4               1.743590               0.873846         0.493887   \n",
       "\n",
       "   density_Average  \n",
       "0         7.666667  \n",
       "1         0.743223  \n",
       "2         0.781345  \n",
       "3         1.491272  \n",
       "4         1.567755  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unneeded columns\n",
    "mineral.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "mineral.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10407, 13), (52, 12), (622, 12))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, artificial.shape, mineral.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.concat([train, artificial, mineral], axis=0)\n",
    "# train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <th>density_Total</th>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <th>val_e_Average</th>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <th>zaratio_Average</th>\n",
       "      <th>density_Average</th>\n",
       "      <th>Hardness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10402</th>\n",
       "      <td>10402</td>\n",
       "      <td>128.0</td>\n",
       "      <td>7.558488</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>26.385218</td>\n",
       "      <td>11.330440</td>\n",
       "      <td>2.644000</td>\n",
       "      <td>1.631000</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.496070</td>\n",
       "      <td>1.79607</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10403</th>\n",
       "      <td>10403</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.743160</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>20.766935</td>\n",
       "      <td>14.163933</td>\n",
       "      <td>3.090000</td>\n",
       "      <td>1.556667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.480390</td>\n",
       "      <td>0.81480</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10404</th>\n",
       "      <td>10404</td>\n",
       "      <td>196.0</td>\n",
       "      <td>30.920000</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>53.490297</td>\n",
       "      <td>10.074300</td>\n",
       "      <td>2.295000</td>\n",
       "      <td>1.545000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>0.469715</td>\n",
       "      <td>2.11540</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10405</th>\n",
       "      <td>10405</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.553160</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>26.621687</td>\n",
       "      <td>11.290033</td>\n",
       "      <td>2.743333</td>\n",
       "      <td>1.756667</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.486507</td>\n",
       "      <td>0.77755</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10406</th>\n",
       "      <td>10406</td>\n",
       "      <td>288.0</td>\n",
       "      <td>24.655328</td>\n",
       "      <td>11.142857</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>22.536126</td>\n",
       "      <td>10.960357</td>\n",
       "      <td>2.792143</td>\n",
       "      <td>1.772857</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.493919</td>\n",
       "      <td>0.97737</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  allelectrons_Total  density_Total  allelectrons_Average  \\\n",
       "10402  10402               128.0       7.558488             12.000000   \n",
       "10403  10403                30.0       1.743160             10.000000   \n",
       "10404  10404               196.0      30.920000             24.500000   \n",
       "10405  10405                38.0       1.553160             12.666667   \n",
       "10406  10406               288.0      24.655328             11.142857   \n",
       "\n",
       "       val_e_Average  atomicweight_Average  ionenergy_Average  \\\n",
       "10402       4.000000             26.385218          11.330440   \n",
       "10403       5.333333             20.766935          14.163933   \n",
       "10404       5.500000             53.490297          10.074300   \n",
       "10405       4.666667             26.621687          11.290033   \n",
       "10406       4.571429             22.536126          10.960357   \n",
       "\n",
       "       el_neg_chi_Average  R_vdw_element_Average  R_cov_element_Average  \\\n",
       "10402            2.644000               1.631000               0.892000   \n",
       "10403            3.090000               1.556667               0.866667   \n",
       "10404            2.295000               1.545000               1.120000   \n",
       "10405            2.743333               1.756667               0.980000   \n",
       "10406            2.792143               1.772857               0.940000   \n",
       "\n",
       "       zaratio_Average  density_Average  Hardness  \n",
       "10402         0.496070          1.79607       4.0  \n",
       "10403         0.480390          0.81480       5.0  \n",
       "10404         0.469715          2.11540       1.8  \n",
       "10405         0.486507          0.77755       6.0  \n",
       "10406         0.493919          0.97737       6.5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>1%</th>\n",
       "      <th>50%</th>\n",
       "      <th>99%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>5203.000000</td>\n",
       "      <td>3004.386460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.060000</td>\n",
       "      <td>5203.000000</td>\n",
       "      <td>10301.940000</td>\n",
       "      <td>10406.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>128.053516</td>\n",
       "      <td>224.123776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>719.400000</td>\n",
       "      <td>15300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density_Total</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>14.491342</td>\n",
       "      <td>15.972877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.739942</td>\n",
       "      <td>10.650000</td>\n",
       "      <td>75.098979</td>\n",
       "      <td>643.093804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>17.033222</td>\n",
       "      <td>10.468734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_e_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>4.546789</td>\n",
       "      <td>0.690864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>37.507703</td>\n",
       "      <td>26.012313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.773227</td>\n",
       "      <td>26.203827</td>\n",
       "      <td>119.629500</td>\n",
       "      <td>167.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>10.938308</td>\n",
       "      <td>1.408276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.054000</td>\n",
       "      <td>11.202760</td>\n",
       "      <td>13.512520</td>\n",
       "      <td>15.245810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>2.607662</td>\n",
       "      <td>0.334906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>2.706000</td>\n",
       "      <td>2.980000</td>\n",
       "      <td>3.443000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>1.731330</td>\n",
       "      <td>0.192481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.318667</td>\n",
       "      <td>1.732727</td>\n",
       "      <td>2.055000</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>0.944132</td>\n",
       "      <td>0.180017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.505333</td>\n",
       "      <td>0.915556</td>\n",
       "      <td>1.390000</td>\n",
       "      <td>1.615840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zaratio_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>0.493349</td>\n",
       "      <td>0.063080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.405373</td>\n",
       "      <td>0.488550</td>\n",
       "      <td>0.707253</td>\n",
       "      <td>0.825990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>2.132984</td>\n",
       "      <td>1.936656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132734</td>\n",
       "      <td>1.351550</td>\n",
       "      <td>7.986670</td>\n",
       "      <td>10.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hardness</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>4.647126</td>\n",
       "      <td>1.680525</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>8.288000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count         mean          std  min          1%  \\\n",
       "id                     10407.0  5203.000000  3004.386460  0.0  104.060000   \n",
       "allelectrons_Total     10407.0   128.053516   224.123776  0.0    6.000000   \n",
       "density_Total          10407.0    14.491342    15.972877  0.0    0.739942   \n",
       "allelectrons_Average   10407.0    17.033222    10.468734  0.0    4.666667   \n",
       "val_e_Average          10407.0     4.546789     0.690864  0.0    2.000000   \n",
       "atomicweight_Average   10407.0    37.507703    26.012313  0.0    8.773227   \n",
       "ionenergy_Average      10407.0    10.938308     1.408276  0.0    8.054000   \n",
       "el_neg_chi_Average     10407.0     2.607662     0.334906  0.0    1.790000   \n",
       "R_vdw_element_Average  10407.0     1.731330     0.192481  0.0    1.318667   \n",
       "R_cov_element_Average  10407.0     0.944132     0.180017  0.0    0.505333   \n",
       "zaratio_Average        10407.0     0.493349     0.063080  0.0    0.405373   \n",
       "density_Average        10407.0     2.132984     1.936656  0.0    0.132734   \n",
       "Hardness               10407.0     4.647126     1.680525  1.0    1.500000   \n",
       "\n",
       "                               50%           99%           max  \n",
       "id                     5203.000000  10301.940000  10406.000000  \n",
       "allelectrons_Total      100.000000    719.400000  15300.000000  \n",
       "density_Total            10.650000     75.098979    643.093804  \n",
       "allelectrons_Average     12.600000     50.000000     67.000000  \n",
       "val_e_Average             4.714286      5.666667      6.000000  \n",
       "atomicweight_Average     26.203827    119.629500    167.400000  \n",
       "ionenergy_Average        11.202760     13.512520     15.245810  \n",
       "el_neg_chi_Average        2.706000      2.980000      3.443000  \n",
       "R_vdw_element_Average     1.732727      2.055000      2.250000  \n",
       "R_cov_element_Average     0.915556      1.390000      1.615840  \n",
       "zaratio_Average           0.488550      0.707253      0.825990  \n",
       "density_Average           1.351550      7.986670     10.970000  \n",
       "Hardness                  5.500000      8.288000     10.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe([0.01, 0.99]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "TARGET = 'Hardness'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['allelectrons_Total', 'density_Total', 'allelectrons_Average',\n",
      "       'val_e_Average', 'atomicweight_Average', 'ionenergy_Average',\n",
      "       'el_neg_chi_Average', 'R_vdw_element_Average', 'R_cov_element_Average',\n",
      "       'zaratio_Average', 'density_Average'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Selecting numerical variables from the train dataset, excluding 'id' and TARGET\n",
    "num_var = train.drop(['id', TARGET], axis=1).select_dtypes(include=np.number).columns\n",
    "print(num_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining train and test datasets for comparative analysis\n",
    "# 'Source' column is added to label data from each dataset\n",
    "df = pd.concat([\n",
    "    train[num_var].assign(Source='Train'), \n",
    "    test[num_var].assign(Source='Test')\n",
    "], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature name: allelectrons_Total\n",
      "Low Limit: -1064.1000000000076\n",
      "Upper Limit: 1789.5000000000127\n",
      "\n",
      "Feature name: density_Total\n",
      "Low Limit: -110.79861331237501\n",
      "Upper Limit: 186.637534387425\n",
      "\n",
      "Feature name: allelectrons_Average\n",
      "Low Limit: -63.333333333333336\n",
      "Upper Limit: 118.0\n",
      "\n",
      "Feature name: val_e_Average\n",
      "Low Limit: -3.5000000000000018\n",
      "Upper Limit: 11.16666666666667\n",
      "\n",
      "Feature name: atomicweight_Average\n",
      "Low Limit: -157.51118333333332\n",
      "Upper Limit: 285.91391\n",
      "\n",
      "Feature name: ionenergy_Average\n",
      "Low Limit: -0.1337799999999998\n",
      "Upper Limit: 21.7003\n",
      "\n",
      "Feature name: el_neg_chi_Average\n",
      "Low Limit: 0.0050000000000001155\n",
      "Upper Limit: 4.765\n",
      "\n",
      "Feature name: R_vdw_element_Average\n",
      "Low Limit: 0.21416666666666706\n",
      "Upper Limit: 3.1595\n",
      "\n",
      "Feature name: R_cov_element_Average\n",
      "Low Limit: -0.8216666666666667\n",
      "Upper Limit: 2.7169999999999996\n",
      "\n",
      "Feature name: zaratio_Average\n",
      "Low Limit: -0.047446360606061166\n",
      "Upper Limit: 1.160072823232324\n",
      "\n",
      "Feature name: density_Average\n",
      "Low Limit: -11.648170499999999\n",
      "Upper Limit: 19.7675743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for outliers\n",
    "def outlier_thresholds(dataframe, col_name, q1=0.01, q3=0.99):\n",
    "    quartile1 = dataframe[col_name].quantile(q1)\n",
    "    quartile3 = dataframe[col_name].quantile(q3)\n",
    "    IQR = quartile3 - quartile1\n",
    "    up_limit = quartile3 + 1.5 * IQR\n",
    "    low_limit = quartile1 - 1.5 * IQR\n",
    "    print(f'Feature name: {col_name}')\n",
    "    print(f'Low Limit: {low_limit}')\n",
    "    print(f'Upper Limit: {up_limit}')\n",
    "    print()\n",
    "    return low_limit, up_limit\n",
    "\n",
    "\n",
    "def remove_outlier(dataframe, col_name):\n",
    "    \"\"\"\n",
    "    Example Usage:\n",
    "    for col in num_cols:\n",
    "    new_df = remove_outlier(titanic, col)\n",
    "    \"\"\"\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n",
    "    df_without_outliers = dataframe[~((dataframe[col_name] < low_limit) | (dataframe[col_name] > up_limit))]    \n",
    "    return df_without_outliers\n",
    "\n",
    "def cap_outliers(dataframe, col_name):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n",
    "\n",
    "    dataframe[col_name] = np.where(dataframe[col_name] > up_limit, up_limit, \n",
    "                                   np.where(dataframe[col_name] < low_limit, low_limit, dataframe[col_name]))\n",
    "    return dataframe\n",
    "\n",
    "df_capped = train.copy()\n",
    "for col in num_var:\n",
    "    df_capped = cap_outliers(df_capped, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>1%</th>\n",
       "      <th>50%</th>\n",
       "      <th>99%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>5203.000000</td>\n",
       "      <td>3004.386460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>104.060000</td>\n",
       "      <td>5203.000000</td>\n",
       "      <td>10301.940000</td>\n",
       "      <td>10406.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>125.050950</td>\n",
       "      <td>122.817572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>719.400000</td>\n",
       "      <td>1789.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density_Total</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>14.433119</td>\n",
       "      <td>14.640489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.739942</td>\n",
       "      <td>10.650000</td>\n",
       "      <td>75.098979</td>\n",
       "      <td>186.637534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>17.033222</td>\n",
       "      <td>10.468734</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_e_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>4.546789</td>\n",
       "      <td>0.690864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>37.507703</td>\n",
       "      <td>26.012313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.773227</td>\n",
       "      <td>26.203827</td>\n",
       "      <td>119.629500</td>\n",
       "      <td>167.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>10.938308</td>\n",
       "      <td>1.408276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.054000</td>\n",
       "      <td>11.202760</td>\n",
       "      <td>13.512520</td>\n",
       "      <td>15.245810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>2.607694</td>\n",
       "      <td>0.334655</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>2.706000</td>\n",
       "      <td>2.980000</td>\n",
       "      <td>3.443000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>1.732730</td>\n",
       "      <td>0.180280</td>\n",
       "      <td>0.214167</td>\n",
       "      <td>1.318667</td>\n",
       "      <td>1.732727</td>\n",
       "      <td>2.055000</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>0.944132</td>\n",
       "      <td>0.180017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.505333</td>\n",
       "      <td>0.915556</td>\n",
       "      <td>1.390000</td>\n",
       "      <td>1.615840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zaratio_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>0.493349</td>\n",
       "      <td>0.063080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405373</td>\n",
       "      <td>0.488550</td>\n",
       "      <td>0.707253</td>\n",
       "      <td>0.825990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>2.132984</td>\n",
       "      <td>1.936656</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132734</td>\n",
       "      <td>1.351550</td>\n",
       "      <td>7.986670</td>\n",
       "      <td>10.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hardness</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>4.647126</td>\n",
       "      <td>1.680525</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>8.288000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count         mean          std       min  \\\n",
       "id                     10407.0  5203.000000  3004.386460  0.000000   \n",
       "allelectrons_Total     10407.0   125.050950   122.817572  0.000000   \n",
       "density_Total          10407.0    14.433119    14.640489  0.000000   \n",
       "allelectrons_Average   10407.0    17.033222    10.468734  0.000000   \n",
       "val_e_Average          10407.0     4.546789     0.690864  0.000000   \n",
       "atomicweight_Average   10407.0    37.507703    26.012313  0.000000   \n",
       "ionenergy_Average      10407.0    10.938308     1.408276  0.000000   \n",
       "el_neg_chi_Average     10407.0     2.607694     0.334655  0.005000   \n",
       "R_vdw_element_Average  10407.0     1.732730     0.180280  0.214167   \n",
       "R_cov_element_Average  10407.0     0.944132     0.180017  0.000000   \n",
       "zaratio_Average        10407.0     0.493349     0.063080  0.000000   \n",
       "density_Average        10407.0     2.132984     1.936656  0.000000   \n",
       "Hardness               10407.0     4.647126     1.680525  1.000000   \n",
       "\n",
       "                               1%          50%           99%           max  \n",
       "id                     104.060000  5203.000000  10301.940000  10406.000000  \n",
       "allelectrons_Total       6.000000   100.000000    719.400000   1789.500000  \n",
       "density_Total            0.739942    10.650000     75.098979    186.637534  \n",
       "allelectrons_Average     4.666667    12.600000     50.000000     67.000000  \n",
       "val_e_Average            2.000000     4.714286      5.666667      6.000000  \n",
       "atomicweight_Average     8.773227    26.203827    119.629500    167.400000  \n",
       "ionenergy_Average        8.054000    11.202760     13.512520     15.245810  \n",
       "el_neg_chi_Average       1.790000     2.706000      2.980000      3.443000  \n",
       "R_vdw_element_Average    1.318667     1.732727      2.055000      2.250000  \n",
       "R_cov_element_Average    0.505333     0.915556      1.390000      1.615840  \n",
       "zaratio_Average          0.405373     0.488550      0.707253      0.825990  \n",
       "density_Average          0.132734     1.351550      7.986670     10.970000  \n",
       "Hardness                 1.500000     5.500000      8.288000     10.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_capped.describe([0.01, 0.99]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No missing data in the both train and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL CROSS-VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    return tfp.stats.percentile(tf.abs(y_true - y_pred), q=50)\n",
    "\n",
    "def metric_fn(y_true, y_pred):\n",
    "    return tfp.stats.percentile(tf.abs(y_true - y_pred), q=100) - tfp.stats.percentile(tf.abs(y_true - y_pred), q=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True, mode='min')\n",
    "reduce_LR = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=5, min_lr=0.00001,factor=0.8)\n",
    "\n",
    "class KerasRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, epochs=100, batch_size=32):\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.InputLayer(input_shape=(len(num_var),)),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dense(256, activation='relu'),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(0.013, beta_1=0.5),\n",
    "                    loss=loss_fn,\n",
    "                      metrics=[metric_fn])\n",
    "        return model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=0, callbacks=[early_stopping,reduce_LR], validation_split=0.1)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def custom_loss_function(preds, targets):\n",
    "#     # Define your custom loss function here\n",
    "#     return torch.nn.functional.mse_loss(preds, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastai.tabular.all import *\n",
    "\n",
    "# def create_fastai_regressor(dls):\n",
    "#     \"\"\"\n",
    "#     Create a FastAI tabular regressor.\n",
    "#     :param dls: FastAI Dataloader\n",
    "#     :return: FastAI Learner\n",
    "#     \"\"\"\n",
    "#     learn = tabular_learner(dls, y_range=(1, 10), layers=[256,128,64], loss_func=custom_loss_function, metrics=make_scorer(median_absolute_error, greater_is_better=False))\n",
    "#     return learn\n",
    "\n",
    "\n",
    "# # Define your categorical and continuous features\n",
    "# cont_names = list(num_var)\n",
    "# y_name = TARGET\n",
    "\n",
    "# # # Split your data into a training set and a validation set\n",
    "# # splits = RandomSplitter()(range_of(df))\n",
    "\n",
    "# # Create a TabularPandas object\n",
    "# to = TabularPandas(train, procs=[Normalize],\n",
    "#                    cont_names=cont_names,\n",
    "#                    y_names=y_name,\n",
    "#                 #    splits=splits,\n",
    "#                    )\n",
    "\n",
    "# # Create a DataLoaders object\n",
    "# dls = to.dataloaders(bs=64)  # bs is batch size, adjust as needed\n",
    "\n",
    "# class FastAIRegressor(BaseEstimator, RegressorMixin):\n",
    "#     def __init__(self, dls):\n",
    "#         self.dls = dls\n",
    "#         self.learn = None\n",
    "\n",
    "#     def fit(self, X, y):\n",
    "#         with warnings.catch_warnings():\n",
    "#             warnings.simplefilter('ignore')\n",
    "#             self.learn = create_fastai_regressor(self.dls)\n",
    "\n",
    "#             with self.learn.no_bar(), self.learn.no_logging():\n",
    "#                 self.learn.fit_one_cycle(100, 0.00001)\n",
    "#             return self\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         dl = self.dls.test_dl(X)\n",
    "#         with self.learn.no_bar(), self.learn.no_logging():\n",
    "#             preds, _ = self.learn.get_preds(dl=dl)\n",
    "#         return preds.numpy()\n",
    "\n",
    "#     def score(self, X, y):\n",
    "#         # Implement a scoring method if needed\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RegressionModel(nn.Module):\n",
    "#     def __init__(self, input_size):\n",
    "#         super(RegressionModel, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_size, 256)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(256, 128)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.fc3 = nn.Linear(128, 64)\n",
    "#         self.relu3 = nn.ReLU()\n",
    "#         self.fc4 = nn.Linear(64, 1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.relu1(self.fc1(x))\n",
    "#         x = self.relu2(self.fc2(x))\n",
    "#         x = self.relu3(self.fc3(x))\n",
    "#         x = self.fc4(x)\n",
    "#         return x\n",
    "\n",
    "# class PyTorchRegressor(BaseEstimator, RegressorMixin):\n",
    "#     def __init__(self, input_size, epochs=100, lr=0.00001, batch_size=32, weight_decay=1e-5):\n",
    "#         self.input_size = input_size\n",
    "#         self.model = RegressionModel(input_size)\n",
    "#         self.epochs = epochs\n",
    "#         self.batch_size = batch_size\n",
    "#         self.lr = lr\n",
    "#         self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "#         self.criterion = nn.L1Loss()  # L1 Loss is equivalent to MAE\n",
    "#         self.weight_decay = weight_decay\n",
    "\n",
    "#     def fit(self, X, y):\n",
    "#         X = torch.tensor(X.values, dtype=torch.float32) if isinstance(X, pd.DataFrame) else torch.tensor(X, dtype=torch.float32)\n",
    "#         y = torch.tensor(y.values, dtype=torch.float32).view(-1, 1) if isinstance(y, pd.DataFrame) or isinstance(y, pd.Series) else torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "        \n",
    "#         dataset = TensorDataset(X, y)\n",
    "#         loader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "#         for epoch in range(self.epochs):\n",
    "#             self.model.train()\n",
    "#             for X_batch, y_batch in loader:\n",
    "#                 self.optimizer.zero_grad()\n",
    "#                 output = self.model(X_batch)\n",
    "#                 loss = self.criterion(output, y_batch)\n",
    "#                 loss.backward()\n",
    "#                 self.optimizer.step()\n",
    "#         return self\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         self.model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             X = torch.tensor(X.values, dtype=torch.float32) if isinstance(X, pd.DataFrame) else torch.tensor(X, dtype=torch.float32)\n",
    "#             predictions = self.model(X)\n",
    "#         return predictions.numpy()\n",
    "\n",
    "#     def score(self, X, y):\n",
    "#         predictions = self.predict(X)\n",
    "#         return -self.criterion(torch.tensor(predictions), torch.tensor(y, dtype=torch.float32)).item()  # Negative MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor, GradientBoostingRegressor, RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.linear_model import LogisticRegression, RidgeCV, PassiveAggressiveRegressor, SGDRegressor, Perceptron, LinearRegression, TheilSenRegressor, HuberRegressor, RANSACRegressor, Lasso, ElasticNet, Lars, LassoLars, OrthogonalMatchingPursuit, BayesianRidge, ARDRegression, TweedieRegressor, PoissonRegressor, GammaRegressor, LassoLars\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn import svm\n",
    "\n",
    "MLA = [\n",
    "\t# Trial Models\n",
    "\tMLPRegressor(random_state=5),\n",
    "\tTheilSenRegressor(random_state=5),\n",
    "\tHuberRegressor(),\n",
    "\tRANSACRegressor(random_state=5),\n",
    "\tLasso(random_state=5),\n",
    "\tElasticNet(random_state=5),\n",
    "\tLars(random_state=5),\n",
    "\tLassoLars(random_state=5),\n",
    "\tOrthogonalMatchingPursuit(),\n",
    "\tBayesianRidge(),\n",
    "\tARDRegression(),\n",
    "    TweedieRegressor(power=1.5, alpha=0.5),\n",
    "    PoissonRegressor(alpha=0.5),\n",
    "    GammaRegressor(alpha=0.5),\n",
    "    LassoLars(alpha=0.1, random_state=5),\n",
    "\n",
    "\t# GLM\n",
    "\tLinearRegression(),\n",
    "\tPassiveAggressiveRegressor(random_state=5),\n",
    "\tRidgeCV(),\n",
    "\t# SGDRegressor(),\n",
    "\n",
    "\t# # SVM\n",
    "\t# svm.SVR(kernel='linear'),\n",
    "    # svm.SVR(kernel='poly'),\n",
    "    # svm.SVR(kernel='rbf'),\n",
    "    # svm.SVR(kernel='sigmoid'),\n",
    "\t# svm.NuSVR(),\n",
    "\n",
    "\t# Trees    \n",
    "\tDecisionTreeRegressor(random_state=5),\n",
    "\tExtraTreeRegressor(random_state=5),\n",
    "\n",
    "\tXGBRegressor(random_state=5),\n",
    "\tLGBMRegressor(n_jobs=-1, random_state=5),\n",
    "\tCatBoostRegressor(random_state=5, verbose=False, early_stopping_rounds=100),\n",
    "\t\n",
    "\t# KNeighbors\n",
    "\tKNeighborsRegressor(),\n",
    "\tKNeighborsRegressor(n_neighbors=2),\n",
    "\tKNeighborsRegressor(n_neighbors=4),\n",
    "\tKNeighborsRegressor(n_neighbors=8),\n",
    "\tKNeighborsRegressor(n_neighbors=16),\n",
    "\tKNeighborsRegressor(n_neighbors=32),\n",
    "\tKNeighborsRegressor(n_neighbors=64),\n",
    "\tKNeighborsRegressor(n_neighbors=128),\n",
    "\tKNeighborsRegressor(n_neighbors=256),\n",
    "\tKNeighborsRegressor(n_neighbors=512),\n",
    "\tKNeighborsRegressor(n_neighbors=1024),\n",
    "\n",
    "\t# Ensemble Methods\n",
    "\tAdaBoostRegressor(random_state=5),\n",
    "\tBaggingRegressor(random_state=5),\n",
    "\tExtraTreesRegressor(random_state=5),\n",
    "\tGradientBoostingRegressor(random_state=5),\n",
    "\tHistGradientBoostingRegressor(random_state=5),\n",
    "\tRandomForestRegressor(random_state=5),\n",
    "    \n",
    "\t# Neural Networks\n",
    "\t# FastAIRegressor(dls),\n",
    "\t# PyTorchRegressor(input_size=train[list(num_var)].shape[1]),\n",
    "\tKerasRegressor(epochs=100, batch_size=32),\n",
    "    ]\n",
    "\n",
    "\n",
    "# split dataset in cross-validation with splitter class\n",
    "# cv_split could KFold, StratifiedKFold or RepeatedKFold depending on the problem\n",
    "cv_split = KFold(n_splits=10, shuffle=True, random_state=5)\n",
    "cv_split_trial = KFold(n_splits=3, shuffle=True, random_state=5) # For quick trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with MLPRegressor\n",
      "Done with TheilSenRegressor\n",
      "Done with HuberRegressor\n",
      "Done with RANSACRegressor\n",
      "Done with Lasso\n",
      "Done with ElasticNet\n",
      "Done with Lars\n",
      "Done with LassoLars\n",
      "Done with OrthogonalMatchingPursuit\n",
      "Done with BayesianRidge\n",
      "Done with ARDRegression\n",
      "Done with TweedieRegressor\n",
      "Done with PoissonRegressor\n",
      "Done with GammaRegressor\n",
      "Done with LassoLars_1\n",
      "Done with LinearRegression\n",
      "Done with PassiveAggressiveRegressor\n",
      "Done with RidgeCV\n",
      "Done with DecisionTreeRegressor\n",
      "Done with ExtraTreeRegressor\n",
      "Done with XGBRegressor\n",
      "Done with LGBMRegressor\n",
      "Done with CatBoostRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor_1\n",
      "Done with KNeighborsRegressor_2\n",
      "Done with KNeighborsRegressor_3\n",
      "Done with KNeighborsRegressor_4\n",
      "Done with KNeighborsRegressor_5\n",
      "Done with KNeighborsRegressor_6\n",
      "Done with KNeighborsRegressor_7\n",
      "Done with KNeighborsRegressor_8\n",
      "Done with KNeighborsRegressor_9\n",
      "Done with KNeighborsRegressor_10\n",
      "Done with AdaBoostRegressor\n",
      "Done with BaggingRegressor\n",
      "Done with ExtraTreesRegressor\n",
      "Done with GradientBoostingRegressor\n",
      "Done with HistGradientBoostingRegressor\n",
      "Done with RandomForestRegressor\n",
      "109/109 [==============================] - 0s 2ms/step\n",
      "217/217 [==============================] - 0s 2ms/step\n",
      "109/109 [==============================] - 0s 2ms/step\n",
      "217/217 [==============================] - 0s 2ms/step\n",
      "109/109 [==============================] - 0s 2ms/step\n",
      "217/217 [==============================] - 1s 4ms/step\n",
      "Done with KerasRegressor\n",
      "CPU times: total: 1min 47s\n",
      "Wall time: 3min 50s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Parameters</th>\n",
       "      <th>MLA Train Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy 3*STD</th>\n",
       "      <th>MLA Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>KerasRegressor</td>\n",
       "      <td>{'batch_size': 32, 'epochs': 100}</td>\n",
       "      <td>0.576596</td>\n",
       "      <td>0.580477</td>\n",
       "      <td>0.136238</td>\n",
       "      <td>0 min 42.76 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>{'categorical_features': None, 'early_stopping...</td>\n",
       "      <td>0.518749</td>\n",
       "      <td>0.656185</td>\n",
       "      <td>0.046055</td>\n",
       "      <td>0 min 1.28 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'criter...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.065863</td>\n",
       "      <td>0 min 2.74 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CatBoostRegressor</td>\n",
       "      <td>{'loss_function': 'RMSE', 'verbose': False, 'r...</td>\n",
       "      <td>0.4792</td>\n",
       "      <td>0.661653</td>\n",
       "      <td>0.037293</td>\n",
       "      <td>0 min 5.30 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...</td>\n",
       "      <td>0.242167</td>\n",
       "      <td>0.662333</td>\n",
       "      <td>0.058447</td>\n",
       "      <td>0 min 5.40 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>0.5169</td>\n",
       "      <td>0.666064</td>\n",
       "      <td>0.048586</td>\n",
       "      <td>0 min 0.27 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>{'objective': 'reg:squarederror', 'base_score'...</td>\n",
       "      <td>0.294985</td>\n",
       "      <td>0.681328</td>\n",
       "      <td>0.042431</td>\n",
       "      <td>0 min 0.79 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.07874</td>\n",
       "      <td>0 min 0.57 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>{'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': ...</td>\n",
       "      <td>0.667212</td>\n",
       "      <td>0.710249</td>\n",
       "      <td>0.058916</td>\n",
       "      <td>0 min 1.46 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.028284</td>\n",
       "      <td>0 min 0.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>KNeighborsRegressor_3</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.063738</td>\n",
       "      <td>0 min 0.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>KNeighborsRegressor_2</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.035355</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>KNeighborsRegressor_4</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.023385</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'squared_error...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 min 0.11 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ExtraTreeRegressor</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'squared_error...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 min 0.03 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>KNeighborsRegressor_5</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.048614</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>KNeighborsRegressor_1</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.070711</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>KNeighborsRegressor_6</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.836198</td>\n",
       "      <td>0.845312</td>\n",
       "      <td>0.08146</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TheilSenRegressor</td>\n",
       "      <td>{'copy_X': True, 'fit_intercept': True, 'max_i...</td>\n",
       "      <td>0.905906</td>\n",
       "      <td>0.909104</td>\n",
       "      <td>0.039869</td>\n",
       "      <td>0 min 3.39 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>KNeighborsRegressor_7</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.916927</td>\n",
       "      <td>0.923958</td>\n",
       "      <td>0.094457</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HuberRegressor</td>\n",
       "      <td>{'alpha': 0.0001, 'epsilon': 1.35, 'fit_interc...</td>\n",
       "      <td>0.938122</td>\n",
       "      <td>0.936989</td>\n",
       "      <td>0.114728</td>\n",
       "      <td>0 min 0.20 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ARDRegression</td>\n",
       "      <td>{'alpha_1': 1e-06, 'alpha_2': 1e-06, 'compute_...</td>\n",
       "      <td>0.969573</td>\n",
       "      <td>0.966068</td>\n",
       "      <td>0.020782</td>\n",
       "      <td>0 min 0.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lars</td>\n",
       "      <td>{'copy_X': True, 'eps': 2.220446049250313e-16,...</td>\n",
       "      <td>0.96502</td>\n",
       "      <td>0.966119</td>\n",
       "      <td>0.026752</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>{'copy_X': True, 'fit_intercept': True, 'n_job...</td>\n",
       "      <td>0.96502</td>\n",
       "      <td>0.966119</td>\n",
       "      <td>0.026752</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>{'alpha_per_target': False, 'alphas': (0.1, 1....</td>\n",
       "      <td>0.968325</td>\n",
       "      <td>0.969011</td>\n",
       "      <td>0.022271</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BayesianRidge</td>\n",
       "      <td>{'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_in...</td>\n",
       "      <td>0.968403</td>\n",
       "      <td>0.969025</td>\n",
       "      <td>0.021671</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>KNeighborsRegressor_8</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.981224</td>\n",
       "      <td>0.98862</td>\n",
       "      <td>0.055716</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>{'base_estimator': None, 'learning_rate': 1.0,...</td>\n",
       "      <td>0.97938</td>\n",
       "      <td>0.989872</td>\n",
       "      <td>0.080126</td>\n",
       "      <td>0 min 0.28 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>KNeighborsRegressor_9</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>1.037129</td>\n",
       "      <td>1.035911</td>\n",
       "      <td>0.067497</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PoissonRegressor</td>\n",
       "      <td>{'alpha': 0.5, 'fit_intercept': True, 'max_ite...</td>\n",
       "      <td>1.038843</td>\n",
       "      <td>1.039091</td>\n",
       "      <td>0.052759</td>\n",
       "      <td>0 min 0.07 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OrthogonalMatchingPursuit</td>\n",
       "      <td>{'fit_intercept': True, 'n_nonzero_coefs': Non...</td>\n",
       "      <td>1.075493</td>\n",
       "      <td>1.075732</td>\n",
       "      <td>0.022092</td>\n",
       "      <td>0 min 0.00 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>{'alpha': 1.0, 'copy_X': True, 'fit_intercept'...</td>\n",
       "      <td>1.077266</td>\n",
       "      <td>1.081071</td>\n",
       "      <td>0.023476</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>{'alpha': 1.0, 'copy_X': True, 'fit_intercept'...</td>\n",
       "      <td>1.082992</td>\n",
       "      <td>1.084759</td>\n",
       "      <td>0.01931</td>\n",
       "      <td>0 min 0.00 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'batch...</td>\n",
       "      <td>1.114877</td>\n",
       "      <td>1.116208</td>\n",
       "      <td>0.312218</td>\n",
       "      <td>0 min 1.17 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>KNeighborsRegressor_10</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>1.1146</td>\n",
       "      <td>1.120638</td>\n",
       "      <td>0.066437</td>\n",
       "      <td>0 min 0.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RANSACRegressor</td>\n",
       "      <td>{'base_estimator': 'deprecated', 'estimator': ...</td>\n",
       "      <td>1.196459</td>\n",
       "      <td>1.191844</td>\n",
       "      <td>0.648952</td>\n",
       "      <td>0 min 0.17 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LassoLars_1</td>\n",
       "      <td>{'alpha': 0.1, 'copy_X': True, 'eps': 2.220446...</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>0.022821</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LassoLars</td>\n",
       "      <td>{'alpha': 1.0, 'copy_X': True, 'eps': 2.220446...</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>0.022821</td>\n",
       "      <td>0 min 0.00 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GammaRegressor</td>\n",
       "      <td>{'alpha': 0.5, 'fit_intercept': True, 'max_ite...</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>0.022821</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TweedieRegressor</td>\n",
       "      <td>{'alpha': 0.5, 'fit_intercept': True, 'link': ...</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>0.022821</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PassiveAggressiveRegressor</td>\n",
       "      <td>{'C': 1.0, 'average': False, 'early_stopping':...</td>\n",
       "      <td>2.981941</td>\n",
       "      <td>3.010767</td>\n",
       "      <td>3.833087</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         MLA Name  \\\n",
       "40                 KerasRegressor   \n",
       "38  HistGradientBoostingRegressor   \n",
       "36            ExtraTreesRegressor   \n",
       "22              CatBoostRegressor   \n",
       "39          RandomForestRegressor   \n",
       "21                  LGBMRegressor   \n",
       "20                   XGBRegressor   \n",
       "35               BaggingRegressor   \n",
       "37      GradientBoostingRegressor   \n",
       "23            KNeighborsRegressor   \n",
       "26          KNeighborsRegressor_3   \n",
       "25          KNeighborsRegressor_2   \n",
       "27          KNeighborsRegressor_4   \n",
       "18          DecisionTreeRegressor   \n",
       "19             ExtraTreeRegressor   \n",
       "28          KNeighborsRegressor_5   \n",
       "24          KNeighborsRegressor_1   \n",
       "29          KNeighborsRegressor_6   \n",
       "1               TheilSenRegressor   \n",
       "30          KNeighborsRegressor_7   \n",
       "2                  HuberRegressor   \n",
       "10                  ARDRegression   \n",
       "6                            Lars   \n",
       "15               LinearRegression   \n",
       "17                        RidgeCV   \n",
       "9                   BayesianRidge   \n",
       "31          KNeighborsRegressor_8   \n",
       "34              AdaBoostRegressor   \n",
       "32          KNeighborsRegressor_9   \n",
       "12               PoissonRegressor   \n",
       "8       OrthogonalMatchingPursuit   \n",
       "5                      ElasticNet   \n",
       "4                           Lasso   \n",
       "0                    MLPRegressor   \n",
       "33         KNeighborsRegressor_10   \n",
       "3                 RANSACRegressor   \n",
       "14                    LassoLars_1   \n",
       "7                       LassoLars   \n",
       "13                 GammaRegressor   \n",
       "11               TweedieRegressor   \n",
       "16     PassiveAggressiveRegressor   \n",
       "\n",
       "                                       MLA Parameters MLA Train Accuracy Mean  \\\n",
       "40                  {'batch_size': 32, 'epochs': 100}                0.576596   \n",
       "38  {'categorical_features': None, 'early_stopping...                0.518749   \n",
       "36  {'bootstrap': False, 'ccp_alpha': 0.0, 'criter...                    -0.0   \n",
       "22  {'loss_function': 'RMSE', 'verbose': False, 'r...                  0.4792   \n",
       "39  {'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...                0.242167   \n",
       "21  {'boosting_type': 'gbdt', 'class_weight': None...                  0.5169   \n",
       "20  {'objective': 'reg:squarederror', 'base_score'...                0.294985   \n",
       "35  {'base_estimator': None, 'bootstrap': True, 'b...                    0.25   \n",
       "37  {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': ...                0.667212   \n",
       "23  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                0.613333   \n",
       "26  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                  0.6625   \n",
       "25  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                     0.6   \n",
       "27  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                   0.725   \n",
       "18  {'ccp_alpha': 0.0, 'criterion': 'squared_error...                    -0.0   \n",
       "19  {'ccp_alpha': 0.0, 'criterion': 'squared_error...                    -0.0   \n",
       "28  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                   0.775   \n",
       "24  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                     0.4   \n",
       "29  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                0.836198   \n",
       "1   {'copy_X': True, 'fit_intercept': True, 'max_i...                0.905906   \n",
       "30  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                0.916927   \n",
       "2   {'alpha': 0.0001, 'epsilon': 1.35, 'fit_interc...                0.938122   \n",
       "10  {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'compute_...                0.969573   \n",
       "6   {'copy_X': True, 'eps': 2.220446049250313e-16,...                 0.96502   \n",
       "15  {'copy_X': True, 'fit_intercept': True, 'n_job...                 0.96502   \n",
       "17  {'alpha_per_target': False, 'alphas': (0.1, 1....                0.968325   \n",
       "9   {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_in...                0.968403   \n",
       "31  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                0.981224   \n",
       "34  {'base_estimator': None, 'learning_rate': 1.0,...                 0.97938   \n",
       "32  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                1.037129   \n",
       "12  {'alpha': 0.5, 'fit_intercept': True, 'max_ite...                1.038843   \n",
       "8   {'fit_intercept': True, 'n_nonzero_coefs': Non...                1.075493   \n",
       "5   {'alpha': 1.0, 'copy_X': True, 'fit_intercept'...                1.077266   \n",
       "4   {'alpha': 1.0, 'copy_X': True, 'fit_intercept'...                1.082992   \n",
       "0   {'activation': 'relu', 'alpha': 0.0001, 'batch...                1.114877   \n",
       "33  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                  1.1146   \n",
       "3   {'base_estimator': 'deprecated', 'estimator': ...                1.196459   \n",
       "14  {'alpha': 0.1, 'copy_X': True, 'eps': 2.220446...                1.352874   \n",
       "7   {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446...                1.352874   \n",
       "13  {'alpha': 0.5, 'fit_intercept': True, 'max_ite...                1.352874   \n",
       "11  {'alpha': 0.5, 'fit_intercept': True, 'link': ...                1.352874   \n",
       "16  {'C': 1.0, 'average': False, 'early_stopping':...                2.981941   \n",
       "\n",
       "   MLA Test Accuracy Mean MLA Test Accuracy 3*STD         MLA Time  \n",
       "40               0.580477                0.136238  0 min 42.76 sec  \n",
       "38               0.656185                0.046055   0 min 1.28 sec  \n",
       "36                  0.658                0.065863   0 min 2.74 sec  \n",
       "22               0.661653                0.037293   0 min 5.30 sec  \n",
       "39               0.662333                0.058447   0 min 5.40 sec  \n",
       "21               0.666064                0.048586   0 min 0.27 sec  \n",
       "20               0.681328                0.042431   0 min 0.79 sec  \n",
       "35               0.693333                 0.07874   0 min 0.57 sec  \n",
       "37               0.710249                0.058916   0 min 1.46 sec  \n",
       "23               0.766667                0.028284   0 min 0.02 sec  \n",
       "26               0.770833                0.063738   0 min 0.02 sec  \n",
       "25               0.783333                0.035355   0 min 0.01 sec  \n",
       "27               0.783333                0.023385   0 min 0.01 sec  \n",
       "18                    0.8                     0.0   0 min 0.11 sec  \n",
       "19                    0.8                     0.0   0 min 0.03 sec  \n",
       "28               0.802083                0.048614   0 min 0.01 sec  \n",
       "24               0.833333                0.070711   0 min 0.01 sec  \n",
       "29               0.845312                 0.08146   0 min 0.01 sec  \n",
       "1                0.909104                0.039869   0 min 3.39 sec  \n",
       "30               0.923958                0.094457   0 min 0.01 sec  \n",
       "2                0.936989                0.114728   0 min 0.20 sec  \n",
       "10               0.966068                0.020782   0 min 0.02 sec  \n",
       "6                0.966119                0.026752   0 min 0.01 sec  \n",
       "15               0.966119                0.026752   0 min 0.01 sec  \n",
       "17               0.969011                0.022271   0 min 0.01 sec  \n",
       "9                0.969025                0.021671   0 min 0.01 sec  \n",
       "31                0.98862                0.055716   0 min 0.01 sec  \n",
       "34               0.989872                0.080126   0 min 0.28 sec  \n",
       "32               1.035911                0.067497   0 min 0.01 sec  \n",
       "12               1.039091                0.052759   0 min 0.07 sec  \n",
       "8                1.075732                0.022092   0 min 0.00 sec  \n",
       "5                1.081071                0.023476   0 min 0.01 sec  \n",
       "4                1.084759                 0.01931   0 min 0.00 sec  \n",
       "0                1.116208                0.312218   0 min 1.17 sec  \n",
       "33               1.120638                0.066437   0 min 0.02 sec  \n",
       "3                1.191844                0.648952   0 min 0.17 sec  \n",
       "14               1.352874                0.022821   0 min 0.01 sec  \n",
       "7                1.352874                0.022821   0 min 0.00 sec  \n",
       "13               1.352874                0.022821   0 min 0.01 sec  \n",
       "11               1.352874                0.022821   0 min 0.01 sec  \n",
       "16               3.010767                3.833087   0 min 0.01 sec  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# create table to compare MLA metrics\n",
    "MLA_columns = ['MLA Name', 'MLA Parameters', 'MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD', 'MLA Time']\n",
    "MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "\n",
    "# create table to compare MLA predictions\n",
    "MLA_predict = {}\n",
    "\n",
    "# index through MLA and save performance to table\n",
    "row_index = 0\n",
    "scoring = median_abs_error_scorer = make_scorer(median_absolute_error, greater_is_better=False)\n",
    "\n",
    "for alg in MLA:\n",
    "\n",
    "\t# set name and parameters\n",
    "\tMLA_name = alg.__class__.__name__\n",
    "\n",
    "\t# Add suffix if name already exists\n",
    "\tsuffix = 1\n",
    "\toriginal_MLA_name = MLA_name\n",
    "\twhile MLA_compare['MLA Name'].str.contains(MLA_name).any():\n",
    "\t\tMLA_name = f\"{original_MLA_name}_{suffix}\"\n",
    "\t\tsuffix += 1\n",
    "\t\t\n",
    "\tMLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
    "\tMLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
    "\n",
    "\t\"\"\"score model with cross validation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\"\"\"\n",
    "\n",
    "\tcv_results = cross_validate(alg, train[num_var], train[TARGET], cv=cv_split_trial, scoring=scoring, return_train_score=True)\n",
    "\n",
    "\t# Calculate mean time in seconds\n",
    "\tmean_fit_time = cv_results['fit_time'].mean()\n",
    "\n",
    "\t# Convert mean time to minutes and seconds\n",
    "\tminutes = int(mean_fit_time // 60)\n",
    "\tseconds = mean_fit_time % 60\n",
    "\n",
    "\t# Format the time and assign it\n",
    "\tMLA_compare.loc[row_index, 'MLA Time'] = f\"{minutes} min {seconds:.2f} sec\"\n",
    "\tMLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean() * -1\n",
    "\tMLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean() * -1\n",
    "\t#if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\n",
    "\tMLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   #let's know the worst that can happen!\n",
    "\n",
    "\t# # #save MLA predictions - see section 6 for usage\n",
    "\t# alg.fit(data1[data1_x_bin], data1[Target])\n",
    "\t# MLA_predict[MLA_name] = alg.predict(data1[data1_x_bin])\n",
    "\tprint(f'Done with {MLA_name}')\n",
    "\trow_index+=1\n",
    "\n",
    "\n",
    "#print and sort table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html\n",
    "MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = True, inplace = True)\n",
    "MLA_compare.to_csv(f'{experiment}_results.csv', index=False)\n",
    "MLA_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Algorithm')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n",
    "\n",
    "#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\n",
    "plt.title('Machine Learning Algorithm Accuracy Score \\n')\n",
    "plt.xlabel('Accuracy Score (%)')\n",
    "plt.ylabel('Algorithm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENSEMBLE CROSS-VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, y_test, predictions):\n",
    "    weighted_predictions = np.zeros_like(predictions[0])\n",
    "    for i in range(len(MLA)):\n",
    "        # Assign a weight to each prediction\n",
    "        weight = trial.suggest_float(f'w{i}', 0, 1)\n",
    "        weighted_predictions += weight * predictions[i]\n",
    "    weighted_predictions /= np.sum(weighted_predictions)  # Normalize weights\n",
    "\n",
    "    # Calculate metric on your validation set\n",
    "    mae = median_absolute_error(y_test, weighted_predictions)\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_avg_objective(trial, y_true, model_predictions):\n",
    "    # The model_predictions is a list of prediction arrays from the three models\n",
    "    weighted_predictions = np.zeros_like(model_predictions[0])\n",
    "    total_weight = 0\n",
    "\n",
    "    for i in range(len(model_predictions)):\n",
    "        # Define the weight for each model\n",
    "        weight = trial.suggest_float(f'w{i}', 0, 1)\n",
    "        total_weight += weight\n",
    "        weighted_predictions += weight * model_predictions[i]\n",
    "\n",
    "    # Normalize the predictions by the total weight\n",
    "    if total_weight > 0:\n",
    "        weighted_predictions /= total_weight\n",
    "\n",
    "    # Calculate the median absolute error\n",
    "    return median_absolute_error(y_true, weighted_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hill Climbing inspired by code from Kaggle\n",
    "def hill_climbing(x, y):\n",
    "    \n",
    "    # Evaluating oof predictions\n",
    "    scores = {}\n",
    "    for col in x.columns:\n",
    "        scores[col] = median_absolute_error(y, x[col])\n",
    "\n",
    "    # Sorting the model scores in ascending order\n",
    "    scores = {k: v for k, v in sorted(scores.items(), key = lambda item: item[1], reverse = False)}\n",
    "\n",
    "    # Sort oof_df\n",
    "    x = x[list(scores.keys())]\n",
    "\n",
    "    # Initialize weights\n",
    "    weights = {col: 1 if i == 0 else 0 for i, col in enumerate(x.columns)}\n",
    "\n",
    "    STOP = False\n",
    "    current_best_ensemble = x.iloc[:,0]\n",
    "    MODELS = x.iloc[:,1:]\n",
    "    weight_range = np.arange(-0.5, 0.51, 0.01) \n",
    "    history = [median_absolute_error(y, current_best_ensemble)]\n",
    "    j = 0\n",
    "\n",
    "    while not STOP:\n",
    "        j += 1\n",
    "        potential_new_best_cv_score = median_absolute_error(y, current_best_ensemble)\n",
    "        k_best, wgt_best = None, None\n",
    "        for k in MODELS:\n",
    "            for wgt in weight_range:\n",
    "                potential_ensemble = (1 - wgt) * current_best_ensemble + wgt * MODELS[k]\n",
    "                cv_score = median_absolute_error(y, potential_ensemble)\n",
    "                if cv_score < potential_new_best_cv_score:\n",
    "                    potential_new_best_cv_score = cv_score\n",
    "                    k_best, wgt_best = k, wgt\n",
    "\n",
    "        if k_best is not None:\n",
    "            # Update weights\n",
    "            weights = {col: (1 - wgt_best) * weights[col] if col != k_best else wgt_best for col in weights}\n",
    "            current_best_ensemble = (1 - wgt_best) * current_best_ensemble + wgt_best * MODELS[k_best]\n",
    "            MODELS.drop(k_best, axis = 1, inplace = True)\n",
    "            if MODELS.shape[1] == 0:\n",
    "                STOP = True\n",
    "            history.append(potential_new_best_cv_score)\n",
    "        else:\n",
    "            STOP = True\n",
    "        \n",
    "    hill_ens_pred = current_best_ensemble\n",
    "    \n",
    "    return hill_ens_pred, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission_file(ids, predictions, filename):\n",
    "    submission = pd.DataFrame({'id': ids, 'Hardness': predictions})\n",
    "    submission.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "217/217 [==============================] - 1s 2ms/step\n",
      "109/109 [==============================] - 0s 2ms/step\n",
      "The Fold 1 Hill Climb is 0.501949962619042\n",
      "The Fold 1 weight is {'KerasRegressor': 1.0099999999999991, 'HistGradientBoostingRegressor': 0.0, 'CatBoostRegressor': 0.0, 'LGBMRegressor': 0.0, 'RandomForestRegressor': 0.0, 'ExtraTreesRegressor': 0.0, 'XGBRegressor': 0.0, 'BaggingRegressor': 0.0, 'GradientBoostingRegressor': 0.0, 'KNeighborsRegressor': 0.0, 'KNeighborsRegressor_5': 0.0, 'DecisionTreeRegressor': 0.0, 'ExtraTreeRegressor': 0.0, 'KNeighborsRegressor_2': 0.0, 'KNeighborsRegressor_3': 0.0, 'KNeighborsRegressor_4': 0.0, 'KNeighborsRegressor_6': 0.0, 'KNeighborsRegressor_7': 0.0, 'TheilSenRegressor': 0.0, 'KNeighborsRegressor_8': 0.0, 'ARDRegression': 0.0, 'RidgeCV': 0.0, 'BayesianRidge': 0.0, 'LinearRegression': 0.0, 'Lars': 0.0, 'HuberRegressor': 0.0, 'KNeighborsRegressor_9': 0.0, 'AdaBoostRegressor': 0.0, 'KNeighborsRegressor_10': 0.0, 'PoissonRegressor': 0.0, 'OrthogonalMatchingPursuit': 0.0, 'ElasticNet': 0.0, 'Lasso': 0.0, 'MLPRegressor': 0.0, 'KNeighborsRegressor_11': 0.0, 'LassoLars': -0.00999999999999956, 'TweedieRegressor': 0.0, 'GammaRegressor': 0.0, 'LassoLars_1': 0.0, 'RANSACRegressor': 0.0, 'PassiveAggressiveRegressor': 4.440892098500626e-16}\n",
      "\n",
      "Fold 2\n",
      "217/217 [==============================] - 0s 2ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "The Fold 2 Hill Climb is 0.48093786697420615\n",
      "The Fold 2 weight is {'KerasRegressor': 0.9753695078399912, 'HistGradientBoostingRegressor': 0.02020000000000031, 'ExtraTreesRegressor': 0.0, 'LGBMRegressor': 0.0, 'CatBoostRegressor': 0.0, 'RandomForestRegressor': 0.0, 'XGBRegressor': 0.03959200000000015, 'BaggingRegressor': 0.05929297919999999, 'GradientBoostingRegressor': 0.0, 'KNeighborsRegressor_4': 0.0, 'KNeighborsRegressor': 0.0, 'KNeighborsRegressor_3': 0.0, 'KNeighborsRegressor_5': 0.0, 'KNeighborsRegressor_6': 0.0, 'DecisionTreeRegressor': 4.4408920985006005e-16, 'ExtraTreeRegressor': 0.0, 'KNeighborsRegressor_7': 0.0, 'KNeighborsRegressor_2': 0.0, 'KNeighborsRegressor_8': 0.0, 'TheilSenRegressor': -0.009999999999999492, 'HuberRegressor': 4.4408920985006025e-16, 'AdaBoostRegressor': 0.0, 'ARDRegression': 4.4408920985006045e-16, 'Lars': 4.4408920985006064e-16, 'LinearRegression': 4.4408920985006084e-16, 'BayesianRidge': 4.4408920985006104e-16, 'RidgeCV': 4.4408920985006124e-16, 'KNeighborsRegressor_9': 0.0, 'RANSACRegressor': 4.4408920985006143e-16, 'PoissonRegressor': 4.4408920985006163e-16, 'KNeighborsRegressor_10': -0.04644616703999923, 'OrthogonalMatchingPursuit': 0.0, 'ElasticNet': 0.0, 'Lasso': -0.03800831999999936, 'KNeighborsRegressor_11': 0.0, 'MLPRegressor': 4.4408920985006183e-16, 'LassoLars': 4.44089209850062e-16, 'LassoLars_1': 4.440892098500622e-16, 'TweedieRegressor': 4.440892098500624e-16, 'GammaRegressor': 4.440892098500626e-16, 'PassiveAggressiveRegressor': 0.0}\n",
      "\n",
      "Fold 3\n",
      "217/217 [==============================] - 0s 2ms/step\n",
      "109/109 [==============================] - 0s 2ms/step\n",
      "The Fold 3 Hill Climb is 0.4516838073730467\n",
      "The Fold 3 weight is {'KerasRegressor': 1.0499999999999978, 'RandomForestRegressor': 0.0, 'ExtraTreesRegressor': 0.0, 'CatBoostRegressor': 0.0, 'HistGradientBoostingRegressor': 4.440892098500622e-16, 'LGBMRegressor': 0.0, 'BaggingRegressor': 0.0, 'XGBRegressor': 4.440892098500624e-16, 'GradientBoostingRegressor': 4.440892098500626e-16, 'KNeighborsRegressor': 0.0, 'KNeighborsRegressor_4': 0.0, 'KNeighborsRegressor_3': 0.0, 'KNeighborsRegressor_5': 0.0, 'KNeighborsRegressor_6': 0.0, 'DecisionTreeRegressor': 4.44089209850062e-16, 'ExtraTreeRegressor': 0.0, 'KNeighborsRegressor_7': 0.0, 'KNeighborsRegressor_2': 0.0, 'TheilSenRegressor': 0.0, 'KNeighborsRegressor_8': 0.0, 'HuberRegressor': 0.0, 'Lars': 0.0, 'LinearRegression': 0.0, 'RidgeCV': 0.0, 'ARDRegression': 0.0, 'BayesianRidge': 0.0, 'KNeighborsRegressor_9': 0.0, 'AdaBoostRegressor': 0.0, 'MLPRegressor': 0.0, 'KNeighborsRegressor_10': -0.04999999999999952, 'PoissonRegressor': 0.0, 'RANSACRegressor': 0.0, 'OrthogonalMatchingPursuit': 0.0, 'ElasticNet': 0.0, 'Lasso': 0.0, 'KNeighborsRegressor_11': 0.0, 'LassoLars': 0.0, 'TweedieRegressor': 0.0, 'GammaRegressor': 0.0, 'LassoLars_1': 0.0, 'PassiveAggressiveRegressor': 0.0}\n",
      "\n",
      "\n",
      "The average prediction CV score is ==> nan\n",
      "The Optuna weights CV score is ==> nan\n",
      "The Hill Climbing CV score is ==> 0.4781905456554316\n",
      "The 2-Level Stacking CV score is ==> nan\n",
      "The 2-Level Multi-Model Stack with 3-Level Weighted Average CV score is ==> nan\n",
      "The Hill Climbing weights are ==> [{'KerasRegressor': 1.0099999999999991, 'HistGradientBoostingRegressor': 0.0, 'CatBoostRegressor': 0.0, 'LGBMRegressor': 0.0, 'RandomForestRegressor': 0.0, 'ExtraTreesRegressor': 0.0, 'XGBRegressor': 0.0, 'BaggingRegressor': 0.0, 'GradientBoostingRegressor': 0.0, 'KNeighborsRegressor': 0.0, 'KNeighborsRegressor_5': 0.0, 'DecisionTreeRegressor': 0.0, 'ExtraTreeRegressor': 0.0, 'KNeighborsRegressor_2': 0.0, 'KNeighborsRegressor_3': 0.0, 'KNeighborsRegressor_4': 0.0, 'KNeighborsRegressor_6': 0.0, 'KNeighborsRegressor_7': 0.0, 'TheilSenRegressor': 0.0, 'KNeighborsRegressor_8': 0.0, 'ARDRegression': 0.0, 'RidgeCV': 0.0, 'BayesianRidge': 0.0, 'LinearRegression': 0.0, 'Lars': 0.0, 'HuberRegressor': 0.0, 'KNeighborsRegressor_9': 0.0, 'AdaBoostRegressor': 0.0, 'KNeighborsRegressor_10': 0.0, 'PoissonRegressor': 0.0, 'OrthogonalMatchingPursuit': 0.0, 'ElasticNet': 0.0, 'Lasso': 0.0, 'MLPRegressor': 0.0, 'KNeighborsRegressor_11': 0.0, 'LassoLars': -0.00999999999999956, 'TweedieRegressor': 0.0, 'GammaRegressor': 0.0, 'LassoLars_1': 0.0, 'RANSACRegressor': 0.0, 'PassiveAggressiveRegressor': 4.440892098500626e-16}, {'KerasRegressor': 0.9753695078399912, 'HistGradientBoostingRegressor': 0.02020000000000031, 'ExtraTreesRegressor': 0.0, 'LGBMRegressor': 0.0, 'CatBoostRegressor': 0.0, 'RandomForestRegressor': 0.0, 'XGBRegressor': 0.03959200000000015, 'BaggingRegressor': 0.05929297919999999, 'GradientBoostingRegressor': 0.0, 'KNeighborsRegressor_4': 0.0, 'KNeighborsRegressor': 0.0, 'KNeighborsRegressor_3': 0.0, 'KNeighborsRegressor_5': 0.0, 'KNeighborsRegressor_6': 0.0, 'DecisionTreeRegressor': 4.4408920985006005e-16, 'ExtraTreeRegressor': 0.0, 'KNeighborsRegressor_7': 0.0, 'KNeighborsRegressor_2': 0.0, 'KNeighborsRegressor_8': 0.0, 'TheilSenRegressor': -0.009999999999999492, 'HuberRegressor': 4.4408920985006025e-16, 'AdaBoostRegressor': 0.0, 'ARDRegression': 4.4408920985006045e-16, 'Lars': 4.4408920985006064e-16, 'LinearRegression': 4.4408920985006084e-16, 'BayesianRidge': 4.4408920985006104e-16, 'RidgeCV': 4.4408920985006124e-16, 'KNeighborsRegressor_9': 0.0, 'RANSACRegressor': 4.4408920985006143e-16, 'PoissonRegressor': 4.4408920985006163e-16, 'KNeighborsRegressor_10': -0.04644616703999923, 'OrthogonalMatchingPursuit': 0.0, 'ElasticNet': 0.0, 'Lasso': -0.03800831999999936, 'KNeighborsRegressor_11': 0.0, 'MLPRegressor': 4.4408920985006183e-16, 'LassoLars': 4.44089209850062e-16, 'LassoLars_1': 4.440892098500622e-16, 'TweedieRegressor': 4.440892098500624e-16, 'GammaRegressor': 4.440892098500626e-16, 'PassiveAggressiveRegressor': 0.0}, {'KerasRegressor': 1.0499999999999978, 'RandomForestRegressor': 0.0, 'ExtraTreesRegressor': 0.0, 'CatBoostRegressor': 0.0, 'HistGradientBoostingRegressor': 4.440892098500622e-16, 'LGBMRegressor': 0.0, 'BaggingRegressor': 0.0, 'XGBRegressor': 4.440892098500624e-16, 'GradientBoostingRegressor': 4.440892098500626e-16, 'KNeighborsRegressor': 0.0, 'KNeighborsRegressor_4': 0.0, 'KNeighborsRegressor_3': 0.0, 'KNeighborsRegressor_5': 0.0, 'KNeighborsRegressor_6': 0.0, 'DecisionTreeRegressor': 4.44089209850062e-16, 'ExtraTreeRegressor': 0.0, 'KNeighborsRegressor_7': 0.0, 'KNeighborsRegressor_2': 0.0, 'TheilSenRegressor': 0.0, 'KNeighborsRegressor_8': 0.0, 'HuberRegressor': 0.0, 'Lars': 0.0, 'LinearRegression': 0.0, 'RidgeCV': 0.0, 'ARDRegression': 0.0, 'BayesianRidge': 0.0, 'KNeighborsRegressor_9': 0.0, 'AdaBoostRegressor': 0.0, 'MLPRegressor': 0.0, 'KNeighborsRegressor_10': -0.04999999999999952, 'PoissonRegressor': 0.0, 'RANSACRegressor': 0.0, 'OrthogonalMatchingPursuit': 0.0, 'ElasticNet': 0.0, 'Lasso': 0.0, 'KNeighborsRegressor_11': 0.0, 'LassoLars': 0.0, 'TweedieRegressor': 0.0, 'GammaRegressor': 0.0, 'LassoLars_1': 0.0, 'PassiveAggressiveRegressor': 0.0}]\n",
      "CPU times: total: 2min 35s\n",
      "Wall time: 4min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "avg_predictions_scores = []\n",
    "optuna_weights_scores = []\n",
    "hill_climb_scores = []\n",
    "stacked_scores = []\n",
    "optuna_weights_scores_stack = []\n",
    "hill_climb_weights = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(cv_split_trial.split(train[num_var], train[TARGET])):\n",
    "    X_train, X_test = train[num_var].iloc[train_index], train[num_var].iloc[test_index]\n",
    "    y_train, y_test = train[TARGET].iloc[train_index], train[TARGET].iloc[test_index]\n",
    "\n",
    "    print(f'Fold {i+1}')\n",
    "    \n",
    "    MLA_cv_train_preds = []\n",
    "    MLA_cv_preds = []\n",
    "    MLA_cv_preds_dict = {}\n",
    "    MLA_names = []\n",
    "    \n",
    "    suffix = 1\n",
    "    for alg in MLA:\n",
    "        MLA_name = alg.__class__.__name__\n",
    "\n",
    "        # Add suffix if name already exists\n",
    "\n",
    "        original_MLA_name = MLA_name\n",
    "        if MLA_name in MLA_names:\n",
    "        # while MLA_cv_preds.str.contains(MLA_name).any():\n",
    "            MLA_name = f\"{original_MLA_name}_{suffix}\"\n",
    "            suffix += 1\n",
    "            \n",
    "        predictor = alg.fit(X_train, y_train)\n",
    "        pred_train_result = predictor.predict(X_train)\n",
    "        pred_result = predictor.predict(X_test)\n",
    "\n",
    "        MLA_cv_train_preds.append(pred_train_result)\n",
    "        MLA_cv_preds.append(pred_result)\n",
    "        MLA_cv_preds_dict[MLA_name] = pred_result\n",
    "        MLA_names.append(MLA_name)\n",
    "\n",
    "    ##################\n",
    "    ### Hill Climb ###\n",
    "    ##################\n",
    "    hill_climb_pred, hill_climb_weight = hill_climbing(pd.DataFrame(MLA_cv_preds_dict), y_test)\n",
    "    hill_climb_score = median_absolute_error(y_test, hill_climb_pred)\n",
    "    hill_climb_scores.append(hill_climb_score)\n",
    "    hill_climb_weights.append(hill_climb_weight)\n",
    "    print(f'The Fold {i+1} Hill Climb is {hill_climb_score}')\n",
    "    print(f'The Fold {i+1} weight is {hill_climb_weight}')\n",
    "    print()\n",
    "\n",
    "print()\n",
    "print(f'The average prediction CV score is ==> {np.mean(avg_predictions_scores)}')\n",
    "print(f'The Optuna weights CV score is ==> {np.mean(optuna_weights_scores)}')\n",
    "print(f'The Hill Climbing CV score is ==> {np.mean(hill_climb_scores)}')\n",
    "print(f'The 2-Level Stacking CV score is ==> {np.mean(stacked_scores)}')\n",
    "print(f'The 2-Level Multi-Model Stack with 3-Level Weighted Average CV score is ==> {np.mean(optuna_weights_scores_stack)}')\n",
    "print(f'The Hill Climbing weights are ==> {hill_climb_weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'KerasRegressor': 1.0117898359466626,\n",
       "  'HistGradientBoostingRegressor': 0.006733333333333585,\n",
       "  'CatBoostRegressor': 0.0,\n",
       "  'LGBMRegressor': 0.0,\n",
       "  'RandomForestRegressor': 0.0,\n",
       "  'ExtraTreesRegressor': 0.0,\n",
       "  'XGBRegressor': 0.013197333333333531,\n",
       "  'BaggingRegressor': 0.019764326399999997,\n",
       "  'GradientBoostingRegressor': 1.4802973661668753e-16,\n",
       "  'KNeighborsRegressor': 0.0,\n",
       "  'KNeighborsRegressor_5': 0.0,\n",
       "  'DecisionTreeRegressor': 2.9605947323337403e-16,\n",
       "  'ExtraTreeRegressor': 0.0,\n",
       "  'KNeighborsRegressor_2': 0.0,\n",
       "  'KNeighborsRegressor_3': 0.0,\n",
       "  'KNeighborsRegressor_4': 0.0,\n",
       "  'KNeighborsRegressor_6': 0.0,\n",
       "  'KNeighborsRegressor_7': 0.0,\n",
       "  'TheilSenRegressor': -0.003333333333333164,\n",
       "  'KNeighborsRegressor_8': 0.0,\n",
       "  'ARDRegression': 1.4802973661668682e-16,\n",
       "  'RidgeCV': 1.4802973661668709e-16,\n",
       "  'BayesianRidge': 1.4802973661668701e-16,\n",
       "  'LinearRegression': 1.4802973661668694e-16,\n",
       "  'Lars': 1.480297366166869e-16,\n",
       "  'HuberRegressor': 1.4802973661668674e-16,\n",
       "  'KNeighborsRegressor_9': 0.0,\n",
       "  'AdaBoostRegressor': 0.0,\n",
       "  'KNeighborsRegressor_10': -0.03214872234666625,\n",
       "  'PoissonRegressor': 1.480297366166872e-16,\n",
       "  'OrthogonalMatchingPursuit': 0.0,\n",
       "  'ElasticNet': 0.0,\n",
       "  'Lasso': -0.012669439999999787,\n",
       "  'MLPRegressor': 1.4802973661668728e-16,\n",
       "  'KNeighborsRegressor_11': 0.0,\n",
       "  'LassoLars': -0.0033333333333330386,\n",
       "  'TweedieRegressor': 1.4802973661668748e-16,\n",
       "  'GammaRegressor': 1.4802973661668753e-16,\n",
       "  'LassoLars_1': 1.480297366166874e-16,\n",
       "  'RANSACRegressor': 1.4802973661668714e-16,\n",
       "  'PassiveAggressiveRegressor': 1.4802973661668753e-16},\n",
       " 1.0,\n",
       " 41)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get average weights for the models from all the folds\n",
    "\n",
    "average_values = {}\n",
    "\n",
    "for model in hill_climb_weights:\n",
    "    for key, value in model.items():\n",
    "        if key in average_values:\n",
    "            average_values[key] += value\n",
    "        else:\n",
    "            average_values[key] = value\n",
    "\n",
    "num_models = len(hill_climb_weights)\n",
    "average_values = {k: v / num_models for k, v in average_values.items()}\n",
    "\n",
    "# Ensure the new weights sum up to 1\n",
    "sum = 0\n",
    "\n",
    "for k, v in average_values.items():\n",
    "    sum += v\n",
    "\n",
    "average_values, sum, len(average_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MLPRegressor': 1.4802973661668728e-16,\n",
       " 'TheilSenRegressor': -0.003333333333333164,\n",
       " 'HuberRegressor': 1.4802973661668674e-16,\n",
       " 'RANSACRegressor': 1.4802973661668714e-16,\n",
       " 'Lasso': -0.012669439999999787,\n",
       " 'ElasticNet': 0.0,\n",
       " 'Lars': 1.480297366166869e-16,\n",
       " 'LassoLars': -0.0033333333333330386,\n",
       " 'OrthogonalMatchingPursuit': 0.0,\n",
       " 'BayesianRidge': 1.4802973661668701e-16,\n",
       " 'ARDRegression': 1.4802973661668682e-16,\n",
       " 'TweedieRegressor': 1.4802973661668748e-16,\n",
       " 'PoissonRegressor': 1.480297366166872e-16,\n",
       " 'GammaRegressor': 1.4802973661668753e-16,\n",
       " 'LassoLars_1': 1.480297366166874e-16,\n",
       " 'LinearRegression': 1.4802973661668694e-16,\n",
       " 'PassiveAggressiveRegressor': 1.4802973661668753e-16,\n",
       " 'RidgeCV': 1.4802973661668709e-16,\n",
       " 'DecisionTreeRegressor': 2.9605947323337403e-16,\n",
       " 'ExtraTreeRegressor': 0.0,\n",
       " 'XGBRegressor': 0.013197333333333531,\n",
       " 'LGBMRegressor': 0.0,\n",
       " 'CatBoostRegressor': 0.0,\n",
       " 'KNeighborsRegressor': 0.0,\n",
       " 'KNeighborsRegressor_2': 0.0,\n",
       " 'KNeighborsRegressor_3': 0.0,\n",
       " 'KNeighborsRegressor_4': 0.0,\n",
       " 'KNeighborsRegressor_5': 0.0,\n",
       " 'KNeighborsRegressor_6': 0.0,\n",
       " 'KNeighborsRegressor_7': 0.0,\n",
       " 'KNeighborsRegressor_8': 0.0,\n",
       " 'KNeighborsRegressor_9': 0.0,\n",
       " 'KNeighborsRegressor_10': -0.03214872234666625,\n",
       " 'KNeighborsRegressor_11': 0.0,\n",
       " 'AdaBoostRegressor': 0.0,\n",
       " 'BaggingRegressor': 0.019764326399999997,\n",
       " 'ExtraTreesRegressor': 0.0,\n",
       " 'GradientBoostingRegressor': 1.4802973661668753e-16,\n",
       " 'HistGradientBoostingRegressor': 0.006733333333333585,\n",
       " 'RandomForestRegressor': 0.0,\n",
       " 'KerasRegressor': 1.0117898359466626}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an ordered dictionary based on the order of models in MLA\n",
    "ordered_average_values = {}\n",
    "final_mlas = []\n",
    "\n",
    "for model_name in MLA_names:        \n",
    "    if model_name in average_values:\n",
    "        ordered_average_values[model_name] = average_values[model_name]\n",
    "    else:\n",
    "        # Handle case where a model might not be in average_values\n",
    "        ordered_average_values[model_name] = None\n",
    "\n",
    "# Now ordered_average_values has the averages in the same order as MLA\n",
    "ordered_average_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.4802973661668728e-16,\n",
       " -0.003333333333333164,\n",
       " 1.4802973661668674e-16,\n",
       " 1.4802973661668714e-16,\n",
       " -0.012669439999999787,\n",
       " 0.0,\n",
       " 1.480297366166869e-16,\n",
       " -0.0033333333333330386,\n",
       " 0.0,\n",
       " 1.4802973661668701e-16,\n",
       " 1.4802973661668682e-16,\n",
       " 1.4802973661668748e-16,\n",
       " 1.480297366166872e-16,\n",
       " 1.4802973661668753e-16,\n",
       " 1.480297366166874e-16,\n",
       " 1.4802973661668694e-16,\n",
       " 1.4802973661668753e-16,\n",
       " 1.4802973661668709e-16,\n",
       " 2.9605947323337403e-16,\n",
       " 0.0,\n",
       " 0.013197333333333531,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.03214872234666625,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.019764326399999997,\n",
       " 0.0,\n",
       " 1.4802973661668753e-16,\n",
       " 0.006733333333333585,\n",
       " 0.0,\n",
       " 1.0117898359466626]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the ordered weights values as a list to be used for final submission\n",
    "hill_climb_final_weights = []\n",
    "\n",
    "for value in ordered_average_values.values():\n",
    "    hill_climb_final_weights.append(value)\n",
    "\n",
    "hill_climb_final_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with MLPRegressor\n",
      "Done with TheilSenRegressor\n",
      "Done with HuberRegressor\n",
      "Done with RANSACRegressor\n",
      "Done with Lasso\n",
      "Done with ElasticNet\n",
      "Done with Lars\n",
      "Done with LassoLars\n",
      "Done with OrthogonalMatchingPursuit\n",
      "Done with BayesianRidge\n",
      "Done with ARDRegression\n",
      "Done with TweedieRegressor\n",
      "Done with PoissonRegressor\n",
      "Done with GammaRegressor\n",
      "Done with LassoLars\n",
      "Done with LinearRegression\n",
      "Done with PassiveAggressiveRegressor\n",
      "Done with RidgeCV\n",
      "Done with DecisionTreeRegressor\n",
      "Done with ExtraTreeRegressor\n",
      "Done with XGBRegressor\n",
      "Done with LGBMRegressor\n",
      "Done with CatBoostRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with AdaBoostRegressor\n",
      "Done with BaggingRegressor\n",
      "Done with ExtraTreesRegressor\n",
      "Done with GradientBoostingRegressor\n",
      "Done with HistGradientBoostingRegressor\n",
      "Done with RandomForestRegressor\n",
      "217/217 [==============================] - 0s 1ms/step\n",
      "Done with KerasRegressor\n",
      "CPU times: total: 36.1 s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_predictions = []\n",
    "# Make predictions on test set\n",
    "for alg in MLA:\n",
    "        MLA_name = alg.__class__.__name__\n",
    "                \n",
    "        predictor = alg.fit(train[num_var], train[TARGET])\n",
    "        pred_result = predictor.predict(test[num_var])\n",
    "\n",
    "        test_predictions.append(pred_result)\n",
    "        print(f'Done with {MLA_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 41)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_predictions), len(hill_climb_final_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_avg_predictions = np.average(test_predictions, axis=0, weights=hill_climb_final_weights)\n",
    "create_submission_file(test['id'], weighted_avg_predictions, f'submission_{experiment}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
