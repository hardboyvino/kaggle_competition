{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import median_absolute_error, make_scorer\n",
    "\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor, GradientBoostingRegressor, RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.linear_model import LogisticRegression, RidgeCV, PassiveAggressiveRegressor, SGDRegressor, Perceptron, LinearRegression, TheilSenRegressor, HuberRegressor, RANSACRegressor, Lasso, ElasticNet, Lars, LassoLars, OrthogonalMatchingPursuit, BayesianRidge, ARDRegression, TweedieRegressor, PoissonRegressor, GammaRegressor, LassoLars\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "experiment = 'add_pre_combined_model'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <th>density_Total</th>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <th>val_e_Average</th>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <th>zaratio_Average</th>\n",
       "      <th>density_Average</th>\n",
       "      <th>Hardness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.841611</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>20.612526</td>\n",
       "      <td>11.08810</td>\n",
       "      <td>2.766</td>\n",
       "      <td>1.732</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.496070</td>\n",
       "      <td>0.91457</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.558488</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>20.298893</td>\n",
       "      <td>12.04083</td>\n",
       "      <td>2.755</td>\n",
       "      <td>1.631</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.492719</td>\n",
       "      <td>0.71760</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>76.0</td>\n",
       "      <td>8.885992</td>\n",
       "      <td>15.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>33.739258</td>\n",
       "      <td>12.08630</td>\n",
       "      <td>2.828</td>\n",
       "      <td>1.788</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.481478</td>\n",
       "      <td>1.50633</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.795296</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>20.213349</td>\n",
       "      <td>10.94850</td>\n",
       "      <td>2.648</td>\n",
       "      <td>1.626</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.489272</td>\n",
       "      <td>0.78937</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>9.577996</td>\n",
       "      <td>11.6</td>\n",
       "      <td>4.8</td>\n",
       "      <td>24.988133</td>\n",
       "      <td>11.82448</td>\n",
       "      <td>2.766</td>\n",
       "      <td>1.682</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.492736</td>\n",
       "      <td>1.86481</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  allelectrons_Total  density_Total  allelectrons_Average  val_e_Average  \\\n",
       "0   0               100.0       0.841611                  10.0            4.8   \n",
       "1   1               100.0       7.558488                  10.0            4.8   \n",
       "2   2                76.0       8.885992                  15.6            5.6   \n",
       "3   3               100.0       8.795296                  10.0            4.8   \n",
       "4   4               116.0       9.577996                  11.6            4.8   \n",
       "\n",
       "   atomicweight_Average  ionenergy_Average  el_neg_chi_Average  \\\n",
       "0             20.612526           11.08810               2.766   \n",
       "1             20.298893           12.04083               2.755   \n",
       "2             33.739258           12.08630               2.828   \n",
       "3             20.213349           10.94850               2.648   \n",
       "4             24.988133           11.82448               2.766   \n",
       "\n",
       "   R_vdw_element_Average  R_cov_element_Average  zaratio_Average  \\\n",
       "0                  1.732                  0.860         0.496070   \n",
       "1                  1.631                  0.910         0.492719   \n",
       "2                  1.788                  0.864         0.481478   \n",
       "3                  1.626                  0.936         0.489272   \n",
       "4                  1.682                  0.896         0.492736   \n",
       "\n",
       "   density_Average  Hardness  \n",
       "0          0.91457       6.0  \n",
       "1          0.71760       6.5  \n",
       "2          1.50633       2.5  \n",
       "3          0.78937       6.0  \n",
       "4          1.86481       6.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "artificial = pd.read_csv('Artificial_Crystals_Dataset.csv')\n",
    "mineral = pd.read_csv('Mineral_Dataset_Supplementary_Info.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hardness</th>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <th>density_Total</th>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <th>val_e_Average</th>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <th>zaratio_Average</th>\n",
       "      <th>density_Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.5</td>\n",
       "      <td>167.0</td>\n",
       "      <td>23.907992</td>\n",
       "      <td>18.555556</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>41.609136</td>\n",
       "      <td>11.693844</td>\n",
       "      <td>2.938889</td>\n",
       "      <td>1.711111</td>\n",
       "      <td>0.884444</td>\n",
       "      <td>0.477830</td>\n",
       "      <td>2.656444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.740168</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>8.773227</td>\n",
       "      <td>11.614333</td>\n",
       "      <td>1.903333</td>\n",
       "      <td>1.310000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.825990</td>\n",
       "      <td>0.580056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.5</td>\n",
       "      <td>102.0</td>\n",
       "      <td>8.511159</td>\n",
       "      <td>4.434783</td>\n",
       "      <td>3.304348</td>\n",
       "      <td>8.440584</td>\n",
       "      <td>13.176622</td>\n",
       "      <td>2.672609</td>\n",
       "      <td>1.379130</td>\n",
       "      <td>0.530870</td>\n",
       "      <td>0.713850</td>\n",
       "      <td>0.370050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.5</td>\n",
       "      <td>78.0</td>\n",
       "      <td>8.109328</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>27.448814</td>\n",
       "      <td>11.826400</td>\n",
       "      <td>2.960000</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.488163</td>\n",
       "      <td>1.351555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.5</td>\n",
       "      <td>164.0</td>\n",
       "      <td>19.921324</td>\n",
       "      <td>14.909091</td>\n",
       "      <td>5.090909</td>\n",
       "      <td>32.012361</td>\n",
       "      <td>11.255573</td>\n",
       "      <td>2.881818</td>\n",
       "      <td>1.640909</td>\n",
       "      <td>0.841818</td>\n",
       "      <td>0.483480</td>\n",
       "      <td>1.811029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hardness  allelectrons_Total  density_Total  allelectrons_Average  \\\n",
       "0       4.5               167.0      23.907992             18.555556   \n",
       "1       4.0                14.0       1.740168              4.666667   \n",
       "2       2.5               102.0       8.511159              4.434783   \n",
       "3       5.5                78.0       8.109328             13.000000   \n",
       "4       6.5               164.0      19.921324             14.909091   \n",
       "\n",
       "   val_e_Average  atomicweight_Average  ionenergy_Average  el_neg_chi_Average  \\\n",
       "0       5.000000             41.609136          11.693844            2.938889   \n",
       "1       1.333333              8.773227          11.614333            1.903333   \n",
       "2       3.304348              8.440584          13.176622            2.672609   \n",
       "3       5.333333             27.448814          11.826400            2.960000   \n",
       "4       5.090909             32.012361          11.255573            2.881818   \n",
       "\n",
       "   R_vdw_element_Average  R_cov_element_Average  zaratio_Average  \\\n",
       "0               1.711111               0.884444         0.477830   \n",
       "1               1.310000               0.680000         0.825990   \n",
       "2               1.379130               0.530870         0.713850   \n",
       "3               1.625000               0.813333         0.488163   \n",
       "4               1.640909               0.841818         0.483480   \n",
       "\n",
       "   density_Average  \n",
       "0         2.656444  \n",
       "1         0.580056  \n",
       "2         0.370050  \n",
       "3         1.351555  \n",
       "4         1.811029  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename hardness in artifical dataset and drop columns not required\n",
    "artificial.rename(columns={'Hardness (Mohs)': 'Hardness'}, inplace=True)\n",
    "artificial.drop(['Formula', 'Crystal structure', 'Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "artificial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hardness</th>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <th>density_Total</th>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <th>val_e_Average</th>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <th>zaratio_Average</th>\n",
       "      <th>density_Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.3</td>\n",
       "      <td>110.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>36.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>82.598467</td>\n",
       "      <td>8.504133</td>\n",
       "      <td>2.146667</td>\n",
       "      <td>2.006667</td>\n",
       "      <td>1.253333</td>\n",
       "      <td>0.456803</td>\n",
       "      <td>7.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.5</td>\n",
       "      <td>406.0</td>\n",
       "      <td>30.472136</td>\n",
       "      <td>9.902439</td>\n",
       "      <td>4.682927</td>\n",
       "      <td>19.813180</td>\n",
       "      <td>11.456151</td>\n",
       "      <td>2.700244</td>\n",
       "      <td>1.676829</td>\n",
       "      <td>0.868293</td>\n",
       "      <td>0.522909</td>\n",
       "      <td>0.743223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.5</td>\n",
       "      <td>406.0</td>\n",
       "      <td>30.472464</td>\n",
       "      <td>10.410256</td>\n",
       "      <td>4.923077</td>\n",
       "      <td>20.931371</td>\n",
       "      <td>11.541405</td>\n",
       "      <td>2.753590</td>\n",
       "      <td>1.703846</td>\n",
       "      <td>0.894359</td>\n",
       "      <td>0.497498</td>\n",
       "      <td>0.781345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.5</td>\n",
       "      <td>476.0</td>\n",
       "      <td>61.142136</td>\n",
       "      <td>11.609756</td>\n",
       "      <td>4.682927</td>\n",
       "      <td>23.659644</td>\n",
       "      <td>11.487395</td>\n",
       "      <td>2.763659</td>\n",
       "      <td>1.714634</td>\n",
       "      <td>0.848780</td>\n",
       "      <td>0.519474</td>\n",
       "      <td>1.491272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.5</td>\n",
       "      <td>476.0</td>\n",
       "      <td>61.142464</td>\n",
       "      <td>12.205128</td>\n",
       "      <td>4.923077</td>\n",
       "      <td>24.975089</td>\n",
       "      <td>11.574251</td>\n",
       "      <td>2.820256</td>\n",
       "      <td>1.743590</td>\n",
       "      <td>0.873846</td>\n",
       "      <td>0.493887</td>\n",
       "      <td>1.567755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hardness  allelectrons_Total  density_Total  allelectrons_Average  \\\n",
       "0       2.3               110.0      23.000000             36.666667   \n",
       "1       5.5               406.0      30.472136              9.902439   \n",
       "2       5.5               406.0      30.472464             10.410256   \n",
       "3       5.5               476.0      61.142136             11.609756   \n",
       "4       5.5               476.0      61.142464             12.205128   \n",
       "\n",
       "   val_e_Average  atomicweight_Average  ionenergy_Average  el_neg_chi_Average  \\\n",
       "0       2.666667             82.598467           8.504133            2.146667   \n",
       "1       4.682927             19.813180          11.456151            2.700244   \n",
       "2       4.923077             20.931371          11.541405            2.753590   \n",
       "3       4.682927             23.659644          11.487395            2.763659   \n",
       "4       4.923077             24.975089          11.574251            2.820256   \n",
       "\n",
       "   R_vdw_element_Average  R_cov_element_Average  zaratio_Average  \\\n",
       "0               2.006667               1.253333         0.456803   \n",
       "1               1.676829               0.868293         0.522909   \n",
       "2               1.703846               0.894359         0.497498   \n",
       "3               1.714634               0.848780         0.519474   \n",
       "4               1.743590               0.873846         0.493887   \n",
       "\n",
       "   density_Average  \n",
       "0         7.666667  \n",
       "1         0.743223  \n",
       "2         0.781345  \n",
       "3         1.491272  \n",
       "4         1.567755  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unneeded columns\n",
    "mineral.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "mineral.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10407, 13), (52, 12), (622, 12))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, artificial.shape, mineral.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.concat([train, artificial, mineral], axis=0)\n",
    "# train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <th>density_Total</th>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <th>val_e_Average</th>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <th>zaratio_Average</th>\n",
       "      <th>density_Average</th>\n",
       "      <th>Hardness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10402</th>\n",
       "      <td>10402</td>\n",
       "      <td>128.0</td>\n",
       "      <td>7.558488</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>26.385218</td>\n",
       "      <td>11.330440</td>\n",
       "      <td>2.644000</td>\n",
       "      <td>1.631000</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.496070</td>\n",
       "      <td>1.79607</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10403</th>\n",
       "      <td>10403</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.743160</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>20.766935</td>\n",
       "      <td>14.163933</td>\n",
       "      <td>3.090000</td>\n",
       "      <td>1.556667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.480390</td>\n",
       "      <td>0.81480</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10404</th>\n",
       "      <td>10404</td>\n",
       "      <td>196.0</td>\n",
       "      <td>30.920000</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>53.490297</td>\n",
       "      <td>10.074300</td>\n",
       "      <td>2.295000</td>\n",
       "      <td>1.545000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>0.469715</td>\n",
       "      <td>2.11540</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10405</th>\n",
       "      <td>10405</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.553160</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>26.621687</td>\n",
       "      <td>11.290033</td>\n",
       "      <td>2.743333</td>\n",
       "      <td>1.756667</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.486507</td>\n",
       "      <td>0.77755</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10406</th>\n",
       "      <td>10406</td>\n",
       "      <td>288.0</td>\n",
       "      <td>24.655328</td>\n",
       "      <td>11.142857</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>22.536126</td>\n",
       "      <td>10.960357</td>\n",
       "      <td>2.792143</td>\n",
       "      <td>1.772857</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.493919</td>\n",
       "      <td>0.97737</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  allelectrons_Total  density_Total  allelectrons_Average  \\\n",
       "10402  10402               128.0       7.558488             12.000000   \n",
       "10403  10403                30.0       1.743160             10.000000   \n",
       "10404  10404               196.0      30.920000             24.500000   \n",
       "10405  10405                38.0       1.553160             12.666667   \n",
       "10406  10406               288.0      24.655328             11.142857   \n",
       "\n",
       "       val_e_Average  atomicweight_Average  ionenergy_Average  \\\n",
       "10402       4.000000             26.385218          11.330440   \n",
       "10403       5.333333             20.766935          14.163933   \n",
       "10404       5.500000             53.490297          10.074300   \n",
       "10405       4.666667             26.621687          11.290033   \n",
       "10406       4.571429             22.536126          10.960357   \n",
       "\n",
       "       el_neg_chi_Average  R_vdw_element_Average  R_cov_element_Average  \\\n",
       "10402            2.644000               1.631000               0.892000   \n",
       "10403            3.090000               1.556667               0.866667   \n",
       "10404            2.295000               1.545000               1.120000   \n",
       "10405            2.743333               1.756667               0.980000   \n",
       "10406            2.792143               1.772857               0.940000   \n",
       "\n",
       "       zaratio_Average  density_Average  Hardness  \n",
       "10402         0.496070          1.79607       4.0  \n",
       "10403         0.480390          0.81480       5.0  \n",
       "10404         0.469715          2.11540       1.8  \n",
       "10405         0.486507          0.77755       6.0  \n",
       "10406         0.493919          0.97737       6.5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>1%</th>\n",
       "      <th>50%</th>\n",
       "      <th>99%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>5203.000000</td>\n",
       "      <td>3004.386460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.060000</td>\n",
       "      <td>5203.000000</td>\n",
       "      <td>10301.940000</td>\n",
       "      <td>10406.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>128.053516</td>\n",
       "      <td>224.123776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>719.400000</td>\n",
       "      <td>15300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density_Total</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>14.491342</td>\n",
       "      <td>15.972877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.739942</td>\n",
       "      <td>10.650000</td>\n",
       "      <td>75.098979</td>\n",
       "      <td>643.093804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>17.033222</td>\n",
       "      <td>10.468734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_e_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>4.546789</td>\n",
       "      <td>0.690864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>37.507703</td>\n",
       "      <td>26.012313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.773227</td>\n",
       "      <td>26.203827</td>\n",
       "      <td>119.629500</td>\n",
       "      <td>167.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>10.938308</td>\n",
       "      <td>1.408276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.054000</td>\n",
       "      <td>11.202760</td>\n",
       "      <td>13.512520</td>\n",
       "      <td>15.245810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>2.607662</td>\n",
       "      <td>0.334906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>2.706000</td>\n",
       "      <td>2.980000</td>\n",
       "      <td>3.443000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>1.731330</td>\n",
       "      <td>0.192481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.318667</td>\n",
       "      <td>1.732727</td>\n",
       "      <td>2.055000</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>0.944132</td>\n",
       "      <td>0.180017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.505333</td>\n",
       "      <td>0.915556</td>\n",
       "      <td>1.390000</td>\n",
       "      <td>1.615840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zaratio_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>0.493349</td>\n",
       "      <td>0.063080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.405373</td>\n",
       "      <td>0.488550</td>\n",
       "      <td>0.707253</td>\n",
       "      <td>0.825990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>2.132984</td>\n",
       "      <td>1.936656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132734</td>\n",
       "      <td>1.351550</td>\n",
       "      <td>7.986670</td>\n",
       "      <td>10.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hardness</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>4.647126</td>\n",
       "      <td>1.680525</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>8.288000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count         mean          std  min          1%  \\\n",
       "id                     10407.0  5203.000000  3004.386460  0.0  104.060000   \n",
       "allelectrons_Total     10407.0   128.053516   224.123776  0.0    6.000000   \n",
       "density_Total          10407.0    14.491342    15.972877  0.0    0.739942   \n",
       "allelectrons_Average   10407.0    17.033222    10.468734  0.0    4.666667   \n",
       "val_e_Average          10407.0     4.546789     0.690864  0.0    2.000000   \n",
       "atomicweight_Average   10407.0    37.507703    26.012313  0.0    8.773227   \n",
       "ionenergy_Average      10407.0    10.938308     1.408276  0.0    8.054000   \n",
       "el_neg_chi_Average     10407.0     2.607662     0.334906  0.0    1.790000   \n",
       "R_vdw_element_Average  10407.0     1.731330     0.192481  0.0    1.318667   \n",
       "R_cov_element_Average  10407.0     0.944132     0.180017  0.0    0.505333   \n",
       "zaratio_Average        10407.0     0.493349     0.063080  0.0    0.405373   \n",
       "density_Average        10407.0     2.132984     1.936656  0.0    0.132734   \n",
       "Hardness               10407.0     4.647126     1.680525  1.0    1.500000   \n",
       "\n",
       "                               50%           99%           max  \n",
       "id                     5203.000000  10301.940000  10406.000000  \n",
       "allelectrons_Total      100.000000    719.400000  15300.000000  \n",
       "density_Total            10.650000     75.098979    643.093804  \n",
       "allelectrons_Average     12.600000     50.000000     67.000000  \n",
       "val_e_Average             4.714286      5.666667      6.000000  \n",
       "atomicweight_Average     26.203827    119.629500    167.400000  \n",
       "ionenergy_Average        11.202760     13.512520     15.245810  \n",
       "el_neg_chi_Average        2.706000      2.980000      3.443000  \n",
       "R_vdw_element_Average     1.732727      2.055000      2.250000  \n",
       "R_cov_element_Average     0.915556      1.390000      1.615840  \n",
       "zaratio_Average           0.488550      0.707253      0.825990  \n",
       "density_Average           1.351550      7.986670     10.970000  \n",
       "Hardness                  5.500000      8.288000     10.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe([0.01, 0.99]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "TARGET = 'Hardness'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['allelectrons_Total', 'density_Total', 'allelectrons_Average',\n",
      "       'val_e_Average', 'atomicweight_Average', 'ionenergy_Average',\n",
      "       'el_neg_chi_Average', 'R_vdw_element_Average', 'R_cov_element_Average',\n",
      "       'zaratio_Average', 'density_Average'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Selecting numerical variables from the train dataset, excluding 'id' and TARGET\n",
    "num_var = train.drop(['id', TARGET], axis=1).select_dtypes(include=np.number).columns\n",
    "print(num_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining train and test datasets for comparative analysis\n",
    "# 'Source' column is added to label data from each dataset\n",
    "df = pd.concat([\n",
    "    train[num_var].assign(Source='Train'), \n",
    "    test[num_var].assign(Source='Test')\n",
    "], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature name: allelectrons_Total\n",
      "Low Limit: -1064.1000000000076\n",
      "Upper Limit: 1789.5000000000127\n",
      "\n",
      "Feature name: density_Total\n",
      "Low Limit: -109.70094011562419\n",
      "Upper Limit: 184.80760706937366\n",
      "\n",
      "Feature name: allelectrons_Average\n",
      "Low Limit: -63.333333333333336\n",
      "Upper Limit: 118.0\n",
      "\n",
      "Feature name: val_e_Average\n",
      "Low Limit: -3.5000000000000018\n",
      "Upper Limit: 11.16666666666667\n",
      "\n",
      "Feature name: atomicweight_Average\n",
      "Low Limit: -157.51118333333332\n",
      "Upper Limit: 285.91391\n",
      "\n",
      "Feature name: ionenergy_Average\n",
      "Low Limit: -0.1337799999999998\n",
      "Upper Limit: 21.7003\n",
      "\n",
      "Feature name: el_neg_chi_Average\n",
      "Low Limit: 0.0050000000000001155\n",
      "Upper Limit: 4.765\n",
      "\n",
      "Feature name: R_vdw_element_Average\n",
      "Low Limit: 0.37229797979797974\n",
      "Upper Limit: 3.0646212121212124\n",
      "\n",
      "Feature name: R_cov_element_Average\n",
      "Low Limit: -0.6014419504643963\n",
      "Upper Limit: 2.5848651702786376\n",
      "\n",
      "Feature name: zaratio_Average\n",
      "Low Limit: 0.005794696969696755\n",
      "Upper Limit: 1.1281555050505054\n",
      "\n",
      "Feature name: density_Average\n",
      "Low Limit: -11.638980000000002\n",
      "Upper Limit: 19.76206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for outliers\n",
    "def outlier_thresholds(dataframe, col_name, q1=0.01, q3=0.99):\n",
    "    quartile1 = dataframe[col_name].quantile(q1)\n",
    "    quartile3 = dataframe[col_name].quantile(q3)\n",
    "    IQR = quartile3 - quartile1\n",
    "    up_limit = quartile3 + 1.5 * IQR\n",
    "    low_limit = quartile1 - 1.5 * IQR\n",
    "    print(f'Feature name: {col_name}')\n",
    "    print(f'Low Limit: {low_limit}')\n",
    "    print(f'Upper Limit: {up_limit}')\n",
    "    print()\n",
    "    return low_limit, up_limit\n",
    "\n",
    "\n",
    "def remove_outlier(dataframe, col_name):\n",
    "    \"\"\"\n",
    "    Example Usage:\n",
    "    for col in num_cols:\n",
    "    new_df = remove_outlier(titanic, col)\n",
    "    \"\"\"\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n",
    "    df_without_outliers = dataframe[~((dataframe[col_name] < low_limit) | (dataframe[col_name] > up_limit))]    \n",
    "    return df_without_outliers\n",
    "\n",
    "def cap_outliers(dataframe, col_name):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n",
    "\n",
    "    dataframe[col_name] = np.where(dataframe[col_name] > up_limit, up_limit, \n",
    "                                   np.where(dataframe[col_name] < low_limit, low_limit, dataframe[col_name]))\n",
    "    return dataframe\n",
    "\n",
    "df_outliers = train.copy()\n",
    "for col in num_var:\n",
    "    df_outliers = remove_outlier(df_outliers, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>1%</th>\n",
       "      <th>50%</th>\n",
       "      <th>99%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>5201.192420</td>\n",
       "      <td>3005.129652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>106.150000</td>\n",
       "      <td>5201.500000</td>\n",
       "      <td>10300.850000</td>\n",
       "      <td>10406.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>124.139079</td>\n",
       "      <td>109.999695</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>622.000000</td>\n",
       "      <td>1266.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density_Total</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>14.469886</td>\n",
       "      <td>14.249258</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.973995</td>\n",
       "      <td>10.803992</td>\n",
       "      <td>73.958979</td>\n",
       "      <td>178.74200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>17.161600</td>\n",
       "      <td>10.400841</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>5.520000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>67.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_e_Average</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>4.578703</td>\n",
       "      <td>0.580486</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>6.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>37.792042</td>\n",
       "      <td>25.897682</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>10.895366</td>\n",
       "      <td>26.203827</td>\n",
       "      <td>119.629500</td>\n",
       "      <td>167.40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>11.017059</td>\n",
       "      <td>1.058323</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>8.213150</td>\n",
       "      <td>11.217767</td>\n",
       "      <td>13.512520</td>\n",
       "      <td>15.24581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>2.625121</td>\n",
       "      <td>0.260140</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>2.706000</td>\n",
       "      <td>2.980000</td>\n",
       "      <td>3.44300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>1.742674</td>\n",
       "      <td>0.131928</td>\n",
       "      <td>1.028000</td>\n",
       "      <td>1.385714</td>\n",
       "      <td>1.733958</td>\n",
       "      <td>2.055000</td>\n",
       "      <td>2.25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>0.951067</td>\n",
       "      <td>0.161130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.612174</td>\n",
       "      <td>0.918000</td>\n",
       "      <td>1.390000</td>\n",
       "      <td>1.61584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zaratio_Average</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>0.496283</td>\n",
       "      <td>0.050363</td>\n",
       "      <td>0.401635</td>\n",
       "      <td>0.426680</td>\n",
       "      <td>0.488550</td>\n",
       "      <td>0.707270</td>\n",
       "      <td>0.82599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density_Average</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>2.146405</td>\n",
       "      <td>1.938989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136410</td>\n",
       "      <td>1.363050</td>\n",
       "      <td>7.986670</td>\n",
       "      <td>10.97000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hardness</th>\n",
       "      <td>10316.0</td>\n",
       "      <td>4.662606</td>\n",
       "      <td>1.671795</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>8.470000</td>\n",
       "      <td>10.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count         mean          std       min  \\\n",
       "id                     10316.0  5201.192420  3005.129652  0.000000   \n",
       "allelectrons_Total     10316.0   124.139079   109.999695  0.001000   \n",
       "density_Total          10316.0    14.469886    14.249258  0.001000   \n",
       "allelectrons_Average   10316.0    17.161600    10.400841  0.001000   \n",
       "val_e_Average          10316.0     4.578703     0.580486  1.333333   \n",
       "atomicweight_Average   10316.0    37.792042    25.897682  0.001000   \n",
       "ionenergy_Average      10316.0    11.017059     1.058323  0.000167   \n",
       "el_neg_chi_Average     10316.0     2.625121     0.260140  1.666667   \n",
       "R_vdw_element_Average  10316.0     1.742674     0.131928  1.028000   \n",
       "R_cov_element_Average  10316.0     0.951067     0.161130  0.000000   \n",
       "zaratio_Average        10316.0     0.496283     0.050363  0.401635   \n",
       "density_Average        10316.0     2.146405     1.938989  0.000000   \n",
       "Hardness               10316.0     4.662606     1.671795  1.000000   \n",
       "\n",
       "                               1%          50%           99%          max  \n",
       "id                     106.150000  5201.500000  10300.850000  10406.00000  \n",
       "allelectrons_Total      20.000000   100.000000    622.000000   1266.00000  \n",
       "density_Total            0.973995    10.803992     73.958979    178.74200  \n",
       "allelectrons_Average     5.520000    12.600000     50.000000     67.00000  \n",
       "val_e_Average            2.666667     4.750000      5.666667      6.00000  \n",
       "atomicweight_Average    10.895366    26.203827    119.629500    167.40000  \n",
       "ionenergy_Average        8.213150    11.217767     13.512520     15.24581  \n",
       "el_neg_chi_Average       1.950000     2.706000      2.980000      3.44300  \n",
       "R_vdw_element_Average    1.385714     1.733958      2.055000      2.25000  \n",
       "R_cov_element_Average    0.612174     0.918000      1.390000      1.61584  \n",
       "zaratio_Average          0.426680     0.488550      0.707270      0.82599  \n",
       "density_Average          0.136410     1.363050      7.986670     10.97000  \n",
       "Hardness                 1.500000     5.500000      8.470000     10.00000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_outliers.describe([0.01, 0.99]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No missing data in the both train and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL CROSS-VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y_true, y_pred):\n",
    "    return tfp.stats.percentile(tf.abs(y_true - y_pred), q=50)\n",
    "\n",
    "def metric_fn(y_true, y_pred):\n",
    "    return tfp.stats.percentile(tf.abs(y_true - y_pred), q=100) - tfp.stats.percentile(tf.abs(y_true - y_pred), q=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefit_models = [\n",
    "\tXGBRegressor(random_state=5),\n",
    "\tLGBMRegressor(n_jobs=-1, random_state=5),\n",
    "\tCatBoostRegressor(random_state=5, verbose=False, early_stopping_rounds=100),\n",
    "\tGradientBoostingRegressor(random_state=5),\n",
    "\tHistGradientBoostingRegressor(random_state=5),\n",
    "    ]\n",
    "\n",
    "train_new = train[num_var].copy()\n",
    "test_new = test[num_var].copy()\n",
    "\n",
    "for model in prefit_models:\n",
    "    model.fit(train[num_var], train[TARGET])\n",
    "    \n",
    "    train_new[f'Hardness_pred_{model.__class__.__name__}'] = model.predict(train[num_var])\n",
    "    test_new[f'Hardness_pred_{model.__class__.__name__}'] = model.predict(test[num_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['allelectrons_Total', 'density_Total', 'allelectrons_Average',\n",
       "       'val_e_Average', 'atomicweight_Average', 'ionenergy_Average',\n",
       "       'el_neg_chi_Average', 'R_vdw_element_Average', 'R_cov_element_Average',\n",
       "       'zaratio_Average', 'density_Average', 'Hardness_pred_XGBRegressor',\n",
       "       'Hardness_pred_LGBMRegressor', 'Hardness_pred_CatBoostRegressor',\n",
       "       'Hardness_pred_GradientBoostingRegressor',\n",
       "       'Hardness_pred_HistGradientBoostingRegressor'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "# Calculate mutual information - this can be memory and CPU intensive\n",
    "mi_scores = mutual_info_regression(train_new, train[TARGET], discrete_features='auto', n_neighbors=3, copy=True, random_state=5)\n",
    "\n",
    "# Make results easier to interpret by placing them in a DataFrame\n",
    "mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=lgbm_features)\n",
    "mi_scores = mi_scores.sort_values(ascending=False)\n",
    "\n",
    "# Now you have the MI scores sorted from the most to the least informative\n",
    "print(mi_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True, mode='min')\n",
    "reduce_LR = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=5, min_lr=0.00001,factor=0.8)\n",
    "terminate = tf.keras.callbacks.TerminateOnNaN()\n",
    "\n",
    "class KerasRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, epochs=100, batch_size=32):\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.InputLayer(input_shape=(len(train_new.columns),)),\n",
    "            tf.keras.layers.BatchNormalization(epsilon=0.00001),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(0.013, beta_1=0.5),\n",
    "                    loss=loss_fn,\n",
    "                      metrics=[metric_fn])\n",
    "        return model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y, epochs=self.epochs, \n",
    "                       batch_size=self.batch_size, \n",
    "                       verbose=0,\n",
    "                    #    class_weight=model_pre.class_weight,\n",
    "                       callbacks=[early_stopping,reduce_LR], \n",
    "                       validation_split=0.1)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLA = [\n",
    "\t# Trial Models\n",
    "\tMLPRegressor(random_state=5),\n",
    "\tTheilSenRegressor(random_state=5),\n",
    "\tHuberRegressor(),\n",
    "\tRANSACRegressor(random_state=5),\n",
    "\tLasso(random_state=5),\n",
    "\tElasticNet(random_state=5),\n",
    "\tLars(random_state=5),\n",
    "\tLassoLars(random_state=5),\n",
    "\tOrthogonalMatchingPursuit(),\n",
    "\tBayesianRidge(),\n",
    "\tARDRegression(),\n",
    "    TweedieRegressor(power=1.5, alpha=0.5),\n",
    "    PoissonRegressor(alpha=0.5),\n",
    "    GammaRegressor(alpha=0.5),\n",
    "    LassoLars(alpha=0.1, random_state=5),\n",
    "\n",
    "\t# GLM\n",
    "\tLinearRegression(),\n",
    "\tPassiveAggressiveRegressor(random_state=5),\n",
    "\tRidgeCV(),\n",
    "\n",
    "\t# Trees    \n",
    "\tDecisionTreeRegressor(random_state=5),\n",
    "\tExtraTreeRegressor(random_state=5),\n",
    "\n",
    "\tXGBRegressor(random_state=5),\n",
    "\tLGBMRegressor(n_jobs=-1, random_state=5),\n",
    "\tCatBoostRegressor(random_state=5, verbose=False, early_stopping_rounds=100),\n",
    "\t\n",
    "\t# KNeighbors\n",
    "\tKNeighborsRegressor(),\n",
    "\tKNeighborsRegressor(n_neighbors=2),\n",
    "\tKNeighborsRegressor(n_neighbors=4),\n",
    "\tKNeighborsRegressor(n_neighbors=8),\n",
    "\tKNeighborsRegressor(n_neighbors=16),\n",
    "\tKNeighborsRegressor(n_neighbors=32),\n",
    "\tKNeighborsRegressor(n_neighbors=64),\n",
    "\tKNeighborsRegressor(n_neighbors=128),\n",
    "\tKNeighborsRegressor(n_neighbors=256),\n",
    "\tKNeighborsRegressor(n_neighbors=512),\n",
    "\tKNeighborsRegressor(n_neighbors=1024),\n",
    "\n",
    "\t# Ensemble Methods\n",
    "\tAdaBoostRegressor(random_state=5),\n",
    "\tBaggingRegressor(random_state=5),\n",
    "\tExtraTreesRegressor(random_state=5),\n",
    "\tGradientBoostingRegressor(random_state=5),\n",
    "\tHistGradientBoostingRegressor(random_state=5),\n",
    "\tRandomForestRegressor(random_state=5),\n",
    "    \n",
    "\t# Neural Networks\n",
    "\tKerasRegressor(epochs=100, batch_size=32),\n",
    "    ]\n",
    "\n",
    "\n",
    "# split dataset in cross-validation with splitter class\n",
    "# cv_split could KFold, StratifiedKFold or RepeatedKFold depending on the problem\n",
    "cv_split = KFold(n_splits=10, shuffle=True, random_state=5)\n",
    "cv_split_trial = KFold(n_splits=3, shuffle=True, random_state=5) # For quick trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with MLPRegressor\n",
      "Done with TheilSenRegressor\n",
      "Done with HuberRegressor\n",
      "Done with RANSACRegressor\n",
      "Done with Lasso\n",
      "Done with ElasticNet\n",
      "Done with Lars\n",
      "Done with LassoLars\n",
      "Done with OrthogonalMatchingPursuit\n",
      "Done with BayesianRidge\n",
      "Done with ARDRegression\n",
      "Done with TweedieRegressor\n",
      "Done with PoissonRegressor\n",
      "Done with GammaRegressor\n",
      "Done with LassoLars_1\n",
      "Done with LinearRegression\n",
      "Done with PassiveAggressiveRegressor\n",
      "Done with RidgeCV\n",
      "Done with DecisionTreeRegressor\n",
      "Done with ExtraTreeRegressor\n",
      "Done with XGBRegressor\n",
      "Done with LGBMRegressor\n",
      "Done with CatBoostRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor_1\n",
      "Done with KNeighborsRegressor_2\n",
      "Done with KNeighborsRegressor_3\n",
      "Done with KNeighborsRegressor_4\n",
      "Done with KNeighborsRegressor_5\n",
      "Done with KNeighborsRegressor_6\n",
      "Done with KNeighborsRegressor_7\n",
      "Done with KNeighborsRegressor_8\n",
      "Done with KNeighborsRegressor_9\n",
      "Done with KNeighborsRegressor_10\n",
      "Done with AdaBoostRegressor\n",
      "Done with BaggingRegressor\n",
      "Done with ExtraTreesRegressor\n",
      "Done with GradientBoostingRegressor\n",
      "Done with HistGradientBoostingRegressor\n",
      "Done with RandomForestRegressor\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "217/217 [==============================] - 1s 2ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "217/217 [==============================] - 1s 2ms/step\n",
      "109/109 [==============================] - 0s 2ms/step\n",
      "217/217 [==============================] - 0s 2ms/step\n",
      "Done with KerasRegressor\n",
      "CPU times: total: 5min 16s\n",
      "Wall time: 6min 1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Parameters</th>\n",
       "      <th>MLA Train Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy 3*STD</th>\n",
       "      <th>MLA Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>KerasRegressor</td>\n",
       "      <td>{'batch_size': 32, 'epochs': 100}</td>\n",
       "      <td>0.257496</td>\n",
       "      <td>0.257698</td>\n",
       "      <td>0.019253</td>\n",
       "      <td>1 min 5.81 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>0.229687</td>\n",
       "      <td>0.293197</td>\n",
       "      <td>0.01947</td>\n",
       "      <td>0 min 0.24 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.293667</td>\n",
       "      <td>0.018547</td>\n",
       "      <td>0 min 8.60 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'criter...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.294333</td>\n",
       "      <td>0.008602</td>\n",
       "      <td>0 min 3.78 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>{'categorical_features': None, 'early_stopping...</td>\n",
       "      <td>0.228666</td>\n",
       "      <td>0.294641</td>\n",
       "      <td>0.018626</td>\n",
       "      <td>0 min 1.47 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>{'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': ...</td>\n",
       "      <td>0.278159</td>\n",
       "      <td>0.298761</td>\n",
       "      <td>0.015698</td>\n",
       "      <td>0 min 3.09 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CatBoostRegressor</td>\n",
       "      <td>{'loss_function': 'RMSE', 'verbose': False, 'r...</td>\n",
       "      <td>0.213651</td>\n",
       "      <td>0.302564</td>\n",
       "      <td>0.011096</td>\n",
       "      <td>0 min 8.18 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>{'objective': 'reg:squarederror', 'base_score'...</td>\n",
       "      <td>0.133869</td>\n",
       "      <td>0.318166</td>\n",
       "      <td>0.011974</td>\n",
       "      <td>0 min 1.07 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 min 0.82 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HuberRegressor</td>\n",
       "      <td>{'alpha': 0.0001, 'epsilon': 1.35, 'fit_interc...</td>\n",
       "      <td>0.330403</td>\n",
       "      <td>0.331217</td>\n",
       "      <td>0.011043</td>\n",
       "      <td>0 min 0.52 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ARDRegression</td>\n",
       "      <td>{'alpha_1': 1e-06, 'alpha_2': 1e-06, 'compute_...</td>\n",
       "      <td>0.333288</td>\n",
       "      <td>0.334235</td>\n",
       "      <td>0.005975</td>\n",
       "      <td>0 min 0.04 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>{'alpha_per_target': False, 'alphas': (0.1, 1....</td>\n",
       "      <td>0.334761</td>\n",
       "      <td>0.335091</td>\n",
       "      <td>0.00383</td>\n",
       "      <td>0 min 0.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lars</td>\n",
       "      <td>{'copy_X': True, 'eps': 2.220446049250313e-16,...</td>\n",
       "      <td>0.335926</td>\n",
       "      <td>0.335223</td>\n",
       "      <td>0.005021</td>\n",
       "      <td>0 min 0.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>{'copy_X': True, 'fit_intercept': True, 'n_job...</td>\n",
       "      <td>0.335926</td>\n",
       "      <td>0.335223</td>\n",
       "      <td>0.005021</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BayesianRidge</td>\n",
       "      <td>{'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_in...</td>\n",
       "      <td>0.335399</td>\n",
       "      <td>0.335285</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0 min 0.11 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TheilSenRegressor</td>\n",
       "      <td>{'copy_X': True, 'fit_intercept': True, 'max_i...</td>\n",
       "      <td>0.345387</td>\n",
       "      <td>0.343398</td>\n",
       "      <td>0.001662</td>\n",
       "      <td>0 min 4.73 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OrthogonalMatchingPursuit</td>\n",
       "      <td>{'fit_intercept': True, 'n_nonzero_coefs': Non...</td>\n",
       "      <td>0.345889</td>\n",
       "      <td>0.345583</td>\n",
       "      <td>0.020883</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PoissonRegressor</td>\n",
       "      <td>{'alpha': 0.5, 'fit_intercept': True, 'max_ite...</td>\n",
       "      <td>0.456932</td>\n",
       "      <td>0.455524</td>\n",
       "      <td>0.018788</td>\n",
       "      <td>0 min 0.13 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RANSACRegressor</td>\n",
       "      <td>{'base_estimator': 'deprecated', 'estimator': ...</td>\n",
       "      <td>0.47803</td>\n",
       "      <td>0.484311</td>\n",
       "      <td>0.011797</td>\n",
       "      <td>0 min 0.33 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'squared_error...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 min 0.21 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ExtraTreeRegressor</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'squared_error...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 min 0.06 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'batch...</td>\n",
       "      <td>0.491798</td>\n",
       "      <td>0.503121</td>\n",
       "      <td>0.305627</td>\n",
       "      <td>0 min 1.45 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>KNeighborsRegressor_1</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.070711</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>KNeighborsRegressor_2</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>{'base_estimator': None, 'learning_rate': 1.0,...</td>\n",
       "      <td>0.577211</td>\n",
       "      <td>0.578138</td>\n",
       "      <td>0.094826</td>\n",
       "      <td>0 min 1.14 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.586667</td>\n",
       "      <td>0.028284</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>KNeighborsRegressor_3</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.5125</td>\n",
       "      <td>0.5875</td>\n",
       "      <td>0.061237</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>KNeighborsRegressor_4</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.585417</td>\n",
       "      <td>0.63125</td>\n",
       "      <td>0.026517</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>{'alpha': 1.0, 'copy_X': True, 'fit_intercept'...</td>\n",
       "      <td>0.636088</td>\n",
       "      <td>0.636938</td>\n",
       "      <td>0.027541</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>KNeighborsRegressor_5</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.673438</td>\n",
       "      <td>0.033146</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>KNeighborsRegressor_6</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.732292</td>\n",
       "      <td>0.754167</td>\n",
       "      <td>0.075616</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>{'alpha': 1.0, 'copy_X': True, 'fit_intercept'...</td>\n",
       "      <td>0.757595</td>\n",
       "      <td>0.758067</td>\n",
       "      <td>0.038329</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>KNeighborsRegressor_7</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.847526</td>\n",
       "      <td>0.854063</td>\n",
       "      <td>0.091463</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PassiveAggressiveRegressor</td>\n",
       "      <td>{'C': 1.0, 'average': False, 'early_stopping':...</td>\n",
       "      <td>0.868307</td>\n",
       "      <td>0.860489</td>\n",
       "      <td>0.656984</td>\n",
       "      <td>0 min 0.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>KNeighborsRegressor_8</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.931712</td>\n",
       "      <td>0.931901</td>\n",
       "      <td>0.055035</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>KNeighborsRegressor_9</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>1.011214</td>\n",
       "      <td>1.015234</td>\n",
       "      <td>0.073735</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>KNeighborsRegressor_10</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>1.102043</td>\n",
       "      <td>1.107617</td>\n",
       "      <td>0.072542</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LassoLars</td>\n",
       "      <td>{'alpha': 1.0, 'copy_X': True, 'eps': 2.220446...</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>0.022821</td>\n",
       "      <td>0 min 0.02 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LassoLars_1</td>\n",
       "      <td>{'alpha': 0.1, 'copy_X': True, 'eps': 2.220446...</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>0.022821</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GammaRegressor</td>\n",
       "      <td>{'alpha': 0.5, 'fit_intercept': True, 'max_ite...</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>0.022821</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TweedieRegressor</td>\n",
       "      <td>{'alpha': 0.5, 'fit_intercept': True, 'link': ...</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>0.022821</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         MLA Name  \\\n",
       "40                 KerasRegressor   \n",
       "21                  LGBMRegressor   \n",
       "39          RandomForestRegressor   \n",
       "36            ExtraTreesRegressor   \n",
       "38  HistGradientBoostingRegressor   \n",
       "37      GradientBoostingRegressor   \n",
       "22              CatBoostRegressor   \n",
       "20                   XGBRegressor   \n",
       "35               BaggingRegressor   \n",
       "2                  HuberRegressor   \n",
       "10                  ARDRegression   \n",
       "17                        RidgeCV   \n",
       "6                            Lars   \n",
       "15               LinearRegression   \n",
       "9                   BayesianRidge   \n",
       "1               TheilSenRegressor   \n",
       "8       OrthogonalMatchingPursuit   \n",
       "12               PoissonRegressor   \n",
       "3                 RANSACRegressor   \n",
       "18          DecisionTreeRegressor   \n",
       "19             ExtraTreeRegressor   \n",
       "0                    MLPRegressor   \n",
       "24          KNeighborsRegressor_1   \n",
       "25          KNeighborsRegressor_2   \n",
       "34              AdaBoostRegressor   \n",
       "23            KNeighborsRegressor   \n",
       "26          KNeighborsRegressor_3   \n",
       "27          KNeighborsRegressor_4   \n",
       "5                      ElasticNet   \n",
       "28          KNeighborsRegressor_5   \n",
       "29          KNeighborsRegressor_6   \n",
       "4                           Lasso   \n",
       "30          KNeighborsRegressor_7   \n",
       "16     PassiveAggressiveRegressor   \n",
       "31          KNeighborsRegressor_8   \n",
       "32          KNeighborsRegressor_9   \n",
       "33         KNeighborsRegressor_10   \n",
       "7                       LassoLars   \n",
       "14                    LassoLars_1   \n",
       "13                 GammaRegressor   \n",
       "11               TweedieRegressor   \n",
       "\n",
       "                                       MLA Parameters MLA Train Accuracy Mean  \\\n",
       "40                  {'batch_size': 32, 'epochs': 100}                0.257496   \n",
       "21  {'boosting_type': 'gbdt', 'class_weight': None...                0.229687   \n",
       "39  {'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...                   0.108   \n",
       "36  {'bootstrap': False, 'ccp_alpha': 0.0, 'criter...                    -0.0   \n",
       "38  {'categorical_features': None, 'early_stopping...                0.228666   \n",
       "37  {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': ...                0.278159   \n",
       "22  {'loss_function': 'RMSE', 'verbose': False, 'r...                0.213651   \n",
       "20  {'objective': 'reg:squarederror', 'base_score'...                0.133869   \n",
       "35  {'base_estimator': None, 'bootstrap': True, 'b...                0.116667   \n",
       "2   {'alpha': 0.0001, 'epsilon': 1.35, 'fit_interc...                0.330403   \n",
       "10  {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'compute_...                0.333288   \n",
       "17  {'alpha_per_target': False, 'alphas': (0.1, 1....                0.334761   \n",
       "6   {'copy_X': True, 'eps': 2.220446049250313e-16,...                0.335926   \n",
       "15  {'copy_X': True, 'fit_intercept': True, 'n_job...                0.335926   \n",
       "9   {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_in...                0.335399   \n",
       "1   {'copy_X': True, 'fit_intercept': True, 'max_i...                0.345387   \n",
       "8   {'fit_intercept': True, 'n_nonzero_coefs': Non...                0.345889   \n",
       "12  {'alpha': 0.5, 'fit_intercept': True, 'max_ite...                0.456932   \n",
       "3   {'base_estimator': 'deprecated', 'estimator': ...                 0.47803   \n",
       "18  {'ccp_alpha': 0.0, 'criterion': 'squared_error...                    -0.0   \n",
       "19  {'ccp_alpha': 0.0, 'criterion': 'squared_error...                    -0.0   \n",
       "0   {'activation': 'relu', 'alpha': 0.0001, 'batch...                0.491798   \n",
       "24  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                    0.25   \n",
       "25  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                0.433333   \n",
       "34  {'base_estimator': None, 'learning_rate': 1.0,...                0.577211   \n",
       "23  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                    0.46   \n",
       "26  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                  0.5125   \n",
       "27  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                0.585417   \n",
       "5   {'alpha': 1.0, 'copy_X': True, 'fit_intercept'...                0.636088   \n",
       "28  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                0.645833   \n",
       "29  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                0.732292   \n",
       "4   {'alpha': 1.0, 'copy_X': True, 'fit_intercept'...                0.757595   \n",
       "30  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                0.847526   \n",
       "16  {'C': 1.0, 'average': False, 'early_stopping':...                0.868307   \n",
       "31  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                0.931712   \n",
       "32  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                1.011214   \n",
       "33  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                1.102043   \n",
       "7   {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446...                1.352874   \n",
       "14  {'alpha': 0.1, 'copy_X': True, 'eps': 2.220446...                1.352874   \n",
       "13  {'alpha': 0.5, 'fit_intercept': True, 'max_ite...                1.352874   \n",
       "11  {'alpha': 0.5, 'fit_intercept': True, 'link': ...                1.352874   \n",
       "\n",
       "   MLA Test Accuracy Mean MLA Test Accuracy 3*STD        MLA Time  \n",
       "40               0.257698                0.019253  1 min 5.81 sec  \n",
       "21               0.293197                 0.01947  0 min 0.24 sec  \n",
       "39               0.293667                0.018547  0 min 8.60 sec  \n",
       "36               0.294333                0.008602  0 min 3.78 sec  \n",
       "38               0.294641                0.018626  0 min 1.47 sec  \n",
       "37               0.298761                0.015698  0 min 3.09 sec  \n",
       "22               0.302564                0.011096  0 min 8.18 sec  \n",
       "20               0.318166                0.011974  0 min 1.07 sec  \n",
       "35                   0.32                     0.0  0 min 0.82 sec  \n",
       "2                0.331217                0.011043  0 min 0.52 sec  \n",
       "10               0.334235                0.005975  0 min 0.04 sec  \n",
       "17               0.335091                 0.00383  0 min 0.02 sec  \n",
       "6                0.335223                0.005021  0 min 0.02 sec  \n",
       "15               0.335223                0.005021  0 min 0.01 sec  \n",
       "9                0.335285                0.003515  0 min 0.11 sec  \n",
       "1                0.343398                0.001662  0 min 4.73 sec  \n",
       "8                0.345583                0.020883  0 min 0.01 sec  \n",
       "12               0.455524                0.018788  0 min 0.13 sec  \n",
       "3                0.484311                0.011797  0 min 0.33 sec  \n",
       "18                    0.5                     0.0  0 min 0.21 sec  \n",
       "19                    0.5                     0.0  0 min 0.06 sec  \n",
       "0                0.503121                0.305627  0 min 1.45 sec  \n",
       "24               0.566667                0.070711  0 min 0.01 sec  \n",
       "25                  0.575                     0.0  0 min 0.01 sec  \n",
       "34               0.578138                0.094826  0 min 1.14 sec  \n",
       "23               0.586667                0.028284  0 min 0.01 sec  \n",
       "26                 0.5875                0.061237  0 min 0.01 sec  \n",
       "27                0.63125                0.026517  0 min 0.01 sec  \n",
       "5                0.636938                0.027541  0 min 0.01 sec  \n",
       "28               0.673438                0.033146  0 min 0.01 sec  \n",
       "29               0.754167                0.075616  0 min 0.01 sec  \n",
       "4                0.758067                0.038329  0 min 0.01 sec  \n",
       "30               0.854063                0.091463  0 min 0.01 sec  \n",
       "16               0.860489                0.656984  0 min 0.02 sec  \n",
       "31               0.931901                0.055035  0 min 0.01 sec  \n",
       "32               1.015234                0.073735  0 min 0.01 sec  \n",
       "33               1.107617                0.072542  0 min 0.01 sec  \n",
       "7                1.352874                0.022821  0 min 0.02 sec  \n",
       "14               1.352874                0.022821  0 min 0.01 sec  \n",
       "13               1.352874                0.022821  0 min 0.01 sec  \n",
       "11               1.352874                0.022821  0 min 0.01 sec  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# create table to compare MLA metrics\n",
    "MLA_columns = ['MLA Name', 'MLA Parameters', 'MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD', 'MLA Time']\n",
    "MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "\n",
    "# create table to compare MLA predictions\n",
    "MLA_predict = {}\n",
    "\n",
    "# index through MLA and save performance to table\n",
    "row_index = 0\n",
    "scoring = median_abs_error_scorer = make_scorer(median_absolute_error, greater_is_better=False)\n",
    "\n",
    "for alg in MLA:\n",
    "\n",
    "\t# set name and parameters\n",
    "\tMLA_name = alg.__class__.__name__\n",
    "\n",
    "\t# Add suffix if name already exists\n",
    "\tsuffix = 1\n",
    "\toriginal_MLA_name = MLA_name\n",
    "\twhile MLA_compare['MLA Name'].str.contains(MLA_name).any():\n",
    "\t\tMLA_name = f\"{original_MLA_name}_{suffix}\"\n",
    "\t\tsuffix += 1\n",
    "\t\t\n",
    "\tMLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
    "\tMLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
    "\n",
    "\t\"\"\"score model with cross validation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\"\"\"\n",
    "\n",
    "\tcv_results = cross_validate(alg, train_new, train[TARGET], cv=cv_split_trial, scoring=scoring, return_train_score=True)\n",
    "\n",
    "\t# Calculate mean time in seconds\n",
    "\tmean_fit_time = cv_results['fit_time'].mean()\n",
    "\n",
    "\t# Convert mean time to minutes and seconds\n",
    "\tminutes = int(mean_fit_time // 60)\n",
    "\tseconds = mean_fit_time % 60\n",
    "\n",
    "\t# Format the time and assign it\n",
    "\tMLA_compare.loc[row_index, 'MLA Time'] = f\"{minutes} min {seconds:.2f} sec\"\n",
    "\tMLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean() * -1\n",
    "\tMLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean() * -1\n",
    "\t#if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\n",
    "\tMLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   #let's know the worst that can happen!\n",
    "\n",
    "\t# # #save MLA predictions - see section 6 for usage\n",
    "\t# alg.fit(data1[data1_x_bin], data1[Target])\n",
    "\t# MLA_predict[MLA_name] = alg.predict(data1[data1_x_bin])\n",
    "\tprint(f'Done with {MLA_name}')\n",
    "\trow_index+=1\n",
    "\n",
    "\n",
    "#print and sort table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html\n",
    "MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = True, inplace = True)\n",
    "MLA_compare.to_csv(f'{experiment}_results.csv', index=False)\n",
    "MLA_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Algorithm')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n",
    "\n",
    "#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\n",
    "plt.title('Machine Learning Algorithm Accuracy Score \\n')\n",
    "plt.xlabel('Accuracy Score (%)')\n",
    "plt.ylabel('Algorithm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENSEMBLE CROSS-VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hill Climbing inspired by code from Kaggle\n",
    "def hill_climbing(x, y):\n",
    "    \n",
    "    # Evaluating oof predictions\n",
    "    scores = {}\n",
    "    for col in x.columns:\n",
    "        scores[col] = median_absolute_error(y, x[col])\n",
    "\n",
    "    # Sorting the model scores in ascending order\n",
    "    scores = {k: v for k, v in sorted(scores.items(), key = lambda item: item[1], reverse = False)}\n",
    "\n",
    "    # Sort oof_df\n",
    "    x = x[list(scores.keys())]\n",
    "\n",
    "    # Initialize weights\n",
    "    weights = {col: 1 if i == 0 else 0 for i, col in enumerate(x.columns)}\n",
    "\n",
    "    STOP = False\n",
    "    current_best_ensemble = x.iloc[:,0]\n",
    "    MODELS = x.iloc[:,1:]\n",
    "    weight_range = np.arange(-0.5, 0.51, 0.01) \n",
    "    history = [median_absolute_error(y, current_best_ensemble)]\n",
    "    j = 0\n",
    "\n",
    "    while not STOP:\n",
    "        j += 1\n",
    "        potential_new_best_cv_score = median_absolute_error(y, current_best_ensemble)\n",
    "        k_best, wgt_best = None, None\n",
    "        for k in MODELS:\n",
    "            for wgt in weight_range:\n",
    "                potential_ensemble = (1 - wgt) * current_best_ensemble + wgt * MODELS[k]\n",
    "                cv_score = median_absolute_error(y, potential_ensemble)\n",
    "                if cv_score < potential_new_best_cv_score:\n",
    "                    potential_new_best_cv_score = cv_score\n",
    "                    k_best, wgt_best = k, wgt\n",
    "\n",
    "        if k_best is not None:\n",
    "            # Update weights\n",
    "            weights = {col: (1 - wgt_best) * weights[col] if col != k_best else wgt_best for col in weights}\n",
    "            current_best_ensemble = (1 - wgt_best) * current_best_ensemble + wgt_best * MODELS[k_best]\n",
    "            MODELS.drop(k_best, axis = 1, inplace = True)\n",
    "            if MODELS.shape[1] == 0:\n",
    "                STOP = True\n",
    "            history.append(potential_new_best_cv_score)\n",
    "        else:\n",
    "            STOP = True\n",
    "        \n",
    "    hill_ens_pred = current_best_ensemble\n",
    "    \n",
    "    return hill_ens_pred, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission_file(ids, predictions, filename):\n",
    "    submission = pd.DataFrame({'id': ids, 'Hardness': predictions})\n",
    "    submission.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "217/217 [==============================] - 1s 2ms/step\n",
      "109/109 [==============================] - 0s 2ms/step\n",
      "The Fold 1 Keras score is 0.2932853698730469\n",
      "The Fold 1 Hill Climb is 0.27033436327301885\n",
      "The Fold 1 weight is {'KerasRegressor': 1.0603819511999972, 'RandomForestRegressor': 0.0, 'ExtraTreesRegressor': 0.0, 'HistGradientBoostingRegressor': 0.0, 'LGBMRegressor': 0.0, 'CatBoostRegressor': 0.0, 'GradientBoostingRegressor': 0.0, 'XGBRegressor': 0.010000000000000448, 'BaggingRegressor': 0.0, 'HuberRegressor': 0.0, 'RidgeCV': 0.0, 'ARDRegression': 0.0, 'BayesianRidge': -0.02969702999999953, 'Lars': 0.0, 'LinearRegression': 0.0, 'TheilSenRegressor': 0.0, 'OrthogonalMatchingPursuit': 0.0, 'PoissonRegressor': 0.0, 'RANSACRegressor': 0.0, 'DecisionTreeRegressor': 0.0, 'ExtraTreeRegressor': 0.0, 'KNeighborsRegressor_2': 0.0, 'KNeighborsRegressor_3': 0.0, 'KNeighborsRegressor': -0.00989999999999956, 'MLPRegressor': 0.0, 'AdaBoostRegressor': 0.0, 'KNeighborsRegressor_4': 0.0, 'KNeighborsRegressor_5': 0.0, 'ElasticNet': 0.0, 'KNeighborsRegressor_6': 0.0, 'Lasso': 0.0, 'KNeighborsRegressor_7': 0.0, 'PassiveAggressiveRegressor': 4.440892098500626e-16, 'KNeighborsRegressor_8': 0.0, 'KNeighborsRegressor_9': 0.0, 'KNeighborsRegressor_10': 0.0, 'KNeighborsRegressor_11': 0.009999000000000438, 'LassoLars': -0.04078392119999949, 'TweedieRegressor': 0.0, 'GammaRegressor': 0.0, 'LassoLars_1': 0.0}\n",
      "\n",
      "Fold 2\n",
      "217/217 [==============================] - 1s 4ms/step\n",
      "109/109 [==============================] - 0s 3ms/step\n",
      "The Fold 2 Keras score is 0.25146007537841797\n",
      "The Fold 2 Hill Climb is 0.2514600753784153\n",
      "The Fold 2 weight is {'KerasRegressor': 0.9999999999999996, 'ExtraTreesRegressor': 4.440892098500626e-16, 'LGBMRegressor': 0.0, 'RandomForestRegressor': 0.0, 'GradientBoostingRegressor': 0.0, 'HistGradientBoostingRegressor': 0.0, 'CatBoostRegressor': 0.0, 'BaggingRegressor': 0.0, 'XGBRegressor': 0.0, 'HuberRegressor': 0.0, 'ARDRegression': 0.0, 'Lars': 0.0, 'LinearRegression': 0.0, 'RidgeCV': 0.0, 'BayesianRidge': 0.0, 'OrthogonalMatchingPursuit': 0.0, 'TheilSenRegressor': 0.0, 'MLPRegressor': 0.0, 'PoissonRegressor': 0.0, 'RANSACRegressor': 0.0, 'DecisionTreeRegressor': 0.0, 'ExtraTreeRegressor': 0.0, 'AdaBoostRegressor': 0.0, 'KNeighborsRegressor_2': 0.0, 'KNeighborsRegressor_4': 0.0, 'KNeighborsRegressor_3': 0.0, 'PassiveAggressiveRegressor': 0.0, 'KNeighborsRegressor': 0.0, 'KNeighborsRegressor_5': 0.0, 'ElasticNet': 0.0, 'KNeighborsRegressor_6': 0.0, 'Lasso': 0.0, 'KNeighborsRegressor_7': 0.0, 'KNeighborsRegressor_8': 0.0, 'KNeighborsRegressor_9': 0.0, 'KNeighborsRegressor_10': 0.0, 'KNeighborsRegressor_11': 0.0, 'LassoLars': 0.0, 'LassoLars_1': 0.0, 'TweedieRegressor': 0.0, 'GammaRegressor': 0.0}\n",
      "\n",
      "Fold 3\n",
      "217/217 [==============================] - 0s 2ms/step\n",
      "109/109 [==============================] - 0s 2ms/step\n",
      "The Fold 3 Keras score is 0.25032615661621094\n",
      "The Fold 3 Hill Climb is 0.2503261566162083\n",
      "The Fold 3 weight is {'KerasRegressor': 0.9999999999999996, 'LGBMRegressor': 4.440892098500626e-16, 'RandomForestRegressor': 0.0, 'HistGradientBoostingRegressor': 0.0, 'ExtraTreesRegressor': 0.0, 'GradientBoostingRegressor': 0.0, 'CatBoostRegressor': 0.0, 'XGBRegressor': 0.0, 'BaggingRegressor': 0.0, 'HuberRegressor': 0.0, 'ARDRegression': 0.0, 'LinearRegression': 0.0, 'Lars': 0.0, 'RidgeCV': 0.0, 'BayesianRidge': 0.0, 'TheilSenRegressor': 0.0, 'OrthogonalMatchingPursuit': 0.0, 'PoissonRegressor': 0.0, 'RANSACRegressor': 0.0, 'DecisionTreeRegressor': 0.0, 'ExtraTreeRegressor': 0.0, 'MLPRegressor': 0.0, 'KNeighborsRegressor_3': 0.0, 'KNeighborsRegressor': 0.0, 'KNeighborsRegressor_4': 0.0, 'AdaBoostRegressor': 0.0, 'KNeighborsRegressor_2': 0.0, 'KNeighborsRegressor_5': 0.0, 'ElasticNet': 0.0, 'KNeighborsRegressor_6': 0.0, 'KNeighborsRegressor_7': 0.0, 'Lasso': 0.0, 'KNeighborsRegressor_8': 0.0, 'KNeighborsRegressor_9': 0.0, 'KNeighborsRegressor_10': 0.0, 'KNeighborsRegressor_11': 0.0, 'PassiveAggressiveRegressor': 0.0, 'LassoLars': 0.0, 'TweedieRegressor': 0.0, 'GammaRegressor': 0.0, 'LassoLars_1': 0.0}\n",
      "\n",
      "\n",
      "The Hill Climbing CV score is ==> 0.2573735317558808\n",
      "The Hill Climbing weights are ==> [{'KerasRegressor': 1.0603819511999972, 'RandomForestRegressor': 0.0, 'ExtraTreesRegressor': 0.0, 'HistGradientBoostingRegressor': 0.0, 'LGBMRegressor': 0.0, 'CatBoostRegressor': 0.0, 'GradientBoostingRegressor': 0.0, 'XGBRegressor': 0.010000000000000448, 'BaggingRegressor': 0.0, 'HuberRegressor': 0.0, 'RidgeCV': 0.0, 'ARDRegression': 0.0, 'BayesianRidge': -0.02969702999999953, 'Lars': 0.0, 'LinearRegression': 0.0, 'TheilSenRegressor': 0.0, 'OrthogonalMatchingPursuit': 0.0, 'PoissonRegressor': 0.0, 'RANSACRegressor': 0.0, 'DecisionTreeRegressor': 0.0, 'ExtraTreeRegressor': 0.0, 'KNeighborsRegressor_2': 0.0, 'KNeighborsRegressor_3': 0.0, 'KNeighborsRegressor': -0.00989999999999956, 'MLPRegressor': 0.0, 'AdaBoostRegressor': 0.0, 'KNeighborsRegressor_4': 0.0, 'KNeighborsRegressor_5': 0.0, 'ElasticNet': 0.0, 'KNeighborsRegressor_6': 0.0, 'Lasso': 0.0, 'KNeighborsRegressor_7': 0.0, 'PassiveAggressiveRegressor': 4.440892098500626e-16, 'KNeighborsRegressor_8': 0.0, 'KNeighborsRegressor_9': 0.0, 'KNeighborsRegressor_10': 0.0, 'KNeighborsRegressor_11': 0.009999000000000438, 'LassoLars': -0.04078392119999949, 'TweedieRegressor': 0.0, 'GammaRegressor': 0.0, 'LassoLars_1': 0.0}, {'KerasRegressor': 0.9999999999999996, 'ExtraTreesRegressor': 4.440892098500626e-16, 'LGBMRegressor': 0.0, 'RandomForestRegressor': 0.0, 'GradientBoostingRegressor': 0.0, 'HistGradientBoostingRegressor': 0.0, 'CatBoostRegressor': 0.0, 'BaggingRegressor': 0.0, 'XGBRegressor': 0.0, 'HuberRegressor': 0.0, 'ARDRegression': 0.0, 'Lars': 0.0, 'LinearRegression': 0.0, 'RidgeCV': 0.0, 'BayesianRidge': 0.0, 'OrthogonalMatchingPursuit': 0.0, 'TheilSenRegressor': 0.0, 'MLPRegressor': 0.0, 'PoissonRegressor': 0.0, 'RANSACRegressor': 0.0, 'DecisionTreeRegressor': 0.0, 'ExtraTreeRegressor': 0.0, 'AdaBoostRegressor': 0.0, 'KNeighborsRegressor_2': 0.0, 'KNeighborsRegressor_4': 0.0, 'KNeighborsRegressor_3': 0.0, 'PassiveAggressiveRegressor': 0.0, 'KNeighborsRegressor': 0.0, 'KNeighborsRegressor_5': 0.0, 'ElasticNet': 0.0, 'KNeighborsRegressor_6': 0.0, 'Lasso': 0.0, 'KNeighborsRegressor_7': 0.0, 'KNeighborsRegressor_8': 0.0, 'KNeighborsRegressor_9': 0.0, 'KNeighborsRegressor_10': 0.0, 'KNeighborsRegressor_11': 0.0, 'LassoLars': 0.0, 'LassoLars_1': 0.0, 'TweedieRegressor': 0.0, 'GammaRegressor': 0.0}, {'KerasRegressor': 0.9999999999999996, 'LGBMRegressor': 4.440892098500626e-16, 'RandomForestRegressor': 0.0, 'HistGradientBoostingRegressor': 0.0, 'ExtraTreesRegressor': 0.0, 'GradientBoostingRegressor': 0.0, 'CatBoostRegressor': 0.0, 'XGBRegressor': 0.0, 'BaggingRegressor': 0.0, 'HuberRegressor': 0.0, 'ARDRegression': 0.0, 'LinearRegression': 0.0, 'Lars': 0.0, 'RidgeCV': 0.0, 'BayesianRidge': 0.0, 'TheilSenRegressor': 0.0, 'OrthogonalMatchingPursuit': 0.0, 'PoissonRegressor': 0.0, 'RANSACRegressor': 0.0, 'DecisionTreeRegressor': 0.0, 'ExtraTreeRegressor': 0.0, 'MLPRegressor': 0.0, 'KNeighborsRegressor_3': 0.0, 'KNeighborsRegressor': 0.0, 'KNeighborsRegressor_4': 0.0, 'AdaBoostRegressor': 0.0, 'KNeighborsRegressor_2': 0.0, 'KNeighborsRegressor_5': 0.0, 'ElasticNet': 0.0, 'KNeighborsRegressor_6': 0.0, 'KNeighborsRegressor_7': 0.0, 'Lasso': 0.0, 'KNeighborsRegressor_8': 0.0, 'KNeighborsRegressor_9': 0.0, 'KNeighborsRegressor_10': 0.0, 'KNeighborsRegressor_11': 0.0, 'PassiveAggressiveRegressor': 0.0, 'LassoLars': 0.0, 'TweedieRegressor': 0.0, 'GammaRegressor': 0.0, 'LassoLars_1': 0.0}]\n",
      "CPU times: total: 5min 20s\n",
      "Wall time: 5min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "avg_predictions_scores = []\n",
    "optuna_weights_scores = []\n",
    "hill_climb_scores = []\n",
    "stacked_scores = []\n",
    "optuna_weights_scores_stack = []\n",
    "hill_climb_weights = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(cv_split_trial.split(train_new, train[TARGET])):\n",
    "    X_train, X_test = train_new.iloc[train_index], train_new.iloc[test_index]\n",
    "    y_train, y_test = train[TARGET].iloc[train_index], train[TARGET].iloc[test_index]\n",
    "\n",
    "    print(f'Fold {i+1}')\n",
    "    \n",
    "    MLA_cv_train_preds = []\n",
    "    MLA_cv_preds = []\n",
    "    MLA_cv_preds_dict = {}\n",
    "    MLA_names = []\n",
    "    \n",
    "    suffix = 1\n",
    "    for alg in MLA:\n",
    "        MLA_name = alg.__class__.__name__\n",
    "\n",
    "        # Add suffix if name already exists\n",
    "\n",
    "        original_MLA_name = MLA_name\n",
    "        if MLA_name in MLA_names:\n",
    "        # while MLA_cv_preds.str.contains(MLA_name).any():\n",
    "            MLA_name = f\"{original_MLA_name}_{suffix}\"\n",
    "            suffix += 1\n",
    "            \n",
    "        predictor = alg.fit(X_train, y_train)\n",
    "        pred_train_result = predictor.predict(X_train)\n",
    "        pred_result = predictor.predict(X_test)\n",
    "\n",
    "        # I want to know the CV scores for the Keras\n",
    "        # Try understand why the CV score and public score is not correlatiing\n",
    "        if original_MLA_name == 'KerasRegressor':\n",
    "            keras_score = median_absolute_error(y_test, pred_result)\n",
    "            print(f'The Fold {i+1} Keras score is {keras_score}')\n",
    "\n",
    "        MLA_cv_train_preds.append(pred_train_result)\n",
    "        MLA_cv_preds.append(pred_result)\n",
    "        MLA_cv_preds_dict[MLA_name] = pred_result\n",
    "        MLA_names.append(MLA_name)\n",
    "\n",
    "    ##################\n",
    "    ### Hill Climb ###\n",
    "    ##################\n",
    "    hill_climb_pred, hill_climb_weight = hill_climbing(pd.DataFrame(MLA_cv_preds_dict), y_test)\n",
    "    hill_climb_score = median_absolute_error(y_test, hill_climb_pred)\n",
    "    hill_climb_scores.append(hill_climb_score)\n",
    "    hill_climb_weights.append(hill_climb_weight)\n",
    "    print(f'The Fold {i+1} Hill Climb is {hill_climb_score}')\n",
    "    print(f'The Fold {i+1} weight is {hill_climb_weight}')\n",
    "    print()\n",
    "\n",
    "print()\n",
    "print(f'The Hill Climbing CV score is ==> {np.mean(hill_climb_scores)}')\n",
    "print(f'The Hill Climbing weights are ==> {hill_climb_weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'KerasRegressor': 1.0201273170666654,\n",
       "  'RandomForestRegressor': 0.0,\n",
       "  'ExtraTreesRegressor': 1.4802973661668753e-16,\n",
       "  'HistGradientBoostingRegressor': 0.0,\n",
       "  'LGBMRegressor': 1.4802973661668753e-16,\n",
       "  'CatBoostRegressor': 0.0,\n",
       "  'GradientBoostingRegressor': 0.0,\n",
       "  'XGBRegressor': 0.0033333333333334827,\n",
       "  'BaggingRegressor': 0.0,\n",
       "  'HuberRegressor': 0.0,\n",
       "  'RidgeCV': 0.0,\n",
       "  'ARDRegression': 0.0,\n",
       "  'BayesianRidge': -0.009899009999999844,\n",
       "  'Lars': 0.0,\n",
       "  'LinearRegression': 0.0,\n",
       "  'TheilSenRegressor': 0.0,\n",
       "  'OrthogonalMatchingPursuit': 0.0,\n",
       "  'PoissonRegressor': 0.0,\n",
       "  'RANSACRegressor': 0.0,\n",
       "  'DecisionTreeRegressor': 0.0,\n",
       "  'ExtraTreeRegressor': 0.0,\n",
       "  'KNeighborsRegressor_2': 0.0,\n",
       "  'KNeighborsRegressor_3': 0.0,\n",
       "  'KNeighborsRegressor': -0.0032999999999998534,\n",
       "  'MLPRegressor': 0.0,\n",
       "  'AdaBoostRegressor': 0.0,\n",
       "  'KNeighborsRegressor_4': 0.0,\n",
       "  'KNeighborsRegressor_5': 0.0,\n",
       "  'ElasticNet': 0.0,\n",
       "  'KNeighborsRegressor_6': 0.0,\n",
       "  'Lasso': 0.0,\n",
       "  'KNeighborsRegressor_7': 0.0,\n",
       "  'PassiveAggressiveRegressor': 1.4802973661668753e-16,\n",
       "  'KNeighborsRegressor_8': 0.0,\n",
       "  'KNeighborsRegressor_9': 0.0,\n",
       "  'KNeighborsRegressor_10': 0.0,\n",
       "  'KNeighborsRegressor_11': 0.003333000000000146,\n",
       "  'LassoLars': -0.01359464039999983,\n",
       "  'TweedieRegressor': 0.0,\n",
       "  'GammaRegressor': 0.0,\n",
       "  'LassoLars_1': 0.0},\n",
       " 1.0000000000000002,\n",
       " 41)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get average weights for the models from all the folds\n",
    "\n",
    "average_values = {}\n",
    "\n",
    "for model in hill_climb_weights:\n",
    "    for key, value in model.items():\n",
    "        if key in average_values:\n",
    "            average_values[key] += value\n",
    "        else:\n",
    "            average_values[key] = value\n",
    "\n",
    "num_models = len(hill_climb_weights)\n",
    "average_values = {k: v / num_models for k, v in average_values.items()}\n",
    "\n",
    "# Ensure the new weights sum up to 1\n",
    "sum = 0\n",
    "\n",
    "for k, v in average_values.items():\n",
    "    sum += v\n",
    "\n",
    "average_values, sum, len(average_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MLPRegressor': 0.0,\n",
       " 'TheilSenRegressor': 0.0,\n",
       " 'HuberRegressor': 0.0,\n",
       " 'RANSACRegressor': 0.0,\n",
       " 'Lasso': 0.0,\n",
       " 'ElasticNet': 0.0,\n",
       " 'Lars': 0.0,\n",
       " 'LassoLars': -0.01359464039999983,\n",
       " 'OrthogonalMatchingPursuit': 0.0,\n",
       " 'BayesianRidge': -0.009899009999999844,\n",
       " 'ARDRegression': 0.0,\n",
       " 'TweedieRegressor': 0.0,\n",
       " 'PoissonRegressor': 0.0,\n",
       " 'GammaRegressor': 0.0,\n",
       " 'LassoLars_1': 0.0,\n",
       " 'LinearRegression': 0.0,\n",
       " 'PassiveAggressiveRegressor': 1.4802973661668753e-16,\n",
       " 'RidgeCV': 0.0,\n",
       " 'DecisionTreeRegressor': 0.0,\n",
       " 'ExtraTreeRegressor': 0.0,\n",
       " 'XGBRegressor': 0.0033333333333334827,\n",
       " 'LGBMRegressor': 1.4802973661668753e-16,\n",
       " 'CatBoostRegressor': 0.0,\n",
       " 'KNeighborsRegressor': -0.0032999999999998534,\n",
       " 'KNeighborsRegressor_2': 0.0,\n",
       " 'KNeighborsRegressor_3': 0.0,\n",
       " 'KNeighborsRegressor_4': 0.0,\n",
       " 'KNeighborsRegressor_5': 0.0,\n",
       " 'KNeighborsRegressor_6': 0.0,\n",
       " 'KNeighborsRegressor_7': 0.0,\n",
       " 'KNeighborsRegressor_8': 0.0,\n",
       " 'KNeighborsRegressor_9': 0.0,\n",
       " 'KNeighborsRegressor_10': 0.0,\n",
       " 'KNeighborsRegressor_11': 0.003333000000000146,\n",
       " 'AdaBoostRegressor': 0.0,\n",
       " 'BaggingRegressor': 0.0,\n",
       " 'ExtraTreesRegressor': 1.4802973661668753e-16,\n",
       " 'GradientBoostingRegressor': 0.0,\n",
       " 'HistGradientBoostingRegressor': 0.0,\n",
       " 'RandomForestRegressor': 0.0,\n",
       " 'KerasRegressor': 1.0201273170666654}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an ordered dictionary based on the order of models in MLA\n",
    "ordered_average_values = {}\n",
    "final_mlas = []\n",
    "\n",
    "for model_name in MLA_names:        \n",
    "    if model_name in average_values:\n",
    "        ordered_average_values[model_name] = average_values[model_name]\n",
    "    else:\n",
    "        # Handle case where a model might not be in average_values\n",
    "        ordered_average_values[model_name] = None\n",
    "\n",
    "# Now ordered_average_values has the averages in the same order as MLA\n",
    "ordered_average_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.01359464039999983,\n",
       " 0.0,\n",
       " -0.009899009999999844,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.4802973661668753e-16,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0033333333333334827,\n",
       " 1.4802973661668753e-16,\n",
       " 0.0,\n",
       " -0.0032999999999998534,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.003333000000000146,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.4802973661668753e-16,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0201273170666654]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the ordered weights values as a list to be used for final submission\n",
    "hill_climb_final_weights = []\n",
    "\n",
    "for value in ordered_average_values.values():\n",
    "    hill_climb_final_weights.append(value)\n",
    "\n",
    "hill_climb_final_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with MLPRegressor\n",
      "Done with TheilSenRegressor\n",
      "Done with HuberRegressor\n",
      "Done with RANSACRegressor\n",
      "Done with Lasso\n",
      "Done with ElasticNet\n",
      "Done with Lars\n",
      "Done with LassoLars\n",
      "Done with OrthogonalMatchingPursuit\n",
      "Done with BayesianRidge\n",
      "Done with ARDRegression\n",
      "Done with TweedieRegressor\n",
      "Done with PoissonRegressor\n",
      "Done with GammaRegressor\n",
      "Done with LassoLars\n",
      "Done with LinearRegression\n",
      "Done with PassiveAggressiveRegressor\n",
      "Done with RidgeCV\n",
      "Done with DecisionTreeRegressor\n",
      "Done with ExtraTreeRegressor\n",
      "Done with XGBRegressor\n",
      "Done with LGBMRegressor\n",
      "Done with CatBoostRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with AdaBoostRegressor\n",
      "Done with BaggingRegressor\n",
      "Done with ExtraTreesRegressor\n",
      "Done with GradientBoostingRegressor\n",
      "Done with HistGradientBoostingRegressor\n",
      "Done with RandomForestRegressor\n",
      "217/217 [==============================] - 1s 4ms/step\n",
      "Done with KerasRegressor\n",
      "CPU times: total: 1min 54s\n",
      "Wall time: 1min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_predictions = []\n",
    "# Make predictions on test set\n",
    "for alg in MLA:\n",
    "        MLA_name = alg.__class__.__name__\n",
    "                \n",
    "        predictor = alg.fit(train_new, train[TARGET])\n",
    "        pred_result = predictor.predict(test_new)\n",
    "\n",
    "        test_predictions.append(pred_result)\n",
    "        print(f'Done with {MLA_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 41)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check that the weights and predictions are the same length\n",
    "len(test_predictions), len(hill_climb_final_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_avg_predictions = np.average(test_predictions, axis=0, weights=hill_climb_final_weights)\n",
    "create_submission_file(test['id'], weighted_avg_predictions, f'submission_{experiment}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get NeuralNetwork only submission\n",
    "predictor = KerasRegressor(epochs=100, batch_size=32).fit(train_new, train[TARGET])\n",
    "predictions = predictor.predict(test_new)\n",
    "create_submission_file(test['id'], predictions, f'submission_keras_model.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
