{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adeniyi Babalola\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import median_absolute_error, make_scorer\n",
    "\n",
    "import optuna\n",
    "# Set the Optuna logger to output only warnings or higher level messages\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "experiment = 'baseline_with_neural_net_cv3'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <th>density_Total</th>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <th>val_e_Average</th>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <th>zaratio_Average</th>\n",
       "      <th>density_Average</th>\n",
       "      <th>Hardness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.841611</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>20.612526</td>\n",
       "      <td>11.08810</td>\n",
       "      <td>2.766</td>\n",
       "      <td>1.732</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.496070</td>\n",
       "      <td>0.91457</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.558488</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>20.298893</td>\n",
       "      <td>12.04083</td>\n",
       "      <td>2.755</td>\n",
       "      <td>1.631</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.492719</td>\n",
       "      <td>0.71760</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>76.0</td>\n",
       "      <td>8.885992</td>\n",
       "      <td>15.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>33.739258</td>\n",
       "      <td>12.08630</td>\n",
       "      <td>2.828</td>\n",
       "      <td>1.788</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.481478</td>\n",
       "      <td>1.50633</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.795296</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>20.213349</td>\n",
       "      <td>10.94850</td>\n",
       "      <td>2.648</td>\n",
       "      <td>1.626</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.489272</td>\n",
       "      <td>0.78937</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>9.577996</td>\n",
       "      <td>11.6</td>\n",
       "      <td>4.8</td>\n",
       "      <td>24.988133</td>\n",
       "      <td>11.82448</td>\n",
       "      <td>2.766</td>\n",
       "      <td>1.682</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.492736</td>\n",
       "      <td>1.86481</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  allelectrons_Total  density_Total  allelectrons_Average  val_e_Average  \\\n",
       "0   0               100.0       0.841611                  10.0            4.8   \n",
       "1   1               100.0       7.558488                  10.0            4.8   \n",
       "2   2                76.0       8.885992                  15.6            5.6   \n",
       "3   3               100.0       8.795296                  10.0            4.8   \n",
       "4   4               116.0       9.577996                  11.6            4.8   \n",
       "\n",
       "   atomicweight_Average  ionenergy_Average  el_neg_chi_Average  \\\n",
       "0             20.612526           11.08810               2.766   \n",
       "1             20.298893           12.04083               2.755   \n",
       "2             33.739258           12.08630               2.828   \n",
       "3             20.213349           10.94850               2.648   \n",
       "4             24.988133           11.82448               2.766   \n",
       "\n",
       "   R_vdw_element_Average  R_cov_element_Average  zaratio_Average  \\\n",
       "0                  1.732                  0.860         0.496070   \n",
       "1                  1.631                  0.910         0.492719   \n",
       "2                  1.788                  0.864         0.481478   \n",
       "3                  1.626                  0.936         0.489272   \n",
       "4                  1.682                  0.896         0.492736   \n",
       "\n",
       "   density_Average  Hardness  \n",
       "0          0.91457       6.0  \n",
       "1          0.71760       6.5  \n",
       "2          1.50633       2.5  \n",
       "3          0.78937       6.0  \n",
       "4          1.86481       6.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "artificial = pd.read_csv('Artificial_Crystals_Dataset.csv')\n",
    "mineral = pd.read_csv('Mineral_Dataset_Supplementary_Info.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hardness</th>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <th>density_Total</th>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <th>val_e_Average</th>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <th>zaratio_Average</th>\n",
       "      <th>density_Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.5</td>\n",
       "      <td>167.0</td>\n",
       "      <td>23.907992</td>\n",
       "      <td>18.555556</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>41.609136</td>\n",
       "      <td>11.693844</td>\n",
       "      <td>2.938889</td>\n",
       "      <td>1.711111</td>\n",
       "      <td>0.884444</td>\n",
       "      <td>0.477830</td>\n",
       "      <td>2.656444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.740168</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>8.773227</td>\n",
       "      <td>11.614333</td>\n",
       "      <td>1.903333</td>\n",
       "      <td>1.310000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.825990</td>\n",
       "      <td>0.580056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.5</td>\n",
       "      <td>102.0</td>\n",
       "      <td>8.511159</td>\n",
       "      <td>4.434783</td>\n",
       "      <td>3.304348</td>\n",
       "      <td>8.440584</td>\n",
       "      <td>13.176622</td>\n",
       "      <td>2.672609</td>\n",
       "      <td>1.379130</td>\n",
       "      <td>0.530870</td>\n",
       "      <td>0.713850</td>\n",
       "      <td>0.370050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.5</td>\n",
       "      <td>78.0</td>\n",
       "      <td>8.109328</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>27.448814</td>\n",
       "      <td>11.826400</td>\n",
       "      <td>2.960000</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.488163</td>\n",
       "      <td>1.351555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.5</td>\n",
       "      <td>164.0</td>\n",
       "      <td>19.921324</td>\n",
       "      <td>14.909091</td>\n",
       "      <td>5.090909</td>\n",
       "      <td>32.012361</td>\n",
       "      <td>11.255573</td>\n",
       "      <td>2.881818</td>\n",
       "      <td>1.640909</td>\n",
       "      <td>0.841818</td>\n",
       "      <td>0.483480</td>\n",
       "      <td>1.811029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hardness  allelectrons_Total  density_Total  allelectrons_Average  \\\n",
       "0       4.5               167.0      23.907992             18.555556   \n",
       "1       4.0                14.0       1.740168              4.666667   \n",
       "2       2.5               102.0       8.511159              4.434783   \n",
       "3       5.5                78.0       8.109328             13.000000   \n",
       "4       6.5               164.0      19.921324             14.909091   \n",
       "\n",
       "   val_e_Average  atomicweight_Average  ionenergy_Average  el_neg_chi_Average  \\\n",
       "0       5.000000             41.609136          11.693844            2.938889   \n",
       "1       1.333333              8.773227          11.614333            1.903333   \n",
       "2       3.304348              8.440584          13.176622            2.672609   \n",
       "3       5.333333             27.448814          11.826400            2.960000   \n",
       "4       5.090909             32.012361          11.255573            2.881818   \n",
       "\n",
       "   R_vdw_element_Average  R_cov_element_Average  zaratio_Average  \\\n",
       "0               1.711111               0.884444         0.477830   \n",
       "1               1.310000               0.680000         0.825990   \n",
       "2               1.379130               0.530870         0.713850   \n",
       "3               1.625000               0.813333         0.488163   \n",
       "4               1.640909               0.841818         0.483480   \n",
       "\n",
       "   density_Average  \n",
       "0         2.656444  \n",
       "1         0.580056  \n",
       "2         0.370050  \n",
       "3         1.351555  \n",
       "4         1.811029  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename hardness in artifical dataset and drop columns not required\n",
    "artificial.rename(columns={'Hardness (Mohs)': 'Hardness'}, inplace=True)\n",
    "artificial.drop(['Formula', 'Crystal structure', 'Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "artificial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hardness</th>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <th>density_Total</th>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <th>val_e_Average</th>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <th>zaratio_Average</th>\n",
       "      <th>density_Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.3</td>\n",
       "      <td>110.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>36.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>82.598467</td>\n",
       "      <td>8.504133</td>\n",
       "      <td>2.146667</td>\n",
       "      <td>2.006667</td>\n",
       "      <td>1.253333</td>\n",
       "      <td>0.456803</td>\n",
       "      <td>7.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.5</td>\n",
       "      <td>406.0</td>\n",
       "      <td>30.472136</td>\n",
       "      <td>9.902439</td>\n",
       "      <td>4.682927</td>\n",
       "      <td>19.813180</td>\n",
       "      <td>11.456151</td>\n",
       "      <td>2.700244</td>\n",
       "      <td>1.676829</td>\n",
       "      <td>0.868293</td>\n",
       "      <td>0.522909</td>\n",
       "      <td>0.743223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.5</td>\n",
       "      <td>406.0</td>\n",
       "      <td>30.472464</td>\n",
       "      <td>10.410256</td>\n",
       "      <td>4.923077</td>\n",
       "      <td>20.931371</td>\n",
       "      <td>11.541405</td>\n",
       "      <td>2.753590</td>\n",
       "      <td>1.703846</td>\n",
       "      <td>0.894359</td>\n",
       "      <td>0.497498</td>\n",
       "      <td>0.781345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.5</td>\n",
       "      <td>476.0</td>\n",
       "      <td>61.142136</td>\n",
       "      <td>11.609756</td>\n",
       "      <td>4.682927</td>\n",
       "      <td>23.659644</td>\n",
       "      <td>11.487395</td>\n",
       "      <td>2.763659</td>\n",
       "      <td>1.714634</td>\n",
       "      <td>0.848780</td>\n",
       "      <td>0.519474</td>\n",
       "      <td>1.491272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.5</td>\n",
       "      <td>476.0</td>\n",
       "      <td>61.142464</td>\n",
       "      <td>12.205128</td>\n",
       "      <td>4.923077</td>\n",
       "      <td>24.975089</td>\n",
       "      <td>11.574251</td>\n",
       "      <td>2.820256</td>\n",
       "      <td>1.743590</td>\n",
       "      <td>0.873846</td>\n",
       "      <td>0.493887</td>\n",
       "      <td>1.567755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hardness  allelectrons_Total  density_Total  allelectrons_Average  \\\n",
       "0       2.3               110.0      23.000000             36.666667   \n",
       "1       5.5               406.0      30.472136              9.902439   \n",
       "2       5.5               406.0      30.472464             10.410256   \n",
       "3       5.5               476.0      61.142136             11.609756   \n",
       "4       5.5               476.0      61.142464             12.205128   \n",
       "\n",
       "   val_e_Average  atomicweight_Average  ionenergy_Average  el_neg_chi_Average  \\\n",
       "0       2.666667             82.598467           8.504133            2.146667   \n",
       "1       4.682927             19.813180          11.456151            2.700244   \n",
       "2       4.923077             20.931371          11.541405            2.753590   \n",
       "3       4.682927             23.659644          11.487395            2.763659   \n",
       "4       4.923077             24.975089          11.574251            2.820256   \n",
       "\n",
       "   R_vdw_element_Average  R_cov_element_Average  zaratio_Average  \\\n",
       "0               2.006667               1.253333         0.456803   \n",
       "1               1.676829               0.868293         0.522909   \n",
       "2               1.703846               0.894359         0.497498   \n",
       "3               1.714634               0.848780         0.519474   \n",
       "4               1.743590               0.873846         0.493887   \n",
       "\n",
       "   density_Average  \n",
       "0         7.666667  \n",
       "1         0.743223  \n",
       "2         0.781345  \n",
       "3         1.491272  \n",
       "4         1.567755  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unneeded columns\n",
    "mineral.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "mineral.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10407, 13), (52, 12), (622, 12))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, artificial.shape, mineral.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.concat([train, artificial, mineral], axis=0)\n",
    "# train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <th>density_Total</th>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <th>val_e_Average</th>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <th>zaratio_Average</th>\n",
       "      <th>density_Average</th>\n",
       "      <th>Hardness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10402</th>\n",
       "      <td>10402</td>\n",
       "      <td>128.0</td>\n",
       "      <td>7.558488</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>26.385218</td>\n",
       "      <td>11.330440</td>\n",
       "      <td>2.644000</td>\n",
       "      <td>1.631000</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.496070</td>\n",
       "      <td>1.79607</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10403</th>\n",
       "      <td>10403</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.743160</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>20.766935</td>\n",
       "      <td>14.163933</td>\n",
       "      <td>3.090000</td>\n",
       "      <td>1.556667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.480390</td>\n",
       "      <td>0.81480</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10404</th>\n",
       "      <td>10404</td>\n",
       "      <td>196.0</td>\n",
       "      <td>30.920000</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>53.490297</td>\n",
       "      <td>10.074300</td>\n",
       "      <td>2.295000</td>\n",
       "      <td>1.545000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>0.469715</td>\n",
       "      <td>2.11540</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10405</th>\n",
       "      <td>10405</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.553160</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>26.621687</td>\n",
       "      <td>11.290033</td>\n",
       "      <td>2.743333</td>\n",
       "      <td>1.756667</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.486507</td>\n",
       "      <td>0.77755</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10406</th>\n",
       "      <td>10406</td>\n",
       "      <td>288.0</td>\n",
       "      <td>24.655328</td>\n",
       "      <td>11.142857</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>22.536126</td>\n",
       "      <td>10.960357</td>\n",
       "      <td>2.792143</td>\n",
       "      <td>1.772857</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.493919</td>\n",
       "      <td>0.97737</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  allelectrons_Total  density_Total  allelectrons_Average  \\\n",
       "10402  10402               128.0       7.558488             12.000000   \n",
       "10403  10403                30.0       1.743160             10.000000   \n",
       "10404  10404               196.0      30.920000             24.500000   \n",
       "10405  10405                38.0       1.553160             12.666667   \n",
       "10406  10406               288.0      24.655328             11.142857   \n",
       "\n",
       "       val_e_Average  atomicweight_Average  ionenergy_Average  \\\n",
       "10402       4.000000             26.385218          11.330440   \n",
       "10403       5.333333             20.766935          14.163933   \n",
       "10404       5.500000             53.490297          10.074300   \n",
       "10405       4.666667             26.621687          11.290033   \n",
       "10406       4.571429             22.536126          10.960357   \n",
       "\n",
       "       el_neg_chi_Average  R_vdw_element_Average  R_cov_element_Average  \\\n",
       "10402            2.644000               1.631000               0.892000   \n",
       "10403            3.090000               1.556667               0.866667   \n",
       "10404            2.295000               1.545000               1.120000   \n",
       "10405            2.743333               1.756667               0.980000   \n",
       "10406            2.792143               1.772857               0.940000   \n",
       "\n",
       "       zaratio_Average  density_Average  Hardness  \n",
       "10402         0.496070          1.79607       4.0  \n",
       "10403         0.480390          0.81480       5.0  \n",
       "10404         0.469715          2.11540       1.8  \n",
       "10405         0.486507          0.77755       6.0  \n",
       "10406         0.493919          0.97737       6.5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>1%</th>\n",
       "      <th>50%</th>\n",
       "      <th>99%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>5203.000000</td>\n",
       "      <td>3004.386460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.060000</td>\n",
       "      <td>5203.000000</td>\n",
       "      <td>10301.940000</td>\n",
       "      <td>10406.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>128.053516</td>\n",
       "      <td>224.123776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>719.400000</td>\n",
       "      <td>15300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density_Total</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>14.491342</td>\n",
       "      <td>15.972877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.739942</td>\n",
       "      <td>10.650000</td>\n",
       "      <td>75.098979</td>\n",
       "      <td>643.093804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>17.033222</td>\n",
       "      <td>10.468734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_e_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>4.546789</td>\n",
       "      <td>0.690864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>37.507703</td>\n",
       "      <td>26.012313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.773227</td>\n",
       "      <td>26.203827</td>\n",
       "      <td>119.629500</td>\n",
       "      <td>167.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>10.938308</td>\n",
       "      <td>1.408276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.054000</td>\n",
       "      <td>11.202760</td>\n",
       "      <td>13.512520</td>\n",
       "      <td>15.245810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>2.607662</td>\n",
       "      <td>0.334906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>2.706000</td>\n",
       "      <td>2.980000</td>\n",
       "      <td>3.443000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>1.731330</td>\n",
       "      <td>0.192481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.318667</td>\n",
       "      <td>1.732727</td>\n",
       "      <td>2.055000</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>0.944132</td>\n",
       "      <td>0.180017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.505333</td>\n",
       "      <td>0.915556</td>\n",
       "      <td>1.390000</td>\n",
       "      <td>1.615840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zaratio_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>0.493349</td>\n",
       "      <td>0.063080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.405373</td>\n",
       "      <td>0.488550</td>\n",
       "      <td>0.707253</td>\n",
       "      <td>0.825990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>2.132984</td>\n",
       "      <td>1.936656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132734</td>\n",
       "      <td>1.351550</td>\n",
       "      <td>7.986670</td>\n",
       "      <td>10.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hardness</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>4.647126</td>\n",
       "      <td>1.680525</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>8.288000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count         mean          std  min          1%  \\\n",
       "id                     10407.0  5203.000000  3004.386460  0.0  104.060000   \n",
       "allelectrons_Total     10407.0   128.053516   224.123776  0.0    6.000000   \n",
       "density_Total          10407.0    14.491342    15.972877  0.0    0.739942   \n",
       "allelectrons_Average   10407.0    17.033222    10.468734  0.0    4.666667   \n",
       "val_e_Average          10407.0     4.546789     0.690864  0.0    2.000000   \n",
       "atomicweight_Average   10407.0    37.507703    26.012313  0.0    8.773227   \n",
       "ionenergy_Average      10407.0    10.938308     1.408276  0.0    8.054000   \n",
       "el_neg_chi_Average     10407.0     2.607662     0.334906  0.0    1.790000   \n",
       "R_vdw_element_Average  10407.0     1.731330     0.192481  0.0    1.318667   \n",
       "R_cov_element_Average  10407.0     0.944132     0.180017  0.0    0.505333   \n",
       "zaratio_Average        10407.0     0.493349     0.063080  0.0    0.405373   \n",
       "density_Average        10407.0     2.132984     1.936656  0.0    0.132734   \n",
       "Hardness               10407.0     4.647126     1.680525  1.0    1.500000   \n",
       "\n",
       "                               50%           99%           max  \n",
       "id                     5203.000000  10301.940000  10406.000000  \n",
       "allelectrons_Total      100.000000    719.400000  15300.000000  \n",
       "density_Total            10.650000     75.098979    643.093804  \n",
       "allelectrons_Average     12.600000     50.000000     67.000000  \n",
       "val_e_Average             4.714286      5.666667      6.000000  \n",
       "atomicweight_Average     26.203827    119.629500    167.400000  \n",
       "ionenergy_Average        11.202760     13.512520     15.245810  \n",
       "el_neg_chi_Average        2.706000      2.980000      3.443000  \n",
       "R_vdw_element_Average     1.732727      2.055000      2.250000  \n",
       "R_cov_element_Average     0.915556      1.390000      1.615840  \n",
       "zaratio_Average           0.488550      0.707253      0.825990  \n",
       "density_Average           1.351550      7.986670     10.970000  \n",
       "Hardness                  5.500000      8.288000     10.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe([0.01, 0.99]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "TARGET = 'Hardness'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['allelectrons_Total', 'density_Total', 'allelectrons_Average',\n",
      "       'val_e_Average', 'atomicweight_Average', 'ionenergy_Average',\n",
      "       'el_neg_chi_Average', 'R_vdw_element_Average', 'R_cov_element_Average',\n",
      "       'zaratio_Average', 'density_Average'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Selecting numerical variables from the train dataset, excluding 'id' and TARGET\n",
    "num_var = train.drop(['id', TARGET], axis=1).select_dtypes(include=np.number).columns\n",
    "print(num_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining train and test datasets for comparative analysis\n",
    "# 'Source' column is added to label data from each dataset\n",
    "df = pd.concat([\n",
    "    train[num_var].assign(Source='Train'), \n",
    "    test[num_var].assign(Source='Test')\n",
    "], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature name: allelectrons_Total\n",
      "Low Limit: -1064.1000000000076\n",
      "Upper Limit: 1789.5000000000127\n",
      "\n",
      "Feature name: density_Total\n",
      "Low Limit: -110.79861331237501\n",
      "Upper Limit: 186.637534387425\n",
      "\n",
      "Feature name: allelectrons_Average\n",
      "Low Limit: -63.333333333333336\n",
      "Upper Limit: 118.0\n",
      "\n",
      "Feature name: val_e_Average\n",
      "Low Limit: -3.5000000000000018\n",
      "Upper Limit: 11.16666666666667\n",
      "\n",
      "Feature name: atomicweight_Average\n",
      "Low Limit: -157.51118333333332\n",
      "Upper Limit: 285.91391\n",
      "\n",
      "Feature name: ionenergy_Average\n",
      "Low Limit: -0.1337799999999998\n",
      "Upper Limit: 21.7003\n",
      "\n",
      "Feature name: el_neg_chi_Average\n",
      "Low Limit: 0.0050000000000001155\n",
      "Upper Limit: 4.765\n",
      "\n",
      "Feature name: R_vdw_element_Average\n",
      "Low Limit: 0.21416666666666706\n",
      "Upper Limit: 3.1595\n",
      "\n",
      "Feature name: R_cov_element_Average\n",
      "Low Limit: -0.8216666666666667\n",
      "Upper Limit: 2.7169999999999996\n",
      "\n",
      "Feature name: zaratio_Average\n",
      "Low Limit: -0.047446360606061166\n",
      "Upper Limit: 1.160072823232324\n",
      "\n",
      "Feature name: density_Average\n",
      "Low Limit: -11.648170499999999\n",
      "Upper Limit: 19.7675743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for outliers\n",
    "def outlier_thresholds(dataframe, col_name, q1=0.01, q3=0.99):\n",
    "    quartile1 = dataframe[col_name].quantile(q1)\n",
    "    quartile3 = dataframe[col_name].quantile(q3)\n",
    "    IQR = quartile3 - quartile1\n",
    "    up_limit = quartile3 + 1.5 * IQR\n",
    "    low_limit = quartile1 - 1.5 * IQR\n",
    "    print(f'Feature name: {col_name}')\n",
    "    print(f'Low Limit: {low_limit}')\n",
    "    print(f'Upper Limit: {up_limit}')\n",
    "    print()\n",
    "    return low_limit, up_limit\n",
    "\n",
    "\n",
    "def remove_outlier(dataframe, col_name):\n",
    "    \"\"\"\n",
    "    Example Usage:\n",
    "    for col in num_cols:\n",
    "    new_df = remove_outlier(titanic, col)\n",
    "    \"\"\"\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n",
    "    df_without_outliers = dataframe[~((dataframe[col_name] < low_limit) | (dataframe[col_name] > up_limit))]    \n",
    "    return df_without_outliers\n",
    "\n",
    "def cap_outliers(dataframe, col_name):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n",
    "\n",
    "    dataframe[col_name] = np.where(dataframe[col_name] > up_limit, up_limit, \n",
    "                                   np.where(dataframe[col_name] < low_limit, low_limit, dataframe[col_name]))\n",
    "    return dataframe\n",
    "\n",
    "df_capped = train.copy()\n",
    "for col in num_var:\n",
    "    df_capped = cap_outliers(df_capped, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>1%</th>\n",
       "      <th>50%</th>\n",
       "      <th>99%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>5203.000000</td>\n",
       "      <td>3004.386460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>104.060000</td>\n",
       "      <td>5203.000000</td>\n",
       "      <td>10301.940000</td>\n",
       "      <td>10406.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allelectrons_Total</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>125.050950</td>\n",
       "      <td>122.817572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>719.400000</td>\n",
       "      <td>1789.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density_Total</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>14.433119</td>\n",
       "      <td>14.640489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.739942</td>\n",
       "      <td>10.650000</td>\n",
       "      <td>75.098979</td>\n",
       "      <td>186.637534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allelectrons_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>17.033222</td>\n",
       "      <td>10.468734</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_e_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>4.546789</td>\n",
       "      <td>0.690864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atomicweight_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>37.507703</td>\n",
       "      <td>26.012313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.773227</td>\n",
       "      <td>26.203827</td>\n",
       "      <td>119.629500</td>\n",
       "      <td>167.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ionenergy_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>10.938308</td>\n",
       "      <td>1.408276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.054000</td>\n",
       "      <td>11.202760</td>\n",
       "      <td>13.512520</td>\n",
       "      <td>15.245810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>el_neg_chi_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>2.607694</td>\n",
       "      <td>0.334655</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>2.706000</td>\n",
       "      <td>2.980000</td>\n",
       "      <td>3.443000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_vdw_element_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>1.732730</td>\n",
       "      <td>0.180280</td>\n",
       "      <td>0.214167</td>\n",
       "      <td>1.318667</td>\n",
       "      <td>1.732727</td>\n",
       "      <td>2.055000</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_cov_element_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>0.944132</td>\n",
       "      <td>0.180017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.505333</td>\n",
       "      <td>0.915556</td>\n",
       "      <td>1.390000</td>\n",
       "      <td>1.615840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zaratio_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>0.493349</td>\n",
       "      <td>0.063080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405373</td>\n",
       "      <td>0.488550</td>\n",
       "      <td>0.707253</td>\n",
       "      <td>0.825990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density_Average</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>2.132984</td>\n",
       "      <td>1.936656</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132734</td>\n",
       "      <td>1.351550</td>\n",
       "      <td>7.986670</td>\n",
       "      <td>10.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hardness</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>4.647126</td>\n",
       "      <td>1.680525</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>8.288000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count         mean          std       min  \\\n",
       "id                     10407.0  5203.000000  3004.386460  0.000000   \n",
       "allelectrons_Total     10407.0   125.050950   122.817572  0.000000   \n",
       "density_Total          10407.0    14.433119    14.640489  0.000000   \n",
       "allelectrons_Average   10407.0    17.033222    10.468734  0.000000   \n",
       "val_e_Average          10407.0     4.546789     0.690864  0.000000   \n",
       "atomicweight_Average   10407.0    37.507703    26.012313  0.000000   \n",
       "ionenergy_Average      10407.0    10.938308     1.408276  0.000000   \n",
       "el_neg_chi_Average     10407.0     2.607694     0.334655  0.005000   \n",
       "R_vdw_element_Average  10407.0     1.732730     0.180280  0.214167   \n",
       "R_cov_element_Average  10407.0     0.944132     0.180017  0.000000   \n",
       "zaratio_Average        10407.0     0.493349     0.063080  0.000000   \n",
       "density_Average        10407.0     2.132984     1.936656  0.000000   \n",
       "Hardness               10407.0     4.647126     1.680525  1.000000   \n",
       "\n",
       "                               1%          50%           99%           max  \n",
       "id                     104.060000  5203.000000  10301.940000  10406.000000  \n",
       "allelectrons_Total       6.000000   100.000000    719.400000   1789.500000  \n",
       "density_Total            0.739942    10.650000     75.098979    186.637534  \n",
       "allelectrons_Average     4.666667    12.600000     50.000000     67.000000  \n",
       "val_e_Average            2.000000     4.714286      5.666667      6.000000  \n",
       "atomicweight_Average     8.773227    26.203827    119.629500    167.400000  \n",
       "ionenergy_Average        8.054000    11.202760     13.512520     15.245810  \n",
       "el_neg_chi_Average       1.790000     2.706000      2.980000      3.443000  \n",
       "R_vdw_element_Average    1.318667     1.732727      2.055000      2.250000  \n",
       "R_cov_element_Average    0.505333     0.915556      1.390000      1.615840  \n",
       "zaratio_Average          0.405373     0.488550      0.707253      0.825990  \n",
       "density_Average          0.132734     1.351550      7.986670     10.970000  \n",
       "Hardness                 1.500000     5.500000      8.288000     10.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_capped.describe([0.01, 0.99]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No missing data in the both train and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL CROSS-VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    return tfp.stats.percentile(tf.abs(y_true - y_pred), q=50)\n",
    "\n",
    "def metric_fn(y_true, y_pred):\n",
    "    return tfp.stats.percentile(tf.abs(y_true - y_pred), q=100) - tfp.stats.percentile(tf.abs(y_true - y_pred), q=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True, mode='min')\n",
    "reduce_LR = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=5, min_lr=0.00001,factor=0.8)\n",
    "\n",
    "class KerasRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, epochs=100, batch_size=32):\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.InputLayer(input_shape=(len(num_var),)),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(0.013, beta_1=0.5),\n",
    "                    loss=loss_fn,\n",
    "                      metrics=[metric_fn])\n",
    "        return model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=0, callbacks=[early_stopping,reduce_LR], validation_split=0.1)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def custom_loss_function(preds, targets):\n",
    "#     # Define your custom loss function here\n",
    "#     return torch.nn.functional.mse_loss(preds, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastai.tabular.all import *\n",
    "\n",
    "# def create_fastai_regressor(dls):\n",
    "#     \"\"\"\n",
    "#     Create a FastAI tabular regressor.\n",
    "#     :param dls: FastAI Dataloader\n",
    "#     :return: FastAI Learner\n",
    "#     \"\"\"\n",
    "#     learn = tabular_learner(dls, y_range=(1, 10), layers=[256,128,64], loss_func=custom_loss_function, metrics=make_scorer(median_absolute_error, greater_is_better=False))\n",
    "#     return learn\n",
    "\n",
    "\n",
    "# # Define your categorical and continuous features\n",
    "# cont_names = list(num_var)\n",
    "# y_name = TARGET\n",
    "\n",
    "# # # Split your data into a training set and a validation set\n",
    "# # splits = RandomSplitter()(range_of(df))\n",
    "\n",
    "# # Create a TabularPandas object\n",
    "# to = TabularPandas(train, procs=[Normalize],\n",
    "#                    cont_names=cont_names,\n",
    "#                    y_names=y_name,\n",
    "#                 #    splits=splits,\n",
    "#                    )\n",
    "\n",
    "# # Create a DataLoaders object\n",
    "# dls = to.dataloaders(bs=64)  # bs is batch size, adjust as needed\n",
    "\n",
    "# class FastAIRegressor(BaseEstimator, RegressorMixin):\n",
    "#     def __init__(self, dls):\n",
    "#         self.dls = dls\n",
    "#         self.learn = None\n",
    "\n",
    "#     def fit(self, X, y):\n",
    "#         with warnings.catch_warnings():\n",
    "#             warnings.simplefilter('ignore')\n",
    "#             self.learn = create_fastai_regressor(self.dls)\n",
    "\n",
    "#             with self.learn.no_bar(), self.learn.no_logging():\n",
    "#                 self.learn.fit_one_cycle(100, 0.00001)\n",
    "#             return self\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         dl = self.dls.test_dl(X)\n",
    "#         with self.learn.no_bar(), self.learn.no_logging():\n",
    "#             preds, _ = self.learn.get_preds(dl=dl)\n",
    "#         return preds.numpy()\n",
    "\n",
    "#     def score(self, X, y):\n",
    "#         # Implement a scoring method if needed\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RegressionModel(nn.Module):\n",
    "#     def __init__(self, input_size):\n",
    "#         super(RegressionModel, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_size, 256)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(256, 128)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.fc3 = nn.Linear(128, 64)\n",
    "#         self.relu3 = nn.ReLU()\n",
    "#         self.fc4 = nn.Linear(64, 1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.relu1(self.fc1(x))\n",
    "#         x = self.relu2(self.fc2(x))\n",
    "#         x = self.relu3(self.fc3(x))\n",
    "#         x = self.fc4(x)\n",
    "#         return x\n",
    "\n",
    "# class PyTorchRegressor(BaseEstimator, RegressorMixin):\n",
    "#     def __init__(self, input_size, epochs=100, lr=0.00001, batch_size=32, weight_decay=1e-5):\n",
    "#         self.input_size = input_size\n",
    "#         self.model = RegressionModel(input_size)\n",
    "#         self.epochs = epochs\n",
    "#         self.batch_size = batch_size\n",
    "#         self.lr = lr\n",
    "#         self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "#         self.criterion = nn.L1Loss()  # L1 Loss is equivalent to MAE\n",
    "#         self.weight_decay = weight_decay\n",
    "\n",
    "#     def fit(self, X, y):\n",
    "#         X = torch.tensor(X.values, dtype=torch.float32) if isinstance(X, pd.DataFrame) else torch.tensor(X, dtype=torch.float32)\n",
    "#         y = torch.tensor(y.values, dtype=torch.float32).view(-1, 1) if isinstance(y, pd.DataFrame) or isinstance(y, pd.Series) else torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "        \n",
    "#         dataset = TensorDataset(X, y)\n",
    "#         loader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "#         for epoch in range(self.epochs):\n",
    "#             self.model.train()\n",
    "#             for X_batch, y_batch in loader:\n",
    "#                 self.optimizer.zero_grad()\n",
    "#                 output = self.model(X_batch)\n",
    "#                 loss = self.criterion(output, y_batch)\n",
    "#                 loss.backward()\n",
    "#                 self.optimizer.step()\n",
    "#         return self\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         self.model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             X = torch.tensor(X.values, dtype=torch.float32) if isinstance(X, pd.DataFrame) else torch.tensor(X, dtype=torch.float32)\n",
    "#             predictions = self.model(X)\n",
    "#         return predictions.numpy()\n",
    "\n",
    "#     def score(self, X, y):\n",
    "#         predictions = self.predict(X)\n",
    "#         return -self.criterion(torch.tensor(predictions), torch.tensor(y, dtype=torch.float32)).item()  # Negative MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor, GradientBoostingRegressor, RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.linear_model import LogisticRegression, RidgeCV, PassiveAggressiveRegressor, SGDRegressor, Perceptron, LinearRegression, TheilSenRegressor, HuberRegressor, RANSACRegressor, Lasso, ElasticNet, Lars, LassoLars, OrthogonalMatchingPursuit, BayesianRidge, ARDRegression, TweedieRegressor, PoissonRegressor, GammaRegressor, LassoLars\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn import svm\n",
    "\n",
    "MLA = [\n",
    "\t# Trial Models\n",
    "\tMLPRegressor(random_state=5),\n",
    "\tTheilSenRegressor(random_state=5),\n",
    "\tHuberRegressor(),\n",
    "\tRANSACRegressor(random_state=5),\n",
    "\tLasso(random_state=5),\n",
    "\tElasticNet(random_state=5),\n",
    "\tLars(random_state=5),\n",
    "\tLassoLars(random_state=5),\n",
    "\tOrthogonalMatchingPursuit(),\n",
    "\tBayesianRidge(),\n",
    "\tARDRegression(),\n",
    "    TweedieRegressor(power=1.5, alpha=0.5),\n",
    "    PoissonRegressor(alpha=0.5),\n",
    "    GammaRegressor(alpha=0.5),\n",
    "    LassoLars(alpha=0.1, random_state=5),\n",
    "\n",
    "\t# GLM\n",
    "\tLinearRegression(),\n",
    "\tPassiveAggressiveRegressor(random_state=5),\n",
    "\tRidgeCV(),\n",
    "\t# SGDRegressor(),\n",
    "\n",
    "\t# # SVM\n",
    "\t# svm.SVR(kernel='linear'),\n",
    "    # svm.SVR(kernel='poly'),\n",
    "    # svm.SVR(kernel='rbf'),\n",
    "    # svm.SVR(kernel='sigmoid'),\n",
    "\t# svm.NuSVR(),\n",
    "\n",
    "\t# Trees    \n",
    "\tDecisionTreeRegressor(random_state=5),\n",
    "\tExtraTreeRegressor(random_state=5),\n",
    "\n",
    "\tXGBRegressor(random_state=5),\n",
    "\tLGBMRegressor(n_jobs=-1, random_state=5),\n",
    "\tCatBoostRegressor(random_state=5, verbose=False, early_stopping_rounds=100),\n",
    "\t\n",
    "\t# KNeighbors\n",
    "\tKNeighborsRegressor(),\n",
    "\tKNeighborsRegressor(n_neighbors=2),\n",
    "\tKNeighborsRegressor(n_neighbors=4),\n",
    "\tKNeighborsRegressor(n_neighbors=8),\n",
    "\tKNeighborsRegressor(n_neighbors=16),\n",
    "\tKNeighborsRegressor(n_neighbors=32),\n",
    "\tKNeighborsRegressor(n_neighbors=64),\n",
    "\tKNeighborsRegressor(n_neighbors=128),\n",
    "\tKNeighborsRegressor(n_neighbors=256),\n",
    "\tKNeighborsRegressor(n_neighbors=512),\n",
    "\tKNeighborsRegressor(n_neighbors=1024),\n",
    "\n",
    "\t# Ensemble Methods\n",
    "\tAdaBoostRegressor(random_state=5),\n",
    "\tBaggingRegressor(random_state=5),\n",
    "\tExtraTreesRegressor(random_state=5),\n",
    "\tGradientBoostingRegressor(random_state=5),\n",
    "\tHistGradientBoostingRegressor(random_state=5),\n",
    "\tRandomForestRegressor(random_state=5),\n",
    "    \n",
    "\t# Neural Networks\n",
    "\t# FastAIRegressor(dls),\n",
    "\t# PyTorchRegressor(input_size=train[list(num_var)].shape[1]),\n",
    "\tKerasRegressor(epochs=100, batch_size=32),\n",
    "    ]\n",
    "\n",
    "\n",
    "# split dataset in cross-validation with splitter class\n",
    "# cv_split could KFold, StratifiedKFold or RepeatedKFold depending on the problem\n",
    "cv_split = KFold(n_splits=10, shuffle=True, random_state=5)\n",
    "cv_split_trial = KFold(n_splits=3, shuffle=True, random_state=5) # For quick trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with MLPRegressor\n",
      "Done with TheilSenRegressor\n",
      "Done with HuberRegressor\n",
      "Done with RANSACRegressor\n",
      "Done with Lasso\n",
      "Done with ElasticNet\n",
      "Done with Lars\n",
      "Done with LassoLars\n",
      "Done with OrthogonalMatchingPursuit\n",
      "Done with BayesianRidge\n",
      "Done with ARDRegression\n",
      "Done with TweedieRegressor\n",
      "Done with PoissonRegressor\n",
      "Done with GammaRegressor\n",
      "Done with LassoLars_1\n",
      "Done with LinearRegression\n",
      "Done with PassiveAggressiveRegressor\n",
      "Done with RidgeCV\n",
      "Done with DecisionTreeRegressor\n",
      "Done with ExtraTreeRegressor\n",
      "Done with XGBRegressor\n",
      "Done with LGBMRegressor\n",
      "Done with CatBoostRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor_1\n",
      "Done with KNeighborsRegressor_2\n",
      "Done with KNeighborsRegressor_3\n",
      "Done with KNeighborsRegressor_4\n",
      "Done with KNeighborsRegressor_5\n",
      "Done with KNeighborsRegressor_6\n",
      "Done with KNeighborsRegressor_7\n",
      "Done with KNeighborsRegressor_8\n",
      "Done with KNeighborsRegressor_9\n",
      "Done with KNeighborsRegressor_10\n",
      "Done with AdaBoostRegressor\n",
      "Done with BaggingRegressor\n",
      "Done with ExtraTreesRegressor\n",
      "Done with GradientBoostingRegressor\n",
      "Done with HistGradientBoostingRegressor\n",
      "Done with RandomForestRegressor\n",
      "109/109 [==============================] - 0s 2ms/step\n",
      "217/217 [==============================] - 0s 1ms/step\n",
      "109/109 [==============================] - 0s 1ms/step\n",
      "217/217 [==============================] - 0s 1ms/step\n",
      "109/109 [==============================] - 0s 1ms/step\n",
      "217/217 [==============================] - 0s 1ms/step\n",
      "Done with KerasRegressor\n",
      "CPU times: total: 1min 41s\n",
      "Wall time: 3min 48s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Parameters</th>\n",
       "      <th>MLA Train Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy 3*STD</th>\n",
       "      <th>MLA Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>KerasRegressor</td>\n",
       "      <td>{'batch_size': 32, 'epochs': 100}</td>\n",
       "      <td>0.467585</td>\n",
       "      <td>0.481993</td>\n",
       "      <td>0.133604</td>\n",
       "      <td>0 min 47.16 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>{'categorical_features': None, 'early_stopping...</td>\n",
       "      <td>0.518749</td>\n",
       "      <td>0.656185</td>\n",
       "      <td>0.046055</td>\n",
       "      <td>0 min 1.06 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'criter...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.065863</td>\n",
       "      <td>0 min 2.18 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CatBoostRegressor</td>\n",
       "      <td>{'loss_function': 'RMSE', 'verbose': False, 'r...</td>\n",
       "      <td>0.4792</td>\n",
       "      <td>0.661653</td>\n",
       "      <td>0.037293</td>\n",
       "      <td>0 min 4.91 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...</td>\n",
       "      <td>0.242167</td>\n",
       "      <td>0.662333</td>\n",
       "      <td>0.058447</td>\n",
       "      <td>0 min 4.91 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>0.5169</td>\n",
       "      <td>0.666064</td>\n",
       "      <td>0.048586</td>\n",
       "      <td>0 min 0.27 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>{'objective': 'reg:squarederror', 'base_score'...</td>\n",
       "      <td>0.294985</td>\n",
       "      <td>0.681328</td>\n",
       "      <td>0.042431</td>\n",
       "      <td>0 min 0.72 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.07874</td>\n",
       "      <td>0 min 0.48 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>{'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': ...</td>\n",
       "      <td>0.667212</td>\n",
       "      <td>0.710249</td>\n",
       "      <td>0.058916</td>\n",
       "      <td>0 min 1.30 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.028284</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>KNeighborsRegressor_3</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.063738</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>KNeighborsRegressor_2</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.035355</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>KNeighborsRegressor_4</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.023385</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'squared_error...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 min 0.11 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ExtraTreeRegressor</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'squared_error...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 min 0.03 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>KNeighborsRegressor_5</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.048614</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>KNeighborsRegressor_1</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.070711</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>KNeighborsRegressor_6</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.836198</td>\n",
       "      <td>0.845312</td>\n",
       "      <td>0.08146</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TheilSenRegressor</td>\n",
       "      <td>{'copy_X': True, 'fit_intercept': True, 'max_i...</td>\n",
       "      <td>0.905906</td>\n",
       "      <td>0.909104</td>\n",
       "      <td>0.039869</td>\n",
       "      <td>0 min 2.32 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>KNeighborsRegressor_7</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.916927</td>\n",
       "      <td>0.923958</td>\n",
       "      <td>0.094457</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HuberRegressor</td>\n",
       "      <td>{'alpha': 0.0001, 'epsilon': 1.35, 'fit_interc...</td>\n",
       "      <td>0.938122</td>\n",
       "      <td>0.936989</td>\n",
       "      <td>0.114728</td>\n",
       "      <td>0 min 0.17 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ARDRegression</td>\n",
       "      <td>{'alpha_1': 1e-06, 'alpha_2': 1e-06, 'compute_...</td>\n",
       "      <td>0.969573</td>\n",
       "      <td>0.966068</td>\n",
       "      <td>0.020782</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lars</td>\n",
       "      <td>{'copy_X': True, 'eps': 2.220446049250313e-16,...</td>\n",
       "      <td>0.96502</td>\n",
       "      <td>0.966119</td>\n",
       "      <td>0.026752</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>{'copy_X': True, 'fit_intercept': True, 'n_job...</td>\n",
       "      <td>0.96502</td>\n",
       "      <td>0.966119</td>\n",
       "      <td>0.026752</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>{'alpha_per_target': False, 'alphas': (0.1, 1....</td>\n",
       "      <td>0.968325</td>\n",
       "      <td>0.969011</td>\n",
       "      <td>0.022271</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BayesianRidge</td>\n",
       "      <td>{'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_in...</td>\n",
       "      <td>0.968403</td>\n",
       "      <td>0.969025</td>\n",
       "      <td>0.021671</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>KNeighborsRegressor_8</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>0.981224</td>\n",
       "      <td>0.98862</td>\n",
       "      <td>0.055716</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>{'base_estimator': None, 'learning_rate': 1.0,...</td>\n",
       "      <td>0.97938</td>\n",
       "      <td>0.989872</td>\n",
       "      <td>0.080126</td>\n",
       "      <td>0 min 0.22 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>KNeighborsRegressor_9</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>1.037129</td>\n",
       "      <td>1.035911</td>\n",
       "      <td>0.067497</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PoissonRegressor</td>\n",
       "      <td>{'alpha': 0.5, 'fit_intercept': True, 'max_ite...</td>\n",
       "      <td>1.038843</td>\n",
       "      <td>1.039091</td>\n",
       "      <td>0.052759</td>\n",
       "      <td>0 min 0.06 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OrthogonalMatchingPursuit</td>\n",
       "      <td>{'fit_intercept': True, 'n_nonzero_coefs': Non...</td>\n",
       "      <td>1.075493</td>\n",
       "      <td>1.075732</td>\n",
       "      <td>0.022092</td>\n",
       "      <td>0 min 0.00 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>{'alpha': 1.0, 'copy_X': True, 'fit_intercept'...</td>\n",
       "      <td>1.077266</td>\n",
       "      <td>1.081071</td>\n",
       "      <td>0.023476</td>\n",
       "      <td>0 min 0.00 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>{'alpha': 1.0, 'copy_X': True, 'fit_intercept'...</td>\n",
       "      <td>1.082992</td>\n",
       "      <td>1.084759</td>\n",
       "      <td>0.01931</td>\n",
       "      <td>0 min 0.00 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'batch...</td>\n",
       "      <td>1.114877</td>\n",
       "      <td>1.116208</td>\n",
       "      <td>0.312218</td>\n",
       "      <td>0 min 1.06 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>KNeighborsRegressor_10</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>1.1146</td>\n",
       "      <td>1.120638</td>\n",
       "      <td>0.066437</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RANSACRegressor</td>\n",
       "      <td>{'base_estimator': 'deprecated', 'estimator': ...</td>\n",
       "      <td>1.196459</td>\n",
       "      <td>1.191844</td>\n",
       "      <td>0.648952</td>\n",
       "      <td>0 min 0.15 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LassoLars_1</td>\n",
       "      <td>{'alpha': 0.1, 'copy_X': True, 'eps': 2.220446...</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>0.022821</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LassoLars</td>\n",
       "      <td>{'alpha': 1.0, 'copy_X': True, 'eps': 2.220446...</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>0.022821</td>\n",
       "      <td>0 min 0.00 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GammaRegressor</td>\n",
       "      <td>{'alpha': 0.5, 'fit_intercept': True, 'max_ite...</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>0.022821</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TweedieRegressor</td>\n",
       "      <td>{'alpha': 0.5, 'fit_intercept': True, 'link': ...</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>1.352874</td>\n",
       "      <td>0.022821</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PassiveAggressiveRegressor</td>\n",
       "      <td>{'C': 1.0, 'average': False, 'early_stopping':...</td>\n",
       "      <td>2.981941</td>\n",
       "      <td>3.010767</td>\n",
       "      <td>3.833087</td>\n",
       "      <td>0 min 0.01 sec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         MLA Name  \\\n",
       "40                 KerasRegressor   \n",
       "38  HistGradientBoostingRegressor   \n",
       "36            ExtraTreesRegressor   \n",
       "22              CatBoostRegressor   \n",
       "39          RandomForestRegressor   \n",
       "21                  LGBMRegressor   \n",
       "20                   XGBRegressor   \n",
       "35               BaggingRegressor   \n",
       "37      GradientBoostingRegressor   \n",
       "23            KNeighborsRegressor   \n",
       "26          KNeighborsRegressor_3   \n",
       "25          KNeighborsRegressor_2   \n",
       "27          KNeighborsRegressor_4   \n",
       "18          DecisionTreeRegressor   \n",
       "19             ExtraTreeRegressor   \n",
       "28          KNeighborsRegressor_5   \n",
       "24          KNeighborsRegressor_1   \n",
       "29          KNeighborsRegressor_6   \n",
       "1               TheilSenRegressor   \n",
       "30          KNeighborsRegressor_7   \n",
       "2                  HuberRegressor   \n",
       "10                  ARDRegression   \n",
       "6                            Lars   \n",
       "15               LinearRegression   \n",
       "17                        RidgeCV   \n",
       "9                   BayesianRidge   \n",
       "31          KNeighborsRegressor_8   \n",
       "34              AdaBoostRegressor   \n",
       "32          KNeighborsRegressor_9   \n",
       "12               PoissonRegressor   \n",
       "8       OrthogonalMatchingPursuit   \n",
       "5                      ElasticNet   \n",
       "4                           Lasso   \n",
       "0                    MLPRegressor   \n",
       "33         KNeighborsRegressor_10   \n",
       "3                 RANSACRegressor   \n",
       "14                    LassoLars_1   \n",
       "7                       LassoLars   \n",
       "13                 GammaRegressor   \n",
       "11               TweedieRegressor   \n",
       "16     PassiveAggressiveRegressor   \n",
       "\n",
       "                                       MLA Parameters MLA Train Accuracy Mean  \\\n",
       "40                  {'batch_size': 32, 'epochs': 100}                0.467585   \n",
       "38  {'categorical_features': None, 'early_stopping...                0.518749   \n",
       "36  {'bootstrap': False, 'ccp_alpha': 0.0, 'criter...                    -0.0   \n",
       "22  {'loss_function': 'RMSE', 'verbose': False, 'r...                  0.4792   \n",
       "39  {'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...                0.242167   \n",
       "21  {'boosting_type': 'gbdt', 'class_weight': None...                  0.5169   \n",
       "20  {'objective': 'reg:squarederror', 'base_score'...                0.294985   \n",
       "35  {'base_estimator': None, 'bootstrap': True, 'b...                    0.25   \n",
       "37  {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': ...                0.667212   \n",
       "23  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                0.613333   \n",
       "26  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                  0.6625   \n",
       "25  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                     0.6   \n",
       "27  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                   0.725   \n",
       "18  {'ccp_alpha': 0.0, 'criterion': 'squared_error...                    -0.0   \n",
       "19  {'ccp_alpha': 0.0, 'criterion': 'squared_error...                    -0.0   \n",
       "28  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                   0.775   \n",
       "24  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                     0.4   \n",
       "29  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                0.836198   \n",
       "1   {'copy_X': True, 'fit_intercept': True, 'max_i...                0.905906   \n",
       "30  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                0.916927   \n",
       "2   {'alpha': 0.0001, 'epsilon': 1.35, 'fit_interc...                0.938122   \n",
       "10  {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'compute_...                0.969573   \n",
       "6   {'copy_X': True, 'eps': 2.220446049250313e-16,...                 0.96502   \n",
       "15  {'copy_X': True, 'fit_intercept': True, 'n_job...                 0.96502   \n",
       "17  {'alpha_per_target': False, 'alphas': (0.1, 1....                0.968325   \n",
       "9   {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'alpha_in...                0.968403   \n",
       "31  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                0.981224   \n",
       "34  {'base_estimator': None, 'learning_rate': 1.0,...                 0.97938   \n",
       "32  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                1.037129   \n",
       "12  {'alpha': 0.5, 'fit_intercept': True, 'max_ite...                1.038843   \n",
       "8   {'fit_intercept': True, 'n_nonzero_coefs': Non...                1.075493   \n",
       "5   {'alpha': 1.0, 'copy_X': True, 'fit_intercept'...                1.077266   \n",
       "4   {'alpha': 1.0, 'copy_X': True, 'fit_intercept'...                1.082992   \n",
       "0   {'activation': 'relu', 'alpha': 0.0001, 'batch...                1.114877   \n",
       "33  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                  1.1146   \n",
       "3   {'base_estimator': 'deprecated', 'estimator': ...                1.196459   \n",
       "14  {'alpha': 0.1, 'copy_X': True, 'eps': 2.220446...                1.352874   \n",
       "7   {'alpha': 1.0, 'copy_X': True, 'eps': 2.220446...                1.352874   \n",
       "13  {'alpha': 0.5, 'fit_intercept': True, 'max_ite...                1.352874   \n",
       "11  {'alpha': 0.5, 'fit_intercept': True, 'link': ...                1.352874   \n",
       "16  {'C': 1.0, 'average': False, 'early_stopping':...                2.981941   \n",
       "\n",
       "   MLA Test Accuracy Mean MLA Test Accuracy 3*STD         MLA Time  \n",
       "40               0.481993                0.133604  0 min 47.16 sec  \n",
       "38               0.656185                0.046055   0 min 1.06 sec  \n",
       "36                  0.658                0.065863   0 min 2.18 sec  \n",
       "22               0.661653                0.037293   0 min 4.91 sec  \n",
       "39               0.662333                0.058447   0 min 4.91 sec  \n",
       "21               0.666064                0.048586   0 min 0.27 sec  \n",
       "20               0.681328                0.042431   0 min 0.72 sec  \n",
       "35               0.693333                 0.07874   0 min 0.48 sec  \n",
       "37               0.710249                0.058916   0 min 1.30 sec  \n",
       "23               0.766667                0.028284   0 min 0.01 sec  \n",
       "26               0.770833                0.063738   0 min 0.01 sec  \n",
       "25               0.783333                0.035355   0 min 0.01 sec  \n",
       "27               0.783333                0.023385   0 min 0.01 sec  \n",
       "18                    0.8                     0.0   0 min 0.11 sec  \n",
       "19                    0.8                     0.0   0 min 0.03 sec  \n",
       "28               0.802083                0.048614   0 min 0.01 sec  \n",
       "24               0.833333                0.070711   0 min 0.01 sec  \n",
       "29               0.845312                 0.08146   0 min 0.01 sec  \n",
       "1                0.909104                0.039869   0 min 2.32 sec  \n",
       "30               0.923958                0.094457   0 min 0.01 sec  \n",
       "2                0.936989                0.114728   0 min 0.17 sec  \n",
       "10               0.966068                0.020782   0 min 0.01 sec  \n",
       "6                0.966119                0.026752   0 min 0.01 sec  \n",
       "15               0.966119                0.026752   0 min 0.01 sec  \n",
       "17               0.969011                0.022271   0 min 0.01 sec  \n",
       "9                0.969025                0.021671   0 min 0.01 sec  \n",
       "31                0.98862                0.055716   0 min 0.01 sec  \n",
       "34               0.989872                0.080126   0 min 0.22 sec  \n",
       "32               1.035911                0.067497   0 min 0.01 sec  \n",
       "12               1.039091                0.052759   0 min 0.06 sec  \n",
       "8                1.075732                0.022092   0 min 0.00 sec  \n",
       "5                1.081071                0.023476   0 min 0.00 sec  \n",
       "4                1.084759                 0.01931   0 min 0.00 sec  \n",
       "0                1.116208                0.312218   0 min 1.06 sec  \n",
       "33               1.120638                0.066437   0 min 0.01 sec  \n",
       "3                1.191844                0.648952   0 min 0.15 sec  \n",
       "14               1.352874                0.022821   0 min 0.01 sec  \n",
       "7                1.352874                0.022821   0 min 0.00 sec  \n",
       "13               1.352874                0.022821   0 min 0.01 sec  \n",
       "11               1.352874                0.022821   0 min 0.01 sec  \n",
       "16               3.010767                3.833087   0 min 0.01 sec  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# create table to compare MLA metrics\n",
    "MLA_columns = ['MLA Name', 'MLA Parameters', 'MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD', 'MLA Time']\n",
    "MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "\n",
    "# create table to compare MLA predictions\n",
    "MLA_predict = {}\n",
    "\n",
    "# index through MLA and save performance to table\n",
    "row_index = 0\n",
    "scoring = median_abs_error_scorer = make_scorer(median_absolute_error, greater_is_better=False)\n",
    "\n",
    "for alg in MLA:\n",
    "\n",
    "\t# set name and parameters\n",
    "\tMLA_name = alg.__class__.__name__\n",
    "\n",
    "\t# Add suffix if name already exists\n",
    "\tsuffix = 1\n",
    "\toriginal_MLA_name = MLA_name\n",
    "\twhile MLA_compare['MLA Name'].str.contains(MLA_name).any():\n",
    "\t\tMLA_name = f\"{original_MLA_name}_{suffix}\"\n",
    "\t\tsuffix += 1\n",
    "\t\t\n",
    "\tMLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
    "\tMLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
    "\n",
    "\t\"\"\"score model with cross validation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\"\"\"\n",
    "\n",
    "\tcv_results = cross_validate(alg, train[num_var], train[TARGET], cv=cv_split_trial, scoring=scoring, return_train_score=True)\n",
    "\n",
    "\t# Calculate mean time in seconds\n",
    "\tmean_fit_time = cv_results['fit_time'].mean()\n",
    "\n",
    "\t# Convert mean time to minutes and seconds\n",
    "\tminutes = int(mean_fit_time // 60)\n",
    "\tseconds = mean_fit_time % 60\n",
    "\n",
    "\t# Format the time and assign it\n",
    "\tMLA_compare.loc[row_index, 'MLA Time'] = f\"{minutes} min {seconds:.2f} sec\"\n",
    "\tMLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean() * -1\n",
    "\tMLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean() * -1\n",
    "\t#if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\n",
    "\tMLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   #let's know the worst that can happen!\n",
    "\n",
    "\t# # #save MLA predictions - see section 6 for usage\n",
    "\t# alg.fit(data1[data1_x_bin], data1[Target])\n",
    "\t# MLA_predict[MLA_name] = alg.predict(data1[data1_x_bin])\n",
    "\tprint(f'Done with {MLA_name}')\n",
    "\trow_index+=1\n",
    "\n",
    "\n",
    "#print and sort table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html\n",
    "MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = True, inplace = True)\n",
    "MLA_compare.to_csv(f'{experiment}_results.csv', index=False)\n",
    "MLA_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Algorithm')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg4AAAElCAYAAACMOGpRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAACWdElEQVR4nOydd7ze4/nH358kSELMoHbEHiF2EcTem5olqNKqtvy0VBUtNWqWVq3a0dpbjdoitohRo1btLUQSI/n8/riuJ+ebJ89zcsQ5IXK/X6/zyjnfeX+fc7iv73V/rs8l2xQKhUKhUCi0hU7f9AAKhUKhUChMPpTAoVAoFAqFQpspgUOhUCgUCoU2UwKHQqFQKBQKbaYEDoVCoVAoFNpMCRwKhUKhUCi0mRI4FArfASSdJ+nIVvYPl9R7Uo5pUiFp3ny+zt/AvQdIureDrj3B55JkSQt2xP0LhWaUwKFQmARIelnS55J61m1/LP/n36sj7297Otsvtvd1Jd0p6Uftfd2vgu3/5fON7qh7SDo8f08rddQ96ql/rm/qs86g9EtJc0zqe08qJO0h6RlJn0h6W9KNknp80+P6tlICh0Jh0vESsEPtB0l9gO7f3HAmDyR1+YbvL2AX4IP8d1Lc8xt95hqSpgW2BoYBO0/ie0+Sz0DSGsBRwA62ewCLAZe08z2+Fb/P9qIEDoXCpONCxp14dgUuqB4gaePMQnws6VVJh9ft7yfpPkkf5f4Bld0zSboh35oekLRA5byxKe18g/xrK8cuKulWSR9IelbSDybmYSXtLuk/kj6UdLOk+Sr7/pzj/1jSI5JWq+w7XNLlki6S9DEwIN+2j5A0KMd8Sy17I6lXPl+X/Lnpsbl/F0mvSHpf0u8yG7ROK4+yGjAH8HNge0lTt/LM6+VnNkzSaZLuqmUJJHWSdEje+x1JF0iaoe4Z9pD0P+D26nNJ+mOO4y+5fPGXym3XkfR8/k38NQOd2jLKIEkn5b4XJa2S21/NMew6gV/j1sBHwB+Iv9fqs84s6VxJb+Tv+OrKvs0lDcnf7wuSNsjt43zW+bu+qNlnkNsvk/RWfqZ3S1qicn43SSfkZzpM0r257QZJ+9aNd6ikLRs84wrAYNuPAdj+wPb5tj9p7R65bzNJT+Xne6ekxSr3e1nSgZKGAp/m7/H7avnv93FJ/Sfw+X87sV2+ylf56uAv4GVgHeBZ4o2mM/AaMB9goFce1x/oQwT1SwFvA1vkvvmAT4isxVTALEDf3Hce8D6wItAFGAj8s3J/AwtO6FhgWuBVYLfctwzwHrB4k+e6E/hRg+2bA//NZ+0CHALcV9m/c46/C/B/wFtA19x3OPAFsEV+Dt3yPi8AC1d+PiaP75XP16UypmbHLg4MB/oBUwPH573WaeV393fg0vzM3we2ruwbANyb3/cEPga2yuf6RV77R7l/9/xMegPTAVcCF9Y9wwX5O+jW5Ll+VDc2A9cDMwLzAu8CG1TG9mX+LjsDRwL/A/4KTAOsR/w9TdfKs98G/AmYPa+1XGXfDcSb+Uz52ayR21ckMhTr5u9vLmDR6n8HlWscDlzU7DOofG49cswnA0Mq5/81P5e58hlXyeN+ADxQOW7p/N1N3eAZVwNGAr8HVgWmqdvf7B4LA5/mc04F/Dp/v1NXnnUIME/+PufKMWyUn8u6+fOs3/T/n77y/8++6QGUr/I1JXzREjgcAhwNbADcSkwwYwOHBuedDJyU3/8GuKrJcecBZ1d+3gh4pvJzfeDQ8FhgO+CeumufARzW5L530jhw+BewR+XnTsAIYL4m1/kQWDq/Pxy4u8F9Dqn8/FPgpvy+F+NPsM2OPRT4R2Vfd+BzmgQOuf9jWoK3M4BrKvsH0BI47EK8udb2iQjCaoHDbcBPK/sXIQKLLpVn6F3Z3+i5GgUO/So/XwocVBnb85V9ffL42Svb3ieDzwbPPi8whpbg9Gbgz/n9HLlvpgbnnUH+zTb776Dy8+GMHzj0bnRuHjNjHjND/k2NrP3d1B3XNf+mFsqfjwdOa+W6GwLXEdmV4cCJRJDQ2j1+B1xa9zf+OtC/8qy7V/YfSAaKlW03A7s2G9e39assVRQKk5YLgR2J/6lfUL9T0kqS7pD0rqRhwN7EmyzEm8sLrVz7rcr3I4i32q967HzASplK/UjSR8BOwPdauVYj5gP+XLnGB8REOheApAMUyxjDcv8MtDwnxITb1jE3otmxc1avbXsEMXk2Y0viTfvG/HkgsKGkWRscW39tE1ml6v5XKj+/QgQNs1e2NXruCdHa5/J25fuROa76bc0+xx8C/7E9JH8eCOwoaSrib/ED2x82OG9Cf6cTYuxnIKmzpGNyueNjYjKG+FvpSQQI493L9igiG7KzpE5Elu7CZje0/S/bmwIzE9myAcCPWrsHdb9P22Ny7HM1ehbiv4lt6/7b6kcEYZMVJXAoFCYhtl8hRJIbEanqei4GrgXmsT0DcDox4UL8T2iBBue0J68Cd9mesfI1ne2fTMR19qq7Tjfb9yn0DL8m0skz2Z6RSG2rcr7b42Ea8CYwd+2HXKuepZXjdyUm1v9Jegu4jEhL79iGa6v6M/AGMXnUmJcISqoTeWvP3VGfSTN2AXqnvuAt4i28J/G3+yows6QZG5zX2t/pp4wrCG4UkFafc0diIl+HCC575XYRS2ijWrnX+UTQuzYwwvbgJse13NgeY/s2Ql+x5ATuMc7vM3/f8xBZh0bP8iqRcaj+NzGt7WMmNK5vGyVwKBQmPXsAa9n+tMG+HsSb3ChJKzLuBDWQEML9IIVWs0jq285jux5YWNIPJU2VXytURV8N6CKpa+VrKiLg+U1NyCZpBknbVp7xS2I9voukQ4Hp2/k5mnE5sGmKBKcmUuVqdKCkuYhJZxOgb34tDRxL4+qKG4A+krZQCDX3YdyJ8R/AfpLmlzQdoeS/xPaXbRz724Q+osORtDIxWa5Iy7MvSQS2u9h+k1iOOk3STPl3snqe/ndgN0lrKwShc0laNPcNIQSmU0laHthmAkPpAXxGZIW6E58ZMPYN/xzgRElzZnZiZUnT5P7BxHLKCbSSbVAIObfP51D+d7cGcP8E7nEpsHE+51SEVucz4L4mt7qI+NtbP6/TVVJ/SXM3Of5bSwkcCoVJjO0XbD/cZPdPgT9I+oRYj7+0ct7/iLe9/yNS/0OIiaw9x/YJIZrbnnijeouYKKdp5bS/ESnv2te5tq/K8/6ZKeYniXVkiHXdm4DniFTvKCYuRf+Vsf0UsC/wTyJDMBx4h/gffj0/JIR4t9h+q/YFnAIsJWnJumu/B2xLiAnfJ4SYD1eufQ4xgd1NZJ1G5Vjayp+BbRQVDKd8hfMmhl0JLccTdc/+Z2ATSTMTn88XwDPEZ/hLANsPEoLMk4hM0l20vJn/jghIPiTEiBdPYBwXEH8jrwNPA/fX7T8AeAJ4iPhv4ljGndcuILQdF7Vyjw+BPYHnCT3LRcBxtge2dg/bzxIi31OJzMSmwKa2P290E9uvEtmTg4mg+VXgV0yG87BSoFEoFApTHPnm/xEhonupna/didA47GT7jva8dqFtSNoF+LHtft/0WL5LTHaRTqFQKHwdJG0qqbvC3Oh44m3y5Xa69vqSZsxU9sHEMkj9W3JhEiCpO5HBO/ObHst3jRI4FAqFKY3NiWWYN4CFgO3dfqnXlQkFfi11vYXtke107UIbkbQ+sRzwNhNeDil8RcpSRaFQKBQKhTZTMg6FQqFQKBTaTAkcCoVCoVAotJkSOBQKhUKhUGgzJXAoFAqFQqHQZkrgUCgUCoVCoc2UwKFQKBQKhUKbKYFDoVAoFAqFNlMCh0KhUCgUCm2mBA6FQqFQKBTaTAkcCoVCoVAotJkSOBQKhUKhUGgzJXAoFAqFQqHQZkrgUCgUCoVCoc2UwKFQKBQKhUKbKYFDoVAoFAqFNlMCh0KhUCgUCm2myzc9gML4SBpue7r8fiPgZGBd2690wL0GAMcBrwNdgTNsn9Te9/mm6Nmzp3v16vVND6NQKBQmKx555JH3bM/aaF8JHL7FSFobOAVYv61Bg6TOtkd/xVtdYvtnkmYBnpV0ue1Xv+p468bRxfaXX+cabbyPANke02j/9MOm54DXD+joYUwStn9z+296CIVCYQpBUtM5pyxVfEuRtDpwFrCJ7Rdy286SHpQ0RNIZkjrn9uGSTpD0OLCypEMlPSTpSUln5uSKpJ9LelrSUEn/rL+n7feB/wJzTOB+e0h6LvedJekvuf08SadLegD4k6QFJN0k6RFJ90haNI/bNsf2uKS7c9sSlXsNlbRQbt8/j31S0i9zWy9Jz0q6AHgSmKeDfg2FQqFQqKNkHL6dTANcDfS3/QyApMWA7YBVbX8h6TRgJ+ACYFrgAdv/l8c+bfsP+f2FwCbAdcBBwPy2P5M0Y/1NJc1LLFcMbXY/Sf8GfgcsC3wC3A48XrnM3MAqtkdLug3Y2/bzklYCTgPWAg4lsiivV8axN/Bn2wMlTQ10lrQcsBuwEiDgAUl3AR8CCwG72r6/wXP8GPgxQM9OPdv4kRcKhUKhLZSMw7eTL4D7gD0q29YGlgMekjQkf+6d+0YDV1SOXVPSA5KeICbqJXL7UGCgpJ2B6jLCdpKGEtmG02yPauV+KwJ32f7A9hfAZXVjvyyDhumAVYDL8vwzyEwGMAg4T9KeQOfcNhg4WNKBwHy2RwL9gKtsf2p7OHAlsFoe/0qjoAHA9pm2l7e9fI9OPRodUigUCoWJpMMyDlWBX/48AFg+19L3BkbYvqDJuf2Bz23fV9m2M/BrYqL5EngIOMD2R193jJLmBE6xvc1EXueXwJm2R+TPLxNv46NzvIfYvuYrXHIM8APgNkkH2z6KeOM+3/Zv6u+X9AA+ktSVeLNf3varkg4nsggAGwOrA5sCv5XUB1gUmJ4QR74B/FnStdX71T3rFhMY+6f5byfgI9t96w+wvXdmIDYGHpG0nO2Lc4ljY+BGSXu18T6tMvPSM7P9w0UbUCgUCu3FN7JUYfv0CRzSHxhOvHUjaQNgP2DDTG93BnYFZgc+qp44MeJA228AExU0JL8ELgKqE/matt+TtAhwC/BVAgdsj5C0MXCPpLeB24BrJJ2U97te0hcpmhxVCaBqQcJ7+da/DXC5pE7APLbvkHQvsD1QC+zesN1XUjcigPgTcEztfrbfkTQzEZw8BJwsaSYiONoaeKLBI4wAXpK0re3LUmexlO3HJS1g+wFi6WFDYB5JMwAv2j4ll0yWAu4mMhPHEIHMlsAP62/U2u/8g8c/4J9zjCfnmOIpQstCoTCxfCNLFZIOl3RAfj+OYE9SL2K9e78Uyq0G/JbILrwOYHu07XNsP5vXeFnSsZIeBbaVtKdCHPi4pCskdc/j5pc0WNITko6sjKeXpCfz+86Sjsvzh9befCX1l3SnpMslPSNpoIKfA3MCd0i6o8HjTk+sydfuNZ7Yr347MFVu/gx4i8gg/Au4AXgUmJeYrK/M47pL6pmf3WAiczAMeDWPh1hieErSyNzfqT5bk8sDdwOb5bmXEpP/SOAFoHf+Dq4F3s57zAasn5foC+wraRBwIbAvcKqkEUQg8bM87lxJI/O68+W19wCG57a9gOdsP0roJz4A3gfetv1YXmMxVQShDT73QqFQKHQAHZlx6JZr2zVmJiacesYR7Nn+SNLpwHDbx0Mo7mmZAJvxvu1l8/hZbJ+V3x9JTEqnAn8G/mb7Akn7NLnOHsAw2ytImgYYJOmW3LcMoRd4g1inXzXfkPcnMwyV69yRb9m9iWUH1Fzs16nB9mXy3Bdtr53nz2D7l7kUsnzlfv+r3Heh3DdE0qXALbYvyoBkHduD8w1+kzz+JmDJvP5MRIXCooRAczVgNtufKrQHq0kaDGwFLEIEF68Ab+a1riaWQfrZHinpYmAb2/dmFuHmPG5YjmVQZkVGEcHBUbb/mBml7oolpDVyTB8Ct0jawvbVmUEZKwitoiKOLBQKhQ6jIzMOI233rX0RSvpGNBPsNURSn8xEvCBpu8quSyrfL6ko/3uCqDyoiQNXBf6R31/Y5BbrAbtk0PMAMAsxGQM8aPu19AwYAvRqZahr2l4S6AP8JSfIZmK/ZtufANbNbMpqtoe1cr8aL9kekt8/AvRSVC70sD04t19cd85q+eb+OnCz7beA7wOLE4HTEGJpaD4iqDBwFVEK+SiRFalxbWYuANbJZx9CBI3T5+cwCDgxszUzpt/DQ8BuCk1GH9ufACsAd9p+N48ZSGg0YHxB6FiKOLJQKBQ6jm9DOWYjwV49TxHlf3fYfgLoq/AO6FY5piqWOw/YItfTBxCaiRqewHgE7Gv75nE2hmDzs/x+NPGGvHEuuczQ7GK2X8g36MUncN969gB2J4SS+wL7SKppClrjs8r3oxn3M2rGVEQQ+QpwgKR7iM/hVts7VA+U1JfIgqyRP29Gvt0n1d9DJ+D7WaVR5RhJNwAbEYHJ+rbvVnhXbEzoGk4kMhPNGNUWLUsRRxYKhUL78o0GDmou2PuE0AbUOBo4XtLmtl/Lba1NiD2ANyVNRWQcXs/tg/IeF+X2RtwM/ETS7elfsHDl/BojiQzHw7bPy8xGD+C9uuOQNBswFzEpf8n4Yr9d8tBGIsC3iWWEnwOnAz+yfV8GEDM2ul8jcvnnE0krpSix0UxaE3PeTCzrrAz8VdKCtv8radp8jmeB3pJ62X6Z8HoYj1ymuYUIeo7LbX1zCWWBDACfkLQCsGhqG16zfVYuES0LHAucIqknsVSxQ46t/l5NXSqLOLIxRRxZKBQmlm8649AZuEihqBdREvmRpOuISoDNibf/GyXNCvwr394/ItLkNze57u+IZYZ3899avvoXwMW5Xt+syuFsYgni0Zz83gW2mMBznEmsv89F6CAA/ivpY1oCnJuJzMk1xCQ4gljbf5/QecxEZDE+Jtb6H5O0PiGM7ElUkNygKJWchjBpeogQFs5BGDGdCiHwJKoitgemlvQmkcE4N7UGIwkNQc0TocpfCVHktPl5Pago8QT4ve1jJR1ECC07AS8TVRE9iWDmp5KWIjwgdiICot8T2YcngeWJrMbOxN/fZ8SyR38iOJyOyLIMtP2mpOPzHl2IJZGaOHKa1MIsQwSE+zf/9RQKhUKhvZA9ocx9oZ5cqqiWIB5t+xJJ6wJ/IESYA2xvkMdXm1b1Al4k3BXvz20z2/4gJ/zbgJ/bHpr7+hMVJZvkssuRRFnjB5KOAp5O8eOMwIPERLoTIWo8sibwJDQKGxDlmqOJSpDf2v6kKraUdHJe88wUN55WFTfaXkzSGcRkfgyhXdgEmJXIFo19NknrEeWgexGB4bVEqeeswAa298xnnIEIDO4DFrVttQhlrwMut32+pN2BzWxvIek8IqDavLUli95T9fZRPY+awG90yqNkHAqFQmtIesT28o32fdMZh8mVkW5sbHSrpG2Jt/alWzm/3vXwB1kJ0IXIHixOiEYbcavtD/L79YDNUmcBERTMm9uXklTzppgB2JGo7piXWDbZKwWINe5QeDUMJzI2EOLGxSPxArSIGzch9Ac/JDIAH1auU3229fKrliWYjhCa3gOcIOlY4Hrb90jqQmRg/i7peuD6PGdloooDQtD6p8q9LmsUNJSqikKhUOg4SuDQjmTqfjFiGWIm4LUmh35aOWd+4ABgBdsf5pt01ybnjXMu8Ra/dc3PonLNhgJPQnw6JyFAPEnSiW5x71yTWAIaCPyeSP03FDdKehfY0vZL+fMHld314zva9hn1DyFpWUIceaSk22z/QdKKhLX1NoTnw1qtfA719xqL7TOJ5SN6T9W7pNQKhUKhHSmBQ/uyH/Af4HjgLkkfEpPxNJIWt/10g3PmIgKFYZJmJyb1HRXmUCJ0IO82ud/NhOHSvpneXyYNkpoJPHsSwtOpCC3HsorulPMCd+S9niLKUY+kibiRWPr4AXBsLkfM1Mr4jpA00Pbw1IB8QfzdfZBLLB8BP8pMRvfUswwiljwgli+2J7INOxHZijZTqioKhUKhfSmBw8RRb251E3Au8CPCofEWwt9gkO3DJJ1D9F8YRLhgVnmNECI+QxgqPQIsWVsKkXQCaSDVgCOAkwmhZCfgJWIZoZnAsz9wMBEoPExLRceXRMbhQ+DWHMM+RDXHXxUNsLoQrpJ7ExmJf0j6IeFU+RYRkFR7k3SxfYuiy+bgXO4YDuwMLAgcJ2kMEUj8hBCwXpNCTNEidtyXEHX+Kp9jt/oPQcVyeqIoOodCoTAxlO6YE4HtzlVzK9sH2X7W9mKEadEXttexfVgevztRVvk9wtzJWTECITDsSixvPEpMzB9VbvcWLUZH/wSmVVhmP0YsI+yV93wQmC+3r2H7YOJNvbZscg/x9l7TG/QAfprfP2f7vZx8HwRus30EYfj0PWJyf5UIGCAm/lmJgKM7YeL0GRGYvCjpdqJB17SE1mNkHnuM7ReIYKm2/DENoZf4mAgMTAQOoyr3mim3vUKUqJL3WkFpM97g11QoFAqFDqBkHNqfJYk39npGEbqAj7N08f4srTyIcTMMvYAFMqPRg5iYV8pr7APYdh9JixIloAu3sn1v4M+2B0qamliKaHQ/8vuuea9fKDwwTiWqFt5VuHT+kTClOo+Y4EcROoQ3Ks+5LONWfdxue/da1YekfzcZ10ZEs62Ncywz5HjOA9a2/ZykC4jsxMl5r7E241WKOLJQKBQ6jpJxmHQIOCrT/v8mtA2zNzn2hcxkLEB0wjwzt/cjzKuw/QzxBr5wK9sHAwcrfCvmc4sVdD21QOVt4M0sBV2ECIJuzX2HAHNnADCN7UVsL000uKpet77q46A8/05aqj4ajauRvfYihIX2c3m982mxnIZxbcbH4mI5XSgUCh3GFJFxqPgudCF0AD90XWfIibzuAML/4GeVzU/RuEX3TkR6f7kULL5MpXoif/6EePueX9Iqtu8jvA/OnZjx2b5Y0gOE4PJGRafPrlS0CDnWWjfOd4B1FDbSLwFP2R6n82QGDq0xwaoP4D/147J9e32lBRNuRd6wqqJKEUcWCoVC+zJFBA5UfBcknU+k9v/YQfe6ncgs/DjLAlE4Kc4HvJNBw5r5M0Sw0INI/a9JTOrXZ9AAkU14Ib+/hwhAbs+liHmB/zbZ/qykWnfNU9LAaSlCrzBz3ZiH2e4raRYiYDiM8E+YVdLKjo6aUwEL235KE7avJn0ZGlZ9NBqXpGeoq7QgPBt6KW2vCd+Iu+ruI8LIbEyjcRRxZHOKOLJQKEwMU+JSxWBimQBJK0oaLOkxSfdJWiS3D5B0paSbJD0vaazpkKTdJD0n6UGi22Zte68UBT4OfE4YM72QJZnXEW/2e0p6ETgjjzne9vtEeeOcwOF5uQUUHUCfJoSRXfMN/DqgU17zPuKN+0jgX8D6in4PjwK/S7HiEcDI3L470Rn0QMKGemRqLMaSY3maCGRWAs4Bbs7z364879XA3ZI+BTYjOohCTPb9M5vwJ2L5ZHNgRB57Yh5XP64LiGqQD3LbpcD56R9xA9HTYhTRmfP01GXMRRhtPUm03S4UCoXCJGCKChwUls5rE+l/iBLI1WwvQ7T9rnoT9yUaOPUBtpM0j6Q5iMqCVYlMQLXj5anEZLcUsbTwZWoUriGClaXyej2JDpfdiCWJvrZ3JASGaxCT8tDMkLxAGDktRBgzHWd7t7zm/UT76f2BvxBNqrrl8w3IMS0FLJDbe9t+O5/zbNvdbG9GNMr6R34+8xJLGUvl9pWBWfL8fwKjFAZSPyQcLmckSknfyfv9l7CiXiXHdSqwVp6/Fi2dSevH9UF+znvmthmBmyQtl59zz/zqUfnMOwMn2V7C9iuV3wOSfizpYUkPfzKmao5ZKBQKha/LlLJUUfNdmIswaLo1t88AnC9pIWJSm6pyzm0p0CPf/OcjJq87bb+b2y8hRIjQujXydZmqfwJ429EZEklPEX4LQ/K4NW1XO15O0G5ZYZy0CnCZWqyhp8l/BxFNpi4lykCbsZ2ipfWiwM9sj5K0NtGo6qG8bjciQFiRCA5uJ/5+RgAPtcO4BhPOlnMDV9p+XlI/4Crbn+bndSWwGhH41dt2j8XFObJQKBQ6jCklcBiZa/jdiXX3fYBTiJT5Hba3zPT3nZVzPqt8P5qv91nVrjWm7rpj6q+rSkOsOnYEZsxgYw6iwuGavEYnYmIfSUzOJwHY3lvSG0RFxG/zDR4iUOhve0kiWJiecJZ8A/hzLmGIyKD8pm58WwAv2941f/45LcETtAgWOwEfuXFPj70lrUSIIx+RtFwTIWdrTFAYCUUcWSgUCu3NlBI4AGB7RE50V0s6jcg4vJ67B7ThEg8QE+sshGHRtoSmAb6mNXIT7gO2V/SG+D1R6rhhCjyHA7PbfjbX/89xtLyeGXhZ0fNiHkJL8RERCMxDBAmd6+7zRgZW3YjP40+EMdU1kk6y/U5etweRXThZ0kyEsHNrxu0UWmME8JKkbW1fliLGpWw/LmmBFFY+IGlDoi33DIwv5LybyEwck+PfklgmGQcV58iJoogjC4XCxDBFaRwAHL0chgI7EBPk0Qq3xQkGUbbfJASMg4l0+38qu/cFdlP4NPwQ+EU7DHdfwmL5CuADoj01xLLKHZUyx/8Am0t6nNA+mMiSHEeILr9HBDqPA3MTb+sLKEydqs83kpisNyOcIi8lJv+RhN6it+3XiaWCtwnHx9kILwcIXci+CmvtC3P8p0oaQQQStbLVc1OcOZJYAnoB2AMYntv2ItwsH80xfwC8Tyzz1JwvF5N0Qj7zOCWjhUKhUOg4poiMQ33q3/amlR+rafZDcv95hGNh7fhNKt+fSwNfhRTojdfN0faAyvcvE6ZKjfb1AqjoAcZeU9F9cs2a5qJ6XjKKWL74jMgq/DLfwLdS+EOsD5ybOot18+dLbV8i6e3amDKLMA+xfDENoSeYzfanCrOm1SQNJnQXixDBxSvAmzmOq4FNgX62R0q6GNjG9r2ZRah16xwGrGN7UGohRhHBwVG2/5gi1u4pxFwjx/Qh4Yi5he2rFb05HrD9f/WfeaFQKBQ6jikicPguIakP8TbfAzjYds09cSfbD0uaFbhP0k2VaoP3gQ8lbU9kJ0bUXXa1fHNfCDjZ9luSNiEqGAZlMDM1kWlZlMhoXEVUYDxKLCPUuNYtDpXrAItXgqHpM1AYBJwoaSAhhHxN0kPAOQq/iKttD5G0FuOKUQcSzpFXExmVK2iAiuV0oVAodBhT3FLFZMpTRA8IbD+RgsN/EYLIcchJ9lFa+lvUuITwPfhHg+vf47CPXgLYQ1JfIhi41S2NvBa3vUce/2JuWxQ4q+5aVdFiJ6IRV+0ac9kebvsYwvOhGxGYLGr7biIoeJ3QNexC64xqpmtwsZwuFAqFDqNkHCYPjgaOl7Q3oTtYjph0u0t6idAbzCPpcCJLMCfQW9Jbef72hDbjM+BYopyylgYYAKyd5apTE8sJB9LSUntB2/9VdLqcC3g2r90rl17G0UnUcQuhczgOID0rhqQ48gnC2GkFYNHUNrxm+yxJ0xCB0rHAKYqmYB8SupRTv8oHV6oqCoVCoX0pgcO3j+6SXqv8fKLtE3MJ4hyiW+bThEBxZcKvYEMio/AaERz8IfcvX7nOP509NbKMc4bKvpeyqmIhorPnJ4Sx0wDgHzmRAxzi6FL5U8Kg6VPG9XAYi8JyuhZ8DCX+1u4mOmP+UmG7PYbIpvyLCG5+JekLomJkF9tvSjoIuIMIdG6wfU39fWx/2ezDLFUVE6ZUVxQKha9CCRy+ZdhuuHxk+3zCrGoqYnJ/GtiTsGx+h5j8d6077Uki7T+gtiEndGipcHg5jyNNl0YAy2QJ5raVa11lu+a4uSIxkY8knCqfzu39gSGSHiaWRO4kKjq+IASUv8/jns/zxhB9Jj5LEeeXed3pgPeyhHPZ3GZiCQZJ/YHH0m9iUcYVuBYKhUKhAymBw2SGo0nWr4CbgPXy5yXISbUVtlM4Mc4BPEf0vRgHRXfK5zNoWI8QS9aChGsV7pK1/hLvEU6asxOZkBpT214+A5y7gM1tv5uln3/Mcw8C5s+AYcY87wBgn7pKi62IEs+l814PSbo7j18WWNL2Sw2eo4gjC4VCoYMo4sjJkw2JN/glG+2UdJWkJxUWzTUuSVHl9wjDpl9V9u2ncKR8gJauoevl12NEULIoEUisSvS6WDrFkWcTGYWx98l/F8nx3Zr6iUMIDwkIH42BknYmsgzQUmnxc2DGXH7oB/zD9mhHn427gBXy+AcbBQ1QxJGFQqHQkZSMQwcjaTQxUYsoIfyZW1pmT8z1+gLrAt8H7pX0T0ITsDfwZ4C00F4eOL7+/PRyuI4QLR6Tm98g3uhfBa6TtGmO92jbZ9Td/5cTGGKtqkLAU7YbmTNtTFRQbEpYYfexfYykG4CNiEqL9Ruc1+g+rVLEkYVCodC+lMCh4xlZ69eQk+HRhKnRVybX/P9GGDz9T9JxRHDwI2BHSZtVdAjdW7lUP8KtscqvbF+ero/nE+6XR0gaaHu4pLmIzMIg4AxJRxN/P5uQDaXqeBaYVdLKtgfn0sXChI/EPLbvkHQvIYqcTtIs9ZUWhG33XgqL7ZmJYONXua/6uTQVSBZxZNsoAslCodBWSuAwaZmeKCsk1/GvAWYiunIeUqsYkPQ7YGfgXSIL8Ijt44EjgcWA4yTdSixZfE6s578K7J2T7BfE7/azTP1/TGgcts77jQDulHRAgzEeQAQH/yZKO1/KUkzT4ux4HfAWUb75CbBrihshtBAXElmRs4ggYwFiWewpwhTqIkkLVz6PQ4BpJG1OWFiPJLQTqxNBzntE+emb+fwmmnxdSwgpOzORwVihUCgUvhpF49DxdJM0RNIzhB7giNw+CtjS9rLAmsAJClYgGkctTQQG1ZLKzYENM4MxGiDPfxz41PZGxHLFfwkRZB/gMGAgsQTwNjAj0R+iT55/ODGh15idKN0cQwQYf7bdnXjj31LS/ERVxH3ArMRkPl9eqz8RyLyf4/o70WBrNtvdgMuIEs3NiYChm+05gCNt70tYUS9geyZgU9smDKGust01P4/ziX4cJxMCyW1sjxM0SPqxpIclPfzJmE9a+90UCoVC4StSMg4dT3WpYmXgAklLEhqAo7JSYQxhrjQ7IT68xvYoYFS+3ZPVBz1sD87rXkwsEzTiBtufERmHd1q7boXjJB1FCBhruoT1gKUkbZM/z0AIJA8hlkIeISbyFequVRNIfp/GttXDiMDp75KuB67P4wcR5aOXAjVhZz/S9Mn2M5JeoaX88lbbH9Q/vO0zyeWT3lP1dpPPqFAoFAoTwWQTOEiaHTiJmIw+JN5s/2T7qom83uHAcNvHS/oDcLftf0/EdfoCc9q+MX8eQDglvk4sQXSV1N32iFzr70m8qW+U/y6XJZUvE70f2nQ/wuwJSZsxfgDxWeX70bTye5Z0J7AM8ZkOIybscwh3SgH72r657pybgMcdDb+oq96AcQWSt9reocF9VyS8HLYhPCXWsr23pJUI8eQjkpZrNu66+zSliCMLhUKhfZksAocUBV4NnG97x9w2H9H+uXpcqy6CzbB96NcYXl9iOeHGyrZLKi6NXxC2zOdKWpRYj3+feHt/J4OGNcl0P03Eh7Y/kvQJ4W0wM6FbwPa1kj4mtAmt0Zqo8W4ic9AD2BHolELOm4GfSLo9x7kwERANInQN5xPBT38iAzIWRYfL+2lsW/0G0N32jSnGfDHPWcD2A8ADkjYkumLeA+wE3J73n5cQXi6b5xTnyHakiCQLhcKEmCwCB6Jd9ee2T69tcHR+PDXf8LciRXKSNqa56PC3wK6E0+KrRKodSecB12dVwXLAiXm994ABaX18J+FzsCahE9gjf/4DoWPoR1RMjEXh0tgFOFTSL4hU/euEN8JHwLSSngCeIfQE/yIm1bsIr4PRxDLDLzKzsBdhv9yJyBB8kM+/eeU5FgNmV9hC/7o2FGA3YtJ9n8hIPEdkGKoMJqoWfkeYNL1EGEB9nEseLxL9IrYFVsnzx+T4h0kanmO+kygP7UVkBYYqelG8DhxK6Dw2zYDwQ2D/FHEemdUXnxGBzP+IoKSfpB2IFt4DgN8Q4svewCw5pkKhUChMAiYXceSEnBGrIrlmosPliNK/vsQyQf26PDlpnZrXWo5I2f+xckgX2ysCvwQOs/05MRFe4uj+WFvb305hevQ6cC+wYOocXiB6TywFnAe8arsPsUTxU9uLEULGBW0vTEzCLxOBwWaECPLHwOnACYR7JMDrtmvLFf8jJtRNgGNsL0ksO/QC5gcWIAKJWcnACfi97cuBDYiW1lcQQcTttuckhJaf5TV3Jib7eQktRC2L8ER+v2fe830i07JUiisvIUpHXwVmtt09BZOLp532QcCsua2X7V8QFtWP2J457/2Z7TtyzF2B3k2WQYo4slAoFDqIySXjMA6S/kqI5j4nWkVXRXLNRIerEer8EXmNa8e78LhuhxDLCm9W9tfW8h8hJuJmXGL7Z/lG/VfiLf4YYqLdKo+5EPhTfl+//bQMPOYish7LEW/b6xMZjmmJZYABhB6gytVZEfF06kIgPqvLgDMIsWIX4H7bj+ZzDpQ0NZFl6ZvnrAdsVinZ7EoEC/2Iyo3riczLF4ST5FsKs6sr8vi1c9wP5T26EZme64jumqcCNxAdNKHFTfJqYlmqNu6tAWzfLmkWSdPnvmttj6QBRRxZKBQKHcfkEjg8RU4gALb3SZHhw7mpKpLbiYkQHSatuR1Ci+iwVcFhZZyNXBrbwvBKJcZYsSAxER8KLF/RUDQbI7S0zq6Np6YPuRKoikp3yusfR2Rctspzt7b9bPUatftl6SWSHqWlKmKU7dGVe59v+zf1A5S0NBEE7Q38gOhfMZ6bZIPPpUqbnCMLhUKh0L5MLoHD7UQW4Se2/5bbmjkjNhMd3k2U+tXEgZsSb+BVGrkdDstUO8Aqki4mJrsZFZ0k9yFEheQa/8/qrll1abyPeAPvD2xBCP9q27cnsg07AVZYRn9YJxbch8hOvNP8o2rIhMSMhxGZlo+BxVM3cTOwr6R9MwBaxvZjea0fAHdIWpz0g2jAbcA1kk5yNM2amficPiX0KldIepYwg+pEAzdJWoSRR+Rn9p7tjxsES00pVRWFQqHQvkwWgUNOXFsAJ0n6NeGo+ClwIJECrzKQ6LfwBJGReCav8aikSwidwDvAQw3u87nCs+AUSTMQn09NBzIjseTQnxZR4XtEan/xXFqofZ61TpSdiLLJAbl9X+BcIoh5lxAsjt2u6Hr5LmHgBOGtsBDx9n4boV+YB+ib9xtHjNkKV9DS/vpVQi9SL4ysWU6fRixFfI8wWRqaE/tLhM7gNKK999PEZ/tUg2th+2mFA+Ytef4XROAzMp+19rn+hlgSuig/cwGnZBXJ4cA5koYS4tH6tuFAsZyeFJRqi0KhUENhzldoRmYRNiLEjBvZfia3H56HDACWtf2BpOG2p8v9OxMuiVMT1Rc/tT06l06Wt/2emlhLN6rgsH1PZgK2JLIqcwEX2f593m9/IuUPoTk4WVIvInPwACEG3YBYMtmKqJA40/ZJdVUlXYEPbHfPkspjiGBpGkKvcXY+0wnEcsOcRBXF3/P8lwkh5LqEhuMDQuQ4DZF52c3R++IYQvD5JXCL7QMkbUtkP0YTmZ7Vczx/I0pevwT2z8zEACrVNPXukTV6T9XbR/U8qtGuwlegBA6FwpSFpEdsL99o32SRcfiGmYYQ6/WvBQ0VhhOVF78gJjwAJC1GVBSsmksmpxEp9wsqx1StpacisgCPtFw6KjgkbZTXXie3r0gsK4wglj1uIHo37AasRLyxPyDpLqL6YSHiTf0YQog4F7CX7fMUbpT1bECLOHEPYgJfQdI0xDLFIKLcdVai4mMPIqD4e+Ua79teNnUoVwLr2P5U0oFE6eVfiQBo0cwm1cZxKLC+7dcr2/Yhkk59FD4Ytyj8HCCqaZZynXukpB8T1Sf07NSzwSMWCoVCYWIpgcOE+YLQIOxBBAj1nAIMkVRtYd2soqDKhCygm1Vw3Gr7fRgrcuxHBA5X2f60sn014FrgFdv3A/0lzUQs3ywn6S1aKhqg7ZbTcxKVEVXnyG0Yl2I5XSgUCt9RSuAwYcYQYsDbJB1se5y8d67FX0y8GddoWlHwFWhWwVE/EU5oYhxbfWD7wyYVDdCicdiXCVtOb9TGexbL6UKhUPiOMcUFDnU6hI0IAeC6RKr/14T50Du1YwFsj1A4Ut4j6W3bf69c70Zi4ruNls+zvqLgXsKMqfZmDfF2fZmk2QjRZdUCujXWzQqFkURlxu5EcHNe6gaU4xlBBAfzS1rb9m25dDBORUOD6/8F2F1f03I6aW/L6f7EUs2FQE/C/bJVijiyfSgah0KhUGOKCxxqSFqbWGZY3/YrmUp/D/g/olpjHFL8uAFwt6R3K9s3yutdBeyX256WdAgtFQXzExNd9XoPZWXE9oRm4QkaVCc04EGiSmJuYKDth/P+5+U+iLbXfyKWJe4gnCYXIibt+oqG+ue0pCOJIGpdYpnkUcUH9C4RrLSlSgPb76aI8R+pkYDorPkJEVh1JQKd/XNffRXJ40Tlxt+ySmY00W77Fkl75fFz2n6jDZ9boVAoFNqBycVyul1RuEqeBWxi+4XKrnOIUsqZaxvqqiSuICbIjYEjsgLiZUk9be9P9KR4NjMMWxBVD0sROoXFJD1IuF0ulpf/F1Ga6bzmcnnP/sDqkp4kKhZOzuPvzHNfzeucK+m8PG43orJhSWJCx/bLefxcef6TxIT8BfG7nze37w6sJekZSbcSeo6/pQPljkQDr88J34uViIzD94lgZw8iMNosSzQ/JuyjySqJUwhtw0f5WdwCHEXoPkYDP7d9fgYYXYjg5H3bv3AwyvZutvs4bL1ruozLiX4f46FiOV0oFAodxpSYcfg2VUkMIMoMXyJ6YmynMH6aYJWE7ftTAzBXBgtMTJWEpFto6WWxODAb8J/8HGqMVyVB2EWvSmQ1fk+UnnZIlUQVSfPkvRckdBnjZRuKOLJQKBQ6jikxcPg2VUmcATxvexcY22SrrVUSENqARn0foO1VEgvlPS/LDMNbku5gXMarksifPyKqJM4gyh87pEqiiu1X8xnmBK6WdLntt5sdX8SRhUKh0L5MiYFDN1qqJM4j2kOvSwj8ViGyCLUqiWnznNaqJGYDpm+wvUpfomPlIMatkujH+F0626NKoh9hyf0mkaW4jJicJ+sqCUl9CTOo6YnP8X0ioLq82TlFHNl+FIFkoVCAKVTj4OiQeSywA3CO7Vdy16eEOPJEYK/KKbcB22QFBJJmllTrgfEOsa4/CNhUUldJ0xFVEm1h3rxeN0IXMYioJNhCUvesRNiSlr4W5BgkaVagk6MN9iFEqr/GhY5GWTvnPapVElPlNRbO6w8CtpbUSdFRs3+TsT4IrCppwTx/2rzGdMAMtm8kBKJL5/4FbD9g+1BCu1CtkiCXKOYleoRUn61ZQNuDaNu9BLF0tBpRoVEoFAqFScQUGTikOPJE4k19L0mb5a6HiAlpDJXukbafBm4CXpI0kpjoaoLDuYGZbT9EpO4/JkoWuxEahRrrpDjyfkJnUeNjwop5GNHE6WHbjxK6hw+It+rnHQ2m5gYWknQBIXRcrjKmhwhr6XoGE5mCXxO6he8BwySNIoycuhDLCL2IEs+n8/mXqjzfoYoumGsSywxD8p6vE9mUHrltFPAWLdUdF0salcfOSVRJ/J0Qfo4ChgAn2/6MyJJsLOl2IlBrRNe85uPE8smbREAyDkUcWSgUCh3HlBg4fEmIBbewfaft+W1fS1Qs3EKKI7NKoqYxWIyYWGe03Y1I/S+Y13sN+CDFkT2JNPpChL/Ba3nMECIoWJEQET6V2+/Nfxck9AazSVo+U/q9gVnymgtLWiavNxVwWr51vws8artbjuvAynVrOogNgCtsr00sY1zv6PY5A1EWOTOR0agFO/2AmYiGWrXne832ssC/ia6is+f9jgYWJSouPgFq46gtZXQHFshtS9g28CPgHttdiQzJflmWeW8+2zZu0nfC9q22l7K9dF5nOC2dR6vHnWl7edvL9+jUo9GlCoVCoTCRTIkah44UR4qYsLsSGYDXK/vb20Ia2lccOR9RCTI18Bjjljp+oxbS9UiagzCB2jUFnU0p4shCoVBoX6bEjENNHLlieiA8l3qF/oS/wNQ0F0f2za9FbB+e+6riyCtz/6KM27a7L5FBgHYWRxJ6gjsJceTZlet2J9wja+LI2nPsW3mO+Su+CMfmtsVpyTbU37Mmjqydv7jtPRwtrVckRIqbEMs62N6b0F7MQ4gjZ2nLs0nqI2lI3dcDuW96wv+iJ6HfKBQKhcIkZErMONQspI8l3qQPc4tzZE0ceRzjTvz1FtIzAz1SVFkVR54h6Wjic22rhfS8mrCF9JbAD6snKQbcE/jMjS2kL3S0ql4T+Jfax0L6QdrXQroqjqwKO/+Tws5xkDQ1oT0ZRppcTYhSVdF+lKqKQqEAU2bGoYgjJ19x5A+A1XNs/QjDrL5Nji0UCoVCBzAlBg5FHDmZiiOJLMggoA/hSnmJ7SH1B5WqikKhUOg4psSliiKOnHzFkT8FbrT9Wt6/IS6W04VCodBhTImBwxhanCMPtn1Ubj+U8AXYjQgMqgvjrTlHVrnS9mGS/kBMsFU+y39HAzNJ2iV/rp/YWpvoVge+p+iquSARmHxKvIHPQ4tzJEQfh8sl7UtkUZajuXPkyUR243UisBpZd99J6hwpqQ9RNVHlM+C/wGqSfgpMB0ytaJN+ULMLlqqKQqFQaF+mxMChJo7cGLhH0tu2/04sYZzk6Hi5KPHWPVWe0po4skZVHPkn4u39fhrzie0LFB0h1/0K4sgPgRds95V0J3AE8JDtjyUtCVwkqXPdvf4C7D4BceTbRAXGijmGy4A/Nxj3/Xw1ceRCEyOOtP0EoZ1oSn52y9s+SFKXrOwYjyKObH+KSLJQmLKZEjUOAGRKfAPgkIo4srbvGWI9vXNWLzxLdIx8OYV+jwFz5OHTE62xzyYm36GE2PEDQoR4DFFy+Y/K8seMkg7I758lhJAfEYHKCymO7A68QugYZiPesOuZDbhT0udEcDMdsC0hRPxjChovBY4nxJGPAssAH0v6BDiXCB5fyfE+TZShkmPvTOgdbpU0FNiK6Oj5D0nvEcLNS4FriOWLoTne+/PeAyW9JGkEsRTyW+B8oJOkdwix5JdEZ1CABSQ9KelxSXcDKCy8z5X0hKTHskoE2iamLBQKhUI7M8UFDranq3z/akUc+bnt4yv79iDW7mcj9BAPpqhwRmJyfDvfop8h3nyXBnawvTChNZiVSK1vCUxneyHgSNvvASfnPc4jlgg2sz0N8aZfa+f9GnBB3nMAUTb6srOFdvJ8ihbfAE6wvSAhYOwKLJv7HgYWIIKkU3Ks3QiR4rO2h+W1Lkj/ifOIAOiJfO7jbC9DBD97EkHOsUTlRPe87rLAb2wvlWO5K++9EfAqMKvt2XIs+wAHENmT7rYXyM/lPEKPsX5+lrVgbmwbbkJ0ef6ExJRFHFkoFAodxxS5VDERNBMVrgOc62iaBXCspMWB+QmB4D00Fg0CIGkGolLjrtx0Pi1mTdBcUNmICQkYFwGWJLIHAJ0JTUeNsySdnccfZvstSe3WhntSiimLOLJQKBQ6jhI4NEFSb0LI+A7NRYXrV74fTbylk+fZ9peNRIN5zFrAWRMYRlVQ2UXSVURQMh0RSAzMpZNpmICAMQWHT9leuW57L8KB8VVCZzGc0Dkc0cpzd3Qb7t0ILcWzhC6ij6T3ba9Ud5lW23BDEUcWCoVCe1MChwYo2lWfDvzFtiU1ExXeSpgjDSQm3bVsfyDpPOB6Rbvp8USDydq2h0n6UNJqtu8hBJB3SWq4hGR7yxxff+AKYCfbD0t6Obd3obmA8VlgVkkr2x6saK29MDH5fgL8ijC9upUo8fxaTpMTGEtbnCaXI5ZG1iI8IPZoJqaU1Nn26EafWRFHtj9FHFkoTNlMcRqHVuim6InwFKETuAX4fe47mxAOPirpSeAMoIvtmwhvhYeJEs4D6q45J/BKvjnfCzwvaU9iiWMqRVnl68ApCifF3QnNwDzEksAFOZ5fNxt0VhfMRkz6txH6hKdocXd8ijBpGp1juCW3vwKsUr1WTr4PEmLPCYkpV857PUAsQQz7CmNZDngxt71FLPFMC9wraWR+Fu8S4smngS1y22Bgz3SaPB5YOUWY2zb7fAqFQqHQvpTAIbHd2dG4aQnbS9s+PtfwsT3G9sG2+9he0vaaNVGh7WMcjaEANspgoC/Q2fZzhMjvA6Jy4CPbZ9nuB4zI+21ECCinBn5ge7Es8+yT112KKJMcp/IDGGz74fz+A2DzFAn+FhiYItA5CFfH2wih439t9yAEnm8QARLA6+n50JWwyT6e1sWU5wDbOtwfryZEirVlmraMZRtgr7zuDISGYQPC1bJbXncHYgnmLGDl3HYDLf4YwwnnyGVtj5NSKOLIQqFQ6DjKUkX7MdINGjPZvlXStsBfiU6Wzag6QgL8QNKPid/RHMSEObTJuVWR4HrAZpVyz65Eer+Z0PE5ogxyCKGfuMH2UIUvxHhiSkkzEr0pDpV0Yn7/boop2zqWwcBvJc1NmGY9L+kJ4ARF87Hrbd8jaWngpQzAIMSj+5BVKbSIMMehiCMLhUKh4yiBQweTeoXFiLT9TLT0r6jn08o58xPLHivY/jA1E11buU1VJChga9vP1o2jmdCxFy2mUj2JCojNiLLLRmLKGQFs98+fl2JcfcMExwL8R9Eme2PgRkl72b5dUq2E80hJtxH+EK1RxJGFQqEwiZniAgeFRfF0+f1GxNvruoSS/9dAL9vv1B/byvVuBHZs5ZD9CB+FQ4FzU5z4BfCFpD0IDcHxdedMT0yKwyTNDmxINOFqCzcDV+eywzBCe/FTmgsdx2L7PUkHAb8B1qCBmNL2U5I+kbRSChlbm5VvBvaVtG+KTJex/VhWrLxo+xRJ8xKZkGeAD2xfJOkjYmnkT0CvmriSEI9ukdmROYk24hu09mEUcWT7U8SRhcKUzRSrcZC0NrGGv6FbrKPfA/7vq1zH9ka2P6JFXFn7OkbSIsQE+ALRIfNu4JA89Uyi5HHdBtd8nHCnrDlYDmryDI1+f0cQv9dOhPbgA6JCpKHAs8H5VxPGTisRWoRjJT2e4181j9mD8H0YAkxLBCiNOCLHMDRFnkfk9h8AT+b5SwIXEP02HsxthxGmUKOIgO6yXMoYQ2pDCI3Gzk3uWygUCoUOYooMHCStTojuNrH9QmXXOcB2it4R9efsLOnBDArOUPaEkPSypJ62OxMlkt0I4d58wKa2FyMqGrYlzIx2yPLLA4GDieDgPGAaSYdVbjmUEBPODtxt+zxJvbJCY3dCjzAPUQrZX2HJvJ/tkYSG4P8crbfXBOZKoefvgJuI0tFZgO1tv0y88Z+Wb/23EJmI2R0tq+fNcz4jqivWIwKuL4HnCdvphxXW2r8GVleLtfYmRLAxBnjf9iaZCVkktxk4NjURcwAvE4HOiJrw0/ZttpdJYWqtgRe2ezlcOAuFQqEwCZnilioIpf7VQH9HT4oqw4ng4Re0WD8jaTFgO2DVTPOfRjRquqByzArA1oQAciqilPGRyrW72F4xl0cOI0oyISomliQ0EA9JuoGYUHcj3vpF+BrcRdg0LwTsavv+9DqYy2lDXdMf1LFBPi9EpmCY7RUkTUPoGW4hyiN7EQLM2Yi+HOdUrvG+7WVTA3ElIfTcn2j1vRSwKXAdsGguSdTGcShhIf16ZdtYC2lFM7FbctkEwpthKbfeWrurpIeJwOUY21fXH5Ci0h8D9OzUs5VLFQqFQuGrMiVmHL4A7iMm0UacQpgb9ahsW5uYXB/KVPraQO+681YFrrE9yvYnxERapZl99K22389MwZVEVqIfcJXtT20Pz+2r5fHV6osXCbOmUyVtAHxcue5xkp4jljqOzW3rAbvkMzxAZB3GsZC2/RYwIQvp/fPnDwhviBdpsZDeigiCoMVCek+iKoO810UwtpnYBC2k65jP9vKEruRkSQvUH2D7TNvL216+R6ce41+hUCgUChPNlJhxGEOssd8m6WDbR1V32v5I0sW0dImEeOs/3/ZvvsZ9x7GPrt6y7rgJlQ+OrSTIioulgfWBvYnnqqXzf5XeDPsS2YPl+OYspDcGHskMSZuerRm2X89/X1S0Fl+G0JA0pFRVFAqFQvsyJQYO09oeIWlj4DFJPyeWBPoDq0i6ADgReIgQ/kGYFl0j6STb76QGokeKKmcjqiAGAWdIOpr4XDchvQQIQ6jFCIfJKv2AbSTtR+gOtiAm/jHEm/oxxGS9JVFRMA65dPC57StS+3BR5bobSjokz++ur2khnXwdC+kNCU3GPcQyz+1qYiHdDEkzAf8kfl8PEFmfP7V2Tqmq6HhKlUWhMGXRpsAh/4c9T/V424921KAmEcsQb/df0GLM9CkhKjxQ0VBqPwDbT+ckfEtWMnxBZCReIZpgfZxvwNcSosa3CSfFZtUGVd4mRJVzAxfVRIEK74YH85izs4yxV+0kScpzzqlUV1QzIhfaPkDSmsBAQri4LrFM8mie/y4RrFxBZAueJppdPdpk7B8QLb7/kRoJiCqRT4jAqisRqNSWMo6TtFBuu42wkH4G+FtWSXwJDLD9WQxn7LN1sf1lg/svRiytfEhYXu9n++kGxxUKhUKhg5igxkHSEcRkeApwQn7V+w5MTnxaqarYwPY8tq8lfBL+TFZV2N6fcVPnUxFVDmOIzMFDDa7dmQhGOhNv7TV75CHAkpIeJPQVtezBvUSAIdrOVJkVeZKYQIcSAV1nog9E7bo1HcRgonX32nmfqQg9whjgn07rbFr+FqYiJuX5Kvf8lVp6QnQhJvwviUzB7bbfBG7PfSZKKwH+kfccDSxje0LLMPNKup0IMsbD9n22exPC0btt/73RcSqW04VCodBhtCXj8ANgAdufd/RgJhEdWVXxM+B/QE9iAq0aLH3bqyq2JrINc+SxH1WuUV9VsY7tTyUdCOwv6a/EcsqkqKqYIC6W04VCodBhtCVweJJoivROxw5lklGtqvhFg/2nEN0cq1mValUFhFdD/eexKnCK7cMAFH0cqrRaVZHn1KoqTFZVVLavRnTibFhVQTSAuqVy3eMkHUUsZ9Rso5v1q+gHHGD73Mr9qtRXVQzKz2FqIqMxjJaqiuuB6/P4WlXFpZXn70c0tcL2M5LGq6qQ1Ae4sG4Mn9leia9IEUcWCoVC+9KWwOFoQkT4JC2VAdiu79Y4udCNlqqK84jW0uuS4kgii1CrqqiJI1urqqiJI1ujLyHkG8S4VRX9gBXqjm2Pqop+hPvjm0SW4jJicp4sqipsP0F8ZuOhsKg+DlhU0tPARmli1ZAijpw0FIFkoTDl0BYfh/MJH4BjaNE4nNCRg+pobI8gnmkH4By3WE5/SlhOnwjsVTnlNqL6YTYASTNLqmkA3iH8EwYBm0rqKmk6oqqiLcyb1+tGCBUHEZUHW0jqnpULW+a2sSiYFehk+wpCpFitTLjQYc28c96jWlUxVV5j4bz+IGBrSZ0UvTH6Nxnrg8CqkhbM86fNa0wHzGD7RkJQunTuX8D2A7YPJYSY1aoK6qoqqs/WWkB7AVFZcRexzPNdyYQVCoXCZEFbAocRtk+xfYftu2pfHT6yDiTFkScSb+p7KbpBQggetyOEg1fVjk/l/k3AS5JGEhPdXLl7bmBm2w8RuoCPCW1DN0KjUGOdFEfeT+gsanxM+BAMA96z/XBWrLxEVDG8Dzxv+7G810IVceRylTE9RJQo1jOYyBT8mtBvfI9onjWKMKnqQiwj9CJKQp/O51+q8nyHpjhyTWKZYUje83UiM9Ajt40C3qKlGuRiSaPy2DmJqoq/E7bUowjR6Mm2PyOyJBu3Jo6UtDhRDXMQkd14hhZjrOpxRRxZKBQKHURbAod7JB0taWVJy9a+OnxkHceXhFhwC9t32p6/UlVxCymOrFZVpDiyF1Gd0I1I/S+Y13sN+CDFkT2JZYuFCD+EWgvtIURQsCLwc+Cp3H5v/rsgoTeYTdLymdLvTTg79gQWlrRMXm8q4DRHH4p3gUdtd8txHVi5bk0HsQFwRVZV7A5cb7t73u8TYGYio1ELdvoR7b//V3m+12wvC/ybsJeePe93NFHJ8XleqzaO2lJGd0JY2w1YIqsqfgTcY7srkSHZL8s4781n28b2Go1+ccRyyz359QxRtfHv+oOKc2ShUCh0HG3ROCyT/36/ss3AWu0/nElCR4ojRUzY3YkA5QeSdiAm4rkUbbTfpsV+GSYgjpS0N9FMajVgdeDdrKjYBDgKWETSB4T50y8r1/0q4shLicn/0xz3UMatqpik4kia0yU/h2WIwOYSwleiYVkmFHFkoVAotDcTDBxsrzkpBjIJ6UjL6SvrqireAKYjfBt2INp2/4txlypatZy2fbqkuSqbPkuNwpnEGv9HhPhwT6J19sRYTn8J/MT2uQr3yOXrxvSVxZGS1ptYcWSzqgoi0Btiu+ZMeTXwfUnnNzGMKuLIbwFFOFkofLdoiwHUNJJ2lHSwpENrX5NicB1FiiM3BnbKLEA9NXFkLbBqTRxZo63iyM7ALJKeAg4A1s3rLU4IC/cGdiWMqLpL+iOZ3q9co0dlbJ1sX0JkG5ZNwWR/4BhJDxEukJ0kXUjoGwZKelHSzyviyNGkOJLQTiyQz7kA0db735LuIQKfVSWtJel+SU8q2nEPJ7IXI4ili37A0wrXyG2ADYnqk1/mc/xI0t2S/kPoQHoSQcnaiuqdi4lArS+RURhFZHkOzM9uVkWfioPyc26UOSoUCoVCB9CWpYpriFT0I1TKMSd30i9gA+BuSe/W7XtPbbecrp3zkBpbTk9Xd+vewDu2l0ix5CjC8nkl4Czbv8i39IsIkeFswOC0nK6OvXYvJH1ClF3+hnC/fJrIMjxIVFIcQpQwvkWk9TclgqOtgM2JwOG1PG8moq32MCKr8T5hVrUAoWkYQCw7DKPFllrE8sQswPxEtuOEFFTOSQQc5xABxE7A9kQ1xZu57SFiCWJa2/PmM82Y176AyJLcJekPREbmtvwcXwMWqjcnU2mrXSgUCh2GJuQCLOnJmjNhoXUkTWd7uKTuwN3E5LUZMNz28YpeE7faXiiPP5AQBJ5MCB2rZYnT2F5M0uGV888jxI2X5/l9iEl9F+Bx2wMkvUMskdSYFViEyG58YfuPee5/gHVtvyZpNCHYnIPQU8xOeFs81WRM7xMCyS8lTQ+8YXs6Sf2Bw2rLW5IuJ6ozam22ZyAyOaOIQOIi4GrbQxT9UB4GbqTFzKoH8EQlmFiAaP+9bGYcDptQhU/vqXr7qJ5HtXZIoYMpSxWFwuSHpEds1y9bA23LONwnqU+a8hRa58xccuhKpNofVUupZ41q1mY0kYLvBHyUqfk2k7+TJ3IZ4iUiG9AJ+L7tUdVjM1tRf+/a738kUfppwoPhKiJL8JXHxLj9PRpqKnI8qxPLRedJOtH2BRrfzGq/r3CvQqFQKEwCmgYOiu6FzmN2k/QiMfGI6DWwVLNzp1Rs7ziR530s6SVJ29q+TDHLL2X78UbHp4Ziedt35qa+tCyb3ALsSyxNIKmv7SFtGEP/PH4Zolx1BOER0WhM9xO9LS4hlh2a0ayNd0+ixPMsRc+MZSXdSEuL8DGEzmFZYFZJzxOBzb8I46c2U6oqCoVCoX1pLePQVufDyQpJw21Pl99vRCwTrEs0lfo10Mv2O/XHtnK9G4EdbX/UymE/ydT6e3XblyfW6g8n1v7/llqKqQh3xIaBA2noJOkMIlvwKZFtgPCJeChFlWOA4ZK2a+0ZqqSWYihRBdJsTL8ELpL0W8IYq1n78LNp3Ma7P9Fx8wuisdguhKHWuWppEb6V7X9J6gucTpS4rgPMIGkI4X0xSNJ2tq9u9jylquLbQVmuKBS+O7RF43Ch7R9OaNvkQi0YkLQ2cAbRvfGF1BLsDvzD9oHVY9vhnncSTaQerts+gMgc/Gwirini9zemwb7zSC2EpDWBM2u6iq+DpM62R6eGY6RtS9oe2MH25l/3+pX7dGlWXlk5Zmbgv8DcWSXTkKJx+HZQAodCYfKiNY1DW5wjl6i7WGfCE2CyJdfXzwI2sf1CZdc5RBnkzA3O2VnSg5KGSDojPwckvaxoN42k30l6VtK9kv4h6YDKJbbN85+TVLVJnkfSnZKel1Rt5b2/otzxSUm/zG298vo1y+l5JJ2XxzwhqZEmYDBpjy2ps6TjJD0kaaikvXJ7J0VZ5TOSbpV0o9IkKp/vWEWFxLaS1iOqNT6V9BHR0Or/JB0j6em87vF57rY5tscl3Z3buko6N8f7WAY2SBog6Vq1YjldxzbAvxoFDSqW04VCodBhtKZx+A1wMNBN0se1zYTD4JmTYGwdxTTEGn5/28/U7RtOWk4D1Ul8MaKHxaq5Vn8akca/oHLMCsS6/9JEWv9RooS1RhfbK+byyGFE2h3CxGlJQlPwkKQbCG3JbkSJpoAHJN1FlFwuBOya7pHLAXPVql7UUsJYZYN8Xgi3zGG2V0htwSBJtxCBYC/CFXI2ohzznMo13s9Khp5EKeZK6Wp5YH6eHxK21YtmFqI2jkOJjM7rlW37EBqZPpIWJUpca86RyxI6itbcI2tsT5SUjoftM8m/0d5T9Z5Qt9FCoVAofAWaBg62jwaOlnR0GxwTJyc60nL6mqxmGCXpurr9NcvlR4hJukbVcnphKpbTwLaEDuJKwufgWuAV27U+FC8Ci0t6CfgJIYys8VUsp/9AlG0+SgQqT9aN/dtiOU1+TnMAfQjxZasUcWShUCi0L61lHBbNN/LL1KCplaOD4+RIR1pOt0atFLJaBgkTsJxuwNgSRNsfSvoRcAQtJYxfyXK6tuQCXGp7n1w6qA96vrLlNNHLZB8i8PlKltNt4AdEL48v8t5NNRFFHPntomgdCoXJn9aqKvYnDIxOaLBvcm5yhe0RkjYmOn++bbu+SdKJhJth1XL6Gkkn2X4nNRA9bL9SOWcQcIako/O8TWjbks66eb2RhB31ICK4OQ/4S15rSyK78EXtJIXNcy9iMh9BOD5uIOnzyjHrATsCi6XG4DKiwuMMIouwCfAnwulyJUVFwwvAtHl+57zurfn9+YTl9EKEx8LaRKXIcOAS2+dI+hvR5fPRfIZniKqVWYlulrcTVt/rEUHGvMSyzOPAAgrL6dHEksrqis6ZfyMCkC+Jv8sdgDsV7pnT5efWrKNmoVAoFNqR1pYqfpwTySG2B03CMU0SPOkspyfEg4Tl9NxEEHB2bp+FCBw+ITIKfRucOxdRTrogMUFvTZRKdiFcF39OaCk2AI4lWmg/DWxE9MP4D6F/WJOwhn6aWHJ4O8e+BxHErJvjGET0h/gXoYV4mahMOQXonSLOOYhswHa5bHF0Hnc24Wg5LbHUs1/eb33gMaJMc0VC49CaJqImnHwW2JkGmggVy+lCoVDoMNpSjvmY7WVaPagANLac/ipLOqor/1SlXFPj203Xykr7A3+wvXpu352wef438cb/Wl5uaqLnxR6SXgbWqGVM8tr9CeHr3ER/ihWIwKWRZfRGhMX1uXn+lcDFuTQy9tqK1t/jjSGv8Uh+XZ/P9bmk04meGJcSnUbfzwDuVNu3573uIYKJZfM+u7X2mZZyzG8XZamiUJg80Ne0nL5N0tbE/8iLQr11xrOc/prXWxbYR9JfiDT97JJGEm/b0yrKMs8HnAHENUSb7R5EpuEp22sAKHwq9lSYJ81JvOlXl1I+JTIpw4DRtt9SKCAbteHeaALj/qqaiP0lvWV7G01EG+7WKOLIQqFQaF/aEjjsRawrj85Jq2Y5PX2HjmwyZGItp1thJaKD5A5Eun9JQoNwOFF1MTexzLAi0TL7HqIU9EzCovlWST+0fWFuv9D2QZJeA06QdG5NYEg0jLo8g4VHJa1Pc8voQcCuks7P+/YnLKLruR/4q6QFbf9X0cJ7LmLJorvtGyUNAl603U/SArYfkDSCaMp1H6FhuEzSf4EfEpqIZ4mgaoIUceS3l5J9KBQmTyYYONjuMSkGUhgXRT+KhYlOkdsDqxP2zgsQ5ZWfEvqInoSQ8xdEieJFhMZgjKQTgVMk/YroeHlDXv5LWgSV7xAmX/0kHUoEJEcS9tt3EWWgHynsod8jqjP2IfQSnwL/Izpq/k7h/TF7fr1HBDxjgKEp2vwfIZDcCZg/9SIvAkelKPK5DE7myvGNIPpu7EBkUB4EniPKRZ/PcwuFQqEwCWmLcySSNpN0fH59J3tYfBuos7fenFge2pnQHMxNVFe8kJbYPYmMxGmpb/gNcKftvSs21BcDbzkakv2NECMCbAU8lxUi6xHixIUIAeZyRE+Jg/K4uYiswrvA6bZrgs/7bXcjApqliX4dyxE9M/4vjzkIWMR2d6IHyFLAKsBetqclKi2WJsSh2N4KOJcIfHoSAcPZhEfF74gsyrpEgLQEIfgcDxXnyEKhUOgwJhg4SDqGeJt9Or9+kSWHhY5lB6KpFPlvTSewQOoU3gbetD20lWuo7uf9JD0FPAD8Mbetl1+PEQZQixJBxFhDK9ufML63wwo5jvuI8tyB+fMhRJADUWEyUNLORJYDYpnjREk/B2Zs4L/Qj8iakD4iVYOo22wPS5Otp4H5Gj207TNtL297+R6dSsKsUCgU2pO2aBw2AvrW3mJzXfsx4g230AGkr8NaQB9JJnwKDPyVyDj0Vdg/D5K0me1rm1xqGaLkssZJto+XtBnh8rgAEVwcbfuMujH8cgLD3NP2w5L6EE20Vm5wzMZERmJT4LeS+tg+RmGrvVGOf32iBLQtfFb5vt5Iq1AoFAqTgLb+j3dGIk0MUZJX6Fi2IYSMe9U2KHpVzFP7Ob0mDiICuPECB0lLEen9H9Xvs32tpD0IL4ebgSMkDcxS0rmI6oq2Glo9C8wqaWXbgyVNRWQI/gPMY/sOSfcSOo3pJM1ClIVOp+jvsSgwpHK9ewgNxO2pd/hKYsh6SlVFoVAotC9tCRyOBh6TdAfxdro6sXZd6Dh2YPz1+ysYP8tzNXC4WrptribpMaA7IXr8ue1mnSb/QGggFsuvwVFQwXBg57YaWqX/wjaECHMG4m/qZELEeFFuE3BK2nkfQTROGwo8RZhJzVG55GnA3yQ9QSxvDLD9WY6tfullgpSqim8vpaqiUJg8maABFIxtKrRC/vig7bc6dFSFbwVf19CqleuOY3SV2zYl9BFTE2LQnWy/nf4TCwC9iaqMIwkB5dSERmdr2883u1cxgPr2UgKHQuHby9cygFJLg6ua+9+cWY//SrPGQoXvDO1taNUa9wLft21F465f01KdsTjQz/ZISacCf7Y9UNLUhP5jHFQspwuFQqHDaMtSxWnE+vJQIlW8JJFinkHST2zf0trJhcmXDjC0ao25gUsyuzU18FJl37W2R+b3gwmh5dxEuep42QbbZ5J6jN5T9S5up4VCodCOtCVweAPYw/ZTAPkG+gfijfBKoAQOX5Emqfq9gRG2L+jge79MNKwy8CGwi8ft8vlNcSpRYnkRsSRxeGVftZX4xZIeICo2bpS0V62PRSOKOLJQKBTal7YEDgvXggYY2ylyUdsvpmCt0A7YPr0jr59W0rVf2JpZlfF7QlewZ3tcu2I8NTHMAPzd9iOSzm3lXr0Ji+pTJM1LNOFqGjgUceS3l6JxKBQmT9riHPmUpL9JWiO/TgOeljQNUbZXaAckHS7pgPz+TknHSnpQ0nO1qglJnSUdJ+khSUMl7ZXbp5N0m6RHJT0hafPc3kvSs4pmWE9SKedMBhPOkEiaVdIVee2HJK1a2X6rpKcknS3pFUk9G11b0q8qY/t9nj+tpBskPS7pSUnbAd0lfSzpC0mfZ8XO4cC/FX003iNKN+8nXCN3lTRTjvnfwLuSPs19z7X/b6NQKBQKzWhL4DAA+C/wy/x6Mbd9QTRYKnQMXWyvSHzmh+W2PYBhtlcgqlz2lDQ/YaC0pe1lid/JCWpJBy1E2FIv0WBJYgOipBPgz4RB1ArA1oTVM3nv220vAVxO+CrUGHttYJH8eUXSulrS6nmPN2wvbXtJot/GrETzrqltT51jvybHcLLtXxE6hwNtz070z6h9Bv8jhJrTAtsSDdjGQcVyulAoFDqMtjS5GgmckF/1DG/3ERVqXJn/PgL0yu/XA5ZK3wSI9P5CRMXLUTlRjyGyCLPnMa/Yvr/u2nco3CmHEyZREE2kFq8sP02vaLTVj+iRge2bJH1YuU712lXraoiulgsRhk4nSDoWuN72PZK6EMHO3yVdD1xfHVx6P8xo+67cdD5w2QQ+m7EUcWShUCh0HE0DhzTgafY/XdteumOGVEhq9spVa2UB+9q+uXqgpAHEW/xy2f76ZaKEEirCwgprAh8BA4HfE2/tnYhyyHHsnyUtDdwgaQxR6VCLLGYjOmSOPZS0rpZ0J/Aj2w/nNZYlLKaPlHSb7T9IWhFYm3DJ/BlhsV1jHWB2SU/n5/AIsXQxOH+uWk/PL2lO2280eM4ijiwUCoV2prWMQ6MumCLWyUufim+Gm4GfSLo9A4SFgdeJzMM7uW1NmjR/qmL7S0U/iickHUlUx+wLHAcgqa/tIcSS1Pm2j5V0C2E/DuFM+Wrd2I6QNDB/nlXSbMTf2Ae2L5L0EfCjzGR0t32jpEGM2x77e4R24SVgL6KJ1jVES/BtaPETAVgD+LxZ0ABFHPltpogjC4XJk6aBQ3U9XNIywI7EmvJLZBvkwkTTPUWANU5s43lnE6n5R1PD8C6wBZE5uC6zRA8Dz7TlYrbflPQPYB/g58BfFVbQXQinyL2JwGE9ST8kshQjiHLORYEFASR1A3YnApbXgakIy+wt89r7SPoyz70d6EFkMRbIY9+qiTGB/kTnzkeB0wn77BeJEuAx+bw1tqRxRqVQKBQKHURrSxULEz0TdiBU7pcQJXdFEPk1sd2qKNV2/8r375Hr+FnueHB+1dOoOyWEYVf12r3qft638uN2jYYDrJ//3gK8lb0jXiNEsxAZghG2v6dorvUoEUiMBLYielF8QgQN72bA8gzRS+PeLKu82fZiis6dj9h+HPh+dSAZ5KyVXTmnIZY6FqYOFefIQqFQ6DBaW6p4hhC2bWL7vwCS9pskoyp8m+gGfExUOYwk9Af1rA6cAmB7aGYtICos7rL9AYCky2iZ6JuJMZuSAcN0khYhGnM9ULt23XFFHFkoFAodRGuBw1ZEK+Q7JN0E/JOJ6E5Y+HpIGk10phQhlPyZ7fsmwX3PJpZQRmYL7O6EjmEl4IEJnD4zcCuxtDGzpP1sn5T7lpC0C3ViTEm9gPuJqozlgMebXPsfxN/lYvl96wMp4shCoVBoVybYHVPR0GpzYsliLeAC4KrSo2LSoIo9taT1gYNtr/EN3X8ZwvdhAaK3xPW2l5S0P7C47R9JWpKY9C8nqjUGA9MSwcD5wBO2fybpYuAx2zUx5kbAnwgtzZXARrafk9SJ6Mp5eh63GHAtIQid33arGofSHfPbSxFHFgrfXtRKd8wJGkDZ/tT2xbY3JSaLx4AD23mMhbYxPdFfojW3yD9ktQT58x8l/SK/b6uzY829cvn8/m+SHib6SIwigkiAhfM6PwS2kfQCIWJ8GcD260Qb7O6EV8PLhA/FAYQYc11JIyWNAo7Kc4YSf1/3S/qMyFocWhsLUdUzJ5EtO29CyxuFQqFQaF/a4hw5Ftsf2j7T9todNaDCeHSTNCTFhGcDR+T2Zm6R5wC7AOTb+vbARZLWo+3OjmPJbMNvM/JcinB8fNz2y0QDtPdsL0MINu+wvVWO8d28xN3As8QSx8x5Tk30+T1gfdtdiaWNGvMDl9meBliF8IxAUk+it8ZstmcmKkjGc44sFAqFQsfxlQKHwjfCSNt9bS9KTPIXZIAgwi1yKNG/YS5g9pzQ389lhfWI5YD3GdfZ8VGinHIhQj+xrqI3xmq2hzUYww8kPZrnLgEsXtnXzMVxuxzbU8Asuf8lslRU0oyEO+TdefyFlXP7EZoabD9JtHSHqLJYHBgkaQiwKw08K1QspwuFQqHDaEt3zMK3BNuD8617VsKJsZlb5NlEP5HvERkIqDg71l+3kbNjZd/8wAHACrY/lHRe5T7Q2OES4JLUMixPlHGuYPstSYdP7PPnM9xqe4fWDipVFYVCodBxlMBhMkLSokBn4H1ad4u8itAaTEWIDaHi7Gh7uKS5CHOn8Zwd6247PWGyNEzS7MCGwJ1tHXOWUF4I/IKK46jtjyR9JKmf7XuBnSqnDQJ+QFT0LA70ye33EyZVC9r+bwp357LdtENmqaooFAqF9mWKCxzqqgQ2Ak4G1gV2A34N9LL9Tv2xrVzvRmBH2x+1csydwAG13g2V7QOA5W3/rJVbdMu0PMQb9662RyusnZu5RZ5JmC6NJFwm97d9S1YkDE7vhOHAzoT743GKXhRfEGZOY7H9uKTH8vqvEpP6V+XYHEd9ecNuwDmSauZSNU4Dzlf0qniGWO4YZvtdSfcRNtnKZ9idVlprF8vpbz+luqJQmLyY4gKHGpLWJkyL1rf9Sk6m7wH/x1eoGrG9UceMcOz1OzfZ9T6warpJNtu/HlEJcyawkO0/E62rq7xAZCPq79u/8v0AAEmdbY+ubO9V+f5hwi4a2+cB51X2vUEsmwAcXtn+CFBtlvbr/PcLYGfboxS21P8GXpG0ClFVUQvm7iXMqQqFQqEwiZgixZFZTXAW4Yr5QmXXOYSob+YG5+ws6cGscDhDUufc/nLqDpD0O0nPSrpX0j+y7LDGtnn+c5JWq2yfJ0sfn5d0WOV++2d55JO18kpJvfL6FwBP5rnn5TFPSNovU/tbE34JzxM+CnPl+Z0lHVcpydwrt3eSdJqkZyTdKulGZevufL5jUxy5raT1JA1WlIFeViuHlHSMpKfzusfntm1zbI9Luju3dZV0bo73sVxmQdIASddKup2wpr5X0uPEsstPbX9O2F53JVwspyGWYt5u8Lsq4shCoVDoIKbEjMM0hIlRf9v1zaCGE8HDL4DqJL4Y0cdh1dQUnEasyV9QOWYFYsJempjQHiUqCWp0sb1iLo8cRot184pEP4kRwEOSbiAmyN2IEkYBD0i6i/BwWIhYrrhf0nLEGv+SOYYZUztwBeGbAFGJcXV+vweR8l9B0ethkKLj5XJERcTiROnjf2gRVQK8b3vZDJCuBNax/amkA4H9Jf2VaDi1qG0rKiYADiUyOq9Xtu1DtGXvo9Bs3KLoiwKwLLBUIxtpGCsOvYMoCRXwF9v/aXBcEUcWCoVCBzElBg5fEK2a9yAChHpOAYbU3pqTtYnJ9aFc0uhGtJWusiqxHj+SsEO+rm7/lal1OIpxyxZvzXJJJF1JlCH2IIKHh4GTiMl6NcIx8RXb9+e5LwK9JZ1KtJ2u6gSOS03B3LQ0wFoP6Cdpe+BLQmB5NZH+H05YSe8J3FE39kvy32o5JMSb/2BgGOEr8XdJ19MStAwiTJoupaVssx9wKoDtZyS9Qkv/ilubBQ35+SxIfLZz145XlJDe0+ycIo4sFAqF9mVKDBzGEIr92yQdbHscwV6+sV9MvBnXEHC+7d/QOksS6+6NygWblS3WvxGb8DQYQQg3XyDEgjXGWixneeTSRPfKvfO5ds/dv7J9uaR9iezBcvkcbwN71ISaGcw8RYsB03FEJ8sqtXs2LYeUtCIRYG0D/EzSurb3lrQSsDHwSGZIWmNCLbK3BO63PTzv+S8iYGsaOBRx5LefIo4sFCYvpkiNg+0RxGS2k6Q9GhxyIrAXLRP8bYSlcs3BcGZJ9cZDjxJvzj8hAodNgC6S/gmsQEzI3WoHS/obsWSxY2oIugFbEGK/x/L7nkQAsTkxOW4KLJi6gWNz6aAT8ea/OLCDpGPzFp0Ungt7EV0oTyfcHJcABqZWo0+e/zixzHI/MC8hcpxG0jlEdcbtCkvr+4mMxY2pZ7g29QurEdmLS4nJf3VgZUUPi1OBzQjb6fmIwOr0fIZnczzPEks3O6ZG4p+Vz/nq3FbLsqyhsNW+iHCN3LDB769QKBQKHcQUGTgAZEp8A+AQSZvV7XuPEOVNkz8/TVgd36JwQ7yVmFCrzEMIFq8kKgheJdbsRwAPAWcQb/01fgv8nlhi+DGxzHEF8bZ/KBE01DQYZxOZgoMI98W+RDCyM7EccD6R0dgmt89LLIfU9A87Eyn+nwKvE14QXYhlGRFixNcIf4apiSBo49z+JhHEHJfPcgOwPLHUsQiRZan1oqg1RNuDqOr4FREsdQHeymPvy+Oc19vF9md5v3/aXorInpCfz2O57WBCV/ICEZxtDVzgBg2/ijiyUCgUOo4pbqmi6stg+1WiLwKEfqB63P5U+iDYvoSWtf7qcb0AJO0AHGb7Okn/R0ya/wFOt317HvNrQpzYS9LeRMDQhZiED7T9z6wy2CmNk2YlJtqriIDgNtu1PhQDibf1Q4CtK9u/l9vPAvaq6B/WtD1G0ktUPCVyqeIiIkjqRGRKriUCl6WIJlNXEtUM8xJB0Xa278jzHyXEkytK+pLoWDla0s+I4KBWvtkN6E1oP0YRQUpVl/EAMJuknWkRc/YjAgRs3y5plvxc34xN/n397yOPLeLIQqFQ6CCmuMChI1CUb64FrClpKuIt/lOaeAxowjbOAKTh0aNEdcVn9ftbYwL6h3p2Ao4nljsGE50r9yUChGfrxt7abUdVfB6a6kKajGtjYoljU+C3uYzSGhPSQwBFHFkoFArtzRQXOKhjnCNvBi60vVdl+11EOeaOkg4F/ka8wUOLjfMWkvrRxMZZUndgGeBPRFfJU1LX8CGhozgVeLDBdmW1wjDirf8UIhCAWArpUX8v2/1TZ/ECoWVYGNhX0r5ZYrmM7cdobgddz23ANZJOsv1OBlc98rk/t31FahwuUnTxnMf2HZLuJZZWHiOyG4MkvU0sobxHLPHsBoyW9GpmgppSxJGTJ0UwWSh8e5niAocaakfnyPQWOLZu1xXEpN+NWGYYQ/o6VGycjybKQ+ttnAdKGkksH5yXDotIOogolRSR5r8ulx/qt88O3EhkEqYnqjK2yGufR4gTR9JSpll7lpGSTiCWA35GBFVDc2J/KQWSDe2gG3wuT0uq6UI65XPuQ5SrnpvbIPpXdCYCiBnyGU62fVQGG+cQSxwfE9UmWwCnE8sdB0j6l+3iHlkoFAqTiClSHKl2do4EtrV9kyrOkcSk/JTt7Qlx5EPEpHixwntgACF2fBSYmUjPH2a7v+1FCHOp0UTG4pc5jMG0iBc3IZ0jibdwgL/brgU9r9helhAkjrb9rxzz94lJuBMhTOxP9JE4TdIzhGB0DmDjzKD0IISPcwLbEn4ScxMTd1dgRsIO+hjgf6o4RxLBUhci6/Fp+k88S1RxdM7to2x/QQhAXyL8MdaHELDa3sL2Ura/T4gw77Z9aJbRDs3xFgqFQmESMSVmHL7TzpENnre9nSOvIYKXzkRG5d9EcNHhzpFEwHFYZkW6A2sCT9cfJOnHhPCUnp16NrlUoVAoFCaGKTHjUHWObMQpwK6SqjqAqnPkkPy5d915qwLX2B5l+xMaOEfmv4/QwDnS9sg8pl9+XWX70zQ7qjlHQhPnSEkbMK4Y8zhJzwEX07KMsh6wSz7DA8AsRCDSD7jM9hjbb9G6c+QixN+NiUDmc8Z1jtyKCIKgxTlyTyLQIO91EYRzJNBm50jbtxBLMPcB/yAyMKMbHHem7eVtL9+j03hyjkKhUCh8DabEjENHOke2Rq0q4g1C2PckMcHWt4QeWz6Y/hKL1+3/us6R+9oepxumpJMJM6xf5DH1moGv7BwJrNUBzpHY/iPwx7znxbTSUhtKVUWhUCi0N1Ni4IDtEZI2Bu6R9Lbtv9cdciKhSag6R45XIWD7lco5g4AzJB2d521CegnUMRJ4z/aSkgYDm+b1RhLCv92J4OY84Ji89wPAD+svlEsH41QoNLjfX4DdJa1PVH/8RNLtueSyMGEI9TYRxKyYY7iM8dtvQ1Rb/FXSgrb/K2laovPmG0B32zdKGkRkQpC0kO0HiKWWDQmTrHuIZZ7b8/7zErqHZRvcr/55OwMz2n5f0lJElcotkrrY/rLROaWqYvKkVFUUCt9epsjAAUJ4l+n9uyW9W7fvPUlXAfvlz80qBF6pnPOQpGsJwd7bwBM0qDao4zmiAuIaQi8wnJjof0wEDs8RVRlHAAsCRwLzSrrb9uqE78GFlQqFn+W/iwNrSTqcEB0eSegNZiaWFD6R9AWhw9gsn2NOQi/wel5jWE7UMxHNpDoDfwUGAP9QeFFMR1RWvJ/jGgksmsc/CnypMLGaPZ/tt0Rm5HhJ7xDaiDeIDMKTwAKZiRlNaDFWl9SVKGVdPrfPKGkEoVV5lTCQ6gyM5yBZKBQKhfZHdjHWay8kTWd7uMJ/4W7gx7YfrTtmuO3pJHUhSjZvIib692z/XtJawIm2+0oaACxv+2eSngA2qAkNc0nlVKLp00BJNcHi4kTQ8X1SWEn4InwI/DevN0TRsfJa2xdlZca/8/sfEiWXCxFBxWy2j6yJKYnKiuWIzMgmtIgp98ylkZeB02z/SS1tuDd0SxvuaYgA5D4qYsp8nkbP+H/AErZ3r4kpCU3E9kRANJ6Ysk4cudyps506kb/RwjdFyTgUCt8skh6xvXyjfVOiOLIjOTOFh48CV9QHDUm3POZh4H/A3wnB4IUQ1srALJKmrzuvkdBwMHBwTsjzpcCyNWHlS7aH5Pf1Is2zJI0i+l78KUWS7SGmrLXhHgLsSjS66lAxZRFHFgqFQscx2SxVSJqbeFNdnAh4ricEgJ/XHdcLWMX2xfnzAPKtvaPHaHvHNhw2MrMJw/PfXkTTqv1pWWroRKT/7yIbXTURGr4BHE74LtwoaS/GZwaiguRaxrWtHg1spJaukz+siCkHEMsjzcSUG+W/o4klmfmB7ylcNOHriyl3I7QUzxK6iD6S3s8xjyaWVb5PG8SURRxZKBQK7ctkEThIEvHm/Dfbm+d6+5nE2vivKsd1Id6idyTKECcXPga2An4mqT8hjnyqeoCkBRoIDbcEXrV9vKR5CbHg3cRb+zHExL0+LW/09dxh+9+KxlI12iKmHERkD0bm9f9DNOrae9zLtyqmnK6BmLL6jMsBexI9QJawvUfe/1YiePg+0aK7VYo48rtBWbooFL49TBaBAzF5jLJ9LoCj++J+hA3yS4TJ0XREensaYLFMjZ9PrO3PKekmYAEijf9rGNvR8mDSqtnpuihpD8J2+iPCdOiz1Bn0IkobewLvArvZ/l9qBD4mBHzfA36db+/TEcLHmQhTqEOaPN8bwHSSnicyDW8RHTHXyvFsStg8dyMmzYtzbLsDXSUdQYgydyEqMWbJ67wBDCR0CUcDCyoMnzbP+26RYkSA0xSNpTYlRJSHE94UiwMfKJp3fUAECMsR2YLuxDLCo4S4cUHCTXIgYfz0rqRHCFHpcEI4eR2x3NE9n2cW4F1J/wSmlrQqEThdmp/9QODp1D8sThhnHU0sV8wl6QXbJzX5XAuFQqHQzkwuGoclGNeFEUd/gv8Rwc+ywDa21yBsnO+x3bcyofQlnB/7EJbS80iakzBGWiv3ryBpi9z+O+KNdlVisqtxKuHnsBQxoZ1S2TcHsR6/CTF5Q6zjb+mwfl4TOIEGDaaIYGAfIsjYlghC3gCeySWWe4FZbHcDfgl8YvvlvN5vbHezvRLwB+Au23MRgdSyRKCzEHCs7a5EwLG17eOBIflZDiCyEu/lWI8l7LJrltFH5bm7E5kOE909RxAixfnzc3oif/6i8myvA3/Iz+wN4AGHhfSCRMA2g+15gL1tb0VUUJxg+xcO5a6JJak+xDLPHcTv+HbbszYKGiT9WNLDkh7+ZMwnDT7uQqFQKEwsk0vgMCFadRwEbrM9zPYoouRwPqLx1J22300PgIFEeeOKxOT7gaOHwmWV66xMyxLIhUSgUOPqFAs+TZQfQkyMR0kaSlgzz1XZV89NRJfO7WkRF9aYG7g537p/RQRSjViLmHixPdp2rRy0NVFklUbulv2Af+Y1byIyOBAak2mJwGAq4HlC6Dkhqs82lGjotTORyWgXijiyUCgUOo7JZaniaUJEN5asOpiXmHAmJJKrFwV2xHNX76H8dydgVmC51Ai8TKTyx8P255nW/z8iJb9ZZfepRInmtamBOPxrjG004Q1R45IMSOYEbpI0kAhylpfUsBQnx9tfDdqOS1qZ6MhZYxXG1VhUf1cbE+2+LwReS2+IL4E9JD1s+06afF7A3JLmtP1GszFCEUcWCoVCezO5BA63AcdI2sX2BSmOPIHwK6gX/n1C4+WAeh4ETkmvgQ+BHYgJ+mHgZEkz5bW2JlLwEN4D2xMT3U6EC2JrzAC8k0HDmkSmozVOILMdoQcd5zo1Y6ZdK9s/YdxJ+jbgJzn+zsRyxYT4PKs7XgbWdJhfVQOGQYSV9bGS1iP0Gq2xDLBo+j50y+MbNaLqRCx7DAFeIzIx0wEv155J0rLEMkg9nxAZkTmJ5Y+mFHHkd4cikCwUvh1MFksVuda9JbBtCgifI/QDBzc4fCjRC+LxFFA2u+abxFr5HYQI7xHb19h+HTiKCCwGERNZLeW/L7BbLj38kOii2RoDiTf3JwjhYn03zvoxPWX7/Aa7Dgcuy4zEe5Xt1wFbKlp9r5bjWTPv9wjj97mYGH4P7KtwhbyEcICsCQemlvS0spW2pFUI8eLUhE7jOuJvrBaITE2UjT5O+EL8g9BgzEB8zisQplhTA+cSZZr/A/6Zz95V0hyECHM64F5Jr6fIslAoFAqTgOIc2QC1OEB2IaobzrF91Tc9ro6g4sVQ42jbl0i6kxBAPgFMnxUSqxIlmqsQGZBG7o/nAdfbvjyvfx6hh7iWCJy2c9hzT09ki/rlff4EHGF7DUnXA8cTgdtdwOZ5/+2Iao3da+Oz/XCDZyrOkd9BSsahUJh0qBXnyMllqWJSc7ikdYj19VuAq7/Z4XQoI233bWX/vEQn0Z7582dEJuNpWtwfryeCg9ZYBHjT9kMwtiqG2pKM7bslIalf3TlLEr0vIMpt35zQA9k+k2ww1nuq3iUyLhQKhXakBA4NsH3ANz2GbxFfAp8DcznaeJ8HdLX9pRq4P37Ne/2R8LqoVViIKAtd+Wtet1AoFArtRAkcChNieqISYpik2YENgTvT3Gq8VtqkOLVBxcWzwBySVsilih6E8+RYbN+SZlZzVM6ZVdLKtgenCdXCtp+ijSLYUlVRKBQK7UsJHAq1pls1brJ9UO0H249LeozQJ7xK6A4gJu1rFG2vRfTagPB8OCuvu0DlOp+nRuHUFDOOJISU9fyRMMKqnbMNUf0yA/H3ejJhx30ecHqKNld2NPgaj1JV8d2haBwKhW8HJXCYwrHducn2/pXvBzQ5fcUG5w0CFs+MwwtEw6wa3yOCjDFEdca0tu+U5ErwYiLLMZ2ku/P7LsBPbN8jaYesGhFhunVgW5+1UCgUCl+fyaIcs/Cd4V7g+7aXITITv87tBwD7pEhzNSIbsSNwc25bGhjSzCa8/ibFcrpQKBQ6jhI4FCYlzayzBwEnSvo5MGNagD9EeGYcDvSx/QnNbcLHoVhOFwqFQsdRliomQyQZGGh75/y5C1Gm+IDtTSQNAJbPBlnV814mRIUmOnDuYvutuu0f5vZXOmDoDa2zbR8j6QZgI2CQpPWzPHN1wpb6PEkn0mLE1WaKOLJQKBTalxI4TJ58CiwpqVuKAtelxZJ6QtRspY8inDd/Xrf990RJ5J5fd5CSOmWHzRoNrbMlLWD7CeAJSSsQltUjgddsn5X21bWunePZhEvqkhmI8SjiyO8uRSxZKHwzlMBh8uVG4m38cmIC/QehD2grd9MSNFQZXNsuaVbgdMIECuCXtgfl9ouJXhGDicBlOcIG+mbCTnpaoGYH3Z2wyr6bsM4eRogeZ5f0JNHgam5gNmAawvjpNWAehfPTXERGpQ9wHGETPjdhU30wsAYtVR2FQqFQ6ECKxmHy5Z/A9lkOuRQxWX8VNmFcq+kaG9DilPln4CTbKxDNvs7O7YcBt9tegghc5q2cvxBwmm0RWYVLiWBgbiKwGAAcmedPZ3tJYDti8v+Q0Dj0AXbIfS8Cv7C9GKFpWCf3X0NkL1axPU7QUMSRhUKh0HGUjMNkiu2hknoR2YYbv8Kpd2R/iqHEkkR1+8xEmeTvcts6RGll7Zjp0/ipH9F0DNs3Sfqwcp1XbN+f36+XX4/lz9MRgcU9wAmSjiX6WtyTOo1GFtYrA1vl9xcSPS1qXGZ7dP0DFsvpQqFQ6DhK4DB5cy3RDKo/MEsbz1nT9nuNtgMfEW/1vydS/52I8slR1QM1bsvvej6tHko0zTqj/qBsmb0RcKSk22z/YSIsrD+dwP4ijiwUCoV25jsbOFQtjyVtRDgOrgvsRvgH9LL9Tv2xrVzvRmBH2x+1csydNOjY2KzKoR1YMv+9kHibf/frXCz7T/ySECkeSTT42pfQFSCpr+0hRPnkD4BjJa0HzNTkkjcDR0gamN1G5wK+IP7uPrB9kaSPgB81sLB+N/eNArbPZ9wJeETSA8BiwEKSrrX9ebNnKuLI7y5FHFkofDN85zUOktYGTgE2rJQYvgf831e5ju2NWgsaOgoFzX5PI4C90iTpL4TWocYASa9VvuZuy/1sv0noJ/YhRJLLSxoq6Wlg7zzs98B6KWzclijtHE9MYPsWQkQ5OL0bLiesqvsAD6Zb5GGE5qEHcL2koYRR1EnADwl76d1y+w+JwOMk4Eoi47BHW56rUCgUCu3DdzpwSB+As4BN0v64xjnAdrmmX3/OzpIelDRE0hmSOuf2l7MMEEm/k/SspHsl/UNStZvmtnn+c5KqVQ7zSLpT0vOSDqvcb39JT+bXL3Nbr7z+BcCTee55ecwTtGgQqpxOLA1AvJ3/jahE+AA4wvZrQG/gD5KekXSrpBslbWO7F/CwpGMlPUpM3A8A1xGahGeBFW3vLekY4C5gVuCm/CxHAY8QgsUP8hm6SjoX+BHR7fLn2eVyNSIoeQ8YZnsF2w/bftP2iraXst0nraQ/Idp+r2V7KUJz8X3g8rTBPgzYosHvsIgjC4VCoYP4zi5VEEr+q4H+tp+p2zecmPB+QUw+AEhajFD4r2r7C0mnEenxCyrH1CoMlgamAh4lJs0aXWyvmMsjh9HSyGlFYmlhBPBQGh6ZWDpZiZj0H5B0F1FdsBCwq+37JS1HtLVeMscwY4PnrVZD7EFOyumBMEjSLUTJZC9gcaL08T/5OdR43/ayGSBdSVQwfCrpQGB/SX8lRJGbENUS6xPVEKOB9W2/XhnbPoBt95G0KHCLpIVz37LAUrY/aPAcrTEL8FHFs+E1olRzHIo4slAoFDqO73Lg8AVwHzGJ/qLB/lOI/gfHV7atTUyuD6UAsBvwTt15qwLXpGBwlKTr6vZfmf8+AvTKCobXga5ER8cf5jH9iMBhVuDvtreXdCXxRr460QiqVo3wEdBf0qlEBcWGktYiJs0dJP2JaCC1ck76pxMagW3y/BmIwOUPhB7hIeDt/HdWhdlSZ2BPSUsCVxDBxaD8HKYm/BqGEdmF3wBHEBURn0s6nXB3vLTy/P0Ip0hsPyPpFaAWONw6EUHDRFHEkYVCodC+fJcDhzGEgO82SQfbPqq60/ZHki4m3oxrCDjf9m++xn0/y39HE5/vSOBQomqByv0MzJ73XE3StA3Gvzux5DAMeAO4k5j8ewILENmC+4DLgJ3z57OJ5YK3U/uAYva/j3hDP8b2uZKWJoIngBcIceWqhL5hNWJy36H+4RpVPuQSxkqEIdUjmSFprfRigtUQTXgfmFEtTpFzEyZTnRuVZRYKhUKh/fkuBw7YHiFpY+AeSW/b/nvdIScSb921z+E24BpJJ9l+JzUQPer6NgwCzpB0dJ63CZkWnwDrEqWTixDeBLsDPyYChNuIIGdLIiOxOjFJ7ifpLGDmfJ4rcoLezfaYzAZ8YPtDSX/Ja/40x/NzSb1sv5zXHE1kInaVdD4haOxDBAo1xgAPEsHPqpI2J8oypyeWdwYQuoN3iQzGopKOAza3vXAu9cwA/ItYVthV0s7A8sCixPILwMySHiQyGZ2IpZ83iOWPuYnsxxFEVmQWSY/lZ/0Qoa/YJrUWH+Z9tq17jrGUqoopl1J1USh0DN/pwAHA9geSNgDulvRu3b73JF0F7Jc/Py3pEGI9vhOx3LEP8ErlnIckXUsYKL1NuC+2pfnSg8BBec0zbT8saSAh3tyFEPkdavuxDAi+IESKPyTcE7+XVQhTAWPy+y6EeBLblvQ3ouz0EEJ7MFjS+8QEfSuxBLE28DTwKqHPqKoHpyH0Fr/Ie18J/I8IOgYT1Q8LENUbrxPLQIsR1tFPEMsgXQi9xQhCYDkzIYTcigjUjie0HsfaHihpaiJQ2Ah4w/bGAJLuIwKNWYjlol0JvcnTRDAzF/AxsJDtWpanUCgUCh3MdzZwqPoy2H4VmD9/vLbuuP2p9DmwfQlwSYPr9ar8eLztwyV1J/ovPJLH9K8c/x4tGodfEhPdfwgDptGSlgfes32oorHUK7SIMIfnmB4nKhX6A29Wlh6mIcyR1gIOlvSY7duIzMBJmY34CXCO7eUV7arnz+0HpKfCLEQw8ywRDDxLTMo3pCvlksRyyhc5pg2JKo31gMdtL5BjWYqoWumj8KtYo6ZfkPQFEVSJCDq6Eq6Rw4HfKkpEr7T9fAYeVTfJVXI55VTbq+f1vgT2SfHpy8CmjYIGST8msjn07NSzfnehUCgUvgbf2cChgzlT0uLERHi+7UdbOXak7b4ZZNxMZDBOIayiF80JEGLS35rIQACQE+oQYhmDyvbPiOWAf0l6m8hW3JbX/J6knfLQOSUtRHgh1ISS12flw9TEcsC7wAs5xp6EIHIz4CXgqSyhHEuTio4q9c6RW9t+tu6Y/yhMnDYGbpS0l+3bVecmSQRNbb3XWEpVRaFQKHQcJXCYCGzvOBHnjMg3/6uzCuEHQB/bbwBIWpPwZzir7tQ/AjfUfsjJ9S3bb+RyylLA0Cx1nM72XJVjf08EE0cAR0n6cS0rkpmCGerG+J6kg4iqiTWIiouVbQ+WNBWwsO2nJH0iaSXbDxCujs24GdhX0r65lLJMLsX0JpZf7iCWVS5U9LsYTVRtHEH4P/yJyNosaPu/xLLNXRP8sCuUqopCoVBoX0rgMAnJSXMoMTG/XgsakruJhlJz1J3zlMKUadncNBtwVi5XQCw3/AU4ELiqdp6k4cAqwCWOPhBbAienJ8MooiX1LxsM82rgcELrsA1wiqQZiL+Vk4nsxR45hjHERD4sMyfH113riDxnaAY5LxFi0h/Q4gL5KLAjsAJhbT0N4X/xE9ujJO1GtOKuiSPnkPQqDfwbGlHEkYWvQxFYFgrjI7tkcr+LqA39N77GtaezPTy/PwiYA9ic6MfRqIFWa9eqlVa29fjvE3qQ59vyfL2n6u2jeh41ocMKhYaUwKEwpSLpEdvLN9r3nbacLoyLpE0lPSDpMUn/ljR7bl9DYbE9JPf1kDSHpLtz25NK+2xJOwBPSxqZVSqrEcLHRvdbUdLgvOZ9khbJ7QMkXSvpdsJno+G9GmH7fkc/jdaes1hOFwqFQgdRAocpi3uJNtnLEL4Hv87tBxDVCn2JQGAksXxwc25bmnDZnBM4lnDX7EGUop5lu1lXzmeA1fJ+hwLVV/9lgW1sr9HoXl/nIW2faXt528v36NTj61yqUCgUCnUUjcOUxdzAJamjmJrQHECUWM6WvhJX2n5N0kPAOSmKvNr2EIXN9Z21QCGPX52WHhn1zACcn5UdJjwoILQQt1Rsp8e7V3s9cBFHFgqFQvtSAocpi1OBE21fK6k/IYKEECn+iCiFHCRpfdt3K7qLbkz0oTiRthldVTkCuMP2lpJ6EZbZNUbUvml0L9sXUMdX1UNAEUcWvh5F41AojE8JHKYsZiAcHyGcGGvI9hPAE4run4tKWgXYi8hMdCWaVh1G2G0/QZRO9iYaY81BNNm6Q5KIioh7gCWANdOQ6aNmg5I0HyGw3J1wijxG0gO2n01Tqa2IXhqdJW1PGHR1k/Rk5V6FQqFQmAQUjcN3l+6SXqt87U9kGC6T9AhhA11jqhQlDiWyD/8iyiJrjbc6EcHFm0Tg0Z0IOs8mbKx3JHQRswAzAv+UdAYwD/BlXnPuPK8R/YkGXV2JMtFf01wPcTGhg1Dea8P6ixVxZKFQKHQcJePwHcV2s6CwkRvj57aXrG6QdC/RdGsOQp8wT+66LLfX9BBfph7ifeAiWvQQmwPdbO+S19uDyEBAWE4fVBnr+VlhcQrRn+JAWvQQMG4b7sOIIOMkmughinNkoVAodBwlcJhEZOnjScD3ia6OnwN/sn1Vqyd2/LjuJLITj+eY9szJuKEewvYxkm5g0uohxlpLt1UPUaOIIwuFQqF9KYHDJCDX/a8m+lrsmNvmAzb7JsdVYZTtpdOl8TiiBXhDPYSkBRroIUYCr9muOVoum9c5RdH/4kPC+vrUVsZQvd8AwiFyCNFds5ukfoTb5Md191qOluZg41HEkYWvQxFHFgrjUwKHScNaxHLA6bUNtl8BTs236wtp0RP8zPZ9+Zb/e0JU2Ae4lPBN+AXQDdjC9guSziP0BcsQdtS7E226VwYesD0AQNFye4U893Lbh1XG11XSa8TfwyyphziaEDt2JpYW3sljD5C0I6GBeBeYl+ilsa2kxYgOmp8AlwPXE225RXTfvD6v1xN4M+IpPiWWHl4CLlbYWL+Y11kL+HfeY1Repz9wXFpQd+Yr9q4oFAqFwtejiCMnDUsQPRka8Q6wru1lge2Idf4aSwN7A4sRb9sL216RECXuWzluJiJQ2I9oG35S3rOPpL55zG/TPnQpYA1Fk6saK9qeGzgGOM72iUBf4Ke2pwUWAaaRNC3wAvBP210JYeKyRCvuJYm/p/1tL0ZoHuYFZrDdDbgP2CmvO9j2VLanAno5WptvD0yfx67qaGP+e+Aa2z2Bg4ELbJ8PnEYEGt+z/W3J2hQKhcIUQck4fANI+itR3vg5sA7wl5zgRwMLVw59qGavLOkF4Jbc/gSwZuW467L75BPA27mUgKSngF6EE+MPsiyyCyF4XBwYmucPlDQ1UfLYN7etB2wm6YD8uSsRCPQD/gxgu1aJUWM0UWUBsDaxjPBQZha6EUHSdUBvSacSmYraMw3NcVxNi6FUP6LVONl2exZJ0+e+a22PpAH5nD8G6NmpZ6NDCoVCoTCRlMBh0vAUOQEC2N4n1/4fJrIEbxPZhU5ESr7GZ5Xvx1R+HsO4v7vPGhwz9jhJ8xO20ivY/jCXN7pWjtsJeITQJZxK+CYI2Nr2s9UHySCgGaNsj64dSmg6flN/kKSlgfWJbMoPiOWVjQkXyk2B30rq09qNqAgm6ylVFYVCodBxlMChg5E0C3ACsJCkYYRe4F1ayg1nIMR+YyTtSqzbf9173kkEChAp/p8TE+2wrO7YkHGrFq4llhYAFk5r6ZuBfSXtm9mMZWw/BgwiJvs7JC1O6C8acRtwjaSTbL8jaWaiv8WnhN7jCknPAhcpWm7PY/uOLAPdnsh+3EMENUek5uM92x9PIHgZh1JVUSgUCu1LCRw6GNvvA33TXfFWYpngc6LS4HRC+3CFpF2Am2jlTXoiOcr2vZIeI5pOvUpM/vWsafs9SbcQGoJlgJOBoTmxvwRskvvOl/R0Xu8pGpde/gf4HXBLnv8FsA8h5Dw3twH8hgiWLpI0A5GpOMX2R5IOJ3pYDCUsqnelAa1ZUZeqisLXoVRVFArjU8SRk4jUKlxOdJfsbHtNYuJ9DtjE9tLANkSzqVkJ8ePskh6StKrt/sB/JJ0D/AmYS9LmWTVxg6R/Eo6PzxN6AnLf8ZJ65vd/IN76ewMrS+qc1/28MtQTgRdTP3BIjm9EjmVVYinll0Tp5JLAAsC/c+llSUnPSroAeBIYTBhFfUZkWDa0/TjRgfN1Ikg4DtjKdj9C89AJ2FHS8Wn69EvC5bI7cJKkeW0fnvc6XdID+XkUCoVCYRJQMg6TnjFE+eP0xAT6MLBapujfsT1C0tnASZkpmJdYNlgM+C1wu+3dJc0IPCjp30RPiRG2F8tqifEqOLJUcjuiYuELSacRywD1Hggb0CJO/HODcayY1x9NLLkcS5g31VgI2NX2/ZLWy59XJIKEa9O8aVbgDdsb59hmyCWdLYFFc2lkxrzeqYRW4nxJuxNVJ1vkvrmBVSq6itqzFnFkoVAodBAlcPhmuA9YlRADHkVM1iLW9CEqLRavrOVPL2k6mlc6rE6WcdoeWlfpUKNZlUONO1KHMJxYYmg4DsJ++g1gS9svAaTvQ41XbN+f36+XX4/lz9MRgcQ9wAmSjgWut31P+jKMAv4u6XrCAwKizHSr/P5Cxs0uXFYfNORnUMSRhUKh0EF8KwMHSaOJksMuxFr5rrZHtH5Wm657I7Cj7Y8m8vwtgKuAxWw/8zWGcjeRbZiP6B1xIDEh35D7OwHft12tsKg5UDardDhaYf/8UbPh06TKIcfxJKG7mInwc9inlXG09mxVjYaAo22fMd5gpGUJ2+ojJd1m+w+SViQCnG2AnxEGUG29V0OKOLJQKBTal29l4ACMtN0XQNJAomzvxK97Udsbfc1L7ADcm/8eNoFjW+Me4I9EANEJ+ICYRGuT+i2ExuE4AEl9s39Es0qHu4HFU1C4JGHyVE/DKod0sDQt4shLgQGSftfKOGqVFcfmcsRM9TfLDMLNREXEQNvDJc1FiCS7AB/YvkjSR8CPMqPS3f/f3rkHe1VVcfzz1eSVhCPoiGRimZklojxGTRQflb2ElBK0zKaXSb4qnMYaw2ombVInNaV8pOLriihD5AsfiVIiL8ELKZmaki80UEgskdUfa/28P378LvyucO/vdy7rM/Mbzt1nn332Ops5Z+21117L7HZJM/HokeDWmdG4teF4Wqwy69wrnSOTJElaaE/H3iI4Rz4I7C7pC5JmSZov6Z7YVoikQyQ9Gr/5knpK6itpRpQ1SxoWdZ+R1EfSuZLGlm4gaXzJ/C9pXDgkLpR0TlmdbfGARN/AP2Sl8q0kXSrpcUnTJd0uaVSc+2yUz5V0EZ5+GjwXQ2884dVE3GegF74DYTaeZXKwpH9IehN3PpyPR4TsBayS54d4IGS7DBgjaQkegOm5sue3HR4BcjEwC3gmrm3Gd3hUch8eHXIsrqx9X9Ibkv5DS0bLq4Gzom/n4YrHypBnN0lTgcW4srIKeDnuOQN3zjwEeCXKbsaXJXoBi6LNl3Clg5Dtkqj7K+DsKD8SV3Dm4GG4kyRJkg6goRWHmLV+Bl+2eAg3m+8L3AScGdV+CIwNC8UwfLvfccBdUbYPHjmxnCZ8xlziy0BThTPfQGBQOPMBjADuNLMlwKuSBkX50Xh0xr3wsNAHRN+7Ab/DdxIMwh0Cl5jZr+O6x4G9zWwMvsvhc2Y2BA8Udb6ZHYt/fA+PkMvD8KWER/Etlt3xmf6jsQNiGXAgrtQ8a2Zz4j7P49sfP4Xvjnhv/OYBXaLOG2Ft2BpfKjjTzH6OKwUHm1kPfNlgx6h/Dq6MdMOtEmZm/wVejPOnmdkeuJJ1f1y/XfR/LbAzvoTRHVckmoCdQpZu0e7J0dZ5wFFRd0K0WXp+z5rZYDM7v2wskfRtSXMkzVm5diVJkiTJ5qNRlyq6yzMjglscrsTzJTTJ4yF0weMKgJvNL4gljVvNbGnM2q+StA0wJczr72Bm8yXtKGln/IO+3Myek3Qa1Z35ZuDLE7+J8pvi77m4FWKSma0FXpR0f9TZE9/WWOrnjYSnf1AeMrk1Z8iOkq30vPvhPiXT4/4HApPK+tU1/j0Az155JrCGdaNVPlIm86eAASULDG5V+DCwngySnqIiFLU8rsN2ZlZKZHUNMKnsXk1UIZ0jkyRJ2o9GVRze8XEoER+UC8xsqjyK4HgAMztX0p9wH4GZ4SA4IywFnwOulnSBmVVuO5yEO+HtRMsHqKozX/gDHIYnjTI8YJFJGrcJMpY79lV1QgTaXbZgtZkNlNQDXyIYiy9HrKgch2AtHr56jXxb6fOtyCXgFDO7iwqqyaD1Q1GfUeXe5aRzZJIkSQfTqIpDNXrhQYOgLIKgpA+ZJ3V6TNIQYM9YD19qZpdL6opncKz8uDYBl+Mpng+Jstac+UYCE83sO2X3fQBfPpgJfE3SNfgMfzhwA55G+oOS+pvZM3gMhdao6oTYEbKZ2TtbMiOGxKl4HIdLgaclfcnMJsnNDgMigNPD+JJKE2X+HlW4C/iupPsidsQe+Bj2qZRBvuNlnVDUZvaapOWShpnZg/hSUJvSaM+dO3dVtNeZ6IMHxepMpEzFIGUqBptDpl1bO1EkxWE8bjZfjjvw7Rblp0s6FJ8FL8KjJ44Gxkl6C3fOO6GyMTNbJKkn8C+LDJRmdrc8UNJfwzy/CvgKvixxXkUTk6N8LO4XsBh3SpwHvGZmqyWdDNwZjoWzNyDbqcBv5fEX3oMvH5zUQbK9XHHt/OjHGHwXw2WSfoJHfrwJWIBHc7xO0o/xMNnVQk6Dp//uD8wLxWMZroQNryJDP9YPRQ2uJE4Ia8hTwNc38Byr8YR5OvFOg6Q5KVPjkzIVg5TpXbRvlkvAm4qkbWMW3xt4BI/O+GJZuYDfAn83swvr29tNJz7iq2NL6GhgjJmNqHe/qpEvhWKQMhWDlKkYtLdMRbI4NDLT5CGSuwA/N7PS7oJvyTNedsGdEqv5FxSRQfgWSQEr8LTYSZIkyRZAKg6bAfNEUdXKL8RjL3Qqwt9gn3r3o0Z+X+8OtAMpUzFImYpBytRGcqkiSZIkSZKaaegAUEmSJEmSNBapOCRJkiRJUjOpOCSdAklHSnpC0pOSflTlfFdJTXF+lqT+dehmm6hBphMlLVNLrpZv1qOfbUHSVZJeltTcynlJuihkXijPotqw1CDPcEmvlY3R2dXqNRKSdpF0v6TFkhbJo85W1inaONUiU6HGSlI3SY9IWhAynVOlTvu898wsf/kr9A+P5PkPPOdHFzzWxF4VdU4GJsTxaKCp3v3eDDKdCFxS7762Ua6D8aBlza2c/ywer0R40rRZ9e7zJsozHJhW7362Uaa+wH5x3BNYUuX/XtHGqRaZCjVW8ey3jeNt8CSG+1fUaZf3Xlocks7AUOBJM3vKzP6HB6qqjCsxAs91AXALcHhsJ21UapGpcJjZDDyNfGuMAK4152FgO3l+moakBnkKh5m9YGbz4nglnr+mX0W1oo1TLTIVinj2q+LPbeJXuduhXd57qTgknYF+rJtKfCnrvxTeqWNma/Bol707pHfvjlpkAjgmTMW3SNqlY7rWrtQqd5E4IMzJd0j6WL070xbCtL0vPpstp7DjtAGZoGBjJWlreYLCl4HpZtbqOG3O914qDklSXP4I9DezAcB0WmYWSeMwD9jVzPYBLsbzwBQCeYbcycDpZvZ6vfuzOdiITIUbKzN72zwR4fuBoZI+3hH3TcUh6Qz8Cyifbb+floRo69WR9B48adqrHdK7d8dGZTKzV82slNL8CjyiZ9GpZSwLg5m9XjInm9ntwDaS+tS5WxtFnvJ+MnC9md1apUrhxmljMhV1rADMbAVwP3Bkxal2ee+l4pB0BmYDH5a0m6QuuBPQ1Io6U2nJqjoKuM/CY6hB2ahMFWvKR+HrtkVnKnBCeO3vjyeMe6HenXq3SNqptKYsaSj+zm1khZXo75XA38zsglaqFWqcapGpaGMlaQd5qgMkdQc+CTxeUa1d3nsZcjopPGa2RtL38DTeWwNXmWcI/Rkwx8ym4i+NiZKexJ3ZNpQOvO7UKNOpko4C1uAynVi3DteIpBtx7/U+kpYCP8WdujCzCcDtuMf+k8AbtD0baodSgzyj8NTya4DVwOgGV1gBPoGnsH8s1s8BzgI+AMUcJ2qTqWhj1Re4RtLWuJJzs5lN64j3XoacTpIkSZKkZnKpIkmSJEmSmknFIUmSJEmSmknFIUmSJEmSmknFIUmSJEmSmknFIUmSJEmSmknFIUmSQiNppCSTtGe9+9JWJG0VWSabJT0mabak3Trw/vtKujKOj4ksiw9K6h1lH5LUVFa/i6QZEUwo2UJJxSFJkqIzBngo/m03Yr/85uZYYGdggJntDXwRWLEpDbbxo34WcFEcnwIMAX4HHBdlvwB+UqocCdfujX4nWyipOCRJUlgi98BBwDcoC24TyX9+HTP5hZJOifIhkv4SiYwekdRT0omSLim7dpqk4XG8StL5khbgCZDODqtAs6Tfl0Ua3F3SPdHuvJipXytpZFm710uqzHDaF3jBzNYCmNlSM1se9Y+MthZIujfKtpc0JWR6WNKAKB8vaaKkmXjAnx0kTY6+zpb0iSrPrieusCyIorVAV6AH8JakYcCLZvb3ikunAMfXNEBJpyTNTUmSFJkRwJ1mtkTSq5IGmdlc4NtAf2BgROHcPkJ3NwHHmtlsSe/DIwRuiPcCs8zsBwCSFpvZz+J4IvB5PNnY9cC5ZnabpG74pOxK4AxgiqRewIG0hP8tcTPwUHyk7wWuM7P5knYALgcONrOnJW0f9c8B5pvZSEmHAdcCA+PcXsBBZrZa0g3AhWb2kKQP4BFIP1px78FAc9nfvwTuAZ4HvgJMonqkwWbcMpFsoaTikCRJkRkD/CaOb4q/5wJHABMilTBm9m9Je+Oz+9lR9jpAGA1a4208MVKJQyWdic/KtwcWSfoz0M/Mbot234y6D0i6NJSAY4DJpf6UMLOlkj4CHBa/eyV9KdqfYWZPl/oflxwUbWFm90nqHQoQwFQzKylCRwB7lcn2PknblpI4BX2BZWV9mY5nWUXSCXhY6T0k/RBYDpxmZm+Y2duS/iepp5mt3NDDSzonqTgkSVJIYhZ+GLC3JMNzepikcW1sag3rLtt2Kzt+08zejvt1Ay4FBpvZc5LGV9StxrX47H00reRziAyndwB3SHoJGAnc3UYZAP5TdrwVsH+ZElON1VTpv6QeeN6TTwPTgKPxPA7H41YQ8CWNDbWddGLSxyFJkqIyCphoZruaWX8z2wV4GhiGz5y/U3IUDCXjCaCvpCFR1jPOPwMMjB0OuwBDW7lf6SP7SvhWjAKIWffSkj+DpK7x8QW4Gjg96i2ubFDSfpJ2juOtgAHAP4GHgYNLOyzKlioeJPwLwg/jlZLlpIK7cWfH0n0GVqnzN2D3KuXjgIvM7C2gO2C4/0OPaKt33PetKtcmWwCpOCRJUlTGALdVlE2O8iuAZ4GF4dh4XOwIOBa4OMqm48rATFzhWIzvMJhX7WZmtgKfcTfjPgOzy05/Fc9WuhD4C7BTXPMS/oH+Qysy7Aj8UVIzsBC3flxiZstwP41bo6+lLZHjgUFxn3NZ32eixKnA4HCiXAycVEWex4Fe4SQJQCgxQ81sShRdHHKeBNwQZYcCf2rlvskWQGbHTJIkaSfC8vAYsJ+ZvVbv/lQi6QxgpZld0YZrbgV+ZGZL2q9nSSOTFockSZJ2QNIRuLXh4kZUGoLLgP/WWjl2pkxJpWHLJi0OSZIkSZLUTFockiRJkiSpmVQckiRJkiSpmVQckiRJkiSpmVQckiRJkiSpmVQckiRJkiSpmf8D0wlcjDx78wsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n",
    "\n",
    "#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\n",
    "plt.title('Machine Learning Algorithm Accuracy Score \\n')\n",
    "plt.xlabel('Accuracy Score (%)')\n",
    "plt.ylabel('Algorithm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENSEMBLE CROSS-VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, y_test, predictions):\n",
    "    weighted_predictions = np.zeros_like(predictions[0])\n",
    "    for i in range(len(MLA)):\n",
    "        # Assign a weight to each prediction\n",
    "        weight = trial.suggest_float(f'w{i}', 0, 1)\n",
    "        weighted_predictions += weight * predictions[i]\n",
    "    weighted_predictions /= np.sum(weighted_predictions)  # Normalize weights\n",
    "\n",
    "    # Calculate metric on your validation set\n",
    "    mae = median_absolute_error(y_test, weighted_predictions)\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_avg_objective(trial, y_true, model_predictions):\n",
    "    # The model_predictions is a list of prediction arrays from the three models\n",
    "    weighted_predictions = np.zeros_like(model_predictions[0])\n",
    "    total_weight = 0\n",
    "\n",
    "    for i in range(len(model_predictions)):\n",
    "        # Define the weight for each model\n",
    "        weight = trial.suggest_float(f'w{i}', 0, 1)\n",
    "        total_weight += weight\n",
    "        weighted_predictions += weight * model_predictions[i]\n",
    "\n",
    "    # Normalize the predictions by the total weight\n",
    "    if total_weight > 0:\n",
    "        weighted_predictions /= total_weight\n",
    "\n",
    "    # Calculate the median absolute error\n",
    "    return median_absolute_error(y_true, weighted_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hill Climbing inspired by code from Kaggle\n",
    "def hill_climbing(x, y):\n",
    "    \n",
    "    # Evaluating oof predictions\n",
    "    scores = {}\n",
    "    for col in x.columns:\n",
    "        scores[col] = median_absolute_error(y, x[col])\n",
    "\n",
    "    # Sorting the model scores in ascending order\n",
    "    scores = {k: v for k, v in sorted(scores.items(), key = lambda item: item[1], reverse = False)}\n",
    "\n",
    "    # Sort oof_df\n",
    "    x = x[list(scores.keys())]\n",
    "\n",
    "    # Initialize weights\n",
    "    weights = {col: 1 if i == 0 else 0 for i, col in enumerate(x.columns)}\n",
    "\n",
    "    STOP = False\n",
    "    current_best_ensemble = x.iloc[:,0]\n",
    "    MODELS = x.iloc[:,1:]\n",
    "    weight_range = np.arange(-0.5, 0.51, 0.01) \n",
    "    history = [median_absolute_error(y, current_best_ensemble)]\n",
    "    j = 0\n",
    "\n",
    "    while not STOP:\n",
    "        j += 1\n",
    "        potential_new_best_cv_score = median_absolute_error(y, current_best_ensemble)\n",
    "        k_best, wgt_best = None, None\n",
    "        for k in MODELS:\n",
    "            for wgt in weight_range:\n",
    "                potential_ensemble = (1 - wgt) * current_best_ensemble + wgt * MODELS[k]\n",
    "                cv_score = median_absolute_error(y, potential_ensemble)\n",
    "                if cv_score < potential_new_best_cv_score:\n",
    "                    potential_new_best_cv_score = cv_score\n",
    "                    k_best, wgt_best = k, wgt\n",
    "\n",
    "        if k_best is not None:\n",
    "            # Update weights\n",
    "            weights = {col: (1 - wgt_best) * weights[col] if col != k_best else wgt_best for col in weights}\n",
    "            current_best_ensemble = (1 - wgt_best) * current_best_ensemble + wgt_best * MODELS[k_best]\n",
    "            MODELS.drop(k_best, axis = 1, inplace = True)\n",
    "            if MODELS.shape[1] == 0:\n",
    "                STOP = True\n",
    "            history.append(potential_new_best_cv_score)\n",
    "        else:\n",
    "            STOP = True\n",
    "        \n",
    "    hill_ens_pred = current_best_ensemble\n",
    "    \n",
    "    return hill_ens_pred, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission_file(ids, predictions, filename):\n",
    "    submission = pd.DataFrame({'id': ids, 'Hardness': predictions})\n",
    "    submission.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "217/217 [==============================] - 0s 1ms/step\n",
      "109/109 [==============================] - 0s 1ms/step\n",
      "The Fold 1 Hill Climb is 0.5012212028842082\n",
      "The Fold 1 weight is {'KerasRegressor': 1.1099999999999992, 'HistGradientBoostingRegressor': 0.0, 'CatBoostRegressor': 0.0, 'LGBMRegressor': 0.0, 'RandomForestRegressor': 0.0, 'ExtraTreesRegressor': 0.0, 'XGBRegressor': 0.0, 'BaggingRegressor': 0.0, 'GradientBoostingRegressor': 0.0, 'KNeighborsRegressor': 0.0, 'KNeighborsRegressor_5': 0.0, 'DecisionTreeRegressor': 0.0, 'ExtraTreeRegressor': 0.0, 'KNeighborsRegressor_2': 0.0, 'KNeighborsRegressor_3': 0.0, 'KNeighborsRegressor_4': 0.0, 'KNeighborsRegressor_6': 0.0, 'KNeighborsRegressor_7': 0.0, 'TheilSenRegressor': 0.0, 'KNeighborsRegressor_8': 0.0, 'ARDRegression': 0.0, 'RidgeCV': 0.0, 'BayesianRidge': 0.0, 'LinearRegression': 0.0, 'Lars': 0.0, 'HuberRegressor': 0.0, 'KNeighborsRegressor_9': 0.0, 'AdaBoostRegressor': 0.0, 'KNeighborsRegressor_10': 0.0, 'PoissonRegressor': 0.0, 'OrthogonalMatchingPursuit': 0.0, 'ElasticNet': 0.0, 'Lasso': 0.0, 'MLPRegressor': 0.0, 'KNeighborsRegressor_11': 0.0, 'LassoLars': -0.1099999999999996, 'TweedieRegressor': 0.0, 'GammaRegressor': 0.0, 'LassoLars_1': 0.0, 'RANSACRegressor': 0.0, 'PassiveAggressiveRegressor': 4.440892098500626e-16}\n",
      "\n",
      "Fold 2\n",
      "217/217 [==============================] - 0s 1ms/step\n",
      "109/109 [==============================] - 0s 1ms/step\n",
      "The Fold 2 Hill Climb is 0.5011233349466329\n",
      "The Fold 2 weight is {'KerasRegressor': 0.9998999999999991, 'HistGradientBoostingRegressor': 0.0, 'ExtraTreesRegressor': 0.0, 'LGBMRegressor': 0.0, 'CatBoostRegressor': 0.0, 'RandomForestRegressor': 0.0, 'XGBRegressor': 0.010000000000000453, 'BaggingRegressor': 0.0, 'GradientBoostingRegressor': 0.0, 'KNeighborsRegressor_4': 0.0, 'KNeighborsRegressor': 0.0, 'KNeighborsRegressor_3': 0.0, 'KNeighborsRegressor_5': 0.0, 'KNeighborsRegressor_6': 0.0, 'DecisionTreeRegressor': 0.0, 'ExtraTreeRegressor': 0.0, 'KNeighborsRegressor_7': 0.0, 'KNeighborsRegressor_2': 0.0, 'KNeighborsRegressor_8': 0.0, 'TheilSenRegressor': 0.0, 'HuberRegressor': 0.0, 'AdaBoostRegressor': 0.0, 'ARDRegression': 0.0, 'Lars': 0.0, 'LinearRegression': 0.0, 'BayesianRidge': 0.0, 'RidgeCV': 0.0, 'KNeighborsRegressor_9': -0.009899999999999565, 'RANSACRegressor': 0.0, 'PoissonRegressor': 0.0, 'KNeighborsRegressor_10': 0.0, 'OrthogonalMatchingPursuit': 0.0, 'ElasticNet': 0.0, 'Lasso': 0.0, 'KNeighborsRegressor_11': 0.0, 'MLPRegressor': 0.0, 'LassoLars': 0.0, 'LassoLars_1': 0.0, 'TweedieRegressor': 0.0, 'GammaRegressor': 0.0, 'PassiveAggressiveRegressor': 0.0}\n",
      "\n",
      "Fold 3\n",
      "217/217 [==============================] - 0s 1ms/step\n",
      "109/109 [==============================] - 0s 1ms/step\n",
      "The Fold 3 Hill Climb is 0.4686558034587085\n",
      "The Fold 3 weight is {'KerasRegressor': 1.0705999999999924, 'RandomForestRegressor': 4.4408920985006045e-16, 'ExtraTreesRegressor': 0.0, 'CatBoostRegressor': 4.4408920985006064e-16, 'HistGradientBoostingRegressor': 4.4408920985006084e-16, 'LGBMRegressor': 4.4408920985006104e-16, 'BaggingRegressor': 4.4408920985006124e-16, 'XGBRegressor': 0.0, 'GradientBoostingRegressor': 4.4408920985006143e-16, 'KNeighborsRegressor': 0.0, 'KNeighborsRegressor_4': 0.0, 'KNeighborsRegressor_3': 0.0, 'KNeighborsRegressor_5': 0.0, 'KNeighborsRegressor_6': 0.0, 'DecisionTreeRegressor': 4.4408920985006005e-16, 'ExtraTreeRegressor': 4.4408920985006025e-16, 'KNeighborsRegressor_7': 0.0, 'KNeighborsRegressor_2': 0.0, 'TheilSenRegressor': 4.4408920985006163e-16, 'KNeighborsRegressor_8': 0.0, 'HuberRegressor': -0.009999999999999487, 'Lars': 0.0, 'LinearRegression': 0.0, 'RidgeCV': 0.0, 'ARDRegression': 0.0, 'BayesianRidge': 0.0, 'KNeighborsRegressor_9': 0.0, 'AdaBoostRegressor': 0.0, 'MLPRegressor': 4.4408920985006183e-16, 'KNeighborsRegressor_10': 0.0, 'PoissonRegressor': 0.0, 'RANSACRegressor': 0.0, 'OrthogonalMatchingPursuit': 0.0, 'ElasticNet': 0.0, 'Lasso': -0.06059999999999916, 'KNeighborsRegressor_11': 0.0, 'LassoLars': 4.44089209850062e-16, 'TweedieRegressor': 4.440892098500622e-16, 'GammaRegressor': 4.440892098500624e-16, 'LassoLars_1': 4.440892098500626e-16, 'PassiveAggressiveRegressor': 4.4408920985005986e-16}\n",
      "\n",
      "\n",
      "The average prediction CV score is ==> nan\n",
      "The Optuna weights CV score is ==> nan\n",
      "The Hill Climbing CV score is ==> 0.49033344709651655\n",
      "The 2-Level Stacking CV score is ==> nan\n",
      "The 2-Level Multi-Model Stack with 3-Level Weighted Average CV score is ==> nan\n",
      "The Hill Climbing weights are ==> [{'KerasRegressor': 1.1099999999999992, 'HistGradientBoostingRegressor': 0.0, 'CatBoostRegressor': 0.0, 'LGBMRegressor': 0.0, 'RandomForestRegressor': 0.0, 'ExtraTreesRegressor': 0.0, 'XGBRegressor': 0.0, 'BaggingRegressor': 0.0, 'GradientBoostingRegressor': 0.0, 'KNeighborsRegressor': 0.0, 'KNeighborsRegressor_5': 0.0, 'DecisionTreeRegressor': 0.0, 'ExtraTreeRegressor': 0.0, 'KNeighborsRegressor_2': 0.0, 'KNeighborsRegressor_3': 0.0, 'KNeighborsRegressor_4': 0.0, 'KNeighborsRegressor_6': 0.0, 'KNeighborsRegressor_7': 0.0, 'TheilSenRegressor': 0.0, 'KNeighborsRegressor_8': 0.0, 'ARDRegression': 0.0, 'RidgeCV': 0.0, 'BayesianRidge': 0.0, 'LinearRegression': 0.0, 'Lars': 0.0, 'HuberRegressor': 0.0, 'KNeighborsRegressor_9': 0.0, 'AdaBoostRegressor': 0.0, 'KNeighborsRegressor_10': 0.0, 'PoissonRegressor': 0.0, 'OrthogonalMatchingPursuit': 0.0, 'ElasticNet': 0.0, 'Lasso': 0.0, 'MLPRegressor': 0.0, 'KNeighborsRegressor_11': 0.0, 'LassoLars': -0.1099999999999996, 'TweedieRegressor': 0.0, 'GammaRegressor': 0.0, 'LassoLars_1': 0.0, 'RANSACRegressor': 0.0, 'PassiveAggressiveRegressor': 4.440892098500626e-16}, {'KerasRegressor': 0.9998999999999991, 'HistGradientBoostingRegressor': 0.0, 'ExtraTreesRegressor': 0.0, 'LGBMRegressor': 0.0, 'CatBoostRegressor': 0.0, 'RandomForestRegressor': 0.0, 'XGBRegressor': 0.010000000000000453, 'BaggingRegressor': 0.0, 'GradientBoostingRegressor': 0.0, 'KNeighborsRegressor_4': 0.0, 'KNeighborsRegressor': 0.0, 'KNeighborsRegressor_3': 0.0, 'KNeighborsRegressor_5': 0.0, 'KNeighborsRegressor_6': 0.0, 'DecisionTreeRegressor': 0.0, 'ExtraTreeRegressor': 0.0, 'KNeighborsRegressor_7': 0.0, 'KNeighborsRegressor_2': 0.0, 'KNeighborsRegressor_8': 0.0, 'TheilSenRegressor': 0.0, 'HuberRegressor': 0.0, 'AdaBoostRegressor': 0.0, 'ARDRegression': 0.0, 'Lars': 0.0, 'LinearRegression': 0.0, 'BayesianRidge': 0.0, 'RidgeCV': 0.0, 'KNeighborsRegressor_9': -0.009899999999999565, 'RANSACRegressor': 0.0, 'PoissonRegressor': 0.0, 'KNeighborsRegressor_10': 0.0, 'OrthogonalMatchingPursuit': 0.0, 'ElasticNet': 0.0, 'Lasso': 0.0, 'KNeighborsRegressor_11': 0.0, 'MLPRegressor': 0.0, 'LassoLars': 0.0, 'LassoLars_1': 0.0, 'TweedieRegressor': 0.0, 'GammaRegressor': 0.0, 'PassiveAggressiveRegressor': 0.0}, {'KerasRegressor': 1.0705999999999924, 'RandomForestRegressor': 4.4408920985006045e-16, 'ExtraTreesRegressor': 0.0, 'CatBoostRegressor': 4.4408920985006064e-16, 'HistGradientBoostingRegressor': 4.4408920985006084e-16, 'LGBMRegressor': 4.4408920985006104e-16, 'BaggingRegressor': 4.4408920985006124e-16, 'XGBRegressor': 0.0, 'GradientBoostingRegressor': 4.4408920985006143e-16, 'KNeighborsRegressor': 0.0, 'KNeighborsRegressor_4': 0.0, 'KNeighborsRegressor_3': 0.0, 'KNeighborsRegressor_5': 0.0, 'KNeighborsRegressor_6': 0.0, 'DecisionTreeRegressor': 4.4408920985006005e-16, 'ExtraTreeRegressor': 4.4408920985006025e-16, 'KNeighborsRegressor_7': 0.0, 'KNeighborsRegressor_2': 0.0, 'TheilSenRegressor': 4.4408920985006163e-16, 'KNeighborsRegressor_8': 0.0, 'HuberRegressor': -0.009999999999999487, 'Lars': 0.0, 'LinearRegression': 0.0, 'RidgeCV': 0.0, 'ARDRegression': 0.0, 'BayesianRidge': 0.0, 'KNeighborsRegressor_9': 0.0, 'AdaBoostRegressor': 0.0, 'MLPRegressor': 4.4408920985006183e-16, 'KNeighborsRegressor_10': 0.0, 'PoissonRegressor': 0.0, 'RANSACRegressor': 0.0, 'OrthogonalMatchingPursuit': 0.0, 'ElasticNet': 0.0, 'Lasso': -0.06059999999999916, 'KNeighborsRegressor_11': 0.0, 'LassoLars': 4.44089209850062e-16, 'TweedieRegressor': 4.440892098500622e-16, 'GammaRegressor': 4.440892098500624e-16, 'LassoLars_1': 4.440892098500626e-16, 'PassiveAggressiveRegressor': 4.4408920985005986e-16}]\n",
      "CPU times: total: 2min 6s\n",
      "Wall time: 3min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "avg_predictions_scores = []\n",
    "optuna_weights_scores = []\n",
    "hill_climb_scores = []\n",
    "stacked_scores = []\n",
    "optuna_weights_scores_stack = []\n",
    "hill_climb_weights = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(cv_split_trial.split(train[num_var], train[TARGET])):\n",
    "    X_train, X_test = train[num_var].iloc[train_index], train[num_var].iloc[test_index]\n",
    "    y_train, y_test = train[TARGET].iloc[train_index], train[TARGET].iloc[test_index]\n",
    "\n",
    "    print(f'Fold {i+1}')\n",
    "    \n",
    "    MLA_cv_train_preds = []\n",
    "    MLA_cv_preds = []\n",
    "    MLA_cv_preds_dict = {}\n",
    "    MLA_names = []\n",
    "    \n",
    "    suffix = 1\n",
    "    for alg in MLA:\n",
    "        MLA_name = alg.__class__.__name__\n",
    "\n",
    "        # Add suffix if name already exists\n",
    "\n",
    "        original_MLA_name = MLA_name\n",
    "        if MLA_name in MLA_names:\n",
    "        # while MLA_cv_preds.str.contains(MLA_name).any():\n",
    "            MLA_name = f\"{original_MLA_name}_{suffix}\"\n",
    "            suffix += 1\n",
    "            \n",
    "        predictor = alg.fit(X_train, y_train)\n",
    "        pred_train_result = predictor.predict(X_train)\n",
    "        pred_result = predictor.predict(X_test)\n",
    "\n",
    "        MLA_cv_train_preds.append(pred_train_result)\n",
    "        MLA_cv_preds.append(pred_result)\n",
    "        MLA_cv_preds_dict[MLA_name] = pred_result\n",
    "        MLA_names.append(MLA_name)\n",
    "\n",
    "    ##################\n",
    "    ### Hill Climb ###\n",
    "    ##################\n",
    "    hill_climb_pred, hill_climb_weight = hill_climbing(pd.DataFrame(MLA_cv_preds_dict), y_test)\n",
    "    hill_climb_score = median_absolute_error(y_test, hill_climb_pred)\n",
    "    hill_climb_scores.append(hill_climb_score)\n",
    "    hill_climb_weights.append(hill_climb_weight)\n",
    "    print(f'The Fold {i+1} Hill Climb is {hill_climb_score}')\n",
    "    print(f'The Fold {i+1} weight is {hill_climb_weight}')\n",
    "    print()\n",
    "\n",
    "print()\n",
    "print(f'The average prediction CV score is ==> {np.mean(avg_predictions_scores)}')\n",
    "print(f'The Optuna weights CV score is ==> {np.mean(optuna_weights_scores)}')\n",
    "print(f'The Hill Climbing CV score is ==> {np.mean(hill_climb_scores)}')\n",
    "print(f'The 2-Level Stacking CV score is ==> {np.mean(stacked_scores)}')\n",
    "print(f'The 2-Level Multi-Model Stack with 3-Level Weighted Average CV score is ==> {np.mean(optuna_weights_scores_stack)}')\n",
    "print(f'The Hill Climbing weights are ==> {hill_climb_weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'KerasRegressor': 1.0601666666666636,\n",
       "  'HistGradientBoostingRegressor': 1.4802973661668694e-16,\n",
       "  'CatBoostRegressor': 1.480297366166869e-16,\n",
       "  'LGBMRegressor': 1.4802973661668701e-16,\n",
       "  'RandomForestRegressor': 1.4802973661668682e-16,\n",
       "  'ExtraTreesRegressor': 0.0,\n",
       "  'XGBRegressor': 0.0033333333333334845,\n",
       "  'BaggingRegressor': 1.4802973661668709e-16,\n",
       "  'GradientBoostingRegressor': 1.4802973661668714e-16,\n",
       "  'KNeighborsRegressor': 0.0,\n",
       "  'KNeighborsRegressor_5': 0.0,\n",
       "  'DecisionTreeRegressor': 1.480297366166867e-16,\n",
       "  'ExtraTreeRegressor': 1.4802973661668674e-16,\n",
       "  'KNeighborsRegressor_2': 0.0,\n",
       "  'KNeighborsRegressor_3': 0.0,\n",
       "  'KNeighborsRegressor_4': 0.0,\n",
       "  'KNeighborsRegressor_6': 0.0,\n",
       "  'KNeighborsRegressor_7': 0.0,\n",
       "  'TheilSenRegressor': 1.480297366166872e-16,\n",
       "  'KNeighborsRegressor_8': 0.0,\n",
       "  'ARDRegression': 0.0,\n",
       "  'RidgeCV': 0.0,\n",
       "  'BayesianRidge': 0.0,\n",
       "  'LinearRegression': 0.0,\n",
       "  'Lars': 0.0,\n",
       "  'HuberRegressor': -0.0033333333333331622,\n",
       "  'KNeighborsRegressor_9': -0.003299999999999855,\n",
       "  'AdaBoostRegressor': 0.0,\n",
       "  'KNeighborsRegressor_10': 0.0,\n",
       "  'PoissonRegressor': 0.0,\n",
       "  'OrthogonalMatchingPursuit': 0.0,\n",
       "  'ElasticNet': 0.0,\n",
       "  'Lasso': -0.02019999999999972,\n",
       "  'MLPRegressor': 1.4802973661668728e-16,\n",
       "  'KNeighborsRegressor_11': 0.0,\n",
       "  'LassoLars': -0.03666666666666638,\n",
       "  'TweedieRegressor': 1.480297366166874e-16,\n",
       "  'GammaRegressor': 1.4802973661668748e-16,\n",
       "  'LassoLars_1': 1.4802973661668753e-16,\n",
       "  'RANSACRegressor': 0.0,\n",
       "  'PassiveAggressiveRegressor': 2.9605947323337417e-16},\n",
       " 1.0000000000000009,\n",
       " 41)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get average weights for the models from all the folds\n",
    "\n",
    "average_values = {}\n",
    "\n",
    "for model in hill_climb_weights:\n",
    "    for key, value in model.items():\n",
    "        if key in average_values:\n",
    "            average_values[key] += value\n",
    "        else:\n",
    "            average_values[key] = value\n",
    "\n",
    "num_models = len(hill_climb_weights)\n",
    "average_values = {k: v / num_models for k, v in average_values.items()}\n",
    "\n",
    "# Ensure the new weights sum up to 1\n",
    "sum = 0\n",
    "\n",
    "for k, v in average_values.items():\n",
    "    sum += v\n",
    "\n",
    "average_values, sum, len(average_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MLPRegressor': 1.4802973661668728e-16,\n",
       " 'TheilSenRegressor': 1.480297366166872e-16,\n",
       " 'HuberRegressor': -0.0033333333333331622,\n",
       " 'RANSACRegressor': 0.0,\n",
       " 'Lasso': -0.02019999999999972,\n",
       " 'ElasticNet': 0.0,\n",
       " 'Lars': 0.0,\n",
       " 'LassoLars': -0.03666666666666638,\n",
       " 'OrthogonalMatchingPursuit': 0.0,\n",
       " 'BayesianRidge': 0.0,\n",
       " 'ARDRegression': 0.0,\n",
       " 'TweedieRegressor': 1.480297366166874e-16,\n",
       " 'PoissonRegressor': 0.0,\n",
       " 'GammaRegressor': 1.4802973661668748e-16,\n",
       " 'LassoLars_1': 1.4802973661668753e-16,\n",
       " 'LinearRegression': 0.0,\n",
       " 'PassiveAggressiveRegressor': 2.9605947323337417e-16,\n",
       " 'RidgeCV': 0.0,\n",
       " 'DecisionTreeRegressor': 1.480297366166867e-16,\n",
       " 'ExtraTreeRegressor': 1.4802973661668674e-16,\n",
       " 'XGBRegressor': 0.0033333333333334845,\n",
       " 'LGBMRegressor': 1.4802973661668701e-16,\n",
       " 'CatBoostRegressor': 1.480297366166869e-16,\n",
       " 'KNeighborsRegressor': 0.0,\n",
       " 'KNeighborsRegressor_2': 0.0,\n",
       " 'KNeighborsRegressor_3': 0.0,\n",
       " 'KNeighborsRegressor_4': 0.0,\n",
       " 'KNeighborsRegressor_5': 0.0,\n",
       " 'KNeighborsRegressor_6': 0.0,\n",
       " 'KNeighborsRegressor_7': 0.0,\n",
       " 'KNeighborsRegressor_8': 0.0,\n",
       " 'KNeighborsRegressor_9': -0.003299999999999855,\n",
       " 'KNeighborsRegressor_10': 0.0,\n",
       " 'KNeighborsRegressor_11': 0.0,\n",
       " 'AdaBoostRegressor': 0.0,\n",
       " 'BaggingRegressor': 1.4802973661668709e-16,\n",
       " 'ExtraTreesRegressor': 0.0,\n",
       " 'GradientBoostingRegressor': 1.4802973661668714e-16,\n",
       " 'HistGradientBoostingRegressor': 1.4802973661668694e-16,\n",
       " 'RandomForestRegressor': 1.4802973661668682e-16,\n",
       " 'KerasRegressor': 1.0601666666666636}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an ordered dictionary based on the order of models in MLA\n",
    "ordered_average_values = {}\n",
    "final_mlas = []\n",
    "\n",
    "for model_name in MLA_names:        \n",
    "    if model_name in average_values:\n",
    "        ordered_average_values[model_name] = average_values[model_name]\n",
    "    else:\n",
    "        # Handle case where a model might not be in average_values\n",
    "        ordered_average_values[model_name] = None\n",
    "\n",
    "# Now ordered_average_values has the averages in the same order as MLA\n",
    "ordered_average_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.4802973661668728e-16,\n",
       " 1.480297366166872e-16,\n",
       " -0.0033333333333331622,\n",
       " 0.0,\n",
       " -0.02019999999999972,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.03666666666666638,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.480297366166874e-16,\n",
       " 0.0,\n",
       " 1.4802973661668748e-16,\n",
       " 1.4802973661668753e-16,\n",
       " 0.0,\n",
       " 2.9605947323337417e-16,\n",
       " 0.0,\n",
       " 1.480297366166867e-16,\n",
       " 1.4802973661668674e-16,\n",
       " 0.0033333333333334845,\n",
       " 1.4802973661668701e-16,\n",
       " 1.480297366166869e-16,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.003299999999999855,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.4802973661668709e-16,\n",
       " 0.0,\n",
       " 1.4802973661668714e-16,\n",
       " 1.4802973661668694e-16,\n",
       " 1.4802973661668682e-16,\n",
       " 1.0601666666666636]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the ordered weights values as a list to be used for final submission\n",
    "hill_climb_final_weights = []\n",
    "\n",
    "for value in ordered_average_values.values():\n",
    "    hill_climb_final_weights.append(value)\n",
    "\n",
    "hill_climb_final_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with MLPRegressor\n",
      "Done with TheilSenRegressor\n",
      "Done with HuberRegressor\n",
      "Done with RANSACRegressor\n",
      "Done with Lasso\n",
      "Done with ElasticNet\n",
      "Done with Lars\n",
      "Done with LassoLars\n",
      "Done with OrthogonalMatchingPursuit\n",
      "Done with BayesianRidge\n",
      "Done with ARDRegression\n",
      "Done with TweedieRegressor\n",
      "Done with PoissonRegressor\n",
      "Done with GammaRegressor\n",
      "Done with LassoLars\n",
      "Done with LinearRegression\n",
      "Done with PassiveAggressiveRegressor\n",
      "Done with RidgeCV\n",
      "Done with DecisionTreeRegressor\n",
      "Done with ExtraTreeRegressor\n",
      "Done with XGBRegressor\n",
      "Done with LGBMRegressor\n",
      "Done with CatBoostRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with KNeighborsRegressor\n",
      "Done with AdaBoostRegressor\n",
      "Done with BaggingRegressor\n",
      "Done with ExtraTreesRegressor\n",
      "Done with GradientBoostingRegressor\n",
      "Done with HistGradientBoostingRegressor\n",
      "Done with RandomForestRegressor\n",
      "217/217 [==============================] - 0s 1ms/step\n",
      "Done with KerasRegressor\n",
      "CPU times: total: 34.7 s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_predictions = []\n",
    "# Make predictions on test set\n",
    "for alg in MLA:\n",
    "        MLA_name = alg.__class__.__name__\n",
    "                \n",
    "        predictor = alg.fit(train[num_var], train[TARGET])\n",
    "        pred_result = predictor.predict(test[num_var])\n",
    "\n",
    "        test_predictions.append(pred_result)\n",
    "        print(f'Done with {MLA_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 41)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_predictions), len(hill_climb_final_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_avg_predictions = np.average(test_predictions, axis=0, weights=hill_climb_final_weights)\n",
    "create_submission_file(test['id'], weighted_avg_predictions, f'submission_{experiment}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
